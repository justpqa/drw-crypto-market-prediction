{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89ecff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justpqa/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler, GPSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import multiprocessing\n",
    "# max_n_jobs = multiprocessing.cpu_count()\n",
    "import shap\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, Sampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nnmx\n",
    "import mlx.optimizers as optimmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dce0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2025de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_version = 2\n",
    "# 1 for pc feature, \n",
    "# 2 for label correlation feature # seems to work most consistently\n",
    "# 3 for best features based on combination rank\n",
    "# 4 for including time features (in case we want to reverse engineer the masked timestamp)\n",
    "# 5 for increasing number of correlation features + only use those that are in the same cluster\n",
    "# 6 is for 2 but more features, use when I want to use more features for larger models or AE approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935ee52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_random_state = 101\n",
    "random.seed(default_random_state)\n",
    "np.random.seed(default_random_state)\n",
    "torch.manual_seed(default_random_state)\n",
    "torch.mps.manual_seed(default_random_state)\n",
    "mx.random.seed(default_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731d3a4",
   "metadata": {},
   "source": [
    "#### Import train data and popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dc4e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X751</th>\n",
       "      <th>X473</th>\n",
       "      <th>X472</th>\n",
       "      <th>X451</th>\n",
       "      <th>X226</th>\n",
       "      <th>X219</th>\n",
       "      <th>X205</th>\n",
       "      <th>X445</th>\n",
       "      <th>X444</th>\n",
       "      <th>X27</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_buy_volume</th>\n",
       "      <th>normalized_sell_volume</th>\n",
       "      <th>liquidity_adjusted_imbalance</th>\n",
       "      <th>pressure_spread_interaction</th>\n",
       "      <th>trade_direction_ratio</th>\n",
       "      <th>net_buy_volume</th>\n",
       "      <th>bid_skew</th>\n",
       "      <th>ask_skew</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.362816</td>\n",
       "      <td>0.255354</td>\n",
       "      <td>0.625153</td>\n",
       "      <td>-0.893206</td>\n",
       "      <td>-0.654146</td>\n",
       "      <td>-1.250753</td>\n",
       "      <td>0.755891</td>\n",
       "      <td>0.625328</td>\n",
       "      <td>1.714323</td>\n",
       "      <td>...</td>\n",
       "      <td>11.542564</td>\n",
       "      <td>5.339347</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>-0.230493</td>\n",
       "      <td>0.796810</td>\n",
       "      <td>131.421</td>\n",
       "      <td>0.644635</td>\n",
       "      <td>0.355365</td>\n",
       "      <td>2023-03-01 00:00:00</td>\n",
       "      <td>0.562539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.378391</td>\n",
       "      <td>0.274621</td>\n",
       "      <td>0.637250</td>\n",
       "      <td>-0.738291</td>\n",
       "      <td>-0.634723</td>\n",
       "      <td>-1.100357</td>\n",
       "      <td>0.760472</td>\n",
       "      <td>0.633046</td>\n",
       "      <td>1.396133</td>\n",
       "      <td>...</td>\n",
       "      <td>13.626484</td>\n",
       "      <td>137.821061</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>-0.549445</td>\n",
       "      <td>0.620251</td>\n",
       "      <td>203.896</td>\n",
       "      <td>0.942921</td>\n",
       "      <td>0.057079</td>\n",
       "      <td>2023-03-01 00:01:00</td>\n",
       "      <td>0.533686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016807</td>\n",
       "      <td>0.382337</td>\n",
       "      <td>0.279272</td>\n",
       "      <td>0.640437</td>\n",
       "      <td>-0.713420</td>\n",
       "      <td>-0.631882</td>\n",
       "      <td>-1.073226</td>\n",
       "      <td>0.761631</td>\n",
       "      <td>0.635009</td>\n",
       "      <td>1.205921</td>\n",
       "      <td>...</td>\n",
       "      <td>360.242073</td>\n",
       "      <td>2.263386</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.530818</td>\n",
       "      <td>0.538664</td>\n",
       "      <td>22.858</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>2023-03-01 00:02:00</td>\n",
       "      <td>0.546505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.036622</td>\n",
       "      <td>0.387473</td>\n",
       "      <td>0.284750</td>\n",
       "      <td>0.642831</td>\n",
       "      <td>-0.644172</td>\n",
       "      <td>-0.612901</td>\n",
       "      <td>-0.982398</td>\n",
       "      <td>0.761936</td>\n",
       "      <td>0.635508</td>\n",
       "      <td>1.419536</td>\n",
       "      <td>...</td>\n",
       "      <td>69.011716</td>\n",
       "      <td>5.946089</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>0.454780</td>\n",
       "      <td>0.728757</td>\n",
       "      <td>210.779</td>\n",
       "      <td>0.187976</td>\n",
       "      <td>0.812024</td>\n",
       "      <td>2023-03-01 00:03:00</td>\n",
       "      <td>0.357703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.053322</td>\n",
       "      <td>0.390820</td>\n",
       "      <td>0.289431</td>\n",
       "      <td>0.648175</td>\n",
       "      <td>-0.628840</td>\n",
       "      <td>-0.607648</td>\n",
       "      <td>-0.952145</td>\n",
       "      <td>0.764770</td>\n",
       "      <td>0.640311</td>\n",
       "      <td>1.408936</td>\n",
       "      <td>...</td>\n",
       "      <td>3.623647</td>\n",
       "      <td>12.867864</td>\n",
       "      <td>0.081042</td>\n",
       "      <td>-0.533689</td>\n",
       "      <td>0.689066</td>\n",
       "      <td>54.004</td>\n",
       "      <td>0.887255</td>\n",
       "      <td>0.112745</td>\n",
       "      <td>2023-03-01 00:04:00</td>\n",
       "      <td>0.362452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X751      X473      X472      X451      X226      X219      X205  \\\n",
       "0  0.000617  0.362816  0.255354  0.625153 -0.893206 -0.654146 -1.250753   \n",
       "1  0.013388  0.378391  0.274621  0.637250 -0.738291 -0.634723 -1.100357   \n",
       "2 -0.016807  0.382337  0.279272  0.640437 -0.713420 -0.631882 -1.073226   \n",
       "3 -0.036622  0.387473  0.284750  0.642831 -0.644172 -0.612901 -0.982398   \n",
       "4 -0.053322  0.390820  0.289431  0.648175 -0.628840 -0.607648 -0.952145   \n",
       "\n",
       "       X445      X444       X27  ...  normalized_buy_volume  \\\n",
       "0  0.755891  0.625328  1.714323  ...              11.542564   \n",
       "1  0.760472  0.633046  1.396133  ...              13.626484   \n",
       "2  0.761631  0.635009  1.205921  ...             360.242073   \n",
       "3  0.761936  0.635508  1.419536  ...              69.011716   \n",
       "4  0.764770  0.640311  1.408936  ...               3.623647   \n",
       "\n",
       "   normalized_sell_volume  liquidity_adjusted_imbalance  \\\n",
       "0                5.339347                      0.063569   \n",
       "1              137.821061                      0.011610   \n",
       "2                2.263386                      0.015877   \n",
       "3                5.946089                      0.025702   \n",
       "4               12.867864                      0.081042   \n",
       "\n",
       "   pressure_spread_interaction  trade_direction_ratio  net_buy_volume  \\\n",
       "0                    -0.230493               0.796810         131.421   \n",
       "1                    -0.549445               0.620251         203.896   \n",
       "2                     0.530818               0.538664          22.858   \n",
       "3                     0.454780               0.728757         210.779   \n",
       "4                    -0.533689               0.689066          54.004   \n",
       "\n",
       "   bid_skew  ask_skew   __index_level_0__     label  \n",
       "0  0.644635  0.355365 2023-03-01 00:00:00  0.562539  \n",
       "1  0.942921  0.057079 2023-03-01 00:01:00  0.533686  \n",
       "2  0.007283  0.992717 2023-03-01 00:02:00  0.546505  \n",
       "3  0.187976  0.812024 2023-03-01 00:03:00  0.357703  \n",
       "4  0.887255  0.112745 2023-03-01 00:04:00  0.362452  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_parquet(f\"data/cleaned/cleaned_train_{feature_version}.parquet\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766f9871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>bid_qty</th>\n",
       "      <th>ask_qty</th>\n",
       "      <th>buy_qty</th>\n",
       "      <th>sell_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221.389</td>\n",
       "      <td>15.283</td>\n",
       "      <td>8.425</td>\n",
       "      <td>176.405</td>\n",
       "      <td>44.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>847.796</td>\n",
       "      <td>38.590</td>\n",
       "      <td>2.336</td>\n",
       "      <td>525.846</td>\n",
       "      <td>321.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295.596</td>\n",
       "      <td>0.442</td>\n",
       "      <td>60.250</td>\n",
       "      <td>159.227</td>\n",
       "      <td>136.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460.705</td>\n",
       "      <td>4.865</td>\n",
       "      <td>21.016</td>\n",
       "      <td>335.742</td>\n",
       "      <td>124.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.818</td>\n",
       "      <td>27.158</td>\n",
       "      <td>3.451</td>\n",
       "      <td>98.411</td>\n",
       "      <td>44.407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    volume  bid_qty  ask_qty  buy_qty  sell_qty\n",
       "0  221.389   15.283    8.425  176.405    44.984\n",
       "1  847.796   38.590    2.336  525.846   321.950\n",
       "2  295.596    0.442   60.250  159.227   136.369\n",
       "3  460.705    4.865   21.016  335.742   124.963\n",
       "4  142.818   27.158    3.451   98.411    44.407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_features_train = pd.read_parquet(\"data/cleaned/popular_features_train.parquet\")\n",
    "popular_features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f1fe5",
   "metadata": {},
   "source": [
    "#### Implement some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb40f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to split into some fold\n",
    "train_df[\"__index_level_0__\"] = pd.to_datetime(train_df[\"__index_level_0__\"])\n",
    "\n",
    "default_cv = 4\n",
    "default_cv_type = \"full\"\n",
    "# NOTE: default_cv must set to 1 instead of 3 based on consistency with LB score contains 49% of test data\n",
    "# NOTE: 3 cv with gap is slightly better or almost equal\n",
    "\n",
    "def create_cv(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"__index_level_0__\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        # if i == 0:\n",
    "        #     train_month = [3, 4, 5, 6, 7, 8]\n",
    "        #     test_month = [9, 10, 11, 12, 1, 2]\n",
    "        # else:\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"__index_level_0__\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"__index_level_0__\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"__index_level_0__\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"__index_level_0__\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"])\n",
    "        Y_test_arr.append(test[\"label\"])  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# def create_cv_random_test(train_df, features=None, test_cv=10):\n",
    "#     # randomize so that we have 1 train, but try it on 10 different test \n",
    "#     if features is not None:\n",
    "#         train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "#     X_train_arr = []\n",
    "#     X_test_arr = []\n",
    "#     Y_train_arr = []\n",
    "#     Y_test_arr = []\n",
    "\n",
    "#     # Create train data\n",
    "#     train_month = [3, 4, 5, 6, 7, 8]\n",
    "#     train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)] \n",
    "#     X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#     Y_train_arr.append(train[\"label\"])\n",
    "\n",
    "#     test_month = [9, 10, 11, 12, 1, 2]\n",
    "#     test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)]\n",
    "#     # Create test data\n",
    "#     for _ in range(test_cv):\n",
    "#         random_test = test.sample(frac = 0.5, random_state = default_random_state)\n",
    "#         X_test_arr.append(random_test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#         Y_test_arr.append(random_test[\"label\"])\n",
    "\n",
    "#     return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr \n",
    "\n",
    "# class [-1, 0, 1] -> [0, 1, 2] => < -0.2 => neg, > 0.2 => pos, else => neutral\n",
    "def create_classification_class(label):\n",
    "    if label < -0.4: return 0\n",
    "    elif label < 0: return 1\n",
    "    elif label < 0.4: return 2\n",
    "    return 3\n",
    "\n",
    "def create_cv_classification(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"__index_level_0__\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        # train_month = [3, 4, 5, 6, 7, 8]\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # test_month = [9, 10, 11, 12, 1, 2] # try to make a gap to see if there is any differences in cv-lb correlation\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"__index_level_0__\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"__index_level_0__\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"__index_level_0__\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"__index_level_0__\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"].apply(lambda x: create_classification_class(x)))\n",
    "        Y_test_arr.append(test[\"label\"].apply(lambda x: create_classification_class(x)))  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8b878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_score(Y_test, Y_pred):\n",
    "    if isinstance(Y_test, pd.Series) or isinstance(Y_test, pd.DataFrame):\n",
    "        Y_test = Y_test.values\n",
    "    if isinstance(Y_pred, pd.Series) or isinstance(Y_pred, pd.DataFrame):\n",
    "        Y_pred = Y_pred.values\n",
    "    Y_test = np.ravel(Y_test)\n",
    "    Y_pred = np.ravel(Y_pred)\n",
    "    pearson = np.corrcoef(Y_test, Y_pred)[0, 1]\n",
    "    if np.isnan(pearson):\n",
    "        if np.std(Y_pred) == 0:\n",
    "            print(Y_pred)\n",
    "            print(\"Error: zero variance prediction\")\n",
    "        elif np.isnan(Y_pred).any():\n",
    "            print(\"Error: nan prediction\")\n",
    "        return -1\n",
    "    else:\n",
    "        return pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce779cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function specifically for cross validation\n",
    "def train_eval_cv(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        cv_score += scoring_function(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_score / cv\n",
    "\n",
    "def train_eval_cv_random_test(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score, test_cv = 10):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        curr_cv_score = 0\n",
    "\n",
    "        # Conduct fitting\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        # sampling and testing\n",
    "        len_test = X_test.shape[0]\n",
    "        for seed in tqdm(range(test_cv)):\n",
    "            np.random.seed(seed)\n",
    "            test_index = np.random.choice(len_test, size = len_test // 2, replace = False) \n",
    "            X_test_sample = X_test.loc[test_index, :]\n",
    "            Y_test_sample = Y_test[test_index]\n",
    "            Y_pred_sample = model.predict(X_test_sample)\n",
    "            curr_cv_score += scoring_function(Y_test_sample, Y_pred_sample)\n",
    "        \n",
    "        cv_score += curr_cv_score / test_cv\n",
    "    \n",
    "    np.random.seed(default_random_state)\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9d975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trees = 1000\n",
    "# Finetuning XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddbb8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning XGBoost\n",
    "def objective_xgboost_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBClassifier(**params)\n",
    "    cv_acc = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_lightgbm_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMClassifier(**params)\n",
    "    cv_acc = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_catboost_classification(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_acc = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778f94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trials = 100\n",
    "default_n_jobs = 1\n",
    "\n",
    "def optimize_xgboost(study_name, storage_name, objective_function=objective_xgboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for XGBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_lightgbm(study_name, storage_name, objective_function=objective_lightgbm, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for LightGBM\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_catboost(study_name, storage_name, objective_function=objective_catboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for CatBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fd743",
   "metadata": {},
   "source": [
    "#### First iteration: training with all features from the collection, no popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5acc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb106a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_catboost = optimize_catboost(\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    "# )\n",
    "# # Need to take down as catboost might not work well in this situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e2b50",
   "metadata": {},
   "source": [
    "Analyze params - cv relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8801e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_study_df(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    study_df = []\n",
    "    for trial in study.trials:\n",
    "        trial_dict = trial.params\n",
    "        trial_dict[\"value\"] = trial.value\n",
    "        study_df.append(trial_dict)\n",
    "\n",
    "    return pd.DataFrame(study_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d57f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_value_viz(study_df):\n",
    "    nrows = (study_df.shape[1] - 1) // 3 + ((study_df.shape[1] - 1) % 3 > 0)\n",
    "    fig, ax = plt.subplots(nrows = nrows, ncols = 3, figsize = (14, 5 * nrows))\n",
    "    for inx, var in enumerate(study_df.columns):\n",
    "        x, y = inx // 3, inx % 3\n",
    "        if var != \"value\":\n",
    "            sns.regplot(study_df, x = var, y = \"value\", ax = ax[x][y], lowess=True, line_kws={'color': 'green'}, ci = 95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad954e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_xgboost = get_study_df(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")   \n",
    "params_value_viz(study_df_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717983ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_lightgbm = get_study_df(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "params_value_viz(study_df_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba067f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df_catboost = get_study_df(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# params_value_viz(study_df_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d81cc8",
   "metadata": {},
   "source": [
    "Analyze feature importance + CV performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ccea6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_from_file(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1942990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(model, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, sample_size=10000):\n",
    "    mean_abs_shap_all = np.zeros(X_train_arr[0].shape[1])\n",
    "    for i in range(default_cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        X_test_sample = X_test.sample(sample_size, random_state = default_random_state)\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        mean_abs_shap = np.mean(np.abs(shap_values), axis = 0)\n",
    "        mean_abs_shap_all += mean_abs_shap\n",
    "    mean_abs_shap_all /= default_cv\n",
    "    return mean_abs_shap_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in xgboost_feature_importances if xgboost_feature_importances[f] > 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7366dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in lightgbm_feature_importances if lightgbm_feature_importances[f] >= 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"iterations\": default_n_trees,\n",
    "#     \"verbose\": False,\n",
    "#     \"random_seed\": default_random_state\n",
    "# }\n",
    "# best_params_catboost = get_best_params_from_file(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# for p in best_params_catboost:\n",
    "#     params[p] = best_params_catboost[p]\n",
    "\n",
    "# catboost_feature_importances = {}\n",
    "\n",
    "# cbr = CatBoostRegressor(**params)\n",
    "# cv_rmse = 0\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "#     Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "#     cbr.fit(X_train, Y_train)\n",
    "#     print(pearson_score(Y_test, cbr.predict(X_test)))\n",
    "#     features = cbr.feature_names_\n",
    "#     # features_i = cbr.feature_importances_.tolist()\n",
    "#     features_i = get_shap_values(cbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "#     for inx, feat in enumerate(features):\n",
    "#         catboost_feature_importances[feat] = catboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# plt.hist(catboost_feature_importances.values())\n",
    "# # can pick up a combination of both past cod and tss, not good at picking up ph, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([f for f in catboost_feature_importances if catboost_feature_importances[f] >= 0.02])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8120d",
   "metadata": {},
   "source": [
    "Get top 20 important features in all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ed2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:49, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca490b7",
   "metadata": {},
   "source": [
    "#### Second Iteration: adding popular feature in addition to original features correlated to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93eefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_popular_feature = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_popular_feature = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d683a",
   "metadata": {},
   "source": [
    "Check for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d18fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "feature_importances_df[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df = feature_importances_df.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8211c2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>importance_xgboost</th>\n",
       "      <th>importance_lightgbm</th>\n",
       "      <th>importance</th>\n",
       "      <th>weighted_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X757</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.067788</td>\n",
       "      <td>0.052993</td>\n",
       "      <td>0.052471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X758</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>0.064893</td>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.049579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X759</td>\n",
       "      <td>0.048026</td>\n",
       "      <td>0.042903</td>\n",
       "      <td>0.045465</td>\n",
       "      <td>0.045555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X508</td>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.047838</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>0.035930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X614</td>\n",
       "      <td>0.042196</td>\n",
       "      <td>0.029092</td>\n",
       "      <td>0.035644</td>\n",
       "      <td>0.035876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>bid_skew</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>trade_intensity</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>spread_indicator</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>avg_trade_size</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>liquidity_imbalance</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     var  importance_xgboost  importance_lightgbm  importance  \\\n",
       "0                   X757            0.038198             0.067788    0.052993   \n",
       "1                   X758            0.035309             0.064893    0.050101   \n",
       "2                   X759            0.048026             0.042903    0.045465   \n",
       "3                   X508            0.024835             0.047838    0.036336   \n",
       "4                   X614            0.042196             0.029092    0.035644   \n",
       "..                   ...                 ...                  ...         ...   \n",
       "135             bid_skew            0.000174             0.000000    0.000087   \n",
       "136      trade_intensity            0.000000             0.000184    0.000092   \n",
       "137     spread_indicator            0.000079             0.000000    0.000039   \n",
       "138       avg_trade_size            0.000000             0.000048    0.000024   \n",
       "139  liquidity_imbalance            0.000000             0.000004    0.000002   \n",
       "\n",
       "     weighted_importance  \n",
       "0               0.052471  \n",
       "1               0.049579  \n",
       "2               0.045555  \n",
       "3               0.035930  \n",
       "4               0.035876  \n",
       "..                   ...  \n",
       "135             0.000090  \n",
       "136             0.000089  \n",
       "137             0.000041  \n",
       "138             0.000023  \n",
       "139             0.000002  \n",
       "\n",
       "[140 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7136debc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>importance_xgboost</th>\n",
       "      <th>importance_lightgbm</th>\n",
       "      <th>importance</th>\n",
       "      <th>weighted_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>order_flow_imbalance</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>2.226598e-03</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.001479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>realized_volatility_proxy</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>2.035748e-03</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.001263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>sell_qty</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>2.555699e-04</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.001114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>volume_weighted_sell</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>2.038325e-04</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>volume_participation</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>5.947269e-05</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>buy_sell_ratio</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>1.345159e-03</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>depth_ratio</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>1.103934e-04</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>selling_pressure</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>1.086897e-03</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>bid_buy_interaction</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>2.837906e-04</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>buy_sell_interaction</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>3.561274e-04</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>volume</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>8.670446e-05</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>buying_pressure</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>4.042214e-04</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>buy_qty</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>1.129109e-04</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>volume_weighted_buy</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>1.941430e-04</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>net_buy_volume</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>1.162511e-03</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>net_trade_flow</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.264015e-03</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>normalized_sell_volume</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>5.668432e-05</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>liquidity_adjusted_imbalance</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>9.237569e-05</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>bid_qty</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>3.686362e-06</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>total_liquidity</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>6.925498e-07</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>market_activity</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>3.906563e-05</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>bid_ask_ratio</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>6.287084e-06</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>normalized_buy_volume</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>1.072271e-05</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>volume_weighted_ask</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>volume_weighted_bid</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>trade_direction_ratio</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>1.287208e-04</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ask_sell_interaction</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>2.313712e-05</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>bid_ask_interaction</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>4.333252e-06</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>bid_sell_interaction</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>7.255136e-06</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>ask_skew</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>ask_qty</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>4.579238e-06</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>ask_buy_interaction</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>1.538641e-06</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>effective_spread_proxy</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>1.821199e-05</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>pressure_spread_interaction</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>1.018139e-05</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>relative_spread</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>2.623259e-06</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>bid_skew</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>trade_intensity</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.837944e-04</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>spread_indicator</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>avg_trade_size</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.825738e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>liquidity_imbalance</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.757692e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              var  importance_xgboost  importance_lightgbm  \\\n",
       "100          order_flow_imbalance            0.000783         2.226598e-03   \n",
       "101     realized_volatility_proxy            0.000544         2.035748e-03   \n",
       "102                      sell_qty            0.001914         2.555699e-04   \n",
       "103          volume_weighted_sell            0.001726         2.038325e-04   \n",
       "104          volume_participation            0.001860         5.947269e-05   \n",
       "105                buy_sell_ratio            0.000617         1.345159e-03   \n",
       "106                   depth_ratio            0.001733         1.103934e-04   \n",
       "107              selling_pressure            0.000776         1.086897e-03   \n",
       "108           bid_buy_interaction            0.001394         2.837906e-04   \n",
       "109          buy_sell_interaction            0.001304         3.561274e-04   \n",
       "110                        volume            0.001385         8.670446e-05   \n",
       "111               buying_pressure            0.000988         4.042214e-04   \n",
       "112                       buy_qty            0.001247         1.129109e-04   \n",
       "113           volume_weighted_buy            0.001131         1.941430e-04   \n",
       "114                net_buy_volume            0.000189         1.162511e-03   \n",
       "115                net_trade_flow            0.000000         1.264015e-03   \n",
       "116        normalized_sell_volume            0.000979         5.668432e-05   \n",
       "117  liquidity_adjusted_imbalance            0.000921         9.237569e-05   \n",
       "118                       bid_qty            0.000857         3.686362e-06   \n",
       "119               total_liquidity            0.000668         6.925498e-07   \n",
       "120               market_activity            0.000595         3.906563e-05   \n",
       "121                 bid_ask_ratio            0.000622         6.287084e-06   \n",
       "122         normalized_buy_volume            0.000601         1.072271e-05   \n",
       "123           volume_weighted_ask            0.000586         0.000000e+00   \n",
       "124           volume_weighted_bid            0.000578         0.000000e+00   \n",
       "125         trade_direction_ratio            0.000320         1.287208e-04   \n",
       "126          ask_sell_interaction            0.000363         2.313712e-05   \n",
       "127           bid_ask_interaction            0.000376         4.333252e-06   \n",
       "128          bid_sell_interaction            0.000308         7.255136e-06   \n",
       "129                      ask_skew            0.000229         0.000000e+00   \n",
       "130                       ask_qty            0.000217         4.579238e-06   \n",
       "131           ask_buy_interaction            0.000204         1.538641e-06   \n",
       "132        effective_spread_proxy            0.000175         1.821199e-05   \n",
       "133   pressure_spread_interaction            0.000179         1.018139e-05   \n",
       "134               relative_spread            0.000182         2.623259e-06   \n",
       "135                      bid_skew            0.000174         0.000000e+00   \n",
       "136               trade_intensity            0.000000         1.837944e-04   \n",
       "137              spread_indicator            0.000079         0.000000e+00   \n",
       "138                avg_trade_size            0.000000         4.825738e-05   \n",
       "139           liquidity_imbalance            0.000000         3.757692e-06   \n",
       "\n",
       "     importance  weighted_importance  \n",
       "100    0.001505             0.001479  \n",
       "101    0.001290             0.001263  \n",
       "102    0.001085             0.001114  \n",
       "103    0.000965             0.000992  \n",
       "104    0.000960             0.000992  \n",
       "105    0.000981             0.000968  \n",
       "106    0.000922             0.000950  \n",
       "107    0.000931             0.000926  \n",
       "108    0.000839             0.000858  \n",
       "109    0.000830             0.000847  \n",
       "110    0.000736             0.000759  \n",
       "111    0.000696             0.000707  \n",
       "112    0.000680             0.000700  \n",
       "113    0.000663             0.000679  \n",
       "114    0.000676             0.000659  \n",
       "115    0.000632             0.000610  \n",
       "116    0.000518             0.000534  \n",
       "117    0.000507             0.000522  \n",
       "118    0.000431             0.000446  \n",
       "119    0.000334             0.000346  \n",
       "120    0.000317             0.000327  \n",
       "121    0.000314             0.000325  \n",
       "122    0.000306             0.000316  \n",
       "123    0.000293             0.000303  \n",
       "124    0.000289             0.000299  \n",
       "125    0.000224             0.000228  \n",
       "126    0.000193             0.000199  \n",
       "127    0.000190             0.000197  \n",
       "128    0.000158             0.000163  \n",
       "129    0.000114             0.000118  \n",
       "130    0.000111             0.000114  \n",
       "131    0.000103             0.000106  \n",
       "132    0.000097             0.000100  \n",
       "133    0.000094             0.000097  \n",
       "134    0.000092             0.000096  \n",
       "135    0.000087             0.000090  \n",
       "136    0.000092             0.000089  \n",
       "137    0.000039             0.000041  \n",
       "138    0.000024             0.000023  \n",
       "139    0.000002             0.000002  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df[~feature_importances_df[\"var\"].str.contains(\"X\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc0ba087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', 'X466', 'X95', 'X23', 'X219', 'X31', 'X373', 'X379', 'X284', 'X750', 'X652', 'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X272', 'X271', 'X218']\n"
     ]
    }
   ],
   "source": [
    "print(feature_importances_df.sort_values(\"importance\", ignore_index=True, ascending=False).head(30)[\"var\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34cec354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', 'X466', 'X95', 'X23', 'X31', 'X219', 'X373', 'X379', 'X284', 'X750', 'X652', 'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X271', 'X272', 'X218']\n"
     ]
    }
   ],
   "source": [
    "print(feature_importances_df.sort_values(\"weighted_importance\", ignore_index=True, ascending=False).head(30)[\"var\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd8bbad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "s1 = set(feature_importances_df.sort_values(\"importance\", ignore_index=True, ascending=False).head(20)[\"var\"].tolist())\n",
    "s2 = set(feature_importances_df.sort_values(\"weighted_importance\", ignore_index=True, ascending=False).head(20)[\"var\"].tolist())\n",
    "print(s1 - s2)\n",
    "print(s2 - s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79548519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>importance_xgboost</th>\n",
       "      <th>importance_lightgbm</th>\n",
       "      <th>importance</th>\n",
       "      <th>weighted_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X757</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.067788</td>\n",
       "      <td>0.052993</td>\n",
       "      <td>0.052471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X758</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>0.064893</td>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.049579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X759</td>\n",
       "      <td>0.048026</td>\n",
       "      <td>0.042903</td>\n",
       "      <td>0.045465</td>\n",
       "      <td>0.045555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X508</td>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.047838</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>0.035930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X614</td>\n",
       "      <td>0.042196</td>\n",
       "      <td>0.029092</td>\n",
       "      <td>0.035644</td>\n",
       "      <td>0.035876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X752</td>\n",
       "      <td>0.028826</td>\n",
       "      <td>0.037114</td>\n",
       "      <td>0.032970</td>\n",
       "      <td>0.032824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X331</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0.030190</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.028016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X445</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>0.028013</td>\n",
       "      <td>0.027683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X465</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>0.030560</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>0.027114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X385</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>0.028484</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.023076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X466</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>0.031595</td>\n",
       "      <td>0.022511</td>\n",
       "      <td>0.022191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X95</td>\n",
       "      <td>0.012651</td>\n",
       "      <td>0.030889</td>\n",
       "      <td>0.021770</td>\n",
       "      <td>0.021448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>X23</td>\n",
       "      <td>0.013061</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.016680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X219</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.022833</td>\n",
       "      <td>0.016384</td>\n",
       "      <td>0.016157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X31</td>\n",
       "      <td>0.017861</td>\n",
       "      <td>0.014734</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.016352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X373</td>\n",
       "      <td>0.013321</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.016023</td>\n",
       "      <td>0.015927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X379</td>\n",
       "      <td>0.014112</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.015851</td>\n",
       "      <td>0.015790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>X284</td>\n",
       "      <td>0.011175</td>\n",
       "      <td>0.019943</td>\n",
       "      <td>0.015559</td>\n",
       "      <td>0.015404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X750</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>0.015410</td>\n",
       "      <td>0.015366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>X652</td>\n",
       "      <td>0.011477</td>\n",
       "      <td>0.018665</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.014944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>X279</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.014298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>X89</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>0.014195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>X169</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.018511</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>0.013611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>X753</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>X226</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>0.013308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>X28</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>0.011363</td>\n",
       "      <td>0.012984</td>\n",
       "      <td>0.013042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>X444</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.015079</td>\n",
       "      <td>0.011827</td>\n",
       "      <td>0.011712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>X272</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>0.011633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>X271</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.011650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>X218</td>\n",
       "      <td>0.010023</td>\n",
       "      <td>0.013019</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>0.011468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>X285</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.011303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>X507</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.011251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>X83</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>0.013637</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.010621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>X181</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>X137</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.013961</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>0.010225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>X269</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>0.011391</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.010259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>X198</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.012828</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.010077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>X291</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.009812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>X472</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.009834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>X300</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.009661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>X756</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>0.009630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>X298</td>\n",
       "      <td>0.007856</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.009421</td>\n",
       "      <td>0.009366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>X751</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.009230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>X656</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.008937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>X27</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.009212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>X712</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.008843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>X21</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>0.008849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>X205</td>\n",
       "      <td>0.008132</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.008852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>X22</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>X196</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.008434</td>\n",
       "      <td>0.008531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var  importance_xgboost  importance_lightgbm  importance  \\\n",
       "0   X757            0.038198             0.067788    0.052993   \n",
       "1   X758            0.035309             0.064893    0.050101   \n",
       "2   X759            0.048026             0.042903    0.045465   \n",
       "3   X508            0.024835             0.047838    0.036336   \n",
       "4   X614            0.042196             0.029092    0.035644   \n",
       "5   X752            0.028826             0.037114    0.032970   \n",
       "6   X331            0.025990             0.030190    0.028090   \n",
       "7   X445            0.018680             0.037346    0.028013   \n",
       "8   X465            0.023904             0.030560    0.027232   \n",
       "9   X385            0.018038             0.028484    0.023261   \n",
       "10  X466            0.013427             0.031595    0.022511   \n",
       "11   X95            0.012651             0.030889    0.021770   \n",
       "12   X23            0.013061             0.020563    0.016812   \n",
       "13  X219            0.009935             0.022833    0.016384   \n",
       "14   X31            0.017861             0.014734    0.016297   \n",
       "15  X373            0.013321             0.018725    0.016023   \n",
       "16  X379            0.014112             0.017591    0.015851   \n",
       "17  X284            0.011175             0.019943    0.015559   \n",
       "18  X750            0.014185             0.016634    0.015410   \n",
       "19  X652            0.011477             0.018665    0.015071   \n",
       "20  X279            0.014679             0.013888    0.014284   \n",
       "21   X89            0.014037             0.014364    0.014201   \n",
       "22  X169            0.009044             0.018511    0.013778   \n",
       "23  X753            0.010345             0.016556    0.013450   \n",
       "24  X226            0.011909             0.014809    0.013359   \n",
       "25   X28            0.014606             0.011363    0.012984   \n",
       "26  X444            0.008575             0.015079    0.011827   \n",
       "27  X272            0.008223             0.015292    0.011757   \n",
       "28  X271            0.009014             0.014480    0.011747   \n",
       "29  X218            0.010023             0.013019    0.011521   \n",
       "30  X285            0.010723             0.011925    0.011324   \n",
       "31  X507            0.010728             0.011813    0.011270   \n",
       "32   X83            0.007810             0.013637    0.010724   \n",
       "33  X181            0.008090             0.013328    0.010709   \n",
       "34  X137            0.006744             0.013961    0.010353   \n",
       "35  X269            0.009204             0.011391    0.010298   \n",
       "36  X198            0.007513             0.012828    0.010171   \n",
       "37  X291            0.010582             0.008984    0.009783   \n",
       "38  X472            0.011281             0.008282    0.009782   \n",
       "39  X300            0.006557             0.012991    0.009774   \n",
       "40  X756            0.006418             0.013077    0.009748   \n",
       "41  X298            0.007856             0.010986    0.009421   \n",
       "42  X751            0.005435             0.013302    0.009369   \n",
       "43  X656            0.004684             0.013500    0.009092   \n",
       "44   X27            0.013452             0.004662    0.009057   \n",
       "45  X712            0.005139             0.012819    0.008979   \n",
       "46   X21            0.006554             0.011312    0.008933   \n",
       "47  X205            0.008132             0.009624    0.008878   \n",
       "48   X22            0.005126             0.011775    0.008451   \n",
       "49  X196            0.011185             0.005682    0.008434   \n",
       "\n",
       "    weighted_importance  \n",
       "0              0.052471  \n",
       "1              0.049579  \n",
       "2              0.045555  \n",
       "3              0.035930  \n",
       "4              0.035876  \n",
       "5              0.032824  \n",
       "6              0.028016  \n",
       "7              0.027683  \n",
       "8              0.027114  \n",
       "9              0.023076  \n",
       "10             0.022191  \n",
       "11             0.021448  \n",
       "12             0.016680  \n",
       "13             0.016157  \n",
       "14             0.016352  \n",
       "15             0.015927  \n",
       "16             0.015790  \n",
       "17             0.015404  \n",
       "18             0.015366  \n",
       "19             0.014944  \n",
       "20             0.014298  \n",
       "21             0.014195  \n",
       "22             0.013611  \n",
       "23             0.013341  \n",
       "24             0.013308  \n",
       "25             0.013042  \n",
       "26             0.011712  \n",
       "27             0.011633  \n",
       "28             0.011650  \n",
       "29             0.011468  \n",
       "30             0.011303  \n",
       "31             0.011251  \n",
       "32             0.010621  \n",
       "33             0.010617  \n",
       "34             0.010225  \n",
       "35             0.010259  \n",
       "36             0.010077  \n",
       "37             0.009812  \n",
       "38             0.009834  \n",
       "39             0.009661  \n",
       "40             0.009630  \n",
       "41             0.009366  \n",
       "42             0.009230  \n",
       "43             0.008937  \n",
       "44             0.009212  \n",
       "45             0.008843  \n",
       "46             0.008849  \n",
       "47             0.008852  \n",
       "48             0.008333  \n",
       "49             0.008531  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df.sort_values(\"importance\", ignore_index=True, ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f391f3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>importance_xgboost</th>\n",
       "      <th>importance_lightgbm</th>\n",
       "      <th>importance</th>\n",
       "      <th>weighted_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X757</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.067788</td>\n",
       "      <td>0.052993</td>\n",
       "      <td>0.052471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X758</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>0.064893</td>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.049579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X759</td>\n",
       "      <td>0.048026</td>\n",
       "      <td>0.042903</td>\n",
       "      <td>0.045465</td>\n",
       "      <td>0.045555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X508</td>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.047838</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>0.035930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X614</td>\n",
       "      <td>0.042196</td>\n",
       "      <td>0.029092</td>\n",
       "      <td>0.035644</td>\n",
       "      <td>0.035876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X752</td>\n",
       "      <td>0.028826</td>\n",
       "      <td>0.037114</td>\n",
       "      <td>0.032970</td>\n",
       "      <td>0.032824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X331</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0.030190</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.028016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X445</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>0.028013</td>\n",
       "      <td>0.027683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X465</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>0.030560</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>0.027114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X385</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>0.028484</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.023076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X466</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>0.031595</td>\n",
       "      <td>0.022511</td>\n",
       "      <td>0.022191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X95</td>\n",
       "      <td>0.012651</td>\n",
       "      <td>0.030889</td>\n",
       "      <td>0.021770</td>\n",
       "      <td>0.021448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>X23</td>\n",
       "      <td>0.013061</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.016680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X31</td>\n",
       "      <td>0.017861</td>\n",
       "      <td>0.014734</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.016352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X219</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.022833</td>\n",
       "      <td>0.016384</td>\n",
       "      <td>0.016157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>X373</td>\n",
       "      <td>0.013321</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.016023</td>\n",
       "      <td>0.015927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>X379</td>\n",
       "      <td>0.014112</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.015851</td>\n",
       "      <td>0.015790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>X284</td>\n",
       "      <td>0.011175</td>\n",
       "      <td>0.019943</td>\n",
       "      <td>0.015559</td>\n",
       "      <td>0.015404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>X750</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>0.015410</td>\n",
       "      <td>0.015366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>X652</td>\n",
       "      <td>0.011477</td>\n",
       "      <td>0.018665</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.014944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>X279</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.014298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>X89</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>0.014195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>X169</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.018511</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>0.013611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>X753</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>X226</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>0.013308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>X28</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>0.011363</td>\n",
       "      <td>0.012984</td>\n",
       "      <td>0.013042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>X444</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.015079</td>\n",
       "      <td>0.011827</td>\n",
       "      <td>0.011712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>X271</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.011650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>X272</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>0.011633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>X218</td>\n",
       "      <td>0.010023</td>\n",
       "      <td>0.013019</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>0.011468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>X285</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.011303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>X507</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.011251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>X83</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>0.013637</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.010621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>X181</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>X269</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>0.011391</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.010259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>X137</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.013961</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>0.010225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>X198</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.012828</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.010077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>X472</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.009834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>X291</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.009812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>X300</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.009661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>X756</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.009748</td>\n",
       "      <td>0.009630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>X298</td>\n",
       "      <td>0.007856</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.009421</td>\n",
       "      <td>0.009366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>X751</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.009230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>X27</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.009212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>X656</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.008937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>X205</td>\n",
       "      <td>0.008132</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.008852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>X21</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>0.008849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>X712</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.008843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>X196</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.008434</td>\n",
       "      <td>0.008531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>X367</td>\n",
       "      <td>0.008994</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>0.008380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var  importance_xgboost  importance_lightgbm  importance  \\\n",
       "0   X757            0.038198             0.067788    0.052993   \n",
       "1   X758            0.035309             0.064893    0.050101   \n",
       "2   X759            0.048026             0.042903    0.045465   \n",
       "3   X508            0.024835             0.047838    0.036336   \n",
       "4   X614            0.042196             0.029092    0.035644   \n",
       "5   X752            0.028826             0.037114    0.032970   \n",
       "6   X331            0.025990             0.030190    0.028090   \n",
       "7   X445            0.018680             0.037346    0.028013   \n",
       "8   X465            0.023904             0.030560    0.027232   \n",
       "9   X385            0.018038             0.028484    0.023261   \n",
       "10  X466            0.013427             0.031595    0.022511   \n",
       "11   X95            0.012651             0.030889    0.021770   \n",
       "12   X23            0.013061             0.020563    0.016812   \n",
       "13   X31            0.017861             0.014734    0.016297   \n",
       "14  X219            0.009935             0.022833    0.016384   \n",
       "15  X373            0.013321             0.018725    0.016023   \n",
       "16  X379            0.014112             0.017591    0.015851   \n",
       "17  X284            0.011175             0.019943    0.015559   \n",
       "18  X750            0.014185             0.016634    0.015410   \n",
       "19  X652            0.011477             0.018665    0.015071   \n",
       "20  X279            0.014679             0.013888    0.014284   \n",
       "21   X89            0.014037             0.014364    0.014201   \n",
       "22  X169            0.009044             0.018511    0.013778   \n",
       "23  X753            0.010345             0.016556    0.013450   \n",
       "24  X226            0.011909             0.014809    0.013359   \n",
       "25   X28            0.014606             0.011363    0.012984   \n",
       "26  X444            0.008575             0.015079    0.011827   \n",
       "27  X271            0.009014             0.014480    0.011747   \n",
       "28  X272            0.008223             0.015292    0.011757   \n",
       "29  X218            0.010023             0.013019    0.011521   \n",
       "30  X285            0.010723             0.011925    0.011324   \n",
       "31  X507            0.010728             0.011813    0.011270   \n",
       "32   X83            0.007810             0.013637    0.010724   \n",
       "33  X181            0.008090             0.013328    0.010709   \n",
       "34  X269            0.009204             0.011391    0.010298   \n",
       "35  X137            0.006744             0.013961    0.010353   \n",
       "36  X198            0.007513             0.012828    0.010171   \n",
       "37  X472            0.011281             0.008282    0.009782   \n",
       "38  X291            0.010582             0.008984    0.009783   \n",
       "39  X300            0.006557             0.012991    0.009774   \n",
       "40  X756            0.006418             0.013077    0.009748   \n",
       "41  X298            0.007856             0.010986    0.009421   \n",
       "42  X751            0.005435             0.013302    0.009369   \n",
       "43   X27            0.013452             0.004662    0.009057   \n",
       "44  X656            0.004684             0.013500    0.009092   \n",
       "45  X205            0.008132             0.009624    0.008878   \n",
       "46   X21            0.006554             0.011312    0.008933   \n",
       "47  X712            0.005139             0.012819    0.008979   \n",
       "48  X196            0.011185             0.005682    0.008434   \n",
       "49  X367            0.008994             0.007722    0.008358   \n",
       "\n",
       "    weighted_importance  \n",
       "0              0.052471  \n",
       "1              0.049579  \n",
       "2              0.045555  \n",
       "3              0.035930  \n",
       "4              0.035876  \n",
       "5              0.032824  \n",
       "6              0.028016  \n",
       "7              0.027683  \n",
       "8              0.027114  \n",
       "9              0.023076  \n",
       "10             0.022191  \n",
       "11             0.021448  \n",
       "12             0.016680  \n",
       "13             0.016352  \n",
       "14             0.016157  \n",
       "15             0.015927  \n",
       "16             0.015790  \n",
       "17             0.015404  \n",
       "18             0.015366  \n",
       "19             0.014944  \n",
       "20             0.014298  \n",
       "21             0.014195  \n",
       "22             0.013611  \n",
       "23             0.013341  \n",
       "24             0.013308  \n",
       "25             0.013042  \n",
       "26             0.011712  \n",
       "27             0.011650  \n",
       "28             0.011633  \n",
       "29             0.011468  \n",
       "30             0.011303  \n",
       "31             0.011251  \n",
       "32             0.010621  \n",
       "33             0.010617  \n",
       "34             0.010259  \n",
       "35             0.010225  \n",
       "36             0.010077  \n",
       "37             0.009834  \n",
       "38             0.009812  \n",
       "39             0.009661  \n",
       "40             0.009630  \n",
       "41             0.009366  \n",
       "42             0.009230  \n",
       "43             0.009212  \n",
       "44             0.008937  \n",
       "45             0.008852  \n",
       "46             0.008849  \n",
       "47             0.008843  \n",
       "48             0.008531  \n",
       "49             0.008380  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df.sort_values(\"weighted_importance\", ignore_index=True, ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6953fd8",
   "metadata": {},
   "source": [
    "#### Third Iteration: a common truncated version using good features across all models + popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ebb508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6] [8, 9, 10, 11]\n",
      "[4, 5, 6, 7] [9, 10, 11, 12]\n",
      "[5, 6, 7, 8] [10, 11, 12, 1]\n",
      "[6, 7, 8, 9] [11, 12, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "best_features = ['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', \n",
    "                 'X466', 'X95', 'X23', 'X219', 'X31', 'X373', 'X379', 'X284', 'X750', 'X652', \n",
    "                 'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X272', 'X271', 'X218']\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c7f75",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d3ed407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 12:38:59,289] Using an existing study with name 'xgboost_2_4_101_1000_common_truncated_30_study' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 12:39:08,225] Trial 100 finished with value: 0.08938545708568955 and parameters: {'max_depth': 2, 'learning_rate': 0.02674981840834514, 'subsample': 0.7073274784254521, 'colsample_bytree': 0.8329657704800023, 'colsample_bynode': 0.24287172843471302, 'colsample_bylevel': 0.32104808882806973, 'min_child_weight': 2, 'reg_alpha': 0.4027758966812238, 'reg_lambda': 25.21224948662328, 'gamma': 3.067154815780649}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:39:16,547] Trial 101 finished with value: 0.09065266204650542 and parameters: {'max_depth': 2, 'learning_rate': 0.018890099917335406, 'subsample': 0.7268670175349469, 'colsample_bytree': 0.891017694980423, 'colsample_bynode': 0.2243005593372538, 'colsample_bylevel': 0.22303594279635017, 'min_child_weight': 2, 'reg_alpha': 4.911311886186155, 'reg_lambda': 11.381177614015549, 'gamma': 3.547507090530845}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:39:24,853] Trial 102 finished with value: 0.0948042625132672 and parameters: {'max_depth': 2, 'learning_rate': 0.03923203128468319, 'subsample': 0.7953627618068905, 'colsample_bytree': 0.8549096496112856, 'colsample_bynode': 0.19215923408507585, 'colsample_bylevel': 0.2790752465566418, 'min_child_weight': 1, 'reg_alpha': 6.436589285267074, 'reg_lambda': 7.972180702110192, 'gamma': 3.8210696551646732}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:39:32,931] Trial 103 finished with value: 0.08619179161795407 and parameters: {'max_depth': 2, 'learning_rate': 0.049069750846027264, 'subsample': 0.7622001747877268, 'colsample_bytree': 0.5536986544343387, 'colsample_bynode': 0.11050323161908687, 'colsample_bylevel': 0.20286145543320697, 'min_child_weight': 2, 'reg_alpha': 2.467797181839737, 'reg_lambda': 15.085536806334652, 'gamma': 3.307349494132372}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:39:42,796] Trial 104 finished with value: 0.08785610125752114 and parameters: {'max_depth': 3, 'learning_rate': 0.05568986990068826, 'subsample': 0.781559298844287, 'colsample_bytree': 0.8809820806812041, 'colsample_bynode': 0.13616272355353273, 'colsample_bylevel': 0.3443890832524029, 'min_child_weight': 2, 'reg_alpha': 13.6208830898325, 'reg_lambda': 11.966953126989914, 'gamma': 2.9189382590109023}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:39:50,711] Trial 105 finished with value: 0.08562870804169478 and parameters: {'max_depth': 2, 'learning_rate': 0.048666665216849044, 'subsample': 0.7411947904468993, 'colsample_bytree': 0.8147200774769833, 'colsample_bynode': 0.18472814298734824, 'colsample_bylevel': 0.3904762127646141, 'min_child_weight': 2, 'reg_alpha': 12.214918031417453, 'reg_lambda': 17.346349765455656, 'gamma': 3.4461975559118216}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:40:00,148] Trial 106 finished with value: 0.078624543428855 and parameters: {'max_depth': 3, 'learning_rate': 0.03184856575352111, 'subsample': 0.8344444532057356, 'colsample_bytree': 0.9714893144977128, 'colsample_bynode': 0.9354783865593886, 'colsample_bylevel': 0.2326388699552362, 'min_child_weight': 1, 'reg_alpha': 17.858428433331714, 'reg_lambda': 7.404093873107713, 'gamma': 3.637808561492145}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:40:07,452] Trial 107 finished with value: 0.09709576210211485 and parameters: {'max_depth': 2, 'learning_rate': 0.04103693244621763, 'subsample': 0.6209224744080939, 'colsample_bytree': 0.9005038023930823, 'colsample_bynode': 0.15574444966285958, 'colsample_bylevel': 0.29576203973336, 'min_child_weight': 3, 'reg_alpha': 0.6442258852641523, 'reg_lambda': 13.456152923619932, 'gamma': 3.1383962325074495}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:40:14,918] Trial 108 finished with value: 0.09184204564013813 and parameters: {'max_depth': 2, 'learning_rate': 0.043602526155629, 'subsample': 0.6088954878729423, 'colsample_bytree': 0.742048564036446, 'colsample_bynode': 0.1598616693304863, 'colsample_bylevel': 0.28879228759270104, 'min_child_weight': 3, 'reg_alpha': 0.04944347667835913, 'reg_lambda': 77.63930925318094, 'gamma': 3.125739485459932}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:40:22,669] Trial 109 finished with value: 0.08980984065265156 and parameters: {'max_depth': 2, 'learning_rate': 0.02170999334520408, 'subsample': 0.7145438741758563, 'colsample_bytree': 0.9060827395498201, 'colsample_bynode': 0.07406485301291742, 'colsample_bylevel': 0.3263923590952308, 'min_child_weight': 3, 'reg_alpha': 10.105751693793096, 'reg_lambda': 27.550166722707836, 'gamma': 2.946266995772845}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:40:30,075] Trial 110 finished with value: 0.09109519589872317 and parameters: {'max_depth': 2, 'learning_rate': 0.038991642861133685, 'subsample': 0.6482434380473949, 'colsample_bytree': 0.7902834589855402, 'colsample_bynode': 0.5149351949741094, 'colsample_bylevel': 0.2577596725787046, 'min_child_weight': 3, 'reg_alpha': 3.990201759179194, 'reg_lambda': 13.918791276397801, 'gamma': 2.7273144471850044}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:40:39,249] Trial 111 finished with value: 0.08578276229776205 and parameters: {'max_depth': 3, 'learning_rate': 0.05391636405410338, 'subsample': 0.7500044338973147, 'colsample_bytree': 0.8667020854063437, 'colsample_bynode': 0.15115165904178918, 'colsample_bylevel': 0.30082247996032285, 'min_child_weight': 2, 'reg_alpha': 6.4647838380581435, 'reg_lambda': 10.010422329733899, 'gamma': 2.6355402871604308}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:40:46,887] Trial 112 finished with value: 0.08846258628338695 and parameters: {'max_depth': 2, 'learning_rate': 0.06476781013237135, 'subsample': 0.8516545412001294, 'colsample_bytree': 0.9268061176174321, 'colsample_bynode': 0.2137943227318468, 'colsample_bylevel': 0.19655789709432236, 'min_child_weight': 2, 'reg_alpha': 2.102702538063756, 'reg_lambda': 5.877414913858393, 'gamma': 3.3925049222433152}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:40:54,524] Trial 113 finished with value: 0.09505036272607473 and parameters: {'max_depth': 2, 'learning_rate': 0.037064055812443986, 'subsample': 0.8171493235084111, 'colsample_bytree': 0.8464122755526775, 'colsample_bynode': 0.12185398054129368, 'colsample_bylevel': 0.35275210370136373, 'min_child_weight': 2, 'reg_alpha': 22.086486261096223, 'reg_lambda': 12.867751045929698, 'gamma': 3.79902090351765}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:41:04,032] Trial 114 finished with value: 0.0820439947878376 and parameters: {'max_depth': 3, 'learning_rate': 0.04803793658490567, 'subsample': 0.8024525052971337, 'colsample_bytree': 0.9012971213486446, 'colsample_bynode': 0.6224269505450893, 'colsample_bylevel': 0.2815534889801152, 'min_child_weight': 3, 'reg_alpha': 15.27549208852647, 'reg_lambda': 15.803698304509524, 'gamma': 3.54557997124185}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:41:12,154] Trial 115 finished with value: 0.08841956537410513 and parameters: {'max_depth': 2, 'learning_rate': 0.0412024112907883, 'subsample': 0.772499920155764, 'colsample_bytree': 0.8227977637939677, 'colsample_bynode': 0.20563258241197835, 'colsample_bylevel': 0.22411569020577332, 'min_child_weight': 2, 'reg_alpha': 12.568935145672382, 'reg_lambda': 20.043105168470504, 'gamma': 3.284704365653866}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:41:21,016] Trial 116 finished with value: 0.08441901975453328 and parameters: {'max_depth': 3, 'learning_rate': 0.054235290883415097, 'subsample': 0.9717365074917769, 'colsample_bytree': 0.9785826154594729, 'colsample_bynode': 0.17388891886066776, 'colsample_bylevel': 0.2479550061098415, 'min_child_weight': 1, 'reg_alpha': 8.32830555983324, 'reg_lambda': 9.062774521466089, 'gamma': 3.129604348965472}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:41:28,981] Trial 117 finished with value: 0.08870152942429058 and parameters: {'max_depth': 2, 'learning_rate': 0.059300969920356925, 'subsample': 0.9146662002359689, 'colsample_bytree': 0.8832161380794368, 'colsample_bynode': 0.2490790399839749, 'colsample_bylevel': 0.6522140969548883, 'min_child_weight': 2, 'reg_alpha': 4.78741591392793, 'reg_lambda': 11.149389214851453, 'gamma': 3.644257302476418}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:41:38,142] Trial 118 finished with value: 0.09124806386506078 and parameters: {'max_depth': 3, 'learning_rate': 0.06872664267463112, 'subsample': 0.9373044257816392, 'colsample_bytree': 0.9348732456372245, 'colsample_bynode': 0.1049823935835799, 'colsample_bylevel': 0.16951295072121841, 'min_child_weight': 1, 'reg_alpha': 10.226925545400471, 'reg_lambda': 18.323715517012847, 'gamma': 4.148323997856706}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:41:45,594] Trial 119 finished with value: 0.06300144483167881 and parameters: {'max_depth': 2, 'learning_rate': 0.0021739719844855124, 'subsample': 0.9976884396331888, 'colsample_bytree': 0.9605552164862162, 'colsample_bynode': 0.2254000362687429, 'colsample_bylevel': 0.9010862374187644, 'min_child_weight': 2, 'reg_alpha': 2.0106050030081755, 'reg_lambda': 1.9303665751693564, 'gamma': 3.4661300562220294}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:41:52,798] Trial 120 finished with value: 0.088775020347856 and parameters: {'max_depth': 2, 'learning_rate': 0.02856012632366957, 'subsample': 0.8853189279199769, 'colsample_bytree': 0.6229156562547402, 'colsample_bynode': 0.15633177016522637, 'colsample_bylevel': 0.3079194847476539, 'min_child_weight': 3, 'reg_alpha': 20.656547306890275, 'reg_lambda': 22.77225570925278, 'gamma': 3.8382182592031975}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:42:00,057] Trial 121 finished with value: 0.09895548999562835 and parameters: {'max_depth': 2, 'learning_rate': 0.035791307350898624, 'subsample': 0.8237356010107595, 'colsample_bytree': 0.8511222451303605, 'colsample_bynode': 0.12019600351199017, 'colsample_bylevel': 0.3438469014060778, 'min_child_weight': 2, 'reg_alpha': 7.248711349591346, 'reg_lambda': 13.315722866728601, 'gamma': 3.953014085343664}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:42:07,430] Trial 122 finished with value: 0.0965289122583526 and parameters: {'max_depth': 2, 'learning_rate': 0.03170681163336098, 'subsample': 0.8319782934458625, 'colsample_bytree': 0.8605395864011179, 'colsample_bynode': 0.1301441819242671, 'colsample_bylevel': 0.3799746411824959, 'min_child_weight': 2, 'reg_alpha': 7.439702945067443, 'reg_lambda': 8.201587907892414, 'gamma': 3.9497028356840715}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:42:14,259] Trial 123 finished with value: 0.09787412093511444 and parameters: {'max_depth': 2, 'learning_rate': 0.033945212090996275, 'subsample': 0.831049041375324, 'colsample_bytree': 0.8599260632017205, 'colsample_bynode': 0.13152707621009305, 'colsample_bylevel': 0.3856391067422392, 'min_child_weight': 2, 'reg_alpha': 6.586983540199325, 'reg_lambda': 13.160018331890711, 'gamma': 3.9954381449657266}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:42:21,732] Trial 124 finished with value: 0.0833487445904803 and parameters: {'max_depth': 2, 'learning_rate': 0.009492028545706183, 'subsample': 0.7824690950422184, 'colsample_bytree': 0.868494106967109, 'colsample_bynode': 0.0892994735361219, 'colsample_bylevel': 0.37444041215040613, 'min_child_weight': 2, 'reg_alpha': 6.191969942778801, 'reg_lambda': 13.996539332225145, 'gamma': 4.019771014130174}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:42:29,032] Trial 125 finished with value: 0.09438507399890793 and parameters: {'max_depth': 2, 'learning_rate': 0.03308193172188246, 'subsample': 0.8626820691441477, 'colsample_bytree': 0.8398128013353374, 'colsample_bynode': 0.13217235548837508, 'colsample_bylevel': 0.3300348719467384, 'min_child_weight': 2, 'reg_alpha': 3.7512661995920644, 'reg_lambda': 16.676033012374933, 'gamma': 3.968355153151752}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:42:36,354] Trial 126 finished with value: 0.08480352085153917 and parameters: {'max_depth': 2, 'learning_rate': 0.023924594944446747, 'subsample': 0.8269270620834359, 'colsample_bytree': 0.9142652616233584, 'colsample_bynode': 0.0738753925083117, 'colsample_bylevel': 0.4221578866294004, 'min_child_weight': 1, 'reg_alpha': 8.342228011854484, 'reg_lambda': 5.271829924035606, 'gamma': 3.902214607727882}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:42:43,557] Trial 127 finished with value: 0.08905183852009944 and parameters: {'max_depth': 2, 'learning_rate': 0.02706100373594885, 'subsample': 0.6262501698946746, 'colsample_bytree': 0.8044457297087743, 'colsample_bynode': 0.12551519815061501, 'colsample_bylevel': 0.35094485795125574, 'min_child_weight': 2, 'reg_alpha': 7.165883457978753, 'reg_lambda': 12.12637189981504, 'gamma': 4.211664994519031}. Best is trial 94 with value: 0.0997864891400562.\n",
      "[I 2025-07-11 12:42:51,165] Trial 128 finished with value: 0.10111190001890986 and parameters: {'max_depth': 2, 'learning_rate': 0.03571251602123245, 'subsample': 0.7284845131177894, 'colsample_bytree': 0.8900200440528983, 'colsample_bynode': 0.18638203553652433, 'colsample_bylevel': 0.27429289794421363, 'min_child_weight': 3, 'reg_alpha': 0.8508785729496249, 'reg_lambda': 7.200790598274197, 'gamma': 4.081911173092974}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:42:58,530] Trial 129 finished with value: 0.09698000762666986 and parameters: {'max_depth': 2, 'learning_rate': 0.03660337934084437, 'subsample': 0.7330774657184322, 'colsample_bytree': 0.8945106811681425, 'colsample_bynode': 0.18037366949043582, 'colsample_bylevel': 0.272071632535979, 'min_child_weight': 3, 'reg_alpha': 2.4509357755363466, 'reg_lambda': 20.899469615102845, 'gamma': 4.068870838434007}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:43:06,016] Trial 130 finished with value: 0.09946976316264967 and parameters: {'max_depth': 2, 'learning_rate': 0.03680574087195237, 'subsample': 0.6826262864038478, 'colsample_bytree': 0.8981297206360659, 'colsample_bynode': 0.18249341589041965, 'colsample_bylevel': 0.2745066708488305, 'min_child_weight': 3, 'reg_alpha': 1.7584781440589414, 'reg_lambda': 20.347477991099836, 'gamma': 4.125809329360475}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:43:13,515] Trial 131 finished with value: 0.09838693604997936 and parameters: {'max_depth': 2, 'learning_rate': 0.03464208888356328, 'subsample': 0.6711889477466219, 'colsample_bytree': 0.896077820932487, 'colsample_bynode': 0.17714502912044966, 'colsample_bylevel': 0.279233356311841, 'min_child_weight': 3, 'reg_alpha': 0.17655393991749024, 'reg_lambda': 20.412464021176568, 'gamma': 4.289365170938843}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:43:21,220] Trial 132 finished with value: 0.09859523168644242 and parameters: {'max_depth': 2, 'learning_rate': 0.035881141135139724, 'subsample': 0.6770251956370742, 'colsample_bytree': 0.8935376747065762, 'colsample_bynode': 0.19844891599999484, 'colsample_bylevel': 0.271480756391698, 'min_child_weight': 3, 'reg_alpha': 0.31209447226266374, 'reg_lambda': 23.50934899958187, 'gamma': 4.362931908643709}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:43:29,010] Trial 133 finished with value: 0.09660721926250013 and parameters: {'max_depth': 2, 'learning_rate': 0.03562100475647032, 'subsample': 0.6736245271157366, 'colsample_bytree': 0.9229667894575478, 'colsample_bynode': 0.18796661808116658, 'colsample_bylevel': 0.28019927576406223, 'min_child_weight': 3, 'reg_alpha': 0.6105590464595401, 'reg_lambda': 28.990799550599903, 'gamma': 4.09917188708562}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:43:36,367] Trial 134 finished with value: 0.08818068763676709 and parameters: {'max_depth': 2, 'learning_rate': 0.035371311908579055, 'subsample': 0.6924064719067016, 'colsample_bytree': 0.897488910869196, 'colsample_bynode': 0.20170578153456195, 'colsample_bylevel': 0.31708321590948974, 'min_child_weight': 3, 'reg_alpha': 3.324948561277819, 'reg_lambda': 21.93506530703857, 'gamma': 4.3458934563452605}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:43:43,671] Trial 135 finished with value: 0.09205639657297708 and parameters: {'max_depth': 2, 'learning_rate': 0.03000989787068341, 'subsample': 0.726501975200773, 'colsample_bytree': 0.9100291095164976, 'colsample_bynode': 0.2399662908303532, 'colsample_bylevel': 0.2413791321047538, 'min_child_weight': 3, 'reg_alpha': 0.26115555697093606, 'reg_lambda': 24.004886590548953, 'gamma': 4.184266909838913}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:43:51,016] Trial 136 finished with value: 0.09507873465035742 and parameters: {'max_depth': 2, 'learning_rate': 0.04183867254135915, 'subsample': 0.6322269015611882, 'colsample_bytree': 0.9342084222397226, 'colsample_bynode': 0.18374778794469454, 'colsample_bylevel': 0.2744992424921205, 'min_child_weight': 3, 'reg_alpha': 2.003834898556393, 'reg_lambda': 19.27448018776672, 'gamma': 4.282765459421605}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:43:58,618] Trial 137 finished with value: 0.0877204024899591 and parameters: {'max_depth': 2, 'learning_rate': 0.022336603765714853, 'subsample': 0.7098448126650385, 'colsample_bytree': 0.24103122817113654, 'colsample_bynode': 0.22090497054114505, 'colsample_bylevel': 0.3137225887239964, 'min_child_weight': 4, 'reg_alpha': 4.201369082110109, 'reg_lambda': 31.40054093140009, 'gamma': 4.0980650555800455}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:44:06,197] Trial 138 finished with value: 0.08988360587453113 and parameters: {'max_depth': 2, 'learning_rate': 0.026231612752329162, 'subsample': 0.6829359386329897, 'colsample_bytree': 0.8348224719676326, 'colsample_bynode': 0.17743992205793202, 'colsample_bylevel': 0.2629369464082235, 'min_child_weight': 3, 'reg_alpha': 3.068454552597867, 'reg_lambda': 21.71721706485328, 'gamma': 4.011059181982603}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:44:14,195] Trial 139 finished with value: 0.08970741883552849 and parameters: {'max_depth': 2, 'learning_rate': 0.012559624977819277, 'subsample': 0.6590209600992999, 'colsample_bytree': 0.8930466790977161, 'colsample_bynode': 0.2583663460475167, 'colsample_bylevel': 0.3023355778221968, 'min_child_weight': 3, 'reg_alpha': 0.3730170233268699, 'reg_lambda': 16.285350689556367, 'gamma': 4.462172376136472}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:44:21,687] Trial 140 finished with value: 0.084140619931512 and parameters: {'max_depth': 2, 'learning_rate': 0.03325101794610405, 'subsample': 0.735725004467938, 'colsample_bytree': 0.9503618603422226, 'colsample_bynode': 0.8468657948961846, 'colsample_bylevel': 0.24328449065215774, 'min_child_weight': 4, 'reg_alpha': 5.07306710856545, 'reg_lambda': 26.902431048942244, 'gamma': 4.292713993820955}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:44:30,955] Trial 141 finished with value: 0.0871894989158038 and parameters: {'max_depth': 3, 'learning_rate': 0.04016459501805675, 'subsample': 0.7004198497735192, 'colsample_bytree': 0.8546875720150306, 'colsample_bynode': 0.14400416428365065, 'colsample_bylevel': 0.2140650499367977, 'min_child_weight': 3, 'reg_alpha': 2.313106364464546, 'reg_lambda': 18.173854846716402, 'gamma': 3.7630966745143377}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:44:38,648] Trial 142 finished with value: 0.08888547228936358 and parameters: {'max_depth': 2, 'learning_rate': 0.036763403391061135, 'subsample': 0.5668043276227105, 'colsample_bytree': 0.8862837669654304, 'colsample_bynode': 0.10015224638779267, 'colsample_bylevel': 0.3360526667377142, 'min_child_weight': 3, 'reg_alpha': 0.1404184389062162, 'reg_lambda': 20.045216775180926, 'gamma': 4.3786565960145385}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:44:46,147] Trial 143 finished with value: 0.09425264554967783 and parameters: {'max_depth': 2, 'learning_rate': 0.030863783262148916, 'subsample': 0.7656236847724387, 'colsample_bytree': 0.9198293221404406, 'colsample_bynode': 0.20169892465425932, 'colsample_bylevel': 0.2760547936709589, 'min_child_weight': 3, 'reg_alpha': 3.8624227702751424, 'reg_lambda': 14.18383427070237, 'gamma': 4.20026638359485}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:44:53,784] Trial 144 finished with value: 0.09862743270175368 and parameters: {'max_depth': 2, 'learning_rate': 0.03747152736050265, 'subsample': 0.6694428931206571, 'colsample_bytree': 0.8992406355731654, 'colsample_bynode': 0.1701908807994879, 'colsample_bylevel': 0.29788612566562256, 'min_child_weight': 4, 'reg_alpha': 6.114995677183756, 'reg_lambda': 21.074071261124008, 'gamma': 4.042875654646429}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:45:01,263] Trial 145 finished with value: 0.09695706044991922 and parameters: {'max_depth': 2, 'learning_rate': 0.04583496427754248, 'subsample': 0.6114968743046679, 'colsample_bytree': 0.9100528355761006, 'colsample_bynode': 0.16987754757316154, 'colsample_bylevel': 0.29143392210629904, 'min_child_weight': 4, 'reg_alpha': 6.19179952363848, 'reg_lambda': 21.277366256357, 'gamma': 4.069749008331578}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:45:08,851] Trial 146 finished with value: 0.09310443066179469 and parameters: {'max_depth': 2, 'learning_rate': 0.037192747269349916, 'subsample': 0.6732567492205394, 'colsample_bytree': 0.8495660521479858, 'colsample_bynode': 0.19466380629439098, 'colsample_bylevel': 0.3569050466407546, 'min_child_weight': 3, 'reg_alpha': 8.591918646421952, 'reg_lambda': 24.105280595198117, 'gamma': 3.8655360732900137}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:45:16,470] Trial 147 finished with value: 0.08372014905420203 and parameters: {'max_depth': 2, 'learning_rate': 0.032933327222876986, 'subsample': 0.650359357151794, 'colsample_bytree': 0.821118537839471, 'colsample_bynode': 0.22762968644952605, 'colsample_bylevel': 0.3258823029623105, 'min_child_weight': 4, 'reg_alpha': 99.52150538954749, 'reg_lambda': 15.56137569163565, 'gamma': 3.9642042196934195}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:45:24,075] Trial 148 finished with value: 0.07064351180739296 and parameters: {'max_depth': 2, 'learning_rate': 0.004291754620992503, 'subsample': 0.7156776577123496, 'colsample_bytree': 0.9366469467869935, 'colsample_bynode': 0.9953504402311264, 'colsample_bylevel': 0.25861594054408127, 'min_child_weight': 3, 'reg_alpha': 2.101577857537398, 'reg_lambda': 17.811515662135605, 'gamma': 4.078203163529958}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:45:31,641] Trial 149 finished with value: 0.09362913921684497 and parameters: {'max_depth': 2, 'learning_rate': 0.02809455624391921, 'subsample': 0.7573886264418233, 'colsample_bytree': 0.14066755810786635, 'colsample_bynode': 0.14992959634029188, 'colsample_bylevel': 0.29910716395895537, 'min_child_weight': 4, 'reg_alpha': 4.259694573136239, 'reg_lambda': 34.2214249165403, 'gamma': 3.7795762411499014}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:45:39,340] Trial 150 finished with value: 0.09698197826848373 and parameters: {'max_depth': 2, 'learning_rate': 0.0412211763168294, 'subsample': 0.6910181027002495, 'colsample_bytree': 0.88267755553417, 'colsample_bynode': 0.17691457351297396, 'colsample_bylevel': 0.2675961535425091, 'min_child_weight': 3, 'reg_alpha': 6.453033724564534, 'reg_lambda': 23.849880773096128, 'gamma': 4.2709245477904965}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:45:46,915] Trial 151 finished with value: 0.09576000014341406 and parameters: {'max_depth': 2, 'learning_rate': 0.04190316894408217, 'subsample': 0.7022285024600037, 'colsample_bytree': 0.8862815222020006, 'colsample_bynode': 0.1765774779148234, 'colsample_bylevel': 0.26788757383315637, 'min_child_weight': 3, 'reg_alpha': 6.641021533796559, 'reg_lambda': 25.41868529274996, 'gamma': 4.291334096176069}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:45:58,276] Trial 152 finished with value: 0.07543938964874981 and parameters: {'max_depth': 8, 'learning_rate': 0.03931943936730326, 'subsample': 0.7362729214965854, 'colsample_bytree': 0.8672162009869268, 'colsample_bynode': 0.21180166437561945, 'colsample_bylevel': 0.2412281678423646, 'min_child_weight': 3, 'reg_alpha': 9.435732778987331, 'reg_lambda': 23.355215713012274, 'gamma': 4.170178087178525}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:46:06,092] Trial 153 finished with value: 0.08619665814068721 and parameters: {'max_depth': 2, 'learning_rate': 0.034977223753829494, 'subsample': 0.6698592497940203, 'colsample_bytree': 0.8980172863817752, 'colsample_bynode': 0.16483747597504572, 'colsample_bylevel': 0.3126324863376455, 'min_child_weight': 3, 'reg_alpha': 1.6175806208935666, 'reg_lambda': 20.491565435886113, 'gamma': 0.2325005025399962}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:46:13,971] Trial 154 finished with value: 0.0946565288539657 and parameters: {'max_depth': 2, 'learning_rate': 0.04392719443605817, 'subsample': 0.689215220870093, 'colsample_bytree': 0.9596836208787501, 'colsample_bynode': 0.1923605212845515, 'colsample_bylevel': 0.27815871915379176, 'min_child_weight': 2, 'reg_alpha': 5.190144702001354, 'reg_lambda': 28.818190310129815, 'gamma': 3.8923193509558383}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:46:21,158] Trial 155 finished with value: 0.0961993211781696 and parameters: {'max_depth': 2, 'learning_rate': 0.031249071146477646, 'subsample': 0.6295433010821725, 'colsample_bytree': 0.8761883422180071, 'colsample_bynode': 0.1437412978223692, 'colsample_bylevel': 0.22927306795795377, 'min_child_weight': 3, 'reg_alpha': 0.09161471711592606, 'reg_lambda': 15.185559667251152, 'gamma': 4.4380418303586975}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:46:28,805] Trial 156 finished with value: 0.08653046752929339 and parameters: {'max_depth': 2, 'learning_rate': 0.02456750874258609, 'subsample': 0.7482521602843815, 'colsample_bytree': 0.8415200154663169, 'colsample_bynode': 0.11784971750355447, 'colsample_bylevel': 0.2971798219210217, 'min_child_weight': 2, 'reg_alpha': 12.087891266884164, 'reg_lambda': 17.957228741610454, 'gamma': 3.9798748528749948}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:46:36,661] Trial 157 finished with value: 0.08808947300222547 and parameters: {'max_depth': 2, 'learning_rate': 0.036327400557336326, 'subsample': 0.7202885584234218, 'colsample_bytree': 0.9106715283491319, 'colsample_bynode': 0.24175940159144305, 'colsample_bylevel': 0.3360540868351752, 'min_child_weight': 3, 'reg_alpha': 3.5163120770007823, 'reg_lambda': 13.439943697517625, 'gamma': 3.6873679916991673}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:46:44,324] Trial 158 finished with value: 0.09164978532830684 and parameters: {'max_depth': 2, 'learning_rate': 0.04465353203296565, 'subsample': 0.6536815372435192, 'colsample_bytree': 0.8588841586879896, 'colsample_bynode': 0.1781823201035192, 'colsample_bylevel': 0.2553590672937607, 'min_child_weight': 4, 'reg_alpha': 7.447122922298054, 'reg_lambda': 20.698477192606354, 'gamma': 4.577949453209803}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:46:52,315] Trial 159 finished with value: 0.08856466048642501 and parameters: {'max_depth': 2, 'learning_rate': 0.038834267202641735, 'subsample': 0.6915947854652343, 'colsample_bytree': 0.933371347177492, 'colsample_bynode': 0.153611517349996, 'colsample_bylevel': 0.19623236901068186, 'min_child_weight': 2, 'reg_alpha': 10.7051121160006, 'reg_lambda': 10.753587769293034, 'gamma': 4.216481308127049}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:47:00,144] Trial 160 finished with value: 0.08686161130059045 and parameters: {'max_depth': 2, 'learning_rate': 0.029036817678985007, 'subsample': 0.7649410860607663, 'colsample_bytree': 0.7740005602467348, 'colsample_bynode': 0.2102672219496435, 'colsample_bylevel': 0.558815558835129, 'min_child_weight': 5, 'reg_alpha': 2.9625693295714086, 'reg_lambda': 48.55482720099856, 'gamma': 4.072018687385756}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:47:08,097] Trial 161 finished with value: 0.09798349134053709 and parameters: {'max_depth': 2, 'learning_rate': 0.04695761817155994, 'subsample': 0.5432298422648019, 'colsample_bytree': 0.908784215649662, 'colsample_bynode': 0.16777557970921703, 'colsample_bylevel': 0.2942893382859156, 'min_child_weight': 4, 'reg_alpha': 5.370742490945262, 'reg_lambda': 22.23019026323692, 'gamma': 4.1071175885227635}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:47:15,891] Trial 162 finished with value: 0.09795721003742891 and parameters: {'max_depth': 2, 'learning_rate': 0.046766426041433495, 'subsample': 0.5313727307545127, 'colsample_bytree': 0.8928030361931906, 'colsample_bynode': 0.13588274697538638, 'colsample_bylevel': 0.28959647025627583, 'min_child_weight': 4, 'reg_alpha': 5.591384195646125, 'reg_lambda': 25.148146251096026, 'gamma': 4.332345885968147}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:47:23,636] Trial 163 finished with value: 0.0879013970044247 and parameters: {'max_depth': 2, 'learning_rate': 0.04644242797972719, 'subsample': 0.5357502890366166, 'colsample_bytree': 0.8773057619793839, 'colsample_bynode': 0.13112544607523502, 'colsample_bylevel': 0.3228397222452335, 'min_child_weight': 4, 'reg_alpha': 5.641830098523665, 'reg_lambda': 26.493810255855703, 'gamma': 4.3208564798828935}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:47:31,152] Trial 164 finished with value: 0.10010046534931369 and parameters: {'max_depth': 2, 'learning_rate': 0.05245637268061353, 'subsample': 0.5061697842250956, 'colsample_bytree': 0.9257505286314642, 'colsample_bynode': 0.16001785515438263, 'colsample_bylevel': 0.2939280335201476, 'min_child_weight': 4, 'reg_alpha': 7.8915346949887155, 'reg_lambda': 25.005168511367792, 'gamma': 4.181891230141414}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:47:39,341] Trial 165 finished with value: 0.08557527786900378 and parameters: {'max_depth': 2, 'learning_rate': 0.051017495669145804, 'subsample': 0.5435455145202824, 'colsample_bytree': 0.9235026424524324, 'colsample_bynode': 0.1458850928482307, 'colsample_bylevel': 0.36311541868294217, 'min_child_weight': 4, 'reg_alpha': 8.528831144410555, 'reg_lambda': 16.598615993129286, 'gamma': 3.831700908121602}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:47:47,114] Trial 166 finished with value: 0.08882762312157032 and parameters: {'max_depth': 2, 'learning_rate': 0.05392454694915676, 'subsample': 0.503438940153007, 'colsample_bytree': 0.9645345914904631, 'colsample_bynode': 0.11411188514300175, 'colsample_bylevel': 0.3081520633698068, 'min_child_weight': 5, 'reg_alpha': 10.04734373328026, 'reg_lambda': 30.3840223733366, 'gamma': 4.409789781219308}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:47:54,993] Trial 167 finished with value: 0.09323674841385288 and parameters: {'max_depth': 2, 'learning_rate': 0.020056894060597606, 'subsample': 0.5000904035692197, 'colsample_bytree': 0.9059383462201682, 'colsample_bynode': 0.19920461747075133, 'colsample_bylevel': 0.29276713729326176, 'min_child_weight': 4, 'reg_alpha': 4.643261793875296, 'reg_lambda': 25.182129662566773, 'gamma': 4.135338437878485}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:48:04,311] Trial 168 finished with value: 0.09081394560401979 and parameters: {'max_depth': 3, 'learning_rate': 0.04131467127620569, 'subsample': 0.4549752330731106, 'colsample_bytree': 0.9972559322007246, 'colsample_bynode': 0.15865886622742295, 'colsample_bylevel': 0.33753012790284637, 'min_child_weight': 4, 'reg_alpha': 7.83481345102517, 'reg_lambda': 61.009478456100396, 'gamma': 1.5093358454660672}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:48:11,930] Trial 169 finished with value: 0.08850772432161977 and parameters: {'max_depth': 2, 'learning_rate': 0.046722365271801056, 'subsample': 0.5747638954525054, 'colsample_bytree': 0.45327508111296794, 'colsample_bynode': 0.22495856014082483, 'colsample_bylevel': 0.28811836698990073, 'min_child_weight': 4, 'reg_alpha': 13.761477190725465, 'reg_lambda': 18.810150394661235, 'gamma': 3.8617828524164444}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:48:21,082] Trial 170 finished with value: 0.08987912523683024 and parameters: {'max_depth': 3, 'learning_rate': 0.03349206753973379, 'subsample': 0.4878591325891485, 'colsample_bytree': 0.9332246710924338, 'colsample_bynode': 0.13298484533224075, 'colsample_bylevel': 0.2512401538958571, 'min_child_weight': 4, 'reg_alpha': 1.939558405379675, 'reg_lambda': 8.09200526184485, 'gamma': 3.611675049056424}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:48:29,015] Trial 171 finished with value: 0.10025739470484087 and parameters: {'max_depth': 2, 'learning_rate': 0.042325086018970774, 'subsample': 0.5311559531263916, 'colsample_bytree': 0.8840750714990984, 'colsample_bynode': 0.16429123349711605, 'colsample_bylevel': 0.27020813639837593, 'min_child_weight': 2, 'reg_alpha': 6.813925240555695, 'reg_lambda': 22.841149186000223, 'gamma': 4.288373053320824}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:48:36,895] Trial 172 finished with value: 0.09392857143526351 and parameters: {'max_depth': 2, 'learning_rate': 0.059295174545490395, 'subsample': 0.5537198957490223, 'colsample_bytree': 0.9058131232119909, 'colsample_bynode': 0.15924611394137467, 'colsample_bylevel': 0.3173762935335902, 'min_child_weight': 2, 'reg_alpha': 5.176654716224609, 'reg_lambda': 23.826699120125785, 'gamma': 4.5207127601596655}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:48:44,814] Trial 173 finished with value: 0.0877513406317014 and parameters: {'max_depth': 2, 'learning_rate': 0.04395040642989951, 'subsample': 0.5388598563699015, 'colsample_bytree': 0.8539085824233146, 'colsample_bynode': 0.19623704001555237, 'colsample_bylevel': 0.23248165117188085, 'min_child_weight': 2, 'reg_alpha': 11.193275944235534, 'reg_lambda': 27.95877114060137, 'gamma': 3.9316087752463083}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:48:52,872] Trial 174 finished with value: 0.08962515797123453 and parameters: {'max_depth': 2, 'learning_rate': 0.05020072987610977, 'subsample': 0.5251096800745714, 'colsample_bytree': 0.8295101049782678, 'colsample_bynode': 0.11162380686161345, 'colsample_bylevel': 0.28560852166652, 'min_child_weight': 2, 'reg_alpha': 7.08761084885157, 'reg_lambda': 22.50180918793525, 'gamma': 4.169734166463033}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:49:00,517] Trial 175 finished with value: 0.09569665667412462 and parameters: {'max_depth': 2, 'learning_rate': 0.036558205660844896, 'subsample': 0.518843585435252, 'colsample_bytree': 0.9509057979854002, 'colsample_bynode': 0.08960470355322211, 'colsample_bylevel': 0.5051347275138305, 'min_child_weight': 5, 'reg_alpha': 3.772873111583178, 'reg_lambda': 13.276046770425848, 'gamma': 4.0226759659709765}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:49:08,199] Trial 176 finished with value: 0.08864276195224603 and parameters: {'max_depth': 2, 'learning_rate': 0.03947630307602892, 'subsample': 0.48229232104650227, 'colsample_bytree': 0.8892752056279118, 'colsample_bynode': 0.16749407336533031, 'colsample_bylevel': 0.3109080462128478, 'min_child_weight': 2, 'reg_alpha': 0.04081121964973977, 'reg_lambda': 99.58697859760866, 'gamma': 4.371688966042166}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:49:15,901] Trial 177 finished with value: 0.09077754414069672 and parameters: {'max_depth': 2, 'learning_rate': 0.032925313655064285, 'subsample': 0.5847794994492247, 'colsample_bytree': 0.9228829603152916, 'colsample_bynode': 0.14026499986004043, 'colsample_bylevel': 0.3490132916733261, 'min_child_weight': 4, 'reg_alpha': 8.569508796892558, 'reg_lambda': 11.868192361548825, 'gamma': 4.250856669124449}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:49:23,203] Trial 178 finished with value: 0.09506035354286646 and parameters: {'max_depth': 2, 'learning_rate': 0.04426859702976359, 'subsample': 0.8114831247678069, 'colsample_bytree': 0.8658110768419899, 'colsample_bynode': 0.19134394791808762, 'colsample_bylevel': 0.25804534376054744, 'min_child_weight': 2, 'reg_alpha': 2.4684318621542785, 'reg_lambda': 18.857197150724154, 'gamma': 3.7430385105993453}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:49:31,339] Trial 179 finished with value: 0.09989306628754811 and parameters: {'max_depth': 2, 'learning_rate': 0.05180521567520264, 'subsample': 0.4638234372268955, 'colsample_bytree': 0.898263372201638, 'colsample_bynode': 0.21659433601649614, 'colsample_bylevel': 0.2824607395447771, 'min_child_weight': 2, 'reg_alpha': 5.388157595270271, 'reg_lambda': 26.102130257466882, 'gamma': 3.962496913318035}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:49:39,041] Trial 180 finished with value: 0.097837569912217 and parameters: {'max_depth': 2, 'learning_rate': 0.05642950593844212, 'subsample': 0.4283510176673558, 'colsample_bytree': 0.9010775660567728, 'colsample_bynode': 0.22019401874896039, 'colsample_bylevel': 0.27517023119835726, 'min_child_weight': 2, 'reg_alpha': 5.622418188437494, 'reg_lambda': 26.58551319641013, 'gamma': 3.9827928965919948}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:49:46,932] Trial 181 finished with value: 0.09943599836464333 and parameters: {'max_depth': 2, 'learning_rate': 0.057092593487069035, 'subsample': 0.42664945489302736, 'colsample_bytree': 0.901852829038018, 'colsample_bynode': 0.22879109005805423, 'colsample_bylevel': 0.27296544388593563, 'min_child_weight': 2, 'reg_alpha': 5.586716807727148, 'reg_lambda': 33.8785747884758, 'gamma': 3.9754526920058644}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:49:56,301] Trial 182 finished with value: 0.08264025784268295 and parameters: {'max_depth': 9, 'learning_rate': 0.06205103459435585, 'subsample': 0.3949282005153639, 'colsample_bytree': 0.9425529914356259, 'colsample_bynode': 0.2544316446485017, 'colsample_bylevel': 0.26775405316164674, 'min_child_weight': 2, 'reg_alpha': 5.789589503463451, 'reg_lambda': 35.50905084389572, 'gamma': 3.9888214069112315}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:50:04,023] Trial 183 finished with value: 0.088362083857018 and parameters: {'max_depth': 2, 'learning_rate': 0.05180714553570773, 'subsample': 0.46862832713621017, 'colsample_bytree': 0.9150718942721816, 'colsample_bynode': 0.23229896627652227, 'colsample_bylevel': 0.22065956843012435, 'min_child_weight': 2, 'reg_alpha': 9.60072466696336, 'reg_lambda': 27.70466305608041, 'gamma': 4.104348841157538}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:50:11,398] Trial 184 finished with value: 0.0939018956071662 and parameters: {'max_depth': 2, 'learning_rate': 0.05633844668112951, 'subsample': 0.38853607980779503, 'colsample_bytree': 0.892486963033469, 'colsample_bynode': 0.20825396836036633, 'colsample_bylevel': 0.24019078992133358, 'min_child_weight': 2, 'reg_alpha': 6.707912957088645, 'reg_lambda': 30.896732121278905, 'gamma': 3.9271417212205413}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:50:18,741] Trial 185 finished with value: 0.07117239768350891 and parameters: {'max_depth': 2, 'learning_rate': 0.0013918333391636506, 'subsample': 0.4222025695975343, 'colsample_bytree': 0.9224500310126781, 'colsample_bynode': 0.22146696572947866, 'colsample_bylevel': 0.2784039364374079, 'min_child_weight': 2, 'reg_alpha': 4.2018424735201325, 'reg_lambda': 33.3918336601165, 'gamma': 4.172426709079828}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:50:26,193] Trial 186 finished with value: 0.08677200211906362 and parameters: {'max_depth': 2, 'learning_rate': 0.01530159436911579, 'subsample': 0.44271628750303693, 'colsample_bytree': 0.9760416171358612, 'colsample_bynode': 0.2381239362860627, 'colsample_bylevel': 0.30764786083917883, 'min_child_weight': 2, 'reg_alpha': 15.490757924649234, 'reg_lambda': 25.62226781198965, 'gamma': 3.842745470091033}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:50:33,450] Trial 187 finished with value: 0.09305730787433925 and parameters: {'max_depth': 2, 'learning_rate': 0.06428944729996693, 'subsample': 0.3655328654040493, 'colsample_bytree': 0.8648473233158137, 'colsample_bynode': 0.26840853704192563, 'colsample_bylevel': 0.25566334906564775, 'min_child_weight': 1, 'reg_alpha': 9.031239616546383, 'reg_lambda': 39.44915135208435, 'gamma': 4.0177423234490925}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:50:41,071] Trial 188 finished with value: 0.09098957827282618 and parameters: {'max_depth': 2, 'learning_rate': 0.0713799509433659, 'subsample': 0.44667251121880863, 'colsample_bytree': 0.7027021871160253, 'colsample_bynode': 0.17837388911573154, 'colsample_bylevel': 0.32788759145413565, 'min_child_weight': 2, 'reg_alpha': 12.896090144428525, 'reg_lambda': 26.36992033902932, 'gamma': 4.225471916543545}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:50:48,496] Trial 189 finished with value: 0.10028528937086058 and parameters: {'max_depth': 2, 'learning_rate': 0.04876897951178206, 'subsample': 0.42303761118859007, 'colsample_bytree': 0.9007417617132065, 'colsample_bynode': 0.215040752144117, 'colsample_bylevel': 0.2919919556720914, 'min_child_weight': 2, 'reg_alpha': 5.279361097946069, 'reg_lambda': 29.5713685694513, 'gamma': 4.331379586339088}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:50:55,987] Trial 190 finished with value: 0.09624363039562635 and parameters: {'max_depth': 2, 'learning_rate': 0.057332747789805134, 'subsample': 0.3602869440427879, 'colsample_bytree': 0.8836885894289531, 'colsample_bynode': 0.28130566891457576, 'colsample_bylevel': 0.28958886169978126, 'min_child_weight': 2, 'reg_alpha': 5.143007886507615, 'reg_lambda': 30.012644452102673, 'gamma': 4.387569411328595}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:51:03,623] Trial 191 finished with value: 0.10055944853852328 and parameters: {'max_depth': 2, 'learning_rate': 0.04820507746003322, 'subsample': 0.41387733217236905, 'colsample_bytree': 0.9052480631893035, 'colsample_bynode': 0.21005443483136815, 'colsample_bylevel': 0.27042411611398876, 'min_child_weight': 2, 'reg_alpha': 7.897587205542099, 'reg_lambda': 28.230603028881468, 'gamma': 4.121140249943167}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:51:11,293] Trial 192 finished with value: 0.09778638797963873 and parameters: {'max_depth': 2, 'learning_rate': 0.04735603087196216, 'subsample': 0.4172095768913971, 'colsample_bytree': 0.8961243100607733, 'colsample_bynode': 0.2132276722757156, 'colsample_bylevel': 0.3004732929027426, 'min_child_weight': 2, 'reg_alpha': 6.828490302016722, 'reg_lambda': 28.808867381891947, 'gamma': 4.110313339679444}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:51:18,910] Trial 193 finished with value: 0.09751145455953478 and parameters: {'max_depth': 2, 'learning_rate': 0.047132506213135424, 'subsample': 0.40966527028639965, 'colsample_bytree': 0.9018846747189911, 'colsample_bynode': 0.21137556309352978, 'colsample_bylevel': 0.27566798971973755, 'min_child_weight': 2, 'reg_alpha': 6.180256772218415, 'reg_lambda': 32.24939246559976, 'gamma': 4.297988984831987}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:51:26,665] Trial 194 finished with value: 0.09073088153363534 and parameters: {'max_depth': 2, 'learning_rate': 0.05290870415661869, 'subsample': 0.41896984680184884, 'colsample_bytree': 0.8442166155745149, 'colsample_bynode': 0.23816163334837678, 'colsample_bylevel': 0.30379092106671435, 'min_child_weight': 2, 'reg_alpha': 3.749693045172622, 'reg_lambda': 27.85802285148972, 'gamma': 4.125930808891209}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:51:34,210] Trial 195 finished with value: 0.08404544271491951 and parameters: {'max_depth': 2, 'learning_rate': 0.04741900214103624, 'subsample': 0.4302082336980352, 'colsample_bytree': 0.899527376095856, 'colsample_bynode': 0.20104219820901084, 'colsample_bylevel': 0.3357654131517274, 'min_child_weight': 2, 'reg_alpha': 7.7486514121462875, 'reg_lambda': 29.367725525700685, 'gamma': 4.522912136719202}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:51:41,697] Trial 196 finished with value: 0.09604305915413527 and parameters: {'max_depth': 2, 'learning_rate': 0.0549500077265307, 'subsample': 0.40450377746146204, 'colsample_bytree': 0.8757198153753565, 'colsample_bynode': 0.2527263240812604, 'colsample_bylevel': 0.29761304034659924, 'min_child_weight': 1, 'reg_alpha': 10.822949187303973, 'reg_lambda': 25.44779166009809, 'gamma': 4.219060978091604}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:51:49,567] Trial 197 finished with value: 0.08895743492859952 and parameters: {'max_depth': 2, 'learning_rate': 0.04353933158031245, 'subsample': 0.449101969496759, 'colsample_bytree': 0.9183734394689577, 'colsample_bynode': 0.21959971144046797, 'colsample_bylevel': 0.3191750612503511, 'min_child_weight': 2, 'reg_alpha': 4.939279000844433, 'reg_lambda': 23.310381585867415, 'gamma': 4.036529741072796}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:51:57,512] Trial 198 finished with value: 0.08976335749193824 and parameters: {'max_depth': 2, 'learning_rate': 0.049395162232187304, 'subsample': 0.4686327133312614, 'colsample_bytree': 0.8590889670396, 'colsample_bynode': 0.18333201424368162, 'colsample_bylevel': 0.27359024944127824, 'min_child_weight': 2, 'reg_alpha': 2.045303791825798, 'reg_lambda': 32.43942252240956, 'gamma': 4.3271047933774724}. Best is trial 128 with value: 0.10111190001890986.\n",
      "[I 2025-07-11 12:52:05,296] Trial 199 finished with value: 0.09454711221409963 and parameters: {'max_depth': 2, 'learning_rate': 0.03890152479934669, 'subsample': 0.34361029705467494, 'colsample_bytree': 0.8859653239002022, 'colsample_bynode': 0.17343385187507632, 'colsample_bylevel': 0.23910031464983478, 'min_child_weight': 2, 'reg_alpha': 6.42241655953181, 'reg_lambda': 35.59511856205888, 'gamma': 4.127659239381981}. Best is trial 128 with value: 0.10111190001890986.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 2, 'learning_rate': 0.03571251602123245, 'subsample': 0.7284845131177894, 'colsample_bytree': 0.8900200440528983, 'colsample_bynode': 0.18638203553652433, 'colsample_bylevel': 0.27429289794421363, 'min_child_weight': 3, 'reg_alpha': 0.8508785729496249, 'reg_lambda': 7.200790598274197, 'gamma': 4.081911173092974}\n",
      "Best Pearson score: 0.10111190001890986\n"
     ]
    }
   ],
   "source": [
    "best_xgboost_params_common_truncated = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features)}_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features)}_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534cb1d",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c656479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 13:33:18,913] Using an existing study with name 'lightgbm_2_4_101_1000_common_truncated_30_study' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for LightGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 13:33:25,043] Trial 100 finished with value: 0.08596512661565917 and parameters: {'max_depth': 2, 'learning_rate': 0.09453122787014898, 'num_leaves': 762, 'subsample': 0.8771526225546469, 'colsample_bytree': 0.27825584977225404, 'min_child_weight': 0.11454953999377121, 'reg_alpha': 3.5722640121866034, 'reg_lambda': 3.4845918867783947}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:33:30,865] Trial 101 finished with value: 0.0885658828219692 and parameters: {'max_depth': 2, 'learning_rate': 0.0792554852449728, 'num_leaves': 721, 'subsample': 0.9092424957410897, 'colsample_bytree': 0.17110347853820157, 'min_child_weight': 0.08705871143263091, 'reg_alpha': 10.067013626938602, 'reg_lambda': 0.27902751625680233}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:33:36,445] Trial 102 finished with value: 0.08636738307610688 and parameters: {'max_depth': 2, 'learning_rate': 0.09999133522614011, 'num_leaves': 709, 'subsample': 0.9055757891672155, 'colsample_bytree': 0.16776414510323345, 'min_child_weight': 0.06269872834450664, 'reg_alpha': 0.8610177382413213, 'reg_lambda': 0.04537432044803241}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:33:42,229] Trial 103 finished with value: 0.07807435184095746 and parameters: {'max_depth': 2, 'learning_rate': 0.07724542259882322, 'num_leaves': 792, 'subsample': 0.7370395231703064, 'colsample_bytree': 0.2242001019350263, 'min_child_weight': 0.2684931943060195, 'reg_alpha': 10.437525338619903, 'reg_lambda': 2.6040090987155664}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:33:47,587] Trial 104 finished with value: 0.0919074726671159 and parameters: {'max_depth': 2, 'learning_rate': 0.06964962797446046, 'num_leaves': 773, 'subsample': 0.7970729418779448, 'colsample_bytree': 0.13303504921671752, 'min_child_weight': 0.06492417928077879, 'reg_alpha': 0.10984308734977954, 'reg_lambda': 6.335983284105193}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:33:53,195] Trial 105 finished with value: 0.08035102880533818 and parameters: {'max_depth': 2, 'learning_rate': 0.06929970121744514, 'num_leaves': 645, 'subsample': 0.8623505708320283, 'colsample_bytree': 0.1838103906725616, 'min_child_weight': 0.04503970860960622, 'reg_alpha': 0.3980644899024014, 'reg_lambda': 5.827164619269036}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:33:58,573] Trial 106 finished with value: 0.08964438713122452 and parameters: {'max_depth': 2, 'learning_rate': 0.06218232859892895, 'num_leaves': 766, 'subsample': 0.8887397693818387, 'colsample_bytree': 0.14003680115696854, 'min_child_weight': 0.097144923046144, 'reg_alpha': 3.5143745170240193, 'reg_lambda': 10.119764888250817}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:34:03,984] Trial 107 finished with value: 0.08847033040320779 and parameters: {'max_depth': 2, 'learning_rate': 0.06070161203563151, 'num_leaves': 771, 'subsample': 0.8277075840911207, 'colsample_bytree': 0.13224206409344746, 'min_child_weight': 0.23899901292569287, 'reg_alpha': 4.438575548040565, 'reg_lambda': 4.887683670564509}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:34:09,242] Trial 108 finished with value: 0.08919847693852077 and parameters: {'max_depth': 2, 'learning_rate': 0.0866005261018132, 'num_leaves': 808, 'subsample': 0.7911984583274345, 'colsample_bytree': 0.10575820010455284, 'min_child_weight': 0.1677191780482184, 'reg_alpha': 4.931971801694755, 'reg_lambda': 10.378462493844602}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:34:14,493] Trial 109 finished with value: 0.0868150800543903 and parameters: {'max_depth': 2, 'learning_rate': 0.06458524790017965, 'num_leaves': 816, 'subsample': 0.8006234198362979, 'colsample_bytree': 0.11118709830874388, 'min_child_weight': 0.15614120706735593, 'reg_alpha': 5.0787963349600975, 'reg_lambda': 10.039322359254918}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:34:19,878] Trial 110 finished with value: 0.08847828854509542 and parameters: {'max_depth': 2, 'learning_rate': 0.08625552450446261, 'num_leaves': 739, 'subsample': 0.9575244019642386, 'colsample_bytree': 0.14113198190846007, 'min_child_weight': 0.19965250705383175, 'reg_alpha': 2.090586848903892, 'reg_lambda': 13.725704085772598}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:34:25,246] Trial 111 finished with value: 0.09292486918996004 and parameters: {'max_depth': 2, 'learning_rate': 0.07417320146933384, 'num_leaves': 803, 'subsample': 0.8802691422278642, 'colsample_bytree': 0.12919293998485834, 'min_child_weight': 0.1160772149541835, 'reg_alpha': 0.1627957682382366, 'reg_lambda': 6.978012381003767}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:34:30,535] Trial 112 finished with value: 0.09205216410801177 and parameters: {'max_depth': 2, 'learning_rate': 0.0755611113088624, 'num_leaves': 841, 'subsample': 0.7678533136790833, 'colsample_bytree': 0.10369512744954232, 'min_child_weight': 0.12490865192572062, 'reg_alpha': 0.5982569763835013, 'reg_lambda': 7.558462519910007}. Best is trial 95 with value: 0.0943629846154106.\n",
      "[I 2025-07-11 13:34:35,929] Trial 113 finished with value: 0.09547275895424814 and parameters: {'max_depth': 2, 'learning_rate': 0.07080163253877017, 'num_leaves': 768, 'subsample': 0.7697109856542574, 'colsample_bytree': 0.1289011200034619, 'min_child_weight': 0.12443145117504491, 'reg_alpha': 0.19437675041595348, 'reg_lambda': 7.1197484161119196}. Best is trial 113 with value: 0.09547275895424814.\n",
      "[I 2025-07-11 13:34:41,337] Trial 114 finished with value: 0.09612377364070968 and parameters: {'max_depth': 2, 'learning_rate': 0.0706508468052558, 'num_leaves': 844, 'subsample': 0.6900988714036562, 'colsample_bytree': 0.12774425252999097, 'min_child_weight': 0.11302183968544866, 'reg_alpha': 0.5130520549504599, 'reg_lambda': 7.080941675844325}. Best is trial 114 with value: 0.09612377364070968.\n",
      "[I 2025-07-11 13:34:46,727] Trial 115 finished with value: 0.09145049152500931 and parameters: {'max_depth': 2, 'learning_rate': 0.07344507781725881, 'num_leaves': 845, 'subsample': 0.7767935727697061, 'colsample_bytree': 0.12121384890809347, 'min_child_weight': 0.13295803419816912, 'reg_alpha': 0.5200004021195017, 'reg_lambda': 6.970921018619634}. Best is trial 114 with value: 0.09612377364070968.\n",
      "[I 2025-07-11 13:34:52,082] Trial 116 finished with value: 0.0963065773886294 and parameters: {'max_depth': 2, 'learning_rate': 0.07408268819908323, 'num_leaves': 698, 'subsample': 0.725433189955895, 'colsample_bytree': 0.12271938022025972, 'min_child_weight': 0.1319623557481868, 'reg_alpha': 0.042602233208792306, 'reg_lambda': 7.40838378582355}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:34:57,702] Trial 117 finished with value: 0.08112550543263726 and parameters: {'max_depth': 2, 'learning_rate': 0.07395282137151189, 'num_leaves': 842, 'subsample': 0.6970704408466337, 'colsample_bytree': 0.19656251661264257, 'min_child_weight': 0.1340815481743651, 'reg_alpha': 0.029213646282445715, 'reg_lambda': 6.841053039838102}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:03,467] Trial 118 finished with value: 0.08225229655171784 and parameters: {'max_depth': 2, 'learning_rate': 0.07107847394549566, 'num_leaves': 723, 'subsample': 0.6965251995093332, 'colsample_bytree': 0.24410030385808645, 'min_child_weight': 0.03371103354622734, 'reg_alpha': 0.019505046533760284, 'reg_lambda': 7.507145180406356}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:08,949] Trial 119 finished with value: 0.08494224941200881 and parameters: {'max_depth': 2, 'learning_rate': 0.08094967549509254, 'num_leaves': 695, 'subsample': 0.6764659453227109, 'colsample_bytree': 0.15719148885168321, 'min_child_weight': 0.12273169412114428, 'reg_alpha': 2.551060821789899, 'reg_lambda': 17.79945514768651}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:14,320] Trial 120 finished with value: 0.08928009223877645 and parameters: {'max_depth': 2, 'learning_rate': 0.07173051434264259, 'num_leaves': 648, 'subsample': 0.7243824090462764, 'colsample_bytree': 0.12267533635576454, 'min_child_weight': 0.22195499777509373, 'reg_alpha': 5.378765023266494, 'reg_lambda': 14.529291570463284}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:19,591] Trial 121 finished with value: 0.09059050124391349 and parameters: {'max_depth': 2, 'learning_rate': 0.054574575962856454, 'num_leaves': 769, 'subsample': 0.7692017906052881, 'colsample_bytree': 0.11491897706572712, 'min_child_weight': 0.0027849399145993617, 'reg_alpha': 0.49588735135643786, 'reg_lambda': 5.712792308945453}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:24,877] Trial 122 finished with value: 0.09183815596314907 and parameters: {'max_depth': 2, 'learning_rate': 0.05299107727375644, 'num_leaves': 839, 'subsample': 0.77236710459053, 'colsample_bytree': 0.10079381053066386, 'min_child_weight': 0.0028539980196225423, 'reg_alpha': 0.5527778471220799, 'reg_lambda': 5.691687714962487}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:30,148] Trial 123 finished with value: 0.08732104874829758 and parameters: {'max_depth': 2, 'learning_rate': 0.05136953373312797, 'num_leaves': 837, 'subsample': 0.7679127046219987, 'colsample_bytree': 0.09722272692937793, 'min_child_weight': 0.0033705838884401373, 'reg_alpha': 0.36576397320420817, 'reg_lambda': 5.937443427264828}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:35,544] Trial 124 finished with value: 0.08598975046082953 and parameters: {'max_depth': 2, 'learning_rate': 0.05434013991372516, 'num_leaves': 769, 'subsample': 0.7473093279937497, 'colsample_bytree': 0.12785258989628684, 'min_child_weight': 0.039307089099617894, 'reg_alpha': 6.059518602484361, 'reg_lambda': 12.868934504167294}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:41,061] Trial 125 finished with value: 0.08393611528060929 and parameters: {'max_depth': 2, 'learning_rate': 0.08055413472253012, 'num_leaves': 882, 'subsample': 0.77194259889147, 'colsample_bytree': 0.15783246197790182, 'min_child_weight': 0.10316120254185035, 'reg_alpha': 8.895205217815446, 'reg_lambda': 8.5496807947961}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:46,354] Trial 126 finished with value: 0.08903205621432067 and parameters: {'max_depth': 2, 'learning_rate': 0.0647245147832576, 'num_leaves': 755, 'subsample': 0.6469401125281963, 'colsample_bytree': 0.11137023860032713, 'min_child_weight': 0.30323249962709303, 'reg_alpha': 1.8888786312688384, 'reg_lambda': 4.659028338887611}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:35:54,851] Trial 127 finished with value: 0.07361187725591913 and parameters: {'max_depth': 3, 'learning_rate': 0.08529659405446957, 'num_leaves': 679, 'subsample': 0.7481787317927633, 'colsample_bytree': 0.20066102547373663, 'min_child_weight': 0.02639552414445126, 'reg_alpha': 5.33112022994823, 'reg_lambda': 16.481558972159647}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:00,111] Trial 128 finished with value: 0.08523550307738853 and parameters: {'max_depth': 2, 'learning_rate': 0.046502566494813005, 'num_leaves': 777, 'subsample': 0.7344056680082954, 'colsample_bytree': 0.09028560313111618, 'min_child_weight': 0.06675803009839681, 'reg_alpha': 8.132937477245935, 'reg_lambda': 7.170530132126901}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:05,848] Trial 129 finished with value: 0.07005700679643928 and parameters: {'max_depth': 2, 'learning_rate': 0.056567015617834386, 'num_leaves': 856, 'subsample': 0.7761441917679124, 'colsample_bytree': 0.8041896279942768, 'min_child_weight': 0.15251151103914837, 'reg_alpha': 0.19489536876431535, 'reg_lambda': 10.673728351815866}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:14,387] Trial 130 finished with value: 0.0634548246195798 and parameters: {'max_depth': 3, 'learning_rate': 0.0723381756964431, 'num_leaves': 832, 'subsample': 0.7156454509619724, 'colsample_bytree': 0.9270210013115301, 'min_child_weight': 0.05438734876402847, 'reg_alpha': 3.2485767478851466, 'reg_lambda': 4.5249386104838045}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:19,779] Trial 131 finished with value: 0.08704776834340283 and parameters: {'max_depth': 2, 'learning_rate': 0.08886971117327504, 'num_leaves': 736, 'subsample': 0.7985700978300261, 'colsample_bytree': 0.1336723813526302, 'min_child_weight': 0.08122164570359353, 'reg_alpha': 4.35692680856783, 'reg_lambda': 2.0382783501707085}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:25,325] Trial 132 finished with value: 0.08462640202704383 and parameters: {'max_depth': 2, 'learning_rate': 0.065809282218593, 'num_leaves': 809, 'subsample': 0.9338644123085909, 'colsample_bytree': 0.16317846775514716, 'min_child_weight': 0.18462292523501844, 'reg_alpha': 2.381641965478539, 'reg_lambda': 8.638749012788681}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:30,627] Trial 133 finished with value: 0.08718568124169243 and parameters: {'max_depth': 2, 'learning_rate': 0.09316450301599695, 'num_leaves': 783, 'subsample': 0.6639042462714577, 'colsample_bytree': 0.10845144590206846, 'min_child_weight': 0.13019071452593256, 'reg_alpha': 2.0193572506126136, 'reg_lambda': 6.221409978551015}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:36,260] Trial 134 finished with value: 0.0851326879877932 and parameters: {'max_depth': 2, 'learning_rate': 0.07848257595926388, 'num_leaves': 704, 'subsample': 0.700195827940557, 'colsample_bytree': 0.18705242063905594, 'min_child_weight': 0.11264853242762563, 'reg_alpha': 0.08852704705161457, 'reg_lambda': 3.5143237125123754}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:41,683] Trial 135 finished with value: 0.09362452165732446 and parameters: {'max_depth': 2, 'learning_rate': 0.06047606260905773, 'num_leaves': 852, 'subsample': 0.9688137829377003, 'colsample_bytree': 0.14940076396219037, 'min_child_weight': 0.010447292191313367, 'reg_alpha': 7.487906885623453, 'reg_lambda': 1.1854118181484412}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:47,101] Trial 136 finished with value: 0.07874577893787911 and parameters: {'max_depth': 2, 'learning_rate': 0.05953820385535495, 'num_leaves': 888, 'subsample': 0.9585032403078526, 'colsample_bytree': 0.14817384585846083, 'min_child_weight': 0.002574793374799933, 'reg_alpha': 91.63903706677854, 'reg_lambda': 0.1468119611298242}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:52,250] Trial 137 finished with value: 0.08552762137458916 and parameters: {'max_depth': 2, 'learning_rate': 0.04417415553339654, 'num_leaves': 860, 'subsample': 0.7553337464128064, 'colsample_bytree': 0.05015669634086534, 'min_child_weight': 0.018753431718678007, 'reg_alpha': 6.601353719015232, 'reg_lambda': 12.510764026398698}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:36:57,668] Trial 138 finished with value: 0.09219002456877537 and parameters: {'max_depth': 2, 'learning_rate': 0.05172237043746951, 'num_leaves': 556, 'subsample': 0.9674997774659481, 'colsample_bytree': 0.12343559291140574, 'min_child_weight': 0.0950318361970677, 'reg_alpha': 8.415465141281825, 'reg_lambda': 8.568779433837992}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:37:05,720] Trial 139 finished with value: 0.08588304327419168 and parameters: {'max_depth': 3, 'learning_rate': 0.05144194500045569, 'num_leaves': 535, 'subsample': 0.7756017570052814, 'colsample_bytree': 0.09174317802685834, 'min_child_weight': 0.05139775269742164, 'reg_alpha': 5.347101393886239, 'reg_lambda': 9.146596194602552}. Best is trial 116 with value: 0.0963065773886294.\n",
      "[I 2025-07-11 13:37:11,094] Trial 140 finished with value: 0.09772799338898451 and parameters: {'max_depth': 2, 'learning_rate': 0.0661089138508364, 'num_leaves': 624, 'subsample': 0.9917736733153091, 'colsample_bytree': 0.11884820157035034, 'min_child_weight': 0.08526601251586977, 'reg_alpha': 3.699339007638837, 'reg_lambda': 6.960245914436728}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:37:16,479] Trial 141 finished with value: 0.08741511098433616 and parameters: {'max_depth': 2, 'learning_rate': 0.06819370856135236, 'num_leaves': 566, 'subsample': 0.973872694054642, 'colsample_bytree': 0.11732154924901839, 'min_child_weight': 0.08204493524660991, 'reg_alpha': 3.6110224125729995, 'reg_lambda': 6.819984596563762}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:37:21,841] Trial 142 finished with value: 0.09032016764634816 and parameters: {'max_depth': 2, 'learning_rate': 0.05590516650117759, 'num_leaves': 667, 'subsample': 0.993776328048337, 'colsample_bytree': 0.14141895386121078, 'min_child_weight': 0.10625939566751932, 'reg_alpha': 1.4180314369786586, 'reg_lambda': 5.230262808038694}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:37:27,064] Trial 143 finished with value: 0.09277033992599781 and parameters: {'max_depth': 2, 'learning_rate': 0.0756739792895846, 'num_leaves': 577, 'subsample': 0.9329204950841015, 'colsample_bytree': 0.09930011682191614, 'min_child_weight': 0.15144875247779854, 'reg_alpha': 0.03974587990472454, 'reg_lambda': 11.462041890039291}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:37:32,311] Trial 144 finished with value: 0.09397323215619413 and parameters: {'max_depth': 2, 'learning_rate': 0.07631225675412595, 'num_leaves': 573, 'subsample': 0.9329474001856135, 'colsample_bytree': 0.08602764147115266, 'min_child_weight': 0.16773895400473204, 'reg_alpha': 6.218472029900912, 'reg_lambda': 11.203945706727227}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:37:37,447] Trial 145 finished with value: 0.08324200058415174 and parameters: {'max_depth': 2, 'learning_rate': 0.07622957128610948, 'num_leaves': 623, 'subsample': 0.9342488514368553, 'colsample_bytree': 0.07099939752942817, 'min_child_weight': 0.16814782191802996, 'reg_alpha': 7.205450517778863, 'reg_lambda': 16.256509280074145}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:37:42,697] Trial 146 finished with value: 0.08424128135229167 and parameters: {'max_depth': 2, 'learning_rate': 0.06153505752294383, 'num_leaves': 566, 'subsample': 0.9979167378288325, 'colsample_bytree': 0.09104271667302766, 'min_child_weight': 0.20108550333803854, 'reg_alpha': 12.562707420845047, 'reg_lambda': 12.193283611195389}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:37:47,969] Trial 147 finished with value: 0.0844608139426335 and parameters: {'max_depth': 2, 'learning_rate': 0.07150827538818305, 'num_leaves': 509, 'subsample': 0.9216453433508163, 'colsample_bytree': 0.10107159160812004, 'min_child_weight': 0.14680615632329444, 'reg_alpha': 5.550233662531251, 'reg_lambda': 9.970438065729224}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:37:53,422] Trial 148 finished with value: 0.08569299395638652 and parameters: {'max_depth': 2, 'learning_rate': 0.08081770184769752, 'num_leaves': 548, 'subsample': 0.9724663495707853, 'colsample_bytree': 0.15481008378584452, 'min_child_weight': 0.10528414328350326, 'reg_alpha': 8.246810971522812, 'reg_lambda': 8.210106016256773}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:38:01,361] Trial 149 finished with value: 0.08405002102771195 and parameters: {'max_depth': 3, 'learning_rate': 0.06685450243864592, 'num_leaves': 584, 'subsample': 0.9418802469293783, 'colsample_bytree': 0.06417401938004988, 'min_child_weight': 0.0925281965324507, 'reg_alpha': 4.0465036825012755, 'reg_lambda': 14.088518894110624}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:39:37,560] Trial 150 finished with value: 0.06389251891437145 and parameters: {'max_depth': 10, 'learning_rate': 0.06270829941114335, 'num_leaves': 618, 'subsample': 0.5556612984364244, 'colsample_bytree': 0.08339129966230294, 'min_child_weight': 0.17876011504715186, 'reg_alpha': 70.15500442451554, 'reg_lambda': 10.413075551923596}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:39:42,894] Trial 151 finished with value: 0.08468863344932204 and parameters: {'max_depth': 2, 'learning_rate': 0.08571989429529545, 'num_leaves': 458, 'subsample': 0.9562907638767975, 'colsample_bytree': 0.12496172304107019, 'min_child_weight': 0.2531267038072176, 'reg_alpha': 3.0165202552900485, 'reg_lambda': 3.8542204695968563}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:39:48,226] Trial 152 finished with value: 0.09021619087962628 and parameters: {'max_depth': 2, 'learning_rate': 0.07554323698669047, 'num_leaves': 604, 'subsample': 0.9812139228703745, 'colsample_bytree': 0.13383773763423656, 'min_child_weight': 0.21265215106171087, 'reg_alpha': 2.088351975551168, 'reg_lambda': 6.827459985593761}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:39:53,458] Trial 153 finished with value: 0.06774069697775631 and parameters: {'max_depth': 2, 'learning_rate': 0.0011166101621552125, 'num_leaves': 587, 'subsample': 0.9241536681690159, 'colsample_bytree': 0.10275717204462198, 'min_child_weight': 0.30229559120501903, 'reg_alpha': 0.1556688963347015, 'reg_lambda': 0.4819234729629768}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:39:58,941] Trial 154 finished with value: 0.08507158839586192 and parameters: {'max_depth': 2, 'learning_rate': 0.08189958200925915, 'num_leaves': 647, 'subsample': 0.9513595123774768, 'colsample_bytree': 0.17038661484954445, 'min_child_weight': 0.12520452726247708, 'reg_alpha': 5.968980416394883, 'reg_lambda': 3.716408109024898}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:04,661] Trial 155 finished with value: 0.07411906813283338 and parameters: {'max_depth': 2, 'learning_rate': 0.07120241341047191, 'num_leaves': 821, 'subsample': 0.8590133018755373, 'colsample_bytree': 0.5855569246528157, 'min_child_weight': 0.15140750368826533, 'reg_alpha': 4.056707597982203, 'reg_lambda': 97.62581676161959}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:10,874] Trial 156 finished with value: 0.06832394145591109 and parameters: {'max_depth': 2, 'learning_rate': 0.09486935944660997, 'num_leaves': 520, 'subsample': 0.8933381166144495, 'colsample_bytree': 0.358296632393466, 'min_child_weight': 0.0710034580427961, 'reg_alpha': 8.854880729103266, 'reg_lambda': 8.24346397655683}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:16,191] Trial 157 finished with value: 0.09287915282024221 and parameters: {'max_depth': 2, 'learning_rate': 0.0637820983538935, 'num_leaves': 500, 'subsample': 0.9698483861715215, 'colsample_bytree': 0.1454865342825058, 'min_child_weight': 0.029240553563896318, 'reg_alpha': 2.1901732410510784, 'reg_lambda': 11.165133840736212}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:21,510] Trial 158 finished with value: 0.08703127023730818 and parameters: {'max_depth': 2, 'learning_rate': 0.06194748170157117, 'num_leaves': 493, 'subsample': 0.976881558509215, 'colsample_bytree': 0.14896626063920732, 'min_child_weight': 0.025394229361009824, 'reg_alpha': 6.142086745922231, 'reg_lambda': 12.350269904430107}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:27,247] Trial 159 finished with value: 0.07924409664581629 and parameters: {'max_depth': 2, 'learning_rate': 0.049427369294928074, 'num_leaves': 488, 'subsample': 0.9847460089109829, 'colsample_bytree': 0.22164465628006938, 'min_child_weight': 0.05563203382277265, 'reg_alpha': 0.06171181441901297, 'reg_lambda': 14.503547194573976}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:35,230] Trial 160 finished with value: 0.07495242813572078 and parameters: {'max_depth': 3, 'learning_rate': 0.00177107159595158, 'num_leaves': 845, 'subsample': 0.7174435866056952, 'colsample_bytree': 0.07503669098296173, 'min_child_weight': 0.08813665937084555, 'reg_alpha': 2.134578413953329, 'reg_lambda': 11.13528478284374}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:40,581] Trial 161 finished with value: 0.09065622895942649 and parameters: {'max_depth': 2, 'learning_rate': 0.07555290748723463, 'num_leaves': 546, 'subsample': 0.9468463599761688, 'colsample_bytree': 0.1297653225986692, 'min_child_weight': 0.12106988290144516, 'reg_alpha': 3.554982223560422, 'reg_lambda': 5.367659942536759}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:45,807] Trial 162 finished with value: 0.09290357565629222 and parameters: {'max_depth': 2, 'learning_rate': 0.05785893189782897, 'num_leaves': 749, 'subsample': 0.9718254537659934, 'colsample_bytree': 0.10937099851968987, 'min_child_weight': 0.03959071510313879, 'reg_alpha': 2.6173032216024676, 'reg_lambda': 2.394123880072427}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:51,058] Trial 163 finished with value: 0.09051323629696689 and parameters: {'max_depth': 2, 'learning_rate': 0.05577075334574025, 'num_leaves': 745, 'subsample': 0.9958181466408974, 'colsample_bytree': 0.10587832462658947, 'min_child_weight': 0.037694313115863035, 'reg_alpha': 0.056494346939249596, 'reg_lambda': 8.276304588024088}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:40:56,325] Trial 164 finished with value: 0.0927681869969514 and parameters: {'max_depth': 2, 'learning_rate': 0.06689134884849932, 'num_leaves': 813, 'subsample': 0.9686249019531602, 'colsample_bytree': 0.08794103739516852, 'min_child_weight': 0.06538161326591359, 'reg_alpha': 5.745202692782788, 'reg_lambda': 3.127954849091166}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:42:48,597] Trial 165 finished with value: 0.07153813741368714 and parameters: {'max_depth': 8, 'learning_rate': 0.06562150957117523, 'num_leaves': 805, 'subsample': 0.9691714699235402, 'colsample_bytree': 0.08985869467421584, 'min_child_weight': 0.06281099834032708, 'reg_alpha': 7.434416028369839, 'reg_lambda': 2.6770431405599875}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:42:53,729] Trial 166 finished with value: 0.08825062570828324 and parameters: {'max_depth': 2, 'learning_rate': 0.059218359011712365, 'num_leaves': 720, 'subsample': 0.9428354147167052, 'colsample_bytree': 0.061002594477631816, 'min_child_weight': 0.039203600932629104, 'reg_alpha': 5.169108384093239, 'reg_lambda': 4.6667917640191625}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:42:59,088] Trial 167 finished with value: 0.08938148212544514 and parameters: {'max_depth': 2, 'learning_rate': 0.0504254045927318, 'num_leaves': 568, 'subsample': 0.9226206270677717, 'colsample_bytree': 0.14244080015959745, 'min_child_weight': 0.09640025525452144, 'reg_alpha': 9.000386985106822, 'reg_lambda': 9.63888987559788}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:04,584] Trial 168 finished with value: 0.08338697915012569 and parameters: {'max_depth': 2, 'learning_rate': 0.06528138470898992, 'num_leaves': 753, 'subsample': 0.9643839377567934, 'colsample_bytree': 0.17896449455156874, 'min_child_weight': 0.024520378626118146, 'reg_alpha': 3.6312906440622736, 'reg_lambda': 2.0325262999854226}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:09,837] Trial 169 finished with value: 0.08316310431415447 and parameters: {'max_depth': 2, 'learning_rate': 0.06932353114194634, 'num_leaves': 778, 'subsample': 0.49526590041646906, 'colsample_bytree': 0.10601966595714796, 'min_child_weight': 0.06842395399733185, 'reg_alpha': 2.087101981004026, 'reg_lambda': 19.292811403373204}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:15,377] Trial 170 finished with value: 0.08239943641489827 and parameters: {'max_depth': 2, 'learning_rate': 0.05677255975562226, 'num_leaves': 816, 'subsample': 0.9088620274073822, 'colsample_bytree': 0.15789646466369378, 'min_child_weight': 0.0804413992298749, 'reg_alpha': 11.871982230487816, 'reg_lambda': 6.3909729827099095}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:20,765] Trial 171 finished with value: 0.09595149185928414 and parameters: {'max_depth': 2, 'learning_rate': 0.07323166308378726, 'num_leaves': 828, 'subsample': 0.9941985120244211, 'colsample_bytree': 0.11813775233877528, 'min_child_weight': 0.13848796995954066, 'reg_alpha': 1.7976133224041408, 'reg_lambda': 4.626285584795961}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:26,501] Trial 172 finished with value: 0.07224972000547952 and parameters: {'max_depth': 2, 'learning_rate': 0.08034756538667456, 'num_leaves': 791, 'subsample': 0.9997969831214405, 'colsample_bytree': 0.6374294909646636, 'min_child_weight': 0.15428003000248863, 'reg_alpha': 4.262541801404541, 'reg_lambda': 3.8022285800741176}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:31,791] Trial 173 finished with value: 0.0939779828244558 and parameters: {'max_depth': 2, 'learning_rate': 0.06119934244015156, 'num_leaves': 828, 'subsample': 0.9800164162270003, 'colsample_bytree': 0.08913845743933427, 'min_child_weight': 0.10952447194303441, 'reg_alpha': 6.437651344561956, 'reg_lambda': 0.039355209331476626}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:36,952] Trial 174 finished with value: 0.0844995284439528 and parameters: {'max_depth': 2, 'learning_rate': 0.07028520944650733, 'num_leaves': 821, 'subsample': 0.976217395194519, 'colsample_bytree': 0.08218116905665132, 'min_child_weight': 0.11581853096519677, 'reg_alpha': 6.589564264456792, 'reg_lambda': 0.8793808914992258}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:42,276] Trial 175 finished with value: 0.0836819619527284 and parameters: {'max_depth': 2, 'learning_rate': 0.06248943894494813, 'num_leaves': 801, 'subsample': 0.9609563559327594, 'colsample_bytree': 0.11438206310078095, 'min_child_weight': 0.167288473506301, 'reg_alpha': 4.799438493191037, 'reg_lambda': 81.42864270417145}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:47,661] Trial 176 finished with value: 0.09054656665105454 and parameters: {'max_depth': 2, 'learning_rate': 0.08926625119907976, 'num_leaves': 864, 'subsample': 0.9305494677447693, 'colsample_bytree': 0.13821726700328343, 'min_child_weight': 0.1326782204466629, 'reg_alpha': 2.3629103612141735, 'reg_lambda': 2.394028585761127}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:52,913] Trial 177 finished with value: 0.08917797597745569 and parameters: {'max_depth': 2, 'learning_rate': 0.08045759598880481, 'num_leaves': 732, 'subsample': 0.9739381374545029, 'colsample_bytree': 0.08445155266433144, 'min_child_weight': 0.09471740679770722, 'reg_alpha': 8.637073913027297, 'reg_lambda': 8.153370792263477}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:43:58,020] Trial 178 finished with value: 0.0849109994623574 and parameters: {'max_depth': 2, 'learning_rate': 0.07341595623293033, 'num_leaves': 434, 'subsample': 0.9994043854900696, 'colsample_bytree': 0.06579812953300455, 'min_child_weight': 0.10617198363929838, 'reg_alpha': 6.7391973211507405, 'reg_lambda': 4.044465928666698}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:03,398] Trial 179 finished with value: 0.09660012149246061 and parameters: {'max_depth': 2, 'learning_rate': 0.06286221925540289, 'num_leaves': 780, 'subsample': 0.9428846036173689, 'colsample_bytree': 0.12186299910901499, 'min_child_weight': 0.1933262637661966, 'reg_alpha': 1.8729281692051087, 'reg_lambda': 0.8636998911181326}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:08,587] Trial 180 finished with value: 0.08636730534105956 and parameters: {'max_depth': 2, 'learning_rate': 0.05953097026377791, 'num_leaves': 513, 'subsample': 0.9422812379334197, 'colsample_bytree': 0.11491328937862658, 'min_child_weight': 0.1888597036807056, 'reg_alpha': 10.373838574699992, 'reg_lambda': 0.9006099683139157}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:13,975] Trial 181 finished with value: 0.09078288555051478 and parameters: {'max_depth': 2, 'learning_rate': 0.06825267375589687, 'num_leaves': 758, 'subsample': 0.9593919324873648, 'colsample_bytree': 0.12739101041233503, 'min_child_weight': 0.15502292463876877, 'reg_alpha': 2.4493271303787694, 'reg_lambda': 3.778743275978202}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:19,436] Trial 182 finished with value: 0.08545623077473485 and parameters: {'max_depth': 2, 'learning_rate': 0.06455653382086013, 'num_leaves': 605, 'subsample': 0.9835967129288512, 'colsample_bytree': 0.15615157261966273, 'min_child_weight': 0.1351265454648721, 'reg_alpha': 4.615318250317802, 'reg_lambda': 0.15285526799606164}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:24,703] Trial 183 finished with value: 0.0888223890613608 and parameters: {'max_depth': 2, 'learning_rate': 0.07636121629800133, 'num_leaves': 786, 'subsample': 0.9281826314154311, 'colsample_bytree': 0.09450258054514178, 'min_child_weight': 0.05538432788909051, 'reg_alpha': 1.4629894507962815, 'reg_lambda': 6.3748527524216705}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:30,103] Trial 184 finished with value: 0.09267940071884816 and parameters: {'max_depth': 2, 'learning_rate': 0.057205569561944246, 'num_leaves': 830, 'subsample': 0.9500690218648109, 'colsample_bytree': 0.13777125919059055, 'min_child_weight': 0.07798267190519709, 'reg_alpha': 3.466836604118567, 'reg_lambda': 2.615940665712138}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:35,374] Trial 185 finished with value: 0.09053163724440479 and parameters: {'max_depth': 2, 'learning_rate': 0.05422829028882735, 'num_leaves': 818, 'subsample': 0.9475292939434063, 'colsample_bytree': 0.11403387628371067, 'min_child_weight': 0.1716527058810358, 'reg_alpha': 5.529156059580875, 'reg_lambda': 2.555434373230432}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:40,742] Trial 186 finished with value: 0.09059614611708938 and parameters: {'max_depth': 2, 'learning_rate': 0.05936911907947325, 'num_leaves': 548, 'subsample': 0.9009501783127911, 'colsample_bytree': 0.14730626542575284, 'min_child_weight': 0.10995596205323444, 'reg_alpha': 4.222274468138113, 'reg_lambda': 0.2587304364881531}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:46,240] Trial 187 finished with value: 0.0857250267599277 and parameters: {'max_depth': 2, 'learning_rate': 0.08666693534509465, 'num_leaves': 841, 'subsample': 0.9717581480528433, 'colsample_bytree': 0.1752455556437085, 'min_child_weight': 0.13500404841274727, 'reg_alpha': 7.592592701761141, 'reg_lambda': 4.454678625640209}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:52,993] Trial 188 finished with value: 0.07503626612946657 and parameters: {'max_depth': 2, 'learning_rate': 0.04739800640289425, 'num_leaves': 859, 'subsample': 0.9814326050420837, 'colsample_bytree': 0.5049793058321428, 'min_child_weight': 0.08182408887835244, 'reg_alpha': 2.4852312563660894, 'reg_lambda': 9.948333176433076}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:44:58,163] Trial 189 finished with value: 0.06536246042908639 and parameters: {'max_depth': 2, 'learning_rate': 0.001416479398809706, 'num_leaves': 798, 'subsample': 0.9566149200742161, 'colsample_bytree': 0.08184522399900769, 'min_child_weight': 0.20672104034338268, 'reg_alpha': 3.264744613673529, 'reg_lambda': 2.2763489868402464}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:45:03,341] Trial 190 finished with value: 0.08059511457199497 and parameters: {'max_depth': 2, 'learning_rate': 0.06530633707414107, 'num_leaves': 825, 'subsample': 0.91873238865309, 'colsample_bytree': 0.05105956486379744, 'min_child_weight': 0.1546776873652877, 'reg_alpha': 6.057801539255593, 'reg_lambda': 7.39401538574226}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:45:08,845] Trial 191 finished with value: 0.09241682537977519 and parameters: {'max_depth': 2, 'learning_rate': 0.07199298340750367, 'num_leaves': 771, 'subsample': 0.9393320019098015, 'colsample_bytree': 0.1322115936111308, 'min_child_weight': 0.04664642478912709, 'reg_alpha': 1.6015870068370588, 'reg_lambda': 5.4285774578759}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:45:14,249] Trial 192 finished with value: 0.089361973713072 and parameters: {'max_depth': 2, 'learning_rate': 0.07756766130435268, 'num_leaves': 753, 'subsample': 0.9401234910534177, 'colsample_bytree': 0.12903186223364813, 'min_child_weight': 0.046733833012608306, 'reg_alpha': 1.7940756658540946, 'reg_lambda': 5.281636721865465}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:45:19,540] Trial 193 finished with value: 0.0937487158097717 and parameters: {'max_depth': 2, 'learning_rate': 0.05899987749639106, 'num_leaves': 783, 'subsample': 0.9836335831788501, 'colsample_bytree': 0.10147916395269507, 'min_child_weight': 0.11467937326111288, 'reg_alpha': 3.94756781670071, 'reg_lambda': 0.0175589942773352}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:45:25,066] Trial 194 finished with value: 0.08596334306252273 and parameters: {'max_depth': 2, 'learning_rate': 0.05836766308432414, 'num_leaves': 782, 'subsample': 0.9854056470097169, 'colsample_bytree': 0.15764249144607387, 'min_child_weight': 0.09227905419506001, 'reg_alpha': 4.030594631573088, 'reg_lambda': 2.0926509027652287}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:45:30,365] Trial 195 finished with value: 0.09042539015943588 and parameters: {'max_depth': 2, 'learning_rate': 0.06262022768752133, 'num_leaves': 765, 'subsample': 0.9977187628597588, 'colsample_bytree': 0.10026678697293544, 'min_child_weight': 0.2310227698801804, 'reg_alpha': 7.356715559636243, 'reg_lambda': 0.06710830886717023}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:45:35,763] Trial 196 finished with value: 0.08563601133882401 and parameters: {'max_depth': 2, 'learning_rate': 0.052792371936647986, 'num_leaves': 803, 'subsample': 0.9497749615688508, 'colsample_bytree': 0.14007463029599224, 'min_child_weight': 0.027801647453346706, 'reg_alpha': 78.96955942025699, 'reg_lambda': 3.447745566881453}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:45:41,155] Trial 197 finished with value: 0.09087848532654191 and parameters: {'max_depth': 2, 'learning_rate': 0.06942028566694676, 'num_leaves': 583, 'subsample': 0.9598793648238453, 'colsample_bytree': 0.11893791570700321, 'min_child_weight': 0.07547749443723376, 'reg_alpha': 5.675135217642183, 'reg_lambda': 4.5353444449401366}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:45:46,316] Trial 198 finished with value: 0.08940639632792463 and parameters: {'max_depth': 2, 'learning_rate': 0.04458086562345476, 'num_leaves': 742, 'subsample': 0.9679233492357863, 'colsample_bytree': 0.08184082678192342, 'min_child_weight': 0.11180866769812277, 'reg_alpha': 2.450390015687553, 'reg_lambda': 2.1439469305483034}. Best is trial 140 with value: 0.09772799338898451.\n",
      "[I 2025-07-11 13:48:33,565] Trial 199 finished with value: 0.04538699591630212 and parameters: {'max_depth': 9, 'learning_rate': 0.056698425360090066, 'num_leaves': 782, 'subsample': 0.9999703873290133, 'colsample_bytree': 0.11900560189252027, 'min_child_weight': 0.047506666960583484, 'reg_alpha': 9.553200238571895, 'reg_lambda': 9.128559237791745}. Best is trial 140 with value: 0.09772799338898451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 2, 'learning_rate': 0.0661089138508364, 'num_leaves': 624, 'subsample': 0.9917736733153091, 'colsample_bytree': 0.11884820157035034, 'min_child_weight': 0.08526601251586977, 'reg_alpha': 3.699339007638837, 'reg_lambda': 6.960245914436728}\n",
      "Best Pearson score: 0.09772799338898451\n"
     ]
    }
   ],
   "source": [
    "best_lightgbm_params_common_truncated = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features)}_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features)}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfaacf4",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_catboost_params_common_truncated = optimize_catboost(\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291147c",
   "metadata": {},
   "source": [
    "Analyze model performance and feature importance across train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6913016",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    xgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    xgbr_arr.append(xgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state,\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    lgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    lgbr_arr.append(lgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances = {}\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    features = xgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "    features = lgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df_common_truncated = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df_common_truncated[\"importance\"] = 1/2 * (feature_importances_df_common_truncated[\"importance_xgboost\"] + feature_importances_df_common_truncated[\"importance_lightgbm\"])\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "feature_importances_df_common_truncated[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df_common_truncated[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df_common_truncated[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f13d6b",
   "metadata": {},
   "source": [
    "#### Fourth iteration: Adding popular feature on top of truncated X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8a9c3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6] [8, 9, 10, 11]\n",
      "[4, 5, 6, 7] [9, 10, 11, 12]\n",
      "[5, 6, 7, 8] [10, 11, 12, 1]\n",
      "[6, 7, 8, 9] [11, 12, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "best_features = ['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', \n",
    "                 'X466', 'X95', 'X23', 'X219', 'X31', 'X373', 'X379', 'X284', 'X750', 'X652', \n",
    "                 'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X272', 'X271', 'X218'] + \\\n",
    "                [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] \n",
    "# Since the features are already normalized, we cannot use the newly created features like order_flow_imbalance,\n",
    "# since they lose their meanings already, but we can still use the old popular features\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c758740",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bbe0881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 13:53:27,750] A new study created in RDB with name: xgboost_2_4_101_1000_common_truncated_30_popular_feature_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 13:53:41,404] Trial 0 finished with value: 0.08347580946595051 and parameters: {'max_depth': 6, 'learning_rate': 0.013846345806771068, 'subsample': 0.0770505151541921, 'colsample_bytree': 0.2129455734138479, 'colsample_bynode': 0.7010131326124469, 'colsample_bylevel': 0.8422020195042726, 'min_child_weight': 4, 'reg_alpha': 89.36130796833973, 'reg_lambda': 72.15438617683047, 'gamma': 0.9496947710239839}. Best is trial 0 with value: 0.08347580946595051.\n",
      "[I 2025-07-11 13:53:58,805] Trial 1 finished with value: 0.08644232521119263 and parameters: {'max_depth': 6, 'learning_rate': 0.0050613213026475335, 'subsample': 0.22279778252707472, 'colsample_bytree': 0.7963216737711408, 'colsample_bynode': 0.9672090612913707, 'colsample_bylevel': 0.27073597872402266, 'min_child_weight': 1, 'reg_alpha': 60.35484222912185, 'reg_lambda': 72.89927572876178, 'gamma': 1.381194142486314}. Best is trial 1 with value: 0.08644232521119263.\n",
      "[I 2025-07-11 13:54:10,788] Trial 2 finished with value: 0.08288564666902314 and parameters: {'max_depth': 8, 'learning_rate': 0.010857627761370678, 'subsample': 0.09606031055508055, 'colsample_bytree': 0.1809757756840008, 'colsample_bynode': 0.227619054831025, 'colsample_bylevel': 0.9946020060963922, 'min_child_weight': 6, 'reg_alpha': 57.87895354754169, 'reg_lambda': 73.48190582693819, 'gamma': 2.709808861147968}. Best is trial 1 with value: 0.08644232521119263.\n",
      "[I 2025-07-11 13:54:22,657] Trial 3 finished with value: 0.08695219008449791 and parameters: {'max_depth': 10, 'learning_rate': 0.04128956447911593, 'subsample': 0.43284793915909797, 'colsample_bytree': 0.38936312567974846, 'colsample_bynode': 0.9552328789753295, 'colsample_bylevel': 0.3764499989979318, 'min_child_weight': 9, 'reg_alpha': 83.0277712198797, 'reg_lambda': 53.81614492475574, 'gamma': 4.612346862836118}. Best is trial 3 with value: 0.08695219008449791.\n",
      "[I 2025-07-11 13:54:30,849] Trial 4 finished with value: 0.07201548475490865 and parameters: {'max_depth': 2, 'learning_rate': 0.0016058130623353558, 'subsample': 0.7164319309110344, 'colsample_bytree': 0.8959558756720097, 'colsample_bynode': 0.20158228585329385, 'colsample_bylevel': 0.3117939176521059, 'min_child_weight': 7, 'reg_alpha': 16.430312402017023, 'reg_lambda': 70.13711366090864, 'gamma': 2.4381761110286404}. Best is trial 3 with value: 0.08695219008449791.\n",
      "[I 2025-07-11 13:54:48,834] Trial 5 finished with value: 0.08754048104444692 and parameters: {'max_depth': 8, 'learning_rate': 0.011043236795269145, 'subsample': 0.09122685971238012, 'colsample_bytree': 0.26273977332687876, 'colsample_bynode': 0.5964448325246123, 'colsample_bylevel': 0.16441197712092778, 'min_child_weight': 6, 'reg_alpha': 13.8009568258896, 'reg_lambda': 5.280840108926621, 'gamma': 0.8913846126807584}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:54:58,887] Trial 6 finished with value: 0.07582603616080327 and parameters: {'max_depth': 5, 'learning_rate': 0.05690817380795722, 'subsample': 0.9518009225359342, 'colsample_bytree': 0.504259045950091, 'colsample_bynode': 0.48806337517211296, 'colsample_bylevel': 0.6554245794664891, 'min_child_weight': 4, 'reg_alpha': 11.757809302799405, 'reg_lambda': 5.110099639577459, 'gamma': 3.1882932640891264}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:55:20,803] Trial 7 finished with value: 0.07877645930539653 and parameters: {'max_depth': 9, 'learning_rate': 0.021903869365420096, 'subsample': 0.6691793183025508, 'colsample_bytree': 0.45334049638369517, 'colsample_bynode': 0.6737655693895496, 'colsample_bylevel': 0.24870342391787859, 'min_child_weight': 7, 'reg_alpha': 52.962339875301446, 'reg_lambda': 74.85203698504924, 'gamma': 0.46878427934628986}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:55:35,593] Trial 8 finished with value: 0.08121820843044894 and parameters: {'max_depth': 9, 'learning_rate': 0.023685582791520273, 'subsample': 0.7103245716826961, 'colsample_bytree': 0.5220231936169049, 'colsample_bynode': 0.976593070682431, 'colsample_bylevel': 0.24335123957144503, 'min_child_weight': 3, 'reg_alpha': 22.765589279419316, 'reg_lambda': 4.816888544201381, 'gamma': 4.51985678726306}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:55:44,021] Trial 9 finished with value: 0.08562303843246895 and parameters: {'max_depth': 2, 'learning_rate': 0.016384475510214467, 'subsample': 0.6493043684499376, 'colsample_bytree': 0.4090448353015824, 'colsample_bynode': 0.0625789605320767, 'colsample_bylevel': 0.8501084412583794, 'min_child_weight': 4, 'reg_alpha': 55.16658450763543, 'reg_lambda': 71.05381400635508, 'gamma': 3.3763942535951474}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:55:55,778] Trial 10 finished with value: 0.08384652220229483 and parameters: {'max_depth': 4, 'learning_rate': 0.004033753369606664, 'subsample': 0.4049052035457443, 'colsample_bytree': 0.05122781195766579, 'colsample_bynode': 0.4815898987695546, 'colsample_bylevel': 0.05730216080796216, 'min_child_weight': 10, 'reg_alpha': 32.16536223784547, 'reg_lambda': 27.281458338385978, 'gamma': 0.06402856674794899}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:56:04,521] Trial 11 finished with value: 0.08055398560781013 and parameters: {'max_depth': 10, 'learning_rate': 0.08976275936403384, 'subsample': 0.3808407789284378, 'colsample_bytree': 0.2780869943246074, 'colsample_bynode': 0.7804348738131006, 'colsample_bylevel': 0.47129536073666406, 'min_child_weight': 10, 'reg_alpha': 99.94726704942818, 'reg_lambda': 39.26788529675173, 'gamma': 4.7333219504443615}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:56:17,261] Trial 12 finished with value: 0.08255583346178699 and parameters: {'max_depth': 8, 'learning_rate': 0.04253012636559527, 'subsample': 0.2754707098318711, 'colsample_bytree': 0.6860945039832803, 'colsample_bynode': 0.8026660745989422, 'colsample_bylevel': 0.07994081186204273, 'min_child_weight': 8, 'reg_alpha': 80.80396376610861, 'reg_lambda': 48.83028679173438, 'gamma': 1.8068544518326868}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:56:43,709] Trial 13 finished with value: 0.08043616640246615 and parameters: {'max_depth': 10, 'learning_rate': 0.005326730223313553, 'subsample': 0.5012615534555591, 'colsample_bytree': 0.3311402045373566, 'colsample_bynode': 0.5825842631417751, 'colsample_bylevel': 0.4583819395854084, 'min_child_weight': 9, 'reg_alpha': 2.563621216573962, 'reg_lambda': 25.137701289237548, 'gamma': 3.973099252125145}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:56:57,562] Trial 14 finished with value: 0.08408688426801636 and parameters: {'max_depth': 8, 'learning_rate': 0.03731238593515763, 'subsample': 0.207017116215725, 'colsample_bytree': 0.6718402246313706, 'colsample_bynode': 0.32014219966204727, 'colsample_bylevel': 0.5828688233044852, 'min_child_weight': 8, 'reg_alpha': 74.00657814865465, 'reg_lambda': 93.20640611332419, 'gamma': 1.8114792659475474}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:57:14,223] Trial 15 finished with value: 0.08265106600884682 and parameters: {'max_depth': 7, 'learning_rate': 0.0015354103584146513, 'subsample': 0.904129671108405, 'colsample_bytree': 0.06367096969373695, 'colsample_bynode': 0.844777156110565, 'colsample_bylevel': 0.39182775681828896, 'min_child_weight': 6, 'reg_alpha': 39.20987279741132, 'reg_lambda': 52.62787316436076, 'gamma': 4.077856976545283}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:57:33,249] Trial 16 finished with value: 0.08380550002712478 and parameters: {'max_depth': 10, 'learning_rate': 0.0075166013352732704, 'subsample': 0.36193706358402533, 'colsample_bytree': 0.35836959451917433, 'colsample_bynode': 0.5892156100202091, 'colsample_bylevel': 0.1363428824337513, 'min_child_weight': 1, 'reg_alpha': 70.51512994362812, 'reg_lambda': 19.320585968376236, 'gamma': 2.2708105513180414}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:57:53,513] Trial 17 finished with value: 0.08008663810501664 and parameters: {'max_depth': 9, 'learning_rate': 0.028697905679710582, 'subsample': 0.5245091701014817, 'colsample_bytree': 0.6133531088382798, 'colsample_bynode': 0.3840286079492211, 'colsample_bylevel': 0.3585486618713584, 'min_child_weight': 8, 'reg_alpha': 40.09651103016735, 'reg_lambda': 56.90769511198274, 'gamma': 1.0354207048219932}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:58:11,323] Trial 18 finished with value: 0.0835526614553675 and parameters: {'max_depth': 7, 'learning_rate': 0.0027165969441890325, 'subsample': 0.8444503968943656, 'colsample_bytree': 0.19123980457351983, 'colsample_bynode': 0.9003301152007738, 'colsample_bylevel': 0.17428083133810013, 'min_child_weight': 5, 'reg_alpha': 0.07178677256159816, 'reg_lambda': 35.11315722984547, 'gamma': 3.33822744454299}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:58:19,192] Trial 19 finished with value: 0.08588902952220176 and parameters: {'max_depth': 7, 'learning_rate': 0.07373215854577415, 'subsample': 0.1471593646192594, 'colsample_bytree': 0.9866005739729706, 'colsample_bynode': 0.7142448933855341, 'colsample_bylevel': 0.6099521131942657, 'min_child_weight': 9, 'reg_alpha': 97.15045358194817, 'reg_lambda': 99.99114602238669, 'gamma': 3.856347321752539}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:58:40,504] Trial 20 finished with value: 0.08328396029178115 and parameters: {'max_depth': 9, 'learning_rate': 0.010199403410260039, 'subsample': 0.31136846948121216, 'colsample_bytree': 0.3178705920093581, 'colsample_bynode': 0.605130214287856, 'colsample_bylevel': 0.17752755505628948, 'min_child_weight': 2, 'reg_alpha': 67.36544699177364, 'reg_lambda': 16.17342106971803, 'gamma': 0.041086145992923706}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:58:54,560] Trial 21 finished with value: 0.0844204396855025 and parameters: {'max_depth': 5, 'learning_rate': 0.0029445696565726757, 'subsample': 0.227521668576905, 'colsample_bytree': 0.8475617477811165, 'colsample_bynode': 0.9939732238107073, 'colsample_bylevel': 0.2850689041809565, 'min_child_weight': 1, 'reg_alpha': 85.02329976560883, 'reg_lambda': 60.568051895196305, 'gamma': 1.3619519353493121}. Best is trial 5 with value: 0.08754048104444692.\n",
      "[I 2025-07-11 13:59:11,196] Trial 22 finished with value: 0.08784413634085302 and parameters: {'max_depth': 6, 'learning_rate': 0.006624235265807322, 'subsample': 0.1720621147174216, 'colsample_bytree': 0.8015610369912111, 'colsample_bynode': 0.8860557540259348, 'colsample_bylevel': 0.4050957611202102, 'min_child_weight': 5, 'reg_alpha': 64.3220802252118, 'reg_lambda': 82.81577258840052, 'gamma': 1.5644037186069788}. Best is trial 22 with value: 0.08784413634085302.\n",
      "[I 2025-07-11 13:59:23,023] Trial 23 finished with value: 0.09085893276782345 and parameters: {'max_depth': 4, 'learning_rate': 0.008921475859388881, 'subsample': 0.06798053122922099, 'colsample_bytree': 0.5698939257938769, 'colsample_bynode': 0.8459779414313349, 'colsample_bylevel': 0.4263218845607095, 'min_child_weight': 5, 'reg_alpha': 43.56792521690515, 'reg_lambda': 87.42951792986116, 'gamma': 0.6392163177002363}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 13:59:33,513] Trial 24 finished with value: 0.08799658594181439 and parameters: {'max_depth': 3, 'learning_rate': 0.007888923866861446, 'subsample': 0.05065596339674678, 'colsample_bytree': 0.5958774177059865, 'colsample_bynode': 0.8579320403040661, 'colsample_bylevel': 0.7046552286667387, 'min_child_weight': 5, 'reg_alpha': 43.58861113599023, 'reg_lambda': 84.82007784195007, 'gamma': 0.6249353878651462}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 13:59:43,937] Trial 25 finished with value: 0.08758609592718364 and parameters: {'max_depth': 3, 'learning_rate': 0.007593448078865399, 'subsample': 0.16956364742894703, 'colsample_bytree': 0.6023001219573425, 'colsample_bynode': 0.8822387411196686, 'colsample_bylevel': 0.7096313633604907, 'min_child_weight': 5, 'reg_alpha': 46.29301418915478, 'reg_lambda': 87.68625844808327, 'gamma': 0.5199277856486365}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 13:59:54,150] Trial 26 finished with value: 0.08932321985718408 and parameters: {'max_depth': 3, 'learning_rate': 0.006826858241763606, 'subsample': 0.05584139396337792, 'colsample_bytree': 0.7393083018789646, 'colsample_bynode': 0.7946331818502024, 'colsample_bylevel': 0.5343713858838487, 'min_child_weight': 3, 'reg_alpha': 27.472919897954956, 'reg_lambda': 85.20215701144434, 'gamma': 0.48923651086447006}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:00:04,649] Trial 27 finished with value: 0.08385818119316014 and parameters: {'max_depth': 3, 'learning_rate': 0.002854410709785814, 'subsample': 0.06535080125377701, 'colsample_bytree': 0.6077593197693352, 'colsample_bynode': 0.7560157386573334, 'colsample_bylevel': 0.5266213575355386, 'min_child_weight': 3, 'reg_alpha': 29.525939597177814, 'reg_lambda': 83.28971820609326, 'gamma': 0.4941918065522258}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:00:15,367] Trial 28 finished with value: 0.08202819627792879 and parameters: {'max_depth': 3, 'learning_rate': 0.01572269227408841, 'subsample': 0.2974731322580216, 'colsample_bytree': 0.7199259600465849, 'colsample_bynode': 0.8038966427744225, 'colsample_bylevel': 0.7282651684497908, 'min_child_weight': 3, 'reg_alpha': 45.91790153374954, 'reg_lambda': 99.92881616277654, 'gamma': 0.3613308922732945}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:00:27,803] Trial 29 finished with value: 0.08182103552224487 and parameters: {'max_depth': 4, 'learning_rate': 0.0010707309891665648, 'subsample': 0.05587793483498961, 'colsample_bytree': 0.746335441033811, 'colsample_bynode': 0.7006415246582152, 'colsample_bylevel': 0.8518541153000514, 'min_child_weight': 4, 'reg_alpha': 29.191249734940964, 'reg_lambda': 63.815779228448804, 'gamma': 0.8837746166249087}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:00:39,710] Trial 30 finished with value: 0.08890769802820103 and parameters: {'max_depth': 4, 'learning_rate': 0.0039893714954970716, 'subsample': 0.11906408517969708, 'colsample_bytree': 0.5489163481111299, 'colsample_bynode': 0.6616357215747017, 'colsample_bylevel': 0.7651783587572342, 'min_child_weight': 2, 'reg_alpha': 38.452372111069664, 'reg_lambda': 91.164462743775, 'gamma': 1.0234609835151929}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:00:52,392] Trial 31 finished with value: 0.08525375215494238 and parameters: {'max_depth': 4, 'learning_rate': 0.004531567646295595, 'subsample': 0.12713889797125147, 'colsample_bytree': 0.5729053887617856, 'colsample_bynode': 0.6553772561408776, 'colsample_bylevel': 0.7798161678363214, 'min_child_weight': 2, 'reg_alpha': 37.81059521141621, 'reg_lambda': 91.40339738299001, 'gamma': 1.010642173119687}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:01:06,531] Trial 32 finished with value: 0.08880578858251566 and parameters: {'max_depth': 5, 'learning_rate': 0.006450618180009775, 'subsample': 0.12025313187651171, 'colsample_bytree': 0.45762429817968, 'colsample_bynode': 0.7493437638719921, 'colsample_bylevel': 0.944142554161688, 'min_child_weight': 2, 'reg_alpha': 47.76076871014551, 'reg_lambda': 78.99127655863337, 'gamma': 0.7364870927411232}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:01:21,039] Trial 33 finished with value: 0.0813907590534932 and parameters: {'max_depth': 5, 'learning_rate': 0.0033989389148739173, 'subsample': 0.22526687476525442, 'colsample_bytree': 0.4590161554655733, 'colsample_bynode': 0.7417451294487062, 'colsample_bylevel': 0.9771583322797378, 'min_child_weight': 2, 'reg_alpha': 34.8899331729598, 'reg_lambda': 78.58635098581817, 'gamma': 1.4561311926676646}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:01:33,262] Trial 34 finished with value: 0.08848924479369757 and parameters: {'max_depth': 4, 'learning_rate': 0.0056424382778784, 'subsample': 0.12058002388564391, 'colsample_bytree': 0.45618096252182216, 'colsample_bynode': 0.6485603623581213, 'colsample_bylevel': 0.9229151250480558, 'min_child_weight': 2, 'reg_alpha': 50.451299966623125, 'reg_lambda': 92.66970585655372, 'gamma': 1.2026947021110626}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:01:48,013] Trial 35 finished with value: 0.08343993653104717 and parameters: {'max_depth': 5, 'learning_rate': 0.013291274352203737, 'subsample': 0.254866720599805, 'colsample_bytree': 0.5400273714280001, 'colsample_bynode': 0.9265675283326049, 'colsample_bylevel': 0.8992493543332607, 'min_child_weight': 3, 'reg_alpha': 23.500616745205548, 'reg_lambda': 66.48093524233998, 'gamma': 2.0733208051007415}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:01:56,436] Trial 36 finished with value: 0.07144609043979303 and parameters: {'max_depth': 2, 'learning_rate': 0.0020298463381868926, 'subsample': 0.1773596442020488, 'colsample_bytree': 0.659306275743027, 'colsample_bynode': 0.784964442168856, 'colsample_bylevel': 0.7650548907513837, 'min_child_weight': 1, 'reg_alpha': 22.460648064263452, 'reg_lambda': 78.39745727132936, 'gamma': 0.7336142545284694}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:02:12,682] Trial 37 finished with value: 0.088307768754947 and parameters: {'max_depth': 6, 'learning_rate': 0.0040782379786451755, 'subsample': 0.12433657607628801, 'colsample_bytree': 0.7733487339233479, 'colsample_bynode': 0.5294625334311666, 'colsample_bylevel': 0.5377084795838563, 'min_child_weight': 4, 'reg_alpha': 60.48656050599912, 'reg_lambda': 95.89341719401439, 'gamma': 0.2757769334892616}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:02:24,888] Trial 38 finished with value: 0.08060879247151388 and parameters: {'max_depth': 4, 'learning_rate': 0.009680343119075688, 'subsample': 0.46107935963932745, 'colsample_bytree': 0.417230911241952, 'colsample_bynode': 0.8219269074081128, 'colsample_bylevel': 0.6504505616555237, 'min_child_weight': 2, 'reg_alpha': 48.85191832649861, 'reg_lambda': 88.29533418188235, 'gamma': 1.1948480162771786}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:02:39,004] Trial 39 finished with value: 0.07517676732836133 and parameters: {'max_depth': 5, 'learning_rate': 0.002246163679106484, 'subsample': 0.5823347720706415, 'colsample_bytree': 0.5041977266909274, 'colsample_bynode': 0.7243456674483268, 'colsample_bylevel': 0.9888793216258414, 'min_child_weight': 3, 'reg_alpha': 16.7680633875449, 'reg_lambda': 78.42005105749801, 'gamma': 0.7532099306076122}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:02:49,341] Trial 40 finished with value: 0.07341463172585702 and parameters: {'max_depth': 3, 'learning_rate': 0.00623623337942321, 'subsample': 0.33939224783587774, 'colsample_bytree': 0.9019628258435907, 'colsample_bynode': 0.9489260569285991, 'colsample_bylevel': 0.8923845430043157, 'min_child_weight': 1, 'reg_alpha': 7.641483286219163, 'reg_lambda': 74.10539492685562, 'gamma': 2.6164705118141445}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:03:01,475] Trial 41 finished with value: 0.08751735543443769 and parameters: {'max_depth': 4, 'learning_rate': 0.004934837641691323, 'subsample': 0.10692868982720088, 'colsample_bytree': 0.4763573023356099, 'colsample_bynode': 0.6705920002311452, 'colsample_bylevel': 0.9194613891710033, 'min_child_weight': 2, 'reg_alpha': 51.00201067749801, 'reg_lambda': 90.5003222212488, 'gamma': 1.1834817261585808}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:03:14,426] Trial 42 finished with value: 0.08853980327682176 and parameters: {'max_depth': 4, 'learning_rate': 0.006062032803910152, 'subsample': 0.10618583596420127, 'colsample_bytree': 0.4253444214934767, 'colsample_bynode': 0.6350900187251975, 'colsample_bylevel': 0.8020359143294529, 'min_child_weight': 2, 'reg_alpha': 58.20895813988343, 'reg_lambda': 95.6019522984964, 'gamma': 0.2588357495731408}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:03:29,213] Trial 43 finished with value: 0.08754217359429205 and parameters: {'max_depth': 5, 'learning_rate': 0.008744600773700931, 'subsample': 0.09282249792182898, 'colsample_bytree': 0.5456909920643955, 'colsample_bynode': 0.5253528611085482, 'colsample_bylevel': 0.46261605127341987, 'min_child_weight': 3, 'reg_alpha': 57.93896383665189, 'reg_lambda': 95.2100069197912, 'gamma': 0.20925744377323385}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:03:46,042] Trial 44 finished with value: 0.08227476215673572 and parameters: {'max_depth': 6, 'learning_rate': 0.003609620024896587, 'subsample': 0.1942125063432844, 'colsample_bytree': 0.3807219730778155, 'colsample_bynode': 0.6197695511098404, 'colsample_bylevel': 0.8132321133857163, 'min_child_weight': 1, 'reg_alpha': 55.51108311210947, 'reg_lambda': 83.1867148469409, 'gamma': 0.0515680177307912}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:03:55,098] Trial 45 finished with value: 0.08769653034734365 and parameters: {'max_depth': 2, 'learning_rate': 0.012285084245042443, 'subsample': 0.08564075072186139, 'colsample_bytree': 0.42129627777092005, 'colsample_bynode': 0.7536666553666143, 'colsample_bylevel': 0.6596634326077806, 'min_child_weight': 4, 'reg_alpha': 43.78421880508764, 'reg_lambda': 86.75716687147295, 'gamma': 0.7400322237706036}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:04:05,350] Trial 46 finished with value: 0.08219614984691893 and parameters: {'max_depth': 3, 'learning_rate': 0.017995532643865202, 'subsample': 0.23208216915916122, 'colsample_bytree': 0.6412278247633498, 'colsample_bynode': 0.45521859080383426, 'colsample_bylevel': 0.8389991197382187, 'min_child_weight': 2, 'reg_alpha': 33.9723266087352, 'reg_lambda': 70.30793489797968, 'gamma': 0.35194316366787703}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:04:17,569] Trial 47 finished with value: 0.08354422280716102 and parameters: {'max_depth': 4, 'learning_rate': 0.006662267127017293, 'subsample': 0.14010863094417356, 'colsample_bytree': 0.24103122817113654, 'colsample_bynode': 0.6963698246569504, 'colsample_bylevel': 0.3361064517047684, 'min_child_weight': 7, 'reg_alpha': 25.575390656943203, 'reg_lambda': 80.69866092609804, 'gamma': 1.6503130064813298}. Best is trial 23 with value: 0.09085893276782345.\n",
      "[I 2025-07-11 14:04:29,209] Trial 48 finished with value: 0.09255002854620495 and parameters: {'max_depth': 4, 'learning_rate': 0.011519542065426666, 'subsample': 0.05467838686695978, 'colsample_bytree': 0.7033566492035458, 'colsample_bynode': 0.54829920185244, 'colsample_bylevel': 0.605500809741058, 'min_child_weight': 6, 'reg_alpha': 60.96055532047474, 'reg_lambda': 94.95796396017865, 'gamma': 3.0251132495719197}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:04:41,186] Trial 49 finished with value: 0.09150082519323757 and parameters: {'max_depth': 5, 'learning_rate': 0.011547871016453258, 'subsample': 0.0545173321889524, 'colsample_bytree': 0.7261733301451883, 'colsample_bynode': 0.8487044078113858, 'colsample_bylevel': 0.5808185895836165, 'min_child_weight': 6, 'reg_alpha': 75.68156118898781, 'reg_lambda': 76.59947773867746, 'gamma': 3.1661977272669874}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:04:49,473] Trial 50 finished with value: 0.08615394216540188 and parameters: {'max_depth': 2, 'learning_rate': 0.01127719186652433, 'subsample': 0.05792215633848545, 'colsample_bytree': 0.7043663916092946, 'colsample_bynode': 0.8468657948961846, 'colsample_bylevel': 0.5817835685723023, 'min_child_weight': 6, 'reg_alpha': 92.16494035982055, 'reg_lambda': 47.17743083585808, 'gamma': 2.8763084522810147}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:05:02,553] Trial 51 finished with value: 0.09053718574468818 and parameters: {'max_depth': 5, 'learning_rate': 0.020529490452549027, 'subsample': 0.1626504801662481, 'colsample_bytree': 0.8204261487135082, 'colsample_bynode': 0.5599300078595393, 'colsample_bylevel': 0.43464115315752855, 'min_child_weight': 7, 'reg_alpha': 40.68613258661575, 'reg_lambda': 75.36469450247984, 'gamma': 3.549691357570611}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:05:17,075] Trial 52 finished with value: 0.08622616288671373 and parameters: {'max_depth': 6, 'learning_rate': 0.020605515777675384, 'subsample': 0.15398762163269056, 'colsample_bytree': 0.8279849152921701, 'colsample_bynode': 0.551669700215639, 'colsample_bylevel': 0.4263072551448702, 'min_child_weight': 7, 'reg_alpha': 40.92520216746482, 'reg_lambda': 74.28508903707619, 'gamma': 2.9328211497406014}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:05:27,289] Trial 53 finished with value: 0.09169555595135515 and parameters: {'max_depth': 5, 'learning_rate': 0.02489905411270083, 'subsample': 0.08329603445088121, 'colsample_bytree': 0.9198293221404406, 'colsample_bynode': 0.41444844397020686, 'colsample_bylevel': 0.4965889083650484, 'min_child_weight': 7, 'reg_alpha': 76.68248605134828, 'reg_lambda': 90.074508961989, 'gamma': 3.5326415770192616}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:05:37,080] Trial 54 finished with value: 0.09153754978480745 and parameters: {'max_depth': 5, 'learning_rate': 0.02826076950554726, 'subsample': 0.07967119403513678, 'colsample_bytree': 0.9013506539699605, 'colsample_bynode': 0.4276646405361803, 'colsample_bylevel': 0.4890047829335467, 'min_child_weight': 6, 'reg_alpha': 76.1454220488559, 'reg_lambda': 67.84114507808704, 'gamma': 3.65166447053514}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:05:48,682] Trial 55 finished with value: 0.08789981837749958 and parameters: {'max_depth': 5, 'learning_rate': 0.02708978940995062, 'subsample': 0.19026906946688713, 'colsample_bytree': 0.9415025496510754, 'colsample_bynode': 0.366234048525235, 'colsample_bylevel': 0.43936338269134595, 'min_child_weight': 6, 'reg_alpha': 78.02513209293988, 'reg_lambda': 67.13866452513757, 'gamma': 3.660674983233195}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:05:59,761] Trial 56 finished with value: 0.08703846959828374 and parameters: {'max_depth': 6, 'learning_rate': 0.032839142520928594, 'subsample': 0.2624416532942462, 'colsample_bytree': 0.8726985416423834, 'colsample_bynode': 0.4606462077000957, 'colsample_bylevel': 0.5095991798083607, 'min_child_weight': 7, 'reg_alpha': 74.88695652187565, 'reg_lambda': 63.143437015573994, 'gamma': 4.264699658876689}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:06:07,542] Trial 57 finished with value: 0.08915755244459583 and parameters: {'max_depth': 5, 'learning_rate': 0.050106736143697074, 'subsample': 0.0869683007232896, 'colsample_bytree': 0.9880302925519995, 'colsample_bynode': 0.27015521916448687, 'colsample_bylevel': 0.48814862095296435, 'min_child_weight': 7, 'reg_alpha': 88.23872568370416, 'reg_lambda': 58.729431383111915, 'gamma': 3.565416894262949}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:06:20,475] Trial 58 finished with value: 0.08710685756939288 and parameters: {'max_depth': 6, 'learning_rate': 0.024134452800421455, 'subsample': 0.15795795137488994, 'colsample_bytree': 0.9151033338679144, 'colsample_bynode': 0.40720036613955285, 'colsample_bylevel': 0.5723384289871674, 'min_child_weight': 6, 'reg_alpha': 70.87324175032737, 'reg_lambda': 74.75027048277732, 'gamma': 3.1620495065419}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:06:34,750] Trial 59 finished with value: 0.08230026259129634 and parameters: {'max_depth': 5, 'learning_rate': 0.015835535509904648, 'subsample': 0.7782042812125372, 'colsample_bytree': 0.7948052524763405, 'colsample_bynode': 0.3206007864602971, 'colsample_bylevel': 0.6176345344370461, 'min_child_weight': 8, 'reg_alpha': 63.853191838711766, 'reg_lambda': 69.13883861306574, 'gamma': 3.7089664360528642}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:06:50,316] Trial 60 finished with value: 0.08262699089019526 and parameters: {'max_depth': 7, 'learning_rate': 0.018261613612197282, 'subsample': 0.9973212700691432, 'colsample_bytree': 0.8588359334685556, 'colsample_bynode': 0.14669229462975852, 'colsample_bylevel': 0.3467369222306165, 'min_child_weight': 5, 'reg_alpha': 81.05470589739646, 'reg_lambda': 98.2785058327833, 'gamma': 3.273619048981693}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:07:01,981] Trial 61 finished with value: 0.09023221064275817 and parameters: {'max_depth': 4, 'learning_rate': 0.014259354413829542, 'subsample': 0.07971787137803617, 'colsample_bytree': 0.7393458320670682, 'colsample_bynode': 0.4214120466026655, 'colsample_bylevel': 0.5013127348723667, 'min_child_weight': 6, 'reg_alpha': 75.08041360000925, 'reg_lambda': 86.0383357548374, 'gamma': 3.043529825288406}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:07:12,434] Trial 62 finished with value: 0.08968334079787094 and parameters: {'max_depth': 4, 'learning_rate': 0.014136487214014993, 'subsample': 0.08335748390439857, 'colsample_bytree': 0.9444991704820436, 'colsample_bynode': 0.41270961657859884, 'colsample_bylevel': 0.38553413968877476, 'min_child_weight': 6, 'reg_alpha': 73.23407365624735, 'reg_lambda': 88.19579797584967, 'gamma': 3.0157389670007713}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:07:22,675] Trial 63 finished with value: 0.09122008590527624 and parameters: {'max_depth': 5, 'learning_rate': 0.020138009781294354, 'subsample': 0.07969290634622399, 'colsample_bytree': 0.8268516756673876, 'colsample_bynode': 0.49794029728509626, 'colsample_bylevel': 0.49544354997667983, 'min_child_weight': 7, 'reg_alpha': 84.99245198237935, 'reg_lambda': 81.79764650480632, 'gamma': 3.5253447215678784}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:07:33,343] Trial 64 finished with value: 0.08724514952803505 and parameters: {'max_depth': 5, 'learning_rate': 0.03131229967334864, 'subsample': 0.1537737811982208, 'colsample_bytree': 0.8143623874535653, 'colsample_bynode': 0.5655448505196501, 'colsample_bylevel': 0.41292228247466545, 'min_child_weight': 7, 'reg_alpha': 86.76241129888673, 'reg_lambda': 81.61590790398486, 'gamma': 4.308741208458675}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:07:42,286] Trial 65 finished with value: 0.09118864077057717 and parameters: {'max_depth': 5, 'learning_rate': 0.020625333753200505, 'subsample': 0.05214178788261065, 'colsample_bytree': 0.7691213459623547, 'colsample_bynode': 0.34995626567122273, 'colsample_bylevel': 0.5652118480446395, 'min_child_weight': 8, 'reg_alpha': 79.37166584397275, 'reg_lambda': 71.96300259426867, 'gamma': 3.3968764221969208}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:07:50,180] Trial 66 finished with value: 0.08670618535909476 and parameters: {'max_depth': 5, 'learning_rate': 0.039831578074088984, 'subsample': 0.06580349376124761, 'colsample_bytree': 0.7646378221891661, 'colsample_bynode': 0.34155039395437303, 'colsample_bylevel': 0.6082411076648347, 'min_child_weight': 8, 'reg_alpha': 93.04748135606802, 'reg_lambda': 52.70100474586021, 'gamma': 3.443792590520404}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:08:01,952] Trial 67 finished with value: 0.08770140666941942 and parameters: {'max_depth': 6, 'learning_rate': 0.025000383567516743, 'subsample': 0.20936492693733977, 'colsample_bytree': 0.9562342889832705, 'colsample_bynode': 0.23729469238795564, 'colsample_bylevel': 0.5509240513236103, 'min_child_weight': 8, 'reg_alpha': 83.21263217774111, 'reg_lambda': 71.3215864824269, 'gamma': 4.9330007265838365}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:08:11,686] Trial 68 finished with value: 0.09235653092789886 and parameters: {'max_depth': 5, 'learning_rate': 0.04813136840115028, 'subsample': 0.10149510846290248, 'colsample_bytree': 0.6953551454616678, 'colsample_bynode': 0.28179012821460714, 'colsample_bylevel': 0.6455123260441435, 'min_child_weight': 9, 'reg_alpha': 67.57583330523323, 'reg_lambda': 43.09063225939557, 'gamma': 2.7118564994642433}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:08:20,330] Trial 69 finished with value: 0.08459828133416422 and parameters: {'max_depth': 6, 'learning_rate': 0.06774260710140961, 'subsample': 0.09538649417817995, 'colsample_bytree': 0.8796244901765928, 'colsample_bynode': 0.27494355691802624, 'colsample_bylevel': 0.6682841534235855, 'min_child_weight': 9, 'reg_alpha': 68.06483769649235, 'reg_lambda': 41.931480357737634, 'gamma': 2.749597589168084}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:08:30,059] Trial 70 finished with value: 0.09134886618268065 and parameters: {'max_depth': 5, 'learning_rate': 0.03409588779437589, 'subsample': 0.054890520848420075, 'colsample_bytree': 0.8416226273601212, 'colsample_bynode': 0.49115187756626394, 'colsample_bylevel': 0.629418813285692, 'min_child_weight': 10, 'reg_alpha': 63.364092228734485, 'reg_lambda': 33.17219535867554, 'gamma': 2.3503524699203986}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:08:41,891] Trial 71 finished with value: 0.08749491747365912 and parameters: {'max_depth': 5, 'learning_rate': 0.034229771988171225, 'subsample': 0.1250767903367106, 'colsample_bytree': 0.7789862724944157, 'colsample_bynode': 0.4906720072222694, 'colsample_bylevel': 0.6264739060751146, 'min_child_weight': 10, 'reg_alpha': 64.46171307147304, 'reg_lambda': 33.07136153349998, 'gamma': 2.2711591130569166}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:08:48,675] Trial 72 finished with value: 0.09223038560624933 and parameters: {'max_depth': 5, 'learning_rate': 0.04556805636011647, 'subsample': 0.050606900753732836, 'colsample_bytree': 0.6885220053495932, 'colsample_bynode': 0.37731799023332535, 'colsample_bylevel': 0.565724851729911, 'min_child_weight': 10, 'reg_alpha': 78.18806931246318, 'reg_lambda': 30.375943473922394, 'gamma': 3.941281795306497}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:08:57,176] Trial 73 finished with value: 0.08700679942566167 and parameters: {'max_depth': 5, 'learning_rate': 0.045502307263687244, 'subsample': 0.10716141024206738, 'colsample_bytree': 0.6975668175784399, 'colsample_bynode': 0.49539330677179605, 'colsample_bylevel': 0.6942770653102183, 'min_child_weight': 10, 'reg_alpha': 77.72592950001072, 'reg_lambda': 25.633828034650175, 'gamma': 3.9079157868813827}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:09:07,353] Trial 74 finished with value: 0.08347572338614456 and parameters: {'max_depth': 6, 'learning_rate': 0.05450994194262208, 'subsample': 0.14471642024520942, 'colsample_bytree': 0.6408726746285306, 'colsample_bynode': 0.4382137394931429, 'colsample_bylevel': 0.48289211275369326, 'min_child_weight': 9, 'reg_alpha': 69.9357424377527, 'reg_lambda': 36.018817458735676, 'gamma': 2.5092703666536695}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:09:15,271] Trial 75 finished with value: 0.08733716427353842 and parameters: {'max_depth': 6, 'learning_rate': 0.06159180139215824, 'subsample': 0.08136714333944838, 'colsample_bytree': 0.8463988846143374, 'colsample_bynode': 0.3851783325246382, 'colsample_bylevel': 0.59135385777014, 'min_child_weight': 10, 'reg_alpha': 61.32898364291739, 'reg_lambda': 31.963844175153685, 'gamma': 4.1640073747132424}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:09:23,224] Trial 76 finished with value: 0.08101778019943849 and parameters: {'max_depth': 5, 'learning_rate': 0.09317024726939976, 'subsample': 0.5964907392914104, 'colsample_bytree': 0.9173585573713434, 'colsample_bynode': 0.16261963582254246, 'colsample_bylevel': 0.6335930410460278, 'min_child_weight': 9, 'reg_alpha': 83.39899496269311, 'reg_lambda': 19.228050375072215, 'gamma': 3.7921068794662043}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:09:31,126] Trial 77 finished with value: 0.0915779986304173 and parameters: {'max_depth': 4, 'learning_rate': 0.03776687870731246, 'subsample': 0.05391151447033529, 'colsample_bytree': 0.7287884326773888, 'colsample_bynode': 0.297359221802431, 'colsample_bylevel': 0.5175170331301308, 'min_child_weight': 10, 'reg_alpha': 64.96196146765975, 'reg_lambda': 45.50624582754422, 'gamma': 2.7554166763671892}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:09:39,162] Trial 78 finished with value: 0.09183595497883809 and parameters: {'max_depth': 4, 'learning_rate': 0.04658881090055725, 'subsample': 0.05253532613534508, 'colsample_bytree': 0.6761491686983437, 'colsample_bynode': 0.28497343735500413, 'colsample_bylevel': 0.5469982020501638, 'min_child_weight': 10, 'reg_alpha': 66.66271028366906, 'reg_lambda': 41.6609634125124, 'gamma': 2.3631668254669624}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:09:50,097] Trial 79 finished with value: 0.08614759244647484 and parameters: {'max_depth': 4, 'learning_rate': 0.047561681444638966, 'subsample': 0.18515617199143386, 'colsample_bytree': 0.6767956879167538, 'colsample_bynode': 0.28726384055997806, 'colsample_bylevel': 0.5317960731349175, 'min_child_weight': 10, 'reg_alpha': 67.44137499341501, 'reg_lambda': 49.61723611766399, 'gamma': 2.1322327346249135}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:09:58,210] Trial 80 finished with value: 0.08676231987664106 and parameters: {'max_depth': 4, 'learning_rate': 0.0840312005559166, 'subsample': 0.12608064258188817, 'colsample_bytree': 0.7182576109114934, 'colsample_bynode': 0.2215584980569234, 'colsample_bylevel': 0.4567127956780771, 'min_child_weight': 9, 'reg_alpha': 72.28437069979869, 'reg_lambda': 45.59069264375943, 'gamma': 2.7641002103806556}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:10:06,847] Trial 81 finished with value: 0.08780702282518327 and parameters: {'max_depth': 4, 'learning_rate': 0.03704898792563435, 'subsample': 0.053250660273750985, 'colsample_bytree': 0.6400544662037776, 'colsample_bynode': 0.3149444188468492, 'colsample_bylevel': 0.5560587924015498, 'min_child_weight': 10, 'reg_alpha': 63.110508610384, 'reg_lambda': 41.70740650226591, 'gamma': 2.3949000599882146}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:10:16,330] Trial 82 finished with value: 0.08465293174316235 and parameters: {'max_depth': 3, 'learning_rate': 0.029111084579383883, 'subsample': 0.09980022298324163, 'colsample_bytree': 0.6607074276363177, 'colsample_bynode': 0.17561901880331188, 'colsample_bylevel': 0.5985078929656652, 'min_child_weight': 10, 'reg_alpha': 54.19928168149491, 'reg_lambda': 29.506024255788237, 'gamma': 3.172085122131613}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:10:26,113] Trial 83 finished with value: 0.09074974983283027 and parameters: {'max_depth': 4, 'learning_rate': 0.04270848074506328, 'subsample': 0.10149647627743939, 'colsample_bytree': 0.7408712611724847, 'colsample_bynode': 0.37320494973078855, 'colsample_bylevel': 0.5108928657859313, 'min_child_weight': 9, 'reg_alpha': 68.6495804327973, 'reg_lambda': 37.617912303067655, 'gamma': 2.5824142237109267}. Best is trial 48 with value: 0.09255002854620495.\n",
      "[I 2025-07-11 14:10:35,219] Trial 84 finished with value: 0.09376299917813029 and parameters: {'max_depth': 5, 'learning_rate': 0.055867033901354564, 'subsample': 0.05556874887692709, 'colsample_bytree': 0.7160668672502511, 'colsample_bynode': 0.2594570432591158, 'colsample_bylevel': 0.6752761327222085, 'min_child_weight': 10, 'reg_alpha': 65.52782054731608, 'reg_lambda': 42.4031028195394, 'gamma': 2.0285175183027153}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:10:45,250] Trial 85 finished with value: 0.08828045100482237 and parameters: {'max_depth': 4, 'learning_rate': 0.05681747659136079, 'subsample': 0.141605368767296, 'colsample_bytree': 0.7158444598770272, 'colsample_bynode': 0.24562119581440034, 'colsample_bylevel': 0.7190687992578614, 'min_child_weight': 10, 'reg_alpha': 65.66412033856747, 'reg_lambda': 55.0474657442469, 'gamma': 2.1457051722189835}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:10:54,319] Trial 86 finished with value: 0.08631192768483192 and parameters: {'max_depth': 5, 'learning_rate': 0.07694385095098283, 'subsample': 0.08044471412821308, 'colsample_bytree': 0.5829072977574993, 'colsample_bynode': 0.2998428896175276, 'colsample_bylevel': 0.7464874998657552, 'min_child_weight': 10, 'reg_alpha': 76.63606447196501, 'reg_lambda': 43.04159264524435, 'gamma': 1.7626588534172403}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:11:02,458] Trial 87 finished with value: 0.09049039488957808 and parameters: {'max_depth': 3, 'learning_rate': 0.06794412967790608, 'subsample': 0.1119095995795902, 'colsample_bytree': 0.6877365580872135, 'colsample_bynode': 0.09715932590048976, 'colsample_bylevel': 0.5328773395533525, 'min_child_weight': 9, 'reg_alpha': 81.06517996258754, 'reg_lambda': 50.987971214280904, 'gamma': 1.882056853952623}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:11:14,199] Trial 88 finished with value: 0.08014037067019225 and parameters: {'max_depth': 4, 'learning_rate': 0.03986799508897972, 'subsample': 0.4073364567501917, 'colsample_bytree': 0.6186533214617751, 'colsample_bynode': 0.20026888339975912, 'colsample_bylevel': 0.6836720937550163, 'min_child_weight': 6, 'reg_alpha': 71.76291815199745, 'reg_lambda': 2.070639053636306, 'gamma': 2.865944749834898}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:11:24,994] Trial 89 finished with value: 0.08505041172250236 and parameters: {'max_depth': 5, 'learning_rate': 0.05578078787907562, 'subsample': 0.1371617213520141, 'colsample_bytree': 0.6273163571868225, 'colsample_bynode': 0.33703939496897917, 'colsample_bylevel': 0.6463141682370896, 'min_child_weight': 10, 'reg_alpha': 56.92983689388859, 'reg_lambda': 44.87825871218462, 'gamma': 2.021987847519539}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:11:34,417] Trial 90 finished with value: 0.08784672707370231 and parameters: {'max_depth': 4, 'learning_rate': 0.048228054008815004, 'subsample': 0.17702614979234277, 'colsample_bytree': 0.10712514776090043, 'colsample_bynode': 0.26034574491595, 'colsample_bylevel': 0.5846405746917996, 'min_child_weight': 5, 'reg_alpha': 66.14601003591518, 'reg_lambda': 39.62294000673568, 'gamma': 3.0264264596087194}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:11:43,589] Trial 91 finished with value: 0.09216434763142395 and parameters: {'max_depth': 5, 'learning_rate': 0.03579212760476283, 'subsample': 0.05013090818294456, 'colsample_bytree': 0.9658951700137977, 'colsample_bynode': 0.2990231521309981, 'colsample_bylevel': 0.6661513330315552, 'min_child_weight': 10, 'reg_alpha': 58.852076911182465, 'reg_lambda': 39.55243627580763, 'gamma': 2.27837237194321}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:11:53,418] Trial 92 finished with value: 0.08977572404841394 and parameters: {'max_depth': 5, 'learning_rate': 0.037020098288455656, 'subsample': 0.07317291329593664, 'colsample_bytree': 0.9771254006987089, 'colsample_bynode': 0.2112643209211666, 'colsample_bylevel': 0.6749658425395664, 'min_child_weight': 10, 'reg_alpha': 60.223932647138675, 'reg_lambda': 38.672395178282414, 'gamma': 2.500001468210392}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:12:03,092] Trial 93 finished with value: 0.09277889675377121 and parameters: {'max_depth': 5, 'learning_rate': 0.02778538650563901, 'subsample': 0.06874218176197038, 'colsample_bytree': 0.7539290876937284, 'colsample_bynode': 0.30916610673789846, 'colsample_bylevel': 0.5565247213753038, 'min_child_weight': 9, 'reg_alpha': 74.9816021471844, 'reg_lambda': 47.56091291156357, 'gamma': 2.6454550934778958}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:12:13,790] Trial 94 finished with value: 0.09203545756425943 and parameters: {'max_depth': 4, 'learning_rate': 0.026795351214178705, 'subsample': 0.10666397447111978, 'colsample_bytree': 0.6669445964703796, 'colsample_bynode': 0.30105125847062164, 'colsample_bylevel': 0.5493553656903415, 'min_child_weight': 9, 'reg_alpha': 60.888324410672524, 'reg_lambda': 48.25283822585929, 'gamma': 2.6865166157307674}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:12:23,438] Trial 95 finished with value: 0.08609425226057596 and parameters: {'max_depth': 4, 'learning_rate': 0.04293117251529032, 'subsample': 0.10861696215080852, 'colsample_bytree': 0.6719848436912486, 'colsample_bynode': 0.30287426651503224, 'colsample_bylevel': 0.5517685706820097, 'min_child_weight': 9, 'reg_alpha': 62.071198214824896, 'reg_lambda': 47.50993022092737, 'gamma': 2.6448758312363756}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:12:32,866] Trial 96 finished with value: 0.08660834506729591 and parameters: {'max_depth': 3, 'learning_rate': 0.05061485555087771, 'subsample': 0.13478058412856764, 'colsample_bytree': 0.7911940136230211, 'colsample_bynode': 0.2548465398353193, 'colsample_bylevel': 0.6517674399334092, 'min_child_weight': 9, 'reg_alpha': 51.81346711044126, 'reg_lambda': 55.82253211015766, 'gamma': 2.3097749967966026}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:12:43,014] Trial 97 finished with value: 0.0885102186611365 and parameters: {'max_depth': 4, 'learning_rate': 0.026174803049335445, 'subsample': 0.05091107004650243, 'colsample_bytree': 0.7608379429915307, 'colsample_bynode': 0.39093629100052557, 'colsample_bylevel': 0.6034610625680125, 'min_child_weight': 10, 'reg_alpha': 60.19635164040409, 'reg_lambda': 44.38319260936476, 'gamma': 1.9729106007533623}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:12:54,892] Trial 98 finished with value: 0.08535099681178665 and parameters: {'max_depth': 4, 'learning_rate': 0.03034863654857475, 'subsample': 0.20436637737033855, 'colsample_bytree': 0.6921646458664499, 'colsample_bynode': 0.3276671042230929, 'colsample_bylevel': 0.7354805180713376, 'min_child_weight': 9, 'reg_alpha': 57.39873864898478, 'reg_lambda': 50.935630466672414, 'gamma': 2.7843549712022084}. Best is trial 84 with value: 0.09376299917813029.\n",
      "[I 2025-07-11 14:13:07,257] Trial 99 finished with value: 0.09190911725225573 and parameters: {'max_depth': 6, 'learning_rate': 0.023011403597112574, 'subsample': 0.09668001465482695, 'colsample_bytree': 0.6547398272211457, 'colsample_bynode': 0.3545782259262299, 'colsample_bylevel': 0.4573889030784585, 'min_child_weight': 10, 'reg_alpha': 69.04781714851754, 'reg_lambda': 39.997405934548546, 'gamma': 2.248642685989477}. Best is trial 84 with value: 0.09376299917813029.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.055867033901354564, 'subsample': 0.05556874887692709, 'colsample_bytree': 0.7160668672502511, 'colsample_bynode': 0.2594570432591158, 'colsample_bylevel': 0.6752761327222085, 'min_child_weight': 10, 'reg_alpha': 65.52782054731608, 'reg_lambda': 42.4031028195394, 'gamma': 2.0285175183027153}\n",
      "Best Pearson score: 0.09376299917813029\n"
     ]
    }
   ],
   "source": [
    "best_xgboost_params_common_truncated_popular_feature = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features) - 5}_popular_feature_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features) - 5}_popular_feature_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f517360",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a376aff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 14:13:27,392] A new study created in RDB with name: lightgbm_2_4_101_1000_common_truncated_20_popular_feature_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for LightGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 14:13:53,972] Trial 0 finished with value: 0.0687441712019427 and parameters: {'max_depth': 6, 'learning_rate': 0.013846345806771068, 'num_leaves': 31, 'subsample': 0.2129455734138479, 'colsample_bytree': 0.7010131326124469, 'min_child_weight': 0.8338968626360765, 'reg_alpha': 30.69662196722378, 'reg_lambda': 89.36130796833973}. Best is trial 0 with value: 0.0687441712019427.\n",
      "[I 2025-07-11 14:15:19,769] Trial 1 finished with value: 0.06365150245096533 and parameters: {'max_depth': 8, 'learning_rate': 0.0023981586388374812, 'num_leaves': 568, 'subsample': 0.3845253563252834, 'colsample_bytree': 0.22279778252707472, 'min_child_weight': 0.7856017618643588, 'reg_alpha': 96.54832224119693, 'reg_lambda': 23.23536618147607}. Best is trial 0 with value: 0.0687441712019427.\n",
      "[I 2025-07-11 14:15:25,804] Trial 2 finished with value: 0.06472781831453855 and parameters: {'max_depth': 2, 'learning_rate': 0.016110048377545386, 'num_leaves': 747, 'subsample': 0.31242688707239963, 'colsample_bytree': 0.7010410123411693, 'min_child_weight': 0.5178674741970474, 'reg_alpha': 4.848453742640057, 'reg_lambda': 13.786923756210612}. Best is trial 0 with value: 0.0687441712019427.\n",
      "[I 2025-07-11 14:15:34,869] Trial 3 finished with value: 0.06799837309069594 and parameters: {'max_depth': 3, 'learning_rate': 0.09741723578672784, 'num_leaves': 534, 'subsample': 0.599850058701646, 'colsample_bytree': 0.7480781053559128, 'min_child_weight': 0.5419617722295935, 'reg_alpha': 91.31535576757686, 'reg_lambda': 80.79201509879171}. Best is trial 0 with value: 0.0687441712019427.\n",
      "[I 2025-07-11 14:15:57,491] Trial 4 finished with value: 0.06860230594102897 and parameters: {'max_depth': 5, 'learning_rate': 0.005181418669873028, 'num_leaves': 976, 'subsample': 0.3764499989979318, 'colsample_bytree': 0.8718448255024116, 'min_child_weight': 0.830277712198797, 'reg_alpha': 53.81614492475574, 'reg_lambda': 92.24693725672236}. Best is trial 0 with value: 0.0687441712019427.\n",
      "[I 2025-07-11 14:16:03,348] Trial 5 finished with value: 0.06264604970154321 and parameters: {'max_depth': 2, 'learning_rate': 0.0016058130623353558, 'num_leaves': 719, 'subsample': 0.8959558756720097, 'colsample_bytree': 0.20158228585329385, 'min_child_weight': 0.2755725448969536, 'reg_alpha': 67.24915296568057, 'reg_lambda': 16.430312402017023}. Best is trial 0 with value: 0.0687441712019427.\n",
      "[I 2025-07-11 14:17:23,147] Trial 6 finished with value: 0.07648207305552346 and parameters: {'max_depth': 8, 'learning_rate': 0.009446489461568522, 'num_leaves': 698, 'subsample': 0.5454707827095664, 'colsample_bytree': 0.09122685971238012, 'min_child_weight': 0.22393660350197764, 'reg_alpha': 57.5205086868013, 'reg_lambda': 12.04336601272924}. Best is trial 6 with value: 0.07648207305552346.\n",
      "[I 2025-07-11 14:18:00,696] Trial 7 finished with value: 0.06905209482745056 and parameters: {'max_depth': 6, 'learning_rate': 0.0018880745423615964, 'num_leaves': 56, 'subsample': 0.2193630764093441, 'colsample_bytree': 0.47024972493710754, 'min_child_weight': 0.8775873246276348, 'reg_alpha': 94.9264128985194, 'reg_lambda': 47.816741678956944}. Best is trial 6 with value: 0.07648207305552346.\n",
      "[I 2025-07-11 14:18:34,681] Trial 8 finished with value: 0.07828989114118123 and parameters: {'max_depth': 6, 'learning_rate': 0.01881819922559846, 'num_leaves': 334, 'subsample': 0.16169918837659433, 'colsample_bytree': 0.09854594657598587, 'min_child_weight': 0.6376586528178253, 'reg_alpha': 81.22658949111644, 'reg_lambda': 67.02604203336357}. Best is trial 8 with value: 0.07828989114118123.\n",
      "[I 2025-07-11 14:19:32,521] Trial 9 finished with value: 0.07410665610952741 and parameters: {'max_depth': 7, 'learning_rate': 0.007065418434547894, 'num_leaves': 673, 'subsample': 0.24870342391787859, 'colsample_bytree': 0.676928292923809, 'min_child_weight': 0.5296233987530145, 'reg_alpha': 74.85203698504924, 'reg_lambda': 9.375685586925798}. Best is trial 8 with value: 0.07828989114118123.\n",
      "[I 2025-07-11 14:22:15,891] Trial 10 finished with value: 0.07322703819826909 and parameters: {'max_depth': 10, 'learning_rate': 0.046691858991050356, 'num_leaves': 295, 'subsample': 0.05122781195766579, 'colsample_bytree': 0.40989766162867664, 'min_child_weight': 0.014552444100947026, 'reg_alpha': 31.91376385175545, 'reg_lambda': 63.61778654474863}. Best is trial 8 with value: 0.07828989114118123.\n",
      "[I 2025-07-11 14:23:52,721] Trial 11 finished with value: 0.0752856985555935 and parameters: {'max_depth': 9, 'learning_rate': 0.027650250821282207, 'num_leaves': 298, 'subsample': 0.6314047911569952, 'colsample_bytree': 0.07350057405403307, 'min_child_weight': 0.2843499313706017, 'reg_alpha': 68.846023315329, 'reg_lambda': 41.59452589120947}. Best is trial 8 with value: 0.07828989114118123.\n",
      "[I 2025-07-11 14:24:05,292] Trial 12 finished with value: 0.08560787754764171 and parameters: {'max_depth': 4, 'learning_rate': 0.005501675068218494, 'num_leaves': 323, 'subsample': 0.7515042918504442, 'colsample_bytree': 0.05868593494641514, 'min_child_weight': 0.290572428695116, 'reg_alpha': 49.399778852783804, 'reg_lambda': 65.99827055591432}. Best is trial 12 with value: 0.08560787754764171.\n",
      "[I 2025-07-11 14:24:19,651] Trial 13 finished with value: 0.07333414270344384 and parameters: {'max_depth': 4, 'learning_rate': 0.0036550651829604236, 'num_leaves': 317, 'subsample': 0.7819662305260449, 'colsample_bytree': 0.2973929532979708, 'min_child_weight': 0.6753528454646436, 'reg_alpha': 37.57525773445384, 'reg_lambda': 66.65313160050269}. Best is trial 12 with value: 0.08560787754764171.\n",
      "[I 2025-07-11 14:24:32,424] Trial 14 finished with value: 0.09450970574414437 and parameters: {'max_depth': 4, 'learning_rate': 0.02863289924283241, 'num_leaves': 195, 'subsample': 0.8122934714458931, 'colsample_bytree': 0.05433200355430229, 'min_child_weight': 0.37479350592861993, 'reg_alpha': 16.007288915192156, 'reg_lambda': 66.78410625790377}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:24:46,875] Trial 15 finished with value: 0.07544231171695218 and parameters: {'max_depth': 4, 'learning_rate': 0.037049339346834645, 'num_leaves': 164, 'subsample': 0.7672105901051754, 'colsample_bytree': 0.3220678355822056, 'min_child_weight': 0.39827766866527997, 'reg_alpha': 2.47141147137644, 'reg_lambda': 34.49578104699751}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:25:00,838] Trial 16 finished with value: 0.05869483104087274 and parameters: {'max_depth': 4, 'learning_rate': 0.06869063506789981, 'num_leaves': 164, 'subsample': 0.9357660251228179, 'colsample_bytree': 0.992479472187304, 'min_child_weight': 0.07142973487163695, 'reg_alpha': 16.326634758879518, 'reg_lambda': 59.531808268613545}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:25:10,944] Trial 17 finished with value: 0.061308392361755726 and parameters: {'max_depth': 3, 'learning_rate': 0.0045210146305376874, 'num_leaves': 417, 'subsample': 0.7515661964336279, 'colsample_bytree': 0.5539483455132291, 'min_child_weight': 0.38374745250357134, 'reg_alpha': 41.12310754648652, 'reg_lambda': 73.3632354547023}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:25:33,984] Trial 18 finished with value: 0.08118236940206568 and parameters: {'max_depth': 5, 'learning_rate': 0.009842218211732945, 'num_leaves': 204, 'subsample': 0.9807505306099052, 'colsample_bytree': 0.17154414042897698, 'min_child_weight': 0.38344933889668137, 'reg_alpha': 17.23706069856396, 'reg_lambda': 53.654897672300955}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:25:43,295] Trial 19 finished with value: 0.06653486223610058 and parameters: {'max_depth': 3, 'learning_rate': 0.003326883066095728, 'num_leaves': 457, 'subsample': 0.6803881761974899, 'colsample_bytree': 0.333961722009188, 'min_child_weight': 0.16210002823190595, 'reg_alpha': 19.973536794693047, 'reg_lambda': 78.17063234908666}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:26:03,839] Trial 20 finished with value: 0.08912521644635336 and parameters: {'max_depth': 5, 'learning_rate': 0.022255498628197257, 'num_leaves': 98, 'subsample': 0.8548317245610401, 'colsample_bytree': 0.05637826162675682, 'min_child_weight': 0.9712239782072848, 'reg_alpha': 44.824146639104605, 'reg_lambda': 33.52182802751974}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:26:24,417] Trial 21 finished with value: 0.0895287396218083 and parameters: {'max_depth': 5, 'learning_rate': 0.024811731259095745, 'num_leaves': 122, 'subsample': 0.8568698975159229, 'colsample_bytree': 0.0543703127125462, 'min_child_weight': 0.9858953410241796, 'reg_alpha': 47.163209773681665, 'reg_lambda': 30.73717851852597}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:26:47,665] Trial 22 finished with value: 0.07567476608883313 and parameters: {'max_depth': 5, 'learning_rate': 0.026689094406764317, 'num_leaves': 97, 'subsample': 0.8756769025603172, 'colsample_bytree': 0.18832557721257318, 'min_child_weight': 0.9814671558923616, 'reg_alpha': 46.10220120897394, 'reg_lambda': 28.68648657683525}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:26:54,776] Trial 23 finished with value: 0.07813357947081458 and parameters: {'max_depth': 5, 'learning_rate': 0.051159885182379704, 'num_leaves': 5, 'subsample': 0.8483406448817409, 'colsample_bytree': 0.15422784628447717, 'min_child_weight': 0.9815463547811504, 'reg_alpha': 27.920544672351234, 'reg_lambda': 38.492686844179396}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:27:58,176] Trial 24 finished with value: 0.06845259886998276 and parameters: {'max_depth': 7, 'learning_rate': 0.022813886990633615, 'num_leaves': 223, 'subsample': 0.9978473519254413, 'colsample_bytree': 0.2705293330540105, 'min_child_weight': 0.6936498781721312, 'reg_alpha': 61.51511102897352, 'reg_lambda': 46.71676283688559}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:28:31,172] Trial 25 finished with value: 0.08017447461776418 and parameters: {'max_depth': 6, 'learning_rate': 0.0364280305831978, 'num_leaves': 102, 'subsample': 0.8244230183385396, 'colsample_bytree': 0.054886291022191835, 'min_child_weight': 0.9216879544005718, 'reg_alpha': 41.883273365177914, 'reg_lambda': 26.30261783025504}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:29:39,027] Trial 26 finished with value: 0.07571053722555715 and parameters: {'max_depth': 7, 'learning_rate': 0.013192416049874851, 'num_leaves': 119, 'subsample': 0.6580958270671402, 'colsample_bytree': 0.4174346120153487, 'min_child_weight': 0.7426254244906166, 'reg_alpha': 11.696889087699645, 'reg_lambda': 56.2578687393514}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:30:02,287] Trial 27 finished with value: 0.06688705740695444 and parameters: {'max_depth': 5, 'learning_rate': 0.07456575726073539, 'num_leaves': 225, 'subsample': 0.4585659409080616, 'colsample_bytree': 0.1303732941912425, 'min_child_weight': 0.4506479406938352, 'reg_alpha': 24.714713380403925, 'reg_lambda': 30.82207209345372}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:30:11,165] Trial 28 finished with value: 0.07106688562348797 and parameters: {'max_depth': 3, 'learning_rate': 0.03443436273092072, 'num_leaves': 399, 'subsample': 0.6950602423509984, 'colsample_bytree': 0.23552099448379765, 'min_child_weight': 0.6037159346169273, 'reg_alpha': 34.96009309228487, 'reg_lambda': 20.125185449907843}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:30:26,619] Trial 29 finished with value: 0.05184717333970967 and parameters: {'max_depth': 4, 'learning_rate': 0.0010281343623091527, 'num_leaves': 22, 'subsample': 0.9263879403769152, 'colsample_bytree': 0.5652473124531595, 'min_child_weight': 0.9214417061397814, 'reg_alpha': 51.9469313290289, 'reg_lambda': 1.5582941498195844}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:31:07,227] Trial 30 finished with value: 0.07619726059766826 and parameters: {'max_depth': 6, 'learning_rate': 0.013158809220579996, 'num_leaves': 954, 'subsample': 0.5540641136248285, 'colsample_bytree': 0.3665656707952344, 'min_child_weight': 0.8242681989394651, 'reg_alpha': 10.489990601797992, 'reg_lambda': 99.6810780170168}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:31:19,922] Trial 31 finished with value: 0.08792094666946804 and parameters: {'max_depth': 4, 'learning_rate': 0.007216524317968808, 'num_leaves': 256, 'subsample': 0.8141547286835602, 'colsample_bytree': 0.05548830416294742, 'min_child_weight': 0.29994578254094967, 'reg_alpha': 45.274139446896434, 'reg_lambda': 45.80321081053051}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:31:42,432] Trial 32 finished with value: 0.08162471919309609 and parameters: {'max_depth': 5, 'learning_rate': 0.0075221526005945965, 'num_leaves': 256, 'subsample': 0.8088690885325598, 'colsample_bytree': 0.14105501877543342, 'min_child_weight': 0.1730723995761331, 'reg_alpha': 45.78922458916191, 'reg_lambda': 40.83218415558703}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:31:56,523] Trial 33 finished with value: 0.07204983803832457 and parameters: {'max_depth': 4, 'learning_rate': 0.01823086486255118, 'num_leaves': 164, 'subsample': 0.7094090091992427, 'colsample_bytree': 0.23875082919197577, 'min_child_weight': 0.3462794591843822, 'reg_alpha': 26.086681171360922, 'reg_lambda': 48.714308421437366}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:32:01,893] Trial 34 finished with value: 0.08448716542476253 and parameters: {'max_depth': 2, 'learning_rate': 0.012342973981955295, 'num_leaves': 79, 'subsample': 0.8738808418728284, 'colsample_bytree': 0.12537341169151417, 'min_child_weight': 0.43735939374430677, 'reg_alpha': 64.99125228685105, 'reg_lambda': 34.433383077940334}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:32:09,864] Trial 35 finished with value: 0.09221141381210227 and parameters: {'max_depth': 3, 'learning_rate': 0.02048037957963122, 'num_leaves': 601, 'subsample': 0.9342233237799535, 'colsample_bytree': 0.05068175690393044, 'min_child_weight': 0.7435713046543015, 'reg_alpha': 56.56601421057252, 'reg_lambda': 41.96182939972507}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:32:18,614] Trial 36 finished with value: 0.07189117363467037 and parameters: {'max_depth': 3, 'learning_rate': 0.021842657311182616, 'num_leaves': 606, 'subsample': 0.9387180338780227, 'colsample_bytree': 0.20080437740339505, 'min_child_weight': 0.7773952571256524, 'reg_alpha': 83.37130354698789, 'reg_lambda': 21.557951166907962}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:32:24,137] Trial 37 finished with value: 0.08533241706838612 and parameters: {'max_depth': 2, 'learning_rate': 0.016217620520376737, 'num_leaves': 826, 'subsample': 0.96421184428744, 'colsample_bytree': 0.12101313555690554, 'min_child_weight': 0.9112309532016362, 'reg_alpha': 56.19975233531217, 'reg_lambda': 35.56017779619082}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:32:33,124] Trial 38 finished with value: 0.07115870462710495 and parameters: {'max_depth': 3, 'learning_rate': 0.031150882092241584, 'num_leaves': 629, 'subsample': 0.9012274729605145, 'colsample_bytree': 0.2658316074852595, 'min_child_weight': 0.8689182138018179, 'reg_alpha': 60.40914982763457, 'reg_lambda': 88.17466645133273}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:32:56,353] Trial 39 finished with value: 0.06799091951442292 and parameters: {'max_depth': 5, 'learning_rate': 0.04875897664506011, 'num_leaves': 532, 'subsample': 0.4496557776903787, 'colsample_bytree': 0.8041896279942768, 'min_child_weight': 0.998700500770369, 'reg_alpha': 52.04219790750682, 'reg_lambda': 53.5695333644411}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:33:02,410] Trial 40 finished with value: 0.07359188495122594 and parameters: {'max_depth': 2, 'learning_rate': 0.019520347335080256, 'num_leaves': 476, 'subsample': 0.6051999646561772, 'colsample_bytree': 0.6407184481172815, 'min_child_weight': 0.7476300100808634, 'reg_alpha': 73.23793606862935, 'reg_lambda': 73.82638711339666}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:33:15,738] Trial 41 finished with value: 0.08186818664807066 and parameters: {'max_depth': 4, 'learning_rate': 0.008353052261505692, 'num_leaves': 783, 'subsample': 0.8355882180558641, 'colsample_bytree': 0.09015275524438593, 'min_child_weight': 0.5636272015544643, 'reg_alpha': 45.09089885482616, 'reg_lambda': 44.898106843037745}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:33:23,718] Trial 42 finished with value: 0.09049912431869153 and parameters: {'max_depth': 3, 'learning_rate': 0.011670601896692777, 'num_leaves': 383, 'subsample': 0.877674413140874, 'colsample_bytree': 0.05437497139661486, 'min_child_weight': 0.4770460143134366, 'reg_alpha': 38.02178460787306, 'reg_lambda': 43.53666357106869}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:33:32,202] Trial 43 finished with value: 0.07599088049393066 and parameters: {'max_depth': 3, 'learning_rate': 0.02474206864692031, 'num_leaves': 370, 'subsample': 0.881453548194614, 'colsample_bytree': 0.1750343841518543, 'min_child_weight': 0.47710586305241415, 'reg_alpha': 36.41388100955044, 'reg_lambda': 30.580656915590122}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:33:37,610] Trial 44 finished with value: 0.08456371848535203 and parameters: {'max_depth': 2, 'learning_rate': 0.011791930119130434, 'num_leaves': 138, 'subsample': 0.7162793527522726, 'colsample_bytree': 0.10717855271740193, 'min_child_weight': 0.5857201334804197, 'reg_alpha': 31.948511975461233, 'reg_lambda': 25.545090898369097}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:33:45,515] Trial 45 finished with value: 0.0927079242471695 and parameters: {'max_depth': 3, 'learning_rate': 0.01505242970672715, 'num_leaves': 50, 'subsample': 0.9257842070799719, 'colsample_bytree': 0.05590156869944259, 'min_child_weight': 0.8101275433129811, 'reg_alpha': 7.264192403987337, 'reg_lambda': 60.860489721263136}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:33:53,828] Trial 46 finished with value: 0.07996722352012875 and parameters: {'max_depth': 3, 'learning_rate': 0.01654484876285584, 'num_leaves': 571, 'subsample': 0.9246816369333745, 'colsample_bytree': 0.10213600658172203, 'min_child_weight': 0.5271797649760711, 'reg_alpha': 8.203667185667067, 'reg_lambda': 61.546101450290564}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:33:59,565] Trial 47 finished with value: 0.07858197950585104 and parameters: {'max_depth': 2, 'learning_rate': 0.01062142604935168, 'num_leaves': 47, 'subsample': 0.9585847061325655, 'colsample_bytree': 0.20954291711309428, 'min_child_weight': 0.8223808097744747, 'reg_alpha': 1.2560949258282577, 'reg_lambda': 71.10595835565647}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:34:08,085] Trial 48 finished with value: 0.07357773724958111 and parameters: {'max_depth': 3, 'learning_rate': 0.04178393589273717, 'num_leaves': 463, 'subsample': 0.7915934258385523, 'colsample_bytree': 0.15721055422131655, 'min_child_weight': 0.6277341846776301, 'reg_alpha': 23.72760085324719, 'reg_lambda': 51.42152272921891}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:34:21,293] Trial 49 finished with value: 0.08746402457603233 and parameters: {'max_depth': 4, 'learning_rate': 0.01437867851635021, 'num_leaves': 375, 'subsample': 0.992958212611605, 'colsample_bytree': 0.09793475973225982, 'min_child_weight': 0.6689007841488319, 'reg_alpha': 9.3059723617999, 'reg_lambda': 58.55305706586798}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:34:26,464] Trial 50 finished with value: 0.0834009984883575 and parameters: {'max_depth': 2, 'learning_rate': 0.006060238791657523, 'num_leaves': 260, 'subsample': 0.9115756631596038, 'colsample_bytree': 0.0554548612677539, 'min_child_weight': 0.49389246337302617, 'reg_alpha': 20.513968152314167, 'reg_lambda': 43.068351499625365}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:34:39,497] Trial 51 finished with value: 0.08545179637177402 and parameters: {'max_depth': 4, 'learning_rate': 0.027838250926439104, 'num_leaves': 63, 'subsample': 0.877136149573077, 'colsample_bytree': 0.08689696586648843, 'min_child_weight': 0.8589115681790743, 'reg_alpha': 40.717333072000784, 'reg_lambda': 36.87630225213408}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:35:02,363] Trial 52 finished with value: 0.0771099416305027 and parameters: {'max_depth': 5, 'learning_rate': 0.019524174832412658, 'num_leaves': 181, 'subsample': 0.8538602369834266, 'colsample_bytree': 0.14209480031715133, 'min_child_weight': 0.9664139640402022, 'reg_alpha': 14.501158157153876, 'reg_lambda': 15.653293951193469}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:35:33,971] Trial 53 finished with value: 0.08294515280411535 and parameters: {'max_depth': 6, 'learning_rate': 0.015430178749662718, 'num_leaves': 137, 'subsample': 0.7629177424318198, 'colsample_bytree': 0.059242025079789706, 'min_child_weight': 0.9547098332866978, 'reg_alpha': 56.040393890495295, 'reg_lambda': 40.06047133651197}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:35:41,108] Trial 54 finished with value: 0.09305970811419234 and parameters: {'max_depth': 3, 'learning_rate': 0.021794619161416142, 'num_leaves': 6, 'subsample': 0.7323683664864769, 'colsample_bytree': 0.05201477278721253, 'min_child_weight': 0.7083283068650463, 'reg_alpha': 49.52556118793734, 'reg_lambda': 65.01580524108316}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:35:48,561] Trial 55 finished with value: 0.07383422668863124 and parameters: {'max_depth': 3, 'learning_rate': 0.061859438210507406, 'num_leaves': 6, 'subsample': 0.7324061703273441, 'colsample_bytree': 0.17638290240684887, 'min_child_weight': 0.7399627393806127, 'reg_alpha': 5.4150748924704315, 'reg_lambda': 69.4834012057597}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:35:56,566] Trial 56 finished with value: 0.08301008168599422 and parameters: {'max_depth': 3, 'learning_rate': 0.031688832325652144, 'num_leaves': 54, 'subsample': 0.9029585754614143, 'colsample_bytree': 0.09017281470073374, 'min_child_weight': 0.7068097475170654, 'reg_alpha': 61.69062540367727, 'reg_lambda': 62.87760915958874}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:36:09,868] Trial 57 finished with value: 0.07827643322816735 and parameters: {'max_depth': 4, 'learning_rate': 0.008933073519796877, 'num_leaves': 191, 'subsample': 0.9526484835293335, 'colsample_bytree': 0.12487276960615724, 'min_child_weight': 0.7725663764201168, 'reg_alpha': 49.59090739376687, 'reg_lambda': 81.91481738207194}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:36:18,763] Trial 58 finished with value: 0.07224145101369096 and parameters: {'max_depth': 3, 'learning_rate': 0.010716819000330644, 'num_leaves': 694, 'subsample': 0.7778926855918317, 'colsample_bytree': 0.22077194915801865, 'min_child_weight': 0.6389344628359301, 'reg_alpha': 70.88002178184246, 'reg_lambda': 57.10729738140232}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:36:25,018] Trial 59 finished with value: 0.07452410996542394 and parameters: {'max_depth': 2, 'learning_rate': 0.02850220862266091, 'num_leaves': 649, 'subsample': 0.6539178435901841, 'colsample_bytree': 0.27176822694549546, 'min_child_weight': 0.3509363365003266, 'reg_alpha': 5.0977035701042865, 'reg_lambda': 78.10133696110394}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:36:56,968] Trial 60 finished with value: 0.061269305424307814 and parameters: {'max_depth': 10, 'learning_rate': 0.040423472442863234, 'num_leaves': 33, 'subsample': 0.8389341501152437, 'colsample_bytree': 0.9870650837991455, 'min_child_weight': 0.24610961144380328, 'reg_alpha': 30.19671701178619, 'reg_lambda': 67.5342189122083}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:37:17,660] Trial 61 finished with value: 0.08919051937622152 and parameters: {'max_depth': 5, 'learning_rate': 0.021308265285786544, 'num_leaves': 102, 'subsample': 0.8516563026003293, 'colsample_bytree': 0.053439802070717767, 'min_child_weight': 0.8928174796907745, 'reg_alpha': 38.80604252715754, 'reg_lambda': 33.31207368972171}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:37:30,338] Trial 62 finished with value: 0.09211641038086048 and parameters: {'max_depth': 4, 'learning_rate': 0.02251742504567409, 'num_leaves': 129, 'subsample': 0.8141531126316067, 'colsample_bytree': 0.05031466033698781, 'min_child_weight': 0.9018488655739432, 'reg_alpha': 38.91541102873716, 'reg_lambda': 50.31885680913101}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:37:38,393] Trial 63 finished with value: 0.0864089099490796 and parameters: {'max_depth': 3, 'learning_rate': 0.017498383747750097, 'num_leaves': 134, 'subsample': 0.8084926892135956, 'colsample_bytree': 0.08462080286096987, 'min_child_weight': 0.8462209703526115, 'reg_alpha': 48.388499788341605, 'reg_lambda': 52.48970227581225}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:37:51,830] Trial 64 finished with value: 0.0812639106179602 and parameters: {'max_depth': 4, 'learning_rate': 0.024042510854572905, 'num_leaves': 67, 'subsample': 0.7883441777792388, 'colsample_bytree': 0.1496791264036551, 'min_child_weight': 0.8107138935444376, 'reg_alpha': 54.55240694071834, 'reg_lambda': 64.21058485116218}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:38:05,255] Trial 65 finished with value: 0.08202823302889908 and parameters: {'max_depth': 4, 'learning_rate': 0.015021913906065608, 'num_leaves': 572, 'subsample': 0.08758393255686964, 'colsample_bytree': 0.10762332395418917, 'min_child_weight': 0.9388894130764455, 'reg_alpha': 33.16902270715708, 'reg_lambda': 50.27273744358918}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:39:09,067] Trial 66 finished with value: 0.07777534957812843 and parameters: {'max_depth': 9, 'learning_rate': 0.031095864969367705, 'num_leaves': 229, 'subsample': 0.8971673359550111, 'colsample_bytree': 0.050746570989546325, 'min_child_weight': 0.7982796440498838, 'reg_alpha': 99.49525136326163, 'reg_lambda': 61.29118317934667}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:39:17,172] Trial 67 finished with value: 0.08269424034374184 and parameters: {'max_depth': 3, 'learning_rate': 0.025827217244603382, 'num_leaves': 290, 'subsample': 0.9741359946508819, 'colsample_bytree': 0.0812373434627524, 'min_child_weight': 0.8824315550650788, 'reg_alpha': 13.978935192049377, 'reg_lambda': 56.35112010027757}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:39:30,789] Trial 68 finished with value: 0.07910495617378974 and parameters: {'max_depth': 4, 'learning_rate': 0.020427847835192185, 'num_leaves': 150, 'subsample': 0.7467626401372546, 'colsample_bytree': 0.172495294050043, 'min_child_weight': 0.4203199185863858, 'reg_alpha': 58.25428256433256, 'reg_lambda': 42.96008035829705}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:39:39,079] Trial 69 finished with value: 0.07787825124675872 and parameters: {'max_depth': 3, 'learning_rate': 0.012508064401640743, 'num_leaves': 88, 'subsample': 0.3466106350497148, 'colsample_bytree': 0.12878545673962805, 'min_child_weight': 0.34762739811626214, 'reg_alpha': 41.648591233346075, 'reg_lambda': 75.10953436311819}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:39:52,289] Trial 70 finished with value: 0.08555655045954838 and parameters: {'max_depth': 4, 'learning_rate': 0.04078486392068629, 'num_leaves': 502, 'subsample': 0.9317297777231636, 'colsample_bytree': 0.0791140475158515, 'min_child_weight': 0.7121618264502194, 'reg_alpha': 28.97706782262047, 'reg_lambda': 54.83956195420453}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:40:13,985] Trial 71 finished with value: 0.08537933499939994 and parameters: {'max_depth': 5, 'learning_rate': 0.021197002712708222, 'num_leaves': 107, 'subsample': 0.8669629587327796, 'colsample_bytree': 0.07168115524376029, 'min_child_weight': 0.8761224884713452, 'reg_alpha': 39.68863254132668, 'reg_lambda': 32.19456102229769}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:40:38,184] Trial 72 finished with value: 0.06966831406865617 and parameters: {'max_depth': 5, 'learning_rate': 0.022633913042528323, 'num_leaves': 29, 'subsample': 0.8302443881103041, 'colsample_bytree': 0.465423381567922, 'min_child_weight': 0.9000630126447708, 'reg_alpha': 52.01659235901965, 'reg_lambda': 37.474361026871435}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:41:00,361] Trial 73 finished with value: 0.08436214361827085 and parameters: {'max_depth': 5, 'learning_rate': 0.017629616230660623, 'num_leaves': 110, 'subsample': 0.7971589604856341, 'colsample_bytree': 0.1126163894510588, 'min_child_weight': 0.9442542036570712, 'reg_alpha': 36.90649705836006, 'reg_lambda': 47.49977761139627}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:41:13,080] Trial 74 finished with value: 0.09128481699183164 and parameters: {'max_depth': 4, 'learning_rate': 0.014646820441771997, 'num_leaves': 181, 'subsample': 0.8486042366545044, 'colsample_bytree': 0.05266206478976187, 'min_child_weight': 0.8987919346475186, 'reg_alpha': 42.98276545201027, 'reg_lambda': 28.45053456277}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:41:26,769] Trial 75 finished with value: 0.07916987268603909 and parameters: {'max_depth': 4, 'learning_rate': 0.014136487214014993, 'num_leaves': 216, 'subsample': 0.8895503382788642, 'colsample_bytree': 0.1576717409371574, 'min_child_weight': 0.7736374445188571, 'reg_alpha': 47.14705653537754, 'reg_lambda': 19.02850401609866}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:41:35,405] Trial 76 finished with value: 0.07319771229152515 and parameters: {'max_depth': 3, 'learning_rate': 0.010718689382139455, 'num_leaves': 191, 'subsample': 0.817588689336518, 'colsample_bytree': 0.19210479313640988, 'min_child_weight': 0.8413027297496589, 'reg_alpha': 42.22173447062102, 'reg_lambda': 25.80342496371062}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:41:48,686] Trial 77 finished with value: 0.08622599630459993 and parameters: {'max_depth': 4, 'learning_rate': 0.03275771785905731, 'num_leaves': 286, 'subsample': 0.7337520445061453, 'colsample_bytree': 0.11899670899866154, 'min_child_weight': 0.4609595582043134, 'reg_alpha': 65.84055523820903, 'reg_lambda': 58.7497101882845}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:41:56,825] Trial 78 finished with value: 0.08541798792782342 and parameters: {'max_depth': 3, 'learning_rate': 0.01752628246181173, 'num_leaves': 433, 'subsample': 0.687905293331864, 'colsample_bytree': 0.08003157117434342, 'min_child_weight': 0.9954029971016285, 'reg_alpha': 43.829379401102315, 'reg_lambda': 7.570549804593007}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:42:10,586] Trial 79 finished with value: 0.060745430511807 and parameters: {'max_depth': 4, 'learning_rate': 0.025558572426997238, 'num_leaves': 166, 'subsample': 0.9479067277742176, 'colsample_bytree': 0.6342560146909318, 'min_child_weight': 0.553772673586268, 'reg_alpha': 50.95119290209355, 'reg_lambda': 28.80354178397772}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:42:16,190] Trial 80 finished with value: 0.0827070819175215 and parameters: {'max_depth': 2, 'learning_rate': 0.011979388844994618, 'num_leaves': 318, 'subsample': 0.9158546379439215, 'colsample_bytree': 0.1424113931963469, 'min_child_weight': 0.9190824085953736, 'reg_alpha': 20.889771442976674, 'reg_lambda': 23.28851685113578}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:42:22,004] Trial 81 finished with value: 0.09183088225138325 and parameters: {'max_depth': 6, 'learning_rate': 0.020523458216172075, 'num_leaves': 4, 'subsample': 0.8649565001124149, 'colsample_bytree': 0.05991867128793422, 'min_child_weight': 0.8935420410413444, 'reg_alpha': 38.612462664423276, 'reg_lambda': 38.81165747363499}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:42:30,894] Trial 82 finished with value: 0.0919597053860065 and parameters: {'max_depth': 6, 'learning_rate': 0.028657829800562345, 'num_leaves': 7, 'subsample': 0.8530050910767226, 'colsample_bytree': 0.052133103344986324, 'min_child_weight': 0.8474768360417968, 'reg_alpha': 33.50483112247287, 'reg_lambda': 39.536819845274955}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:42:37,935] Trial 83 finished with value: 0.0796700798498956 and parameters: {'max_depth': 7, 'learning_rate': 0.019011171734110686, 'num_leaves': 5, 'subsample': 0.8700857956842168, 'colsample_bytree': 0.10520141650761217, 'min_child_weight': 0.8057858676610741, 'reg_alpha': 36.73059903624793, 'reg_lambda': 42.758329482223346}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:43:15,937] Trial 84 finished with value: 0.07243383545841788 and parameters: {'max_depth': 8, 'learning_rate': 0.056376542278588085, 'num_leaves': 40, 'subsample': 0.7705657990777586, 'colsample_bytree': 0.050302389874943225, 'min_child_weight': 0.8480457198515984, 'reg_alpha': 33.96273825518885, 'reg_lambda': 47.01932846094423}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:43:22,817] Trial 85 finished with value: 0.08633907866144776 and parameters: {'max_depth': 6, 'learning_rate': 0.03607294985236631, 'num_leaves': 5, 'subsample': 0.8364783650117811, 'colsample_bytree': 0.0782708456928301, 'min_child_weight': 0.7427151405968744, 'reg_alpha': 24.015254768675586, 'reg_lambda': 39.372565056586694}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:44:17,459] Trial 86 finished with value: 0.0797908241333099 and parameters: {'max_depth': 7, 'learning_rate': 0.028844103101303278, 'num_leaves': 72, 'subsample': 0.9222141167302633, 'colsample_bytree': 0.10728537528146431, 'min_child_weight': 0.8267731402200862, 'reg_alpha': 27.278172982366744, 'reg_lambda': 45.13073908189385}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:44:51,186] Trial 87 finished with value: 0.0840472143654996 and parameters: {'max_depth': 6, 'learning_rate': 0.016026266957723606, 'num_leaves': 82, 'subsample': 0.5144498358378516, 'colsample_bytree': 0.06832902421551611, 'min_child_weight': 0.38795158858287265, 'reg_alpha': 35.45008759432359, 'reg_lambda': 35.62052550754893}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:45:29,670] Trial 88 finished with value: 0.08119128955131633 and parameters: {'max_depth': 6, 'learning_rate': 0.01334244614278127, 'num_leaves': 345, 'subsample': 0.9981931131650957, 'colsample_bytree': 0.13297337336784748, 'min_child_weight': 0.5065234870384207, 'reg_alpha': 17.41153942451209, 'reg_lambda': 65.76347306754285}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:45:37,685] Trial 89 finished with value: 0.08519896492963927 and parameters: {'max_depth': 3, 'learning_rate': 0.09847144896766144, 'num_leaves': 34, 'subsample': 0.8943910455268326, 'colsample_bytree': 0.09443806993599618, 'min_child_weight': 0.7909849893295066, 'reg_alpha': 31.443844096617887, 'reg_lambda': 49.58490621428593}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:46:39,496] Trial 90 finished with value: 0.07429171769260941 and parameters: {'max_depth': 7, 'learning_rate': 0.00893103701954709, 'num_leaves': 591, 'subsample': 0.9720275158925904, 'colsample_bytree': 0.16444062622322358, 'min_child_weight': 0.6605307957633436, 'reg_alpha': 43.34797923375479, 'reg_lambda': 69.60206807233051}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:47:15,858] Trial 91 finished with value: 0.08050464680500645 and parameters: {'max_depth': 6, 'learning_rate': 0.02419193252407604, 'num_leaves': 118, 'subsample': 0.8585240040917451, 'colsample_bytree': 0.0744747539817443, 'min_child_weight': 0.9325133602117709, 'reg_alpha': 38.58855926158356, 'reg_lambda': 27.78582936899705}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:47:36,534] Trial 92 finished with value: 0.0900459704668731 and parameters: {'max_depth': 5, 'learning_rate': 0.028999273098403767, 'num_leaves': 54, 'subsample': 0.811226058230669, 'colsample_bytree': 0.06824399643111748, 'min_child_weight': 0.8970440193509588, 'reg_alpha': 46.585363735953344, 'reg_lambda': 40.632146612481726}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:47:44,304] Trial 93 finished with value: 0.0931487289912781 and parameters: {'max_depth': 3, 'learning_rate': 0.02940928478522402, 'num_leaves': 53, 'subsample': 0.8129780280031857, 'colsample_bytree': 0.06971571207606589, 'min_child_weight': 0.8707684475210143, 'reg_alpha': 47.92935610353203, 'reg_lambda': 41.08486689613695}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:47:49,641] Trial 94 finished with value: 0.08152200064577839 and parameters: {'max_depth': 2, 'learning_rate': 0.04465164680664241, 'num_leaves': 22, 'subsample': 0.25818157213274257, 'colsample_bytree': 0.11873554456016167, 'min_child_weight': 0.8672532031991571, 'reg_alpha': 54.051182040619885, 'reg_lambda': 38.20966529545377}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:47:57,603] Trial 95 finished with value: 0.08332039616946527 and parameters: {'max_depth': 3, 'learning_rate': 0.03455815117631028, 'num_leaves': 75, 'subsample': 0.7543426537433576, 'colsample_bytree': 0.09833814023667448, 'min_child_weight': 0.7221812326153506, 'reg_alpha': 50.37419750294246, 'reg_lambda': 45.24755447815345}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:48:05,857] Trial 96 finished with value: 0.07722464225791995 and parameters: {'max_depth': 3, 'learning_rate': 0.019000870833344174, 'num_leaves': 55, 'subsample': 0.8396587490410484, 'colsample_bytree': 0.14191037982435883, 'min_child_weight': 0.7706972402957992, 'reg_alpha': 58.75201759081066, 'reg_lambda': 43.030897150540994}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:48:13,764] Trial 97 finished with value: 0.09349815993806533 and parameters: {'max_depth': 3, 'learning_rate': 0.023275252634276093, 'num_leaves': 753, 'subsample': 0.8776806103694141, 'colsample_bytree': 0.05338419176937467, 'min_child_weight': 0.6856332185026985, 'reg_alpha': 40.677089850410844, 'reg_lambda': 49.958797060341084}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:49:35,431] Trial 98 finished with value: 0.07625960015305765 and parameters: {'max_depth': 8, 'learning_rate': 0.022412668429168624, 'num_leaves': 747, 'subsample': 0.7944002583546785, 'colsample_bytree': 0.073072502313802, 'min_child_weight': 0.6881671730124136, 'reg_alpha': 48.64371271130325, 'reg_lambda': 60.41978900668475}. Best is trial 14 with value: 0.09450970574414437.\n",
      "[I 2025-07-11 14:49:41,478] Trial 99 finished with value: 0.05344943776116358 and parameters: {'max_depth': 2, 'learning_rate': 0.002570131056003082, 'num_leaves': 873, 'subsample': 0.7154636625468712, 'colsample_bytree': 0.732001264918711, 'min_child_weight': 0.7585253526785571, 'reg_alpha': 3.367012383527215, 'reg_lambda': 51.15778880228544}. Best is trial 14 with value: 0.09450970574414437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 4, 'learning_rate': 0.02863289924283241, 'num_leaves': 195, 'subsample': 0.8122934714458931, 'colsample_bytree': 0.05433200355430229, 'min_child_weight': 0.37479350592861993, 'reg_alpha': 16.007288915192156, 'reg_lambda': 66.78410625790377}\n",
      "Best Pearson score: 0.09450970574414437\n"
     ]
    }
   ],
   "source": [
    "best_lightgbm_params_common_truncated_popular_feature = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_popular_feature_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_popular_feature_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922a1c7",
   "metadata": {},
   "source": [
    "#### Fifth Iteration Instead of using GBDT, can we use MLP on these features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58f11b",
   "metadata": {},
   "source": [
    "Convert from normal CV to torch type CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531',\n",
    "                 'X385', 'X23', 'X465', 'X284', 'X331', 'X95', 'X169', 'X285', 'X137', 'X31']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, cv=default_cv):\n",
    "    train_arr = []\n",
    "    test_arr = []\n",
    "    for i in range(cv):\n",
    "        # First shuffle the data\n",
    "        X_train, Y_train = X_train_arr[i], Y_train_arr[i]\n",
    "        X_train[\"label\"] = Y_train\n",
    "        # Instead of shuffle the training data when create the dataloader, try to shuffle beforehand\n",
    "        # X_train = X_train.sample(frac = 1, random_state = default_random_state)\n",
    "        # not shuffle, keep it by date\n",
    "        Y_train = X_train[\"label\"]\n",
    "        X_train = X_train.drop(\"label\", axis = 1)\n",
    "\n",
    "        # Then normalize\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train.values)\n",
    "\n",
    "        # Create train dataset\n",
    "        X_train, Y_train = torch.from_numpy(X_train), torch.from_numpy(Y_train.values)\n",
    "        train_dataset = TensorDataset(X_train, Y_train)\n",
    "        train_arr.append(train_dataset)\n",
    "\n",
    "        # Normalize X_test\n",
    "        X_test = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Create test dataset\n",
    "        X_test, Y_test = torch.from_numpy(X_test), torch.from_numpy(Y_test_arr[i].values)\n",
    "        test_dataset = TensorDataset(X_test, Y_test)\n",
    "        test_arr.append(test_dataset)\n",
    "        \n",
    "    return train_arr, test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr, test_arr = normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da5b12",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = nn.ModuleList()\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nn.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nn.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # Initialze dropout\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            if inx == len(self.layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb08f2",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e892da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp(model, criterion, optimizer, train_dataloader, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in train_dataloader:\n",
    "            # Load to device\n",
    "            inputs, targets= inputs.to(device), targets.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs)\n",
    "            # get error\n",
    "            error = criterion(outputs, targets)\n",
    "            # Zero out the past gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Backprop\n",
    "            error.backward()\n",
    "            # Gradient Descent\n",
    "            optimizer.step()\n",
    "\n",
    "def eval_mlp(model, test_dataloader):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, targets) in enumerate(test_dataloader):\n",
    "            # Load to device\n",
    "            inputs = inputs.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs).detach().cpu().numpy().flatten()\n",
    "            # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "            outputs_all = np.concatenate([outputs_all, outputs])\n",
    "            targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_torch(model, lr, cv, train_arr, test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for i in range(cv):\n",
    "        # Get the dataloader\n",
    "        train_dataset = train_arr[i]\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, num_workers=0)\n",
    "        test_dataset = test_arr[i]\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers=0)\n",
    "\n",
    "        # Reinitialize the model\n",
    "        model.reset()\n",
    "        model.to(device)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp(model, criterion, optimizer, train_dataloader, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp(model, test_dataloader)\n",
    "        print(pearson)\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bc5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process of the default config\n",
    "hidden_layers_size = [16, 8, 4]\n",
    "lr = 0.001\n",
    "batch_size = 60\n",
    "num_epochs = 10\n",
    "\n",
    "mlpr = MLP(len(best_features), hidden_layers_size=hidden_layers_size, dropout = 0.3)\n",
    "\n",
    "train_eval_cv_torch(mlpr, lr, default_cv, train_arr, test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdd235",
   "metadata": {},
   "source": [
    "#### Sixth Iteration: Change this into a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65121481",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_classification(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5950bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_classification = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_xgboost_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_classification = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_lightgbm_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31960b41",
   "metadata": {},
   "source": [
    "#### Seventh Iteration: Search for the best way to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_training_scheme(model, train_df, cv = default_cv, features = None):\n",
    "    folds_trial = [\n",
    "        # level 1\n",
    "        [[0, 1, 2, 3]], \n",
    "        [[0, 1]], [[1, 2]], [[2, 3]],\n",
    "        [[0]], [[1]], [[2]], [[3]],\n",
    "        [[0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1], [2, 3]],\n",
    "        [[0], [1], [2], [3]],\n",
    "        # level 2\n",
    "        [[0, 1, 2, 3], [0, 1]],\n",
    "        [[0, 1, 2, 3], [1, 2]],\n",
    "        [[0, 1, 2, 3], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "        # level 3\n",
    "        [[0, 1, 2, 3], [0, 1], [0]],\n",
    "        [[0, 1, 2, 3], [2, 3], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "    ]\n",
    "\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "\n",
    "    for folds in folds_trial:\n",
    "        print(f\"Current folds list is {folds}\")\n",
    "        model_lst = [deepcopy(model)] * len(folds)\n",
    "        cv_pearson = []\n",
    "        for i in range(cv):\n",
    "            train_month = list(range(3 + i, 7 + i))\n",
    "            test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "            test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "            X_test, Y_test = test.drop([\"timestamp\", \"label\"], axis = 1), test[\"label\"]\n",
    "            Y_pred = np.zeros(Y_test.shape[0])\n",
    "            for j in range(len(folds)):\n",
    "                fold = folds[j]\n",
    "                model = model_lst[j]\n",
    "                train_month_curr = [train_month[f] for f in fold]\n",
    "                train_curr = train_df[train_df[\"timestamp\"].dt.month.isin(train_month_curr)].reset_index().drop(\"index\", axis = 1)\n",
    "                X_train, Y_train = train_curr.drop([\"timestamp\", \"label\"], axis = 1), train_curr[\"label\"]\n",
    "                model.fit(X_train, Y_train)\n",
    "                Y_pred += model.predict(X_test)\n",
    "            Y_pred /= len(folds)\n",
    "            cv_pearson.append(pearson_score(Y_test, Y_pred))\n",
    "            print(f\"Finish fold {i} with score: {pearson_score(Y_test, Y_pred)}\")\n",
    "        print(f\"Finish trial with mean score: {np.mean(np.array(cv_pearson))}\")\n",
    "        print(f\"Finish trial with std score: {np.std(np.array(cv_pearson))}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df66a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "search_training_scheme(xgbr, train_added_df)\n",
    "# Notable\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [1, 2]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]] \n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ea866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "search_training_scheme(lgbr, train_added_df)\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [0]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fe3ca",
   "metadata": {},
   "source": [
    "#### Eighth Iteration: rewrite the code for MLP training using MLX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f11bdd",
   "metadata": {},
   "source": [
    "Create the data for training + custom batch iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb028760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "# best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "#                  'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137', \n",
    "#                 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301'] \n",
    "                #  'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', \n",
    "                #  'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "# best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68496448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "#     X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "#     Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "#     Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f14632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, cv=default_cv):\n",
    "    for i in range(cv):\n",
    "        # Normalize forst\n",
    "        scaler = StandardScaler()\n",
    "        X_train_arr[i] = scaler.fit_transform(X_train_arr[i].values)\n",
    "        X_test_arr[i] = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Convert to mlx format\n",
    "        X_train_arr[i] = mx.array(X_train_arr[i])\n",
    "        X_test_arr[i] = mx.array(X_test_arr[i])\n",
    "        Y_train_arr[i] = mx.array(Y_train_arr[i].values)\n",
    "        Y_test_arr[i] = mx.array(Y_test_arr[i].values)\n",
    "        \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3f916",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993631c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# We do not use the reset method this time so you have to create the model at each fold\n",
    "class MLPMLX(nnmx.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = []\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nnmx.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nnmx.ReLU()\n",
    "\n",
    "        # Initialize dropout\n",
    "        self.dropout = nnmx.Dropout(p = dropout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if inx != len(self.layers) - 1:\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33907ab7",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aaa51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for batch iteration\n",
    "def batch_iterate(batch_size, X, Y, shuffle = True):\n",
    "    for i in range(0, Y.size, batch_size):\n",
    "        X_curr = X[i: min(i + batch_size, Y.size), :]\n",
    "        Y_curr = Y[i: min(i + batch_size, Y.size)]\n",
    "        if shuffle:\n",
    "            inx_lst = mx.random.permutation(batch_size)\n",
    "            X_curr = X_curr[inx_lst, :]\n",
    "            Y_curr = Y_curr[inx_lst]\n",
    "        yield X_curr, Y_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            _, grads = loss_and_grad_fn(model, inputs, targets)\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            optimizer.update(model, grads)\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(model.parameters(), optimizer.state)\n",
    "\n",
    "def eval_mlp_mlx(model, X_test, Y_test, batch_size):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    for (inputs, targets) in batch_iterate(batch_size, X_test, Y_test, shuffle=False):\n",
    "        outputs = model(inputs).reshape(-1)\n",
    "        # convert back to numpy\n",
    "        outputs, targets = np.array(outputs), np.array(targets)\n",
    "        # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "        outputs_all = np.concatenate([outputs_all, outputs])\n",
    "        targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3974705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for _, (X_train, X_test, Y_train, Y_test) in enumerate(zip(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)):\n",
    "        # initialize the model\n",
    "        mx.random.seed(default_random_state)\n",
    "        model = MLPMLX(num_features, hidden_layers_size, dropout)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        def loss_fn(model, X, Y):\n",
    "            Y_pred = model(X).reshape(-1)\n",
    "            return mx.mean(nnmx.losses.mse_loss(Y_pred, Y))\n",
    "        loss_and_grad_fn = nnmx.value_and_grad(model, loss_fn)\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optimmx.Adam(learning_rate = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp_mlx(model, X_test, Y_test, batch_size)\n",
    "        print(pearson)\n",
    "        if pearson == -1:\n",
    "            return pearson\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0617236",
   "metadata": {},
   "source": [
    "Conduct training and evaluating process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training process of the default config\n",
    "# num_features = len(best_features)\n",
    "# hidden_layers_size = [8, 8, 8]\n",
    "# dropout = 0.2\n",
    "# lr = 0.001\n",
    "# batch_size = 180\n",
    "# num_epochs = 10\n",
    "\n",
    "# train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad94fa",
   "metadata": {},
   "source": [
    "Conduct Bayesian Optimization on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b347651",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp_mlx(trial):\n",
    "    # First initialize the parameters\n",
    "    num_features = len(best_features)\n",
    "    num_layers = default_num_layers\n",
    "    log_2_hidden_layers_size = []\n",
    "    for i in range(num_layers):\n",
    "        if len(log_2_hidden_layers_size) == 0:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, 6))\n",
    "        else:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, log_2_hidden_layers_size[-1]))\n",
    "    hidden_layers_size = [2**l for l in log_2_hidden_layers_size]\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.7)\n",
    "    lr = trial.suggest_float(\"lr\", 0.0001, 0.01, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [30, 60, 120, 180, 360, 720])\n",
    "    num_epochs = trial.suggest_categorical(\"num_epochs\", [10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "    \n",
    "    # Conduct training based on those parameters\n",
    "    return train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mlp_mlx(study_name, storage_name, objective_function=objective_mlp_mlx, n_trials = 100, n_jobs = 1):\n",
    "    print(\"Conduct hyperparam opt for MLP\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "                 'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137',]\n",
    "                # 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301',] \n",
    "                #  'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', \n",
    "                #  'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features)\n",
    "\n",
    "# Convert to float32\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "\n",
    "# Convert to MLX\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e30381",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_mlp_mlx(\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\",\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196766ca",
   "metadata": {},
   "source": [
    "#### Nineth Iteration: AE + MLP instead of GBDT feature selection + MLP (train together)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c02845",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gaussian noise for autoencoder\n",
    "class GaussianNoise(nnmx.Module):\n",
    "    def __init__(self, mean: float = 0.0, stddev: float = 0.01):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self, x, training = True):\n",
    "        if training:\n",
    "            x += mx.random.normal(loc=self.mean, scale=self.stddev, shape=x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568359d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# We do not use the reset method this time so you have to create the model at each fold\n",
    "class AEMLX(nnmx.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, latent_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers for encoder\n",
    "        last_layer = num_features\n",
    "        self.encoder_layers = []\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.encoder_layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.encoder_layers.append(nnmx.Linear(last_layer, latent_size))\n",
    "\n",
    "        # Initialize layers for decoder\n",
    "        last_layer = latent_size\n",
    "        self.decoder_layers = []\n",
    "        for current_layer in hidden_layers_size[::-1]:\n",
    "            self.decoder_layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.decoder_layers.append(nnmx.Linear(last_layer, num_features))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nnmx.ReLU()\n",
    "\n",
    "        # Initialze gaussian noise to apply upon training\n",
    "        self.gaussian_noise = GaussianNoise()\n",
    "\n",
    "        # Initialize dropout\n",
    "        self.dropout = nnmx.Dropout(p = dropout)\n",
    "\n",
    "    def __call__(self, x, training = True):\n",
    "        if training:\n",
    "            x = self.gaussian_noise(x)\n",
    "        for inx, layer in enumerate(self.encoder_layers):\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "        for inx, layer in enumerate(self.decoder_layers):\n",
    "            if inx == len(self.decoder_layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def get_latent(self, x):\n",
    "        for inx, layer in enumerate(self.encoder_layers):\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aef2af",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae44b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_aemlp_mlx(ae_model, ae_loss_and_grad_fn, ae_optimizer, ae_num_epochs,\n",
    "                     mlp_model, mlp_loss_and_grad_fn, mlp_optimizer, mlp_num_epochs,\n",
    "                     X_train, Y_train, batch_size):\n",
    "    # Train ae first\n",
    "    ae_model.train()\n",
    "    for _ in tqdm(range(ae_num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            # get gradients for ae, output is the inputs itself\n",
    "            _, ae_grads = ae_loss_and_grad_fn(ae_model, inputs, inputs)\n",
    "\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            ae_optimizer.update(ae_model, ae_grads)\n",
    "\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(ae_model.parameters(), ae_optimizer.state)\n",
    "\n",
    "    # Train mlp later\n",
    "    mlp_model.train()\n",
    "    for _ in tqdm(range(mlp_num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            # get the latent representation for X_train\n",
    "            latent_inputs = ae_model.get_latent(inputs)\n",
    "            used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "            # get gradients for mlp\n",
    "            _, mlp_grads = mlp_loss_and_grad_fn(mlp_model, used_inputs, targets)\n",
    "\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            mlp_optimizer.update(mlp_model, mlp_grads)\n",
    "\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(mlp_model.parameters(), mlp_optimizer.state)\n",
    "\n",
    "    # # Train ae and mlp together\n",
    "    # ae_model.train()\n",
    "    # mlp_model.train()\n",
    "    # for _ in tqdm(range(ae_num_epochs)):\n",
    "    #     for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "    #         # get gradients for ae, output is the inputs itself\n",
    "    #         _, ae_grads = ae_loss_and_grad_fn(ae_model, inputs, inputs)\n",
    "\n",
    "    #         # Update the optimizer state and model parameters in a single call\n",
    "    #         ae_optimizer.update(ae_model, ae_grads)\n",
    "\n",
    "    #         # Force a graph evaluation\n",
    "    #         mx.eval(ae_model.parameters(), ae_optimizer.state)\n",
    "\n",
    "    #         # get gradients for mlp\n",
    "    #         latent_inputs = ae_model.get_latent(inputs)\n",
    "    #         used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "    #         _, mlp_grads = mlp_loss_and_grad_fn(mlp_model, used_inputs, targets)\n",
    "\n",
    "    #         # Update the optimizer state and model parameters in a single call\n",
    "    #         mlp_optimizer.update(mlp_model, mlp_grads)\n",
    "\n",
    "    #         # Force a graph evaluation\n",
    "    #         mx.eval(mlp_model.parameters(), mlp_optimizer.state)\n",
    "\n",
    "def eval_aemlp_mlx(ae_model, mlp_model, X_test, Y_test, batch_size):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    ae_model.eval()\n",
    "    mlp_model.eval()\n",
    "    for (inputs, targets) in batch_iterate(batch_size, X_test, Y_test, shuffle=False):\n",
    "        latent_inputs = ae_model.get_latent(inputs)\n",
    "        used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "        outputs = mlp_model(used_inputs).reshape(-1)\n",
    "        # convert back to numpy\n",
    "        outputs, targets = np.array(outputs), np.array(targets)\n",
    "        # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "        outputs_all = np.concatenate([outputs_all, outputs])\n",
    "        targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6679261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_mlx_aemlp(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout, ae_lr, ae_num_epochs,\n",
    "                            mlp_hidden_layers_size, mlp_dropout, mlp_lr, mlp_num_epochs,\n",
    "                            cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size):\n",
    "    cv_pearson = 0\n",
    "    for _, (X_train, X_test, Y_train, Y_test) in enumerate(zip(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)):\n",
    "        # initialize the model\n",
    "        mx.random.seed(default_random_state)\n",
    "        ae_model = AEMLX(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout)\n",
    "\n",
    "        mx.random.seed(default_random_state)\n",
    "        mlp_model = MLPMLX(ae_latent_size + num_features, mlp_hidden_layers_size, mlp_dropout)\n",
    "\n",
    "        # Initialize the loss function (both use same loss function)\n",
    "        def loss_fn(model, X, Y):\n",
    "            Y_pred = model(X).reshape(-1)\n",
    "            Y = Y.reshape(-1)\n",
    "            return mx.mean(nnmx.losses.mse_loss(Y_pred, Y))\n",
    "        ae_loss_and_grad_fn = nnmx.value_and_grad(ae_model, loss_fn)\n",
    "        mlp_loss_and_grad_fn = nnmx.value_and_grad(mlp_model, loss_fn)\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        ae_optimizer = optimmx.Adam(learning_rate = ae_lr)\n",
    "        mlp_optimizer = optimmx.Adam(learning_rate = mlp_lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_aemlp_mlx(ae_model, ae_loss_and_grad_fn, ae_optimizer, ae_num_epochs,\n",
    "                        mlp_model, mlp_loss_and_grad_fn, mlp_optimizer, mlp_num_epochs,\n",
    "                        X_train, Y_train, batch_size)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_aemlp_mlx(ae_model, mlp_model, X_test, Y_test, batch_size)\n",
    "        print(pearson)\n",
    "        if pearson == -1:\n",
    "            return pearson\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4959ed6",
   "metadata": {},
   "source": [
    "Conduct training and evaluating process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b892fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the CV data, seems to be better with only anonymized features\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col] + \\\n",
    "#                 [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "#                 [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)\n",
    "# for i in range(default_cv):\n",
    "#     X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "#     X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "#     Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "#     Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Training process of the default config\n",
    "# num_features = len(best_features)\n",
    "# ae_hidden_layers_size = [64]\n",
    "# ae_latent_size = 16\n",
    "# mlp_hidden_layers_size = [4, 2]\n",
    "# lr = 0.0005\n",
    "# dropout = 0.5\n",
    "# batch_size = 180\n",
    "# num_epochs = 30\n",
    "\n",
    "# train_eval_cv_mlx_aemlp(num_features, ae_hidden_layers_size, ae_latent_size, \n",
    "#                         mlp_hidden_layers_size, dropout, \n",
    "#                         lr, default_cv,\n",
    "#                         X_train_arr, X_test_arr, Y_train_arr, Y_test_arr,\n",
    "#                         batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477b9b9",
   "metadata": {},
   "source": [
    "Optimize with bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_default_num_layers = 2\n",
    "mlp_default_num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c60d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_aemlp_mlx(trial):\n",
    "    # First initialize the parameters\n",
    "    num_features = len(best_features)\n",
    "\n",
    "    # initialize ae layers\n",
    "    ae_num_layers = ae_default_num_layers\n",
    "    ae_log_2_hidden_layers_size = []\n",
    "    for i in range(ae_num_layers):\n",
    "        if len(ae_log_2_hidden_layers_size) == 0:\n",
    "            ae_log_2_hidden_layers_size.append(trial.suggest_int(f\"ae_log2_hidden_layer_{i}\", 3, int(math.ceil(math.log2(num_features)))))\n",
    "        else:\n",
    "            ae_log_2_hidden_layers_size.append(trial.suggest_int(f\"ae_log2_hidden_layer_{i}\", 3, ae_log_2_hidden_layers_size[-1]))\n",
    "    ae_hidden_layers_size = [2**i for i in ae_log_2_hidden_layers_size]\n",
    "    ae_latent_size = 2**trial.suggest_int(\"ae_log2_latent_size\", 3, ae_log_2_hidden_layers_size[-1])\n",
    "    ae_dropout = trial.suggest_float(\"ae_dropout\", 0.2, 0.7)\n",
    "    ae_lr = trial.suggest_float(\"ae_lr\", 0.0001, 0.01, log=True)\n",
    "    ae_num_epochs = trial.suggest_categorical(\"num_epochs\", [20, 40, 60, 80, 100])\n",
    "\n",
    "    # initialize mlp layers\n",
    "    mlp_num_layers = mlp_default_num_layers\n",
    "    mlp_log_2_hidden_layers_size = []\n",
    "    for i in range(mlp_num_layers):\n",
    "        if len(mlp_log_2_hidden_layers_size) == 0:\n",
    "            mlp_log_2_hidden_layers_size.append(trial.suggest_int(f\"mlp_log2_hidden_layer_{i}\", 2, int(math.ceil(math.log2(ae_latent_size + num_features)))))\n",
    "        else:\n",
    "            mlp_log_2_hidden_layers_size.append(trial.suggest_int(f\"mlp_log2_hidden_layer_{i}\", 2, mlp_log_2_hidden_layers_size[-1]))\n",
    "    mlp_hidden_layers_size = [2**i for i in mlp_log_2_hidden_layers_size]\n",
    "    mlp_dropout = trial.suggest_float(\"mlp_dropout\", 0.2, 0.7)\n",
    "    mlp_lr = trial.suggest_float(\"mlp_lr\", 0.0001, 0.01, log=True)\n",
    "    mlp_num_epochs = trial.suggest_categorical(\"mlp_num_epochs\", [10, 20, 30, 40, 50])\n",
    "    # mlp_num_epochs = ae_num_epochs\n",
    "\n",
    "    # batch size\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [30, 60, 120, 180, 360, 720, 1440])\n",
    "    \n",
    "    # Conduct training based on those parameters\n",
    "    cv_pearson = train_eval_cv_mlx_aemlp(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout, ae_lr, ae_num_epochs,\n",
    "                                         mlp_hidden_layers_size, mlp_dropout, mlp_lr, mlp_num_epochs,\n",
    "                                         default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr,\n",
    "                                         batch_size)\n",
    "    \n",
    "    return cv_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_aemlp_mlx(study_name, storage_name, objective_function=objective_aemlp_mlx, n_trials = 100, n_jobs = 1):\n",
    "    print(\"Conduct hyperparam opt for AE-MLP\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features)\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_aemlp_mlx(\n",
    "    f\"aemlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{ae_default_num_layers}_{mlp_default_num_layers}_study\",\n",
    "    f\"aemlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{ae_default_num_layers}_{mlp_default_num_layers}_study\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
