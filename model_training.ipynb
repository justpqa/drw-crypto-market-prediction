{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89ecff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justpqa/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler, GPSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import multiprocessing\n",
    "# max_n_jobs = multiprocessing.cpu_count()\n",
    "import shap\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, Sampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nnmx\n",
    "import mlx.optimizers as optimmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dce0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2025de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_version = 2\n",
    "# 1 for pc feature, \n",
    "# 2 for label correlation feature # seems to work most consistently\n",
    "# 3 for best features based on combination rank\n",
    "# 4 for including time features (in case we want to reverse engineer the masked timestamp)\n",
    "# 5 for increasing number of correlation features + only use those that are in the same cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935ee52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_random_state = 101\n",
    "random.seed(default_random_state)\n",
    "np.random.seed(default_random_state)\n",
    "torch.manual_seed(default_random_state)\n",
    "torch.mps.manual_seed(default_random_state)\n",
    "mx.random.seed(default_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731d3a4",
   "metadata": {},
   "source": [
    "#### Import train data and popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dc4e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X473</th>\n",
       "      <th>X205</th>\n",
       "      <th>X198</th>\n",
       "      <th>X444</th>\n",
       "      <th>X466</th>\n",
       "      <th>X445</th>\n",
       "      <th>X472</th>\n",
       "      <th>X26</th>\n",
       "      <th>X29</th>\n",
       "      <th>X217</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_buy_volume</th>\n",
       "      <th>normalized_sell_volume</th>\n",
       "      <th>liquidity_adjusted_imbalance</th>\n",
       "      <th>pressure_spread_interaction</th>\n",
       "      <th>trade_direction_ratio</th>\n",
       "      <th>net_buy_volume</th>\n",
       "      <th>bid_skew</th>\n",
       "      <th>ask_skew</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.201346</td>\n",
       "      <td>-1.978504</td>\n",
       "      <td>-1.700689</td>\n",
       "      <td>-0.142546</td>\n",
       "      <td>-0.163476</td>\n",
       "      <td>-0.128331</td>\n",
       "      <td>-0.126241</td>\n",
       "      <td>1.406392</td>\n",
       "      <td>1.474789</td>\n",
       "      <td>-0.981975</td>\n",
       "      <td>...</td>\n",
       "      <td>11.542564</td>\n",
       "      <td>5.339347</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>-0.230493</td>\n",
       "      <td>0.796810</td>\n",
       "      <td>131.421</td>\n",
       "      <td>0.644635</td>\n",
       "      <td>0.355365</td>\n",
       "      <td>2023-03-01 00:00:00</td>\n",
       "      <td>0.562539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186231</td>\n",
       "      <td>-1.830295</td>\n",
       "      <td>-1.669471</td>\n",
       "      <td>-0.135499</td>\n",
       "      <td>-0.159388</td>\n",
       "      <td>-0.124790</td>\n",
       "      <td>-0.115015</td>\n",
       "      <td>1.003783</td>\n",
       "      <td>1.312735</td>\n",
       "      <td>-0.940190</td>\n",
       "      <td>...</td>\n",
       "      <td>13.626484</td>\n",
       "      <td>137.821061</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>-0.549445</td>\n",
       "      <td>0.620251</td>\n",
       "      <td>203.896</td>\n",
       "      <td>0.942921</td>\n",
       "      <td>0.057079</td>\n",
       "      <td>2023-03-01 00:01:00</td>\n",
       "      <td>0.533686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.182398</td>\n",
       "      <td>-1.803540</td>\n",
       "      <td>-1.662645</td>\n",
       "      <td>-0.133705</td>\n",
       "      <td>-0.158627</td>\n",
       "      <td>-0.123891</td>\n",
       "      <td>-0.112303</td>\n",
       "      <td>0.760801</td>\n",
       "      <td>1.219124</td>\n",
       "      <td>-0.933071</td>\n",
       "      <td>...</td>\n",
       "      <td>360.242073</td>\n",
       "      <td>2.263386</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.530818</td>\n",
       "      <td>0.538664</td>\n",
       "      <td>22.858</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>2023-03-01 00:02:00</td>\n",
       "      <td>0.546505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.177415</td>\n",
       "      <td>-1.714013</td>\n",
       "      <td>-1.620037</td>\n",
       "      <td>-0.133251</td>\n",
       "      <td>-0.158334</td>\n",
       "      <td>-0.123658</td>\n",
       "      <td>-0.109113</td>\n",
       "      <td>0.955549</td>\n",
       "      <td>1.353001</td>\n",
       "      <td>-0.891216</td>\n",
       "      <td>...</td>\n",
       "      <td>69.011716</td>\n",
       "      <td>5.946089</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>0.454780</td>\n",
       "      <td>0.728757</td>\n",
       "      <td>210.779</td>\n",
       "      <td>0.187976</td>\n",
       "      <td>0.812024</td>\n",
       "      <td>2023-03-01 00:03:00</td>\n",
       "      <td>0.357703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.174164</td>\n",
       "      <td>-1.684170</td>\n",
       "      <td>-1.600188</td>\n",
       "      <td>-0.128862</td>\n",
       "      <td>-0.156668</td>\n",
       "      <td>-0.121464</td>\n",
       "      <td>-0.106383</td>\n",
       "      <td>0.905460</td>\n",
       "      <td>1.361880</td>\n",
       "      <td>-0.878711</td>\n",
       "      <td>...</td>\n",
       "      <td>3.623647</td>\n",
       "      <td>12.867864</td>\n",
       "      <td>0.081042</td>\n",
       "      <td>-0.533689</td>\n",
       "      <td>0.689066</td>\n",
       "      <td>54.004</td>\n",
       "      <td>0.887255</td>\n",
       "      <td>0.112745</td>\n",
       "      <td>2023-03-01 00:04:00</td>\n",
       "      <td>0.362452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X473      X205      X198      X444      X466      X445      X472  \\\n",
       "0 -0.201346 -1.978504 -1.700689 -0.142546 -0.163476 -0.128331 -0.126241   \n",
       "1 -0.186231 -1.830295 -1.669471 -0.135499 -0.159388 -0.124790 -0.115015   \n",
       "2 -0.182398 -1.803540 -1.662645 -0.133705 -0.158627 -0.123891 -0.112303   \n",
       "3 -0.177415 -1.714013 -1.620037 -0.133251 -0.158334 -0.123658 -0.109113   \n",
       "4 -0.174164 -1.684170 -1.600188 -0.128862 -0.156668 -0.121464 -0.106383   \n",
       "\n",
       "        X26       X29      X217  ...  normalized_buy_volume  \\\n",
       "0  1.406392  1.474789 -0.981975  ...              11.542564   \n",
       "1  1.003783  1.312735 -0.940190  ...              13.626484   \n",
       "2  0.760801  1.219124 -0.933071  ...             360.242073   \n",
       "3  0.955549  1.353001 -0.891216  ...              69.011716   \n",
       "4  0.905460  1.361880 -0.878711  ...               3.623647   \n",
       "\n",
       "   normalized_sell_volume  liquidity_adjusted_imbalance  \\\n",
       "0                5.339347                      0.063569   \n",
       "1              137.821061                      0.011610   \n",
       "2                2.263386                      0.015877   \n",
       "3                5.946089                      0.025702   \n",
       "4               12.867864                      0.081042   \n",
       "\n",
       "   pressure_spread_interaction  trade_direction_ratio  net_buy_volume  \\\n",
       "0                    -0.230493               0.796810         131.421   \n",
       "1                    -0.549445               0.620251         203.896   \n",
       "2                     0.530818               0.538664          22.858   \n",
       "3                     0.454780               0.728757         210.779   \n",
       "4                    -0.533689               0.689066          54.004   \n",
       "\n",
       "   bid_skew  ask_skew           timestamp     label  \n",
       "0  0.644635  0.355365 2023-03-01 00:00:00  0.562539  \n",
       "1  0.942921  0.057079 2023-03-01 00:01:00  0.533686  \n",
       "2  0.007283  0.992717 2023-03-01 00:02:00  0.546505  \n",
       "3  0.187976  0.812024 2023-03-01 00:03:00  0.357703  \n",
       "4  0.887255  0.112745 2023-03-01 00:04:00  0.362452  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_parquet(f\"data/cleaned/cleaned_train_{feature_version}.parquet\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766f9871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>bid_qty</th>\n",
       "      <th>ask_qty</th>\n",
       "      <th>buy_qty</th>\n",
       "      <th>sell_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221.389</td>\n",
       "      <td>15.283</td>\n",
       "      <td>8.425</td>\n",
       "      <td>176.405</td>\n",
       "      <td>44.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>847.796</td>\n",
       "      <td>38.590</td>\n",
       "      <td>2.336</td>\n",
       "      <td>525.846</td>\n",
       "      <td>321.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295.596</td>\n",
       "      <td>0.442</td>\n",
       "      <td>60.250</td>\n",
       "      <td>159.227</td>\n",
       "      <td>136.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460.705</td>\n",
       "      <td>4.865</td>\n",
       "      <td>21.016</td>\n",
       "      <td>335.742</td>\n",
       "      <td>124.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.818</td>\n",
       "      <td>27.158</td>\n",
       "      <td>3.451</td>\n",
       "      <td>98.411</td>\n",
       "      <td>44.407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    volume  bid_qty  ask_qty  buy_qty  sell_qty\n",
       "0  221.389   15.283    8.425  176.405    44.984\n",
       "1  847.796   38.590    2.336  525.846   321.950\n",
       "2  295.596    0.442   60.250  159.227   136.369\n",
       "3  460.705    4.865   21.016  335.742   124.963\n",
       "4  142.818   27.158    3.451   98.411    44.407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_features_train = pd.read_parquet(\"data/cleaned/popular_features_train.parquet\")\n",
    "popular_features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f1fe5",
   "metadata": {},
   "source": [
    "#### Implement some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb40f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to split into some fold\n",
    "train_df[\"timestamp\"] = pd.to_datetime(train_df[\"timestamp\"])\n",
    "\n",
    "default_cv = 4\n",
    "default_cv_type = \"full\"\n",
    "# NOTE: default_cv must set to 1 instead of 3 based on consistency with LB score contains 49% of test data\n",
    "# NOTE: 3 cv with gap is slightly better or almost equal\n",
    "\n",
    "def create_cv(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        # train_month = [3, 4, 5, 6, 7, 8]\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # test_month = [9, 10, 11, 12, 1, 2] # try to make a gap to see if there is any differences in cv-lb correlation\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"])\n",
    "        Y_test_arr.append(test[\"label\"])  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# def create_cv_random_test(train_df, features=None, test_cv=10):\n",
    "#     # randomize so that we have 1 train, but try it on 10 different test \n",
    "#     if features is not None:\n",
    "#         train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "#     X_train_arr = []\n",
    "#     X_test_arr = []\n",
    "#     Y_train_arr = []\n",
    "#     Y_test_arr = []\n",
    "\n",
    "#     # Create train data\n",
    "#     train_month = [3, 4, 5, 6, 7, 8]\n",
    "#     train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)] \n",
    "#     X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#     Y_train_arr.append(train[\"label\"])\n",
    "\n",
    "#     test_month = [9, 10, 11, 12, 1, 2]\n",
    "#     test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)]\n",
    "#     # Create test data\n",
    "#     for _ in range(test_cv):\n",
    "#         random_test = test.sample(frac = 0.5, random_state = default_random_state)\n",
    "#         X_test_arr.append(random_test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#         Y_test_arr.append(random_test[\"label\"])\n",
    "\n",
    "#     return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr \n",
    "\n",
    "# class [-1, 0, 1] -> [0, 1, 2] => < -0.2 => neg, > 0.2 => pos, else => neutral\n",
    "def create_classification_class(label):\n",
    "    if label < -0.4: return 0\n",
    "    elif label < 0: return 1\n",
    "    elif label < 0.4: return 2\n",
    "    return 3\n",
    "\n",
    "def create_cv_classification(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        # train_month = [3, 4, 5, 6, 7, 8]\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # test_month = [9, 10, 11, 12, 1, 2] # try to make a gap to see if there is any differences in cv-lb correlation\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"].apply(lambda x: create_classification_class(x)))\n",
    "        Y_test_arr.append(test[\"label\"].apply(lambda x: create_classification_class(x)))  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8b878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_score(Y_test, Y_pred):\n",
    "    if isinstance(Y_test, pd.Series) or isinstance(Y_test, pd.DataFrame):\n",
    "        Y_test = Y_test.values\n",
    "    if isinstance(Y_pred, pd.Series) or isinstance(Y_pred, pd.DataFrame):\n",
    "        Y_pred = Y_pred.values\n",
    "    Y_test = np.ravel(Y_test)\n",
    "    Y_pred = np.ravel(Y_pred)\n",
    "    pearson = np.corrcoef(Y_test, Y_pred)[0, 1]\n",
    "    if np.isnan(pearson):\n",
    "        if np.std(Y_pred) == 0:\n",
    "            print(Y_pred)\n",
    "            print(\"Error: zero variance prediction\")\n",
    "        elif np.isnan(Y_pred).any():\n",
    "            print(\"Error: nan prediction\")\n",
    "        return -1\n",
    "    else:\n",
    "        return pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce779cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function specifically for cross validation\n",
    "def train_eval_cv(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        cv_score += scoring_function(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_score / cv\n",
    "\n",
    "def train_eval_cv_random_test(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score, test_cv = 10):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        curr_cv_score = 0\n",
    "\n",
    "        # Conduct fitting\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        # sampling and testing\n",
    "        len_test = X_test.shape[0]\n",
    "        for seed in tqdm(range(test_cv)):\n",
    "            np.random.seed(seed)\n",
    "            test_index = np.random.choice(len_test, size = len_test // 2, replace = False) \n",
    "            X_test_sample = X_test.loc[test_index, :]\n",
    "            Y_test_sample = Y_test[test_index]\n",
    "            Y_pred_sample = model.predict(X_test_sample)\n",
    "            curr_cv_score += scoring_function(Y_test_sample, Y_pred_sample)\n",
    "        \n",
    "        cv_score += curr_cv_score / test_cv\n",
    "    \n",
    "    np.random.seed(default_random_state)\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9d975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trees = 2000\n",
    "# Finetuning XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddbb8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning XGBoost\n",
    "def objective_xgboost_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBClassifier(**params)\n",
    "    cv_acc = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_lightgbm_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMClassifier(**params)\n",
    "    cv_acc = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_catboost_classification(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_acc = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778f94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trials = 100\n",
    "default_n_jobs = 2\n",
    "\n",
    "def optimize_xgboost(study_name, storage_name, objective_function=objective_xgboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for XGBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_lightgbm(study_name, storage_name, objective_function=objective_lightgbm, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for LightGBM\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_catboost(study_name, storage_name, objective_function=objective_catboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for CatBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fd743",
   "metadata": {},
   "source": [
    "#### First iteration: training with all features from the collection, no popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5acc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb106a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_catboost = optimize_catboost(\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    "# )\n",
    "# # Need to take down as catboost might not work well in this situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e2b50",
   "metadata": {},
   "source": [
    "Analyze params - cv relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8801e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_study_df(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    study_df = []\n",
    "    for trial in study.trials:\n",
    "        trial_dict = trial.params\n",
    "        trial_dict[\"value\"] = trial.value\n",
    "        study_df.append(trial_dict)\n",
    "\n",
    "    return pd.DataFrame(study_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d57f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_value_viz(study_df):\n",
    "    nrows = (study_df.shape[1] - 1) // 3 + ((study_df.shape[1] - 1) % 3 > 0)\n",
    "    fig, ax = plt.subplots(nrows = nrows, ncols = 3, figsize = (14, 5 * nrows))\n",
    "    for inx, var in enumerate(study_df.columns):\n",
    "        x, y = inx // 3, inx % 3\n",
    "        if var != \"value\":\n",
    "            sns.regplot(study_df, x = var, y = \"value\", ax = ax[x][y], lowess=True, line_kws={'color': 'green'}, ci = 95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad954e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_xgboost = get_study_df(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")   \n",
    "params_value_viz(study_df_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717983ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_lightgbm = get_study_df(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "params_value_viz(study_df_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba067f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df_catboost = get_study_df(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# params_value_viz(study_df_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d81cc8",
   "metadata": {},
   "source": [
    "Analyze feature importance + CV performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ccea6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_from_file(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1942990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(model, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, sample_size=10000):\n",
    "    mean_abs_shap_all = np.zeros(X_train_arr[0].shape[1])\n",
    "    for i in range(default_cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        X_test_sample = X_test.sample(sample_size, random_state = default_random_state)\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        mean_abs_shap = np.mean(np.abs(shap_values), axis = 0)\n",
    "        mean_abs_shap_all += mean_abs_shap\n",
    "    mean_abs_shap_all /= default_cv\n",
    "    return mean_abs_shap_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in xgboost_feature_importances if xgboost_feature_importances[f] > 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7366dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in lightgbm_feature_importances if lightgbm_feature_importances[f] >= 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"iterations\": default_n_trees,\n",
    "#     \"verbose\": False,\n",
    "#     \"random_seed\": default_random_state\n",
    "# }\n",
    "# best_params_catboost = get_best_params_from_file(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# for p in best_params_catboost:\n",
    "#     params[p] = best_params_catboost[p]\n",
    "\n",
    "# catboost_feature_importances = {}\n",
    "\n",
    "# cbr = CatBoostRegressor(**params)\n",
    "# cv_rmse = 0\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "#     Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "#     cbr.fit(X_train, Y_train)\n",
    "#     print(pearson_score(Y_test, cbr.predict(X_test)))\n",
    "#     features = cbr.feature_names_\n",
    "#     # features_i = cbr.feature_importances_.tolist()\n",
    "#     features_i = get_shap_values(cbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "#     for inx, feat in enumerate(features):\n",
    "#         catboost_feature_importances[feat] = catboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# plt.hist(catboost_feature_importances.values())\n",
    "# # can pick up a combination of both past cod and tss, not good at picking up ph, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([f for f in catboost_feature_importances if catboost_feature_importances[f] >= 0.02])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8120d",
   "metadata": {},
   "source": [
    "Get top 20 important features in all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ed2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:49, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca490b7",
   "metadata": {},
   "source": [
    "#### Second Iteration: adding popular feature in addition to original features correlated to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93eefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_popular_feature = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_popular_feature = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d683a",
   "metadata": {},
   "source": [
    "Check for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8211c2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>importance_xgboost</th>\n",
       "      <th>importance_lightgbm</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X862</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.071835</td>\n",
       "      <td>0.044451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X598</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.041165</td>\n",
       "      <td>0.035304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X863</td>\n",
       "      <td>0.020511</td>\n",
       "      <td>0.047957</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X856</td>\n",
       "      <td>0.025189</td>\n",
       "      <td>0.037735</td>\n",
       "      <td>0.031462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X612</td>\n",
       "      <td>0.016267</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>0.027671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>bid_skew</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>ask_skew</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>trade_intensity</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>spread_indicator</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>avg_trade_size</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  var  importance_xgboost  importance_lightgbm  importance\n",
       "0                X862            0.017067             0.071835    0.044451\n",
       "1                X598            0.029444             0.041165    0.035304\n",
       "2                X863            0.020511             0.047957    0.034234\n",
       "3                X856            0.025189             0.037735    0.031462\n",
       "4                X612            0.016267             0.039075    0.027671\n",
       "..                ...                 ...                  ...         ...\n",
       "135          bid_skew            0.001406             0.000061    0.000733\n",
       "136          ask_skew            0.001081             0.000205    0.000643\n",
       "137   trade_intensity            0.000000             0.001089    0.000544\n",
       "138  spread_indicator            0.000935             0.000059    0.000497\n",
       "139    avg_trade_size            0.000000             0.000412    0.000206\n",
       "\n",
       "[140 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df[~feature_importances_df[\"var\"].str.contains(\"X\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ba087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:29, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8dc1e",
   "metadata": {},
   "source": [
    "#### Third iteration: a more truncated version from the first collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7701a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>importance_xgboost</th>\n",
       "      <th>importance_lightgbm</th>\n",
       "      <th>importance</th>\n",
       "      <th>weighted_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X862</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.071835</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>0.043094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X598</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.041165</td>\n",
       "      <td>0.035304</td>\n",
       "      <td>0.035014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X863</td>\n",
       "      <td>0.020511</td>\n",
       "      <td>0.047957</td>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.033554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X856</td>\n",
       "      <td>0.025189</td>\n",
       "      <td>0.037735</td>\n",
       "      <td>0.031462</td>\n",
       "      <td>0.031151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X612</td>\n",
       "      <td>0.016267</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>0.027671</td>\n",
       "      <td>0.027106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>bid_skew</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>ask_skew</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>spread_indicator</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>trade_intensity</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>avg_trade_size</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  var  importance_xgboost  importance_lightgbm  importance  \\\n",
       "0                X862            0.017067             0.071835    0.044451   \n",
       "1                X598            0.029444             0.041165    0.035304   \n",
       "2                X863            0.020511             0.047957    0.034234   \n",
       "3                X856            0.025189             0.037735    0.031462   \n",
       "4                X612            0.016267             0.039075    0.027671   \n",
       "..                ...                 ...                  ...         ...   \n",
       "135          bid_skew            0.001406             0.000061    0.000733   \n",
       "136          ask_skew            0.001081             0.000205    0.000643   \n",
       "137  spread_indicator            0.000935             0.000059    0.000497   \n",
       "138   trade_intensity            0.000000             0.001089    0.000544   \n",
       "139    avg_trade_size            0.000000             0.000412    0.000206   \n",
       "\n",
       "     weighted_importance  \n",
       "0               0.043094  \n",
       "1               0.035014  \n",
       "2               0.033554  \n",
       "3               0.031151  \n",
       "4               0.027106  \n",
       "..                   ...  \n",
       "135             0.000767  \n",
       "136             0.000665  \n",
       "137             0.000519  \n",
       "138             0.000517  \n",
       "139             0.000196  \n",
       "\n",
       "[140 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "feature_importances_df[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df = feature_importances_df.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a614a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', 'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137', 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301', 'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', 'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n"
     ]
    }
   ],
   "source": [
    "print(feature_importances_df.loc[:49, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f34e76",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56532466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_importance_threshold = 0.011\n",
    "# xgboost_best_features = [\n",
    "#     f for f in xgboost_feature_importances if xgboost_feature_importances[f] > xgboost_importance_threshold\n",
    "# ] + [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"]\n",
    "# print(len(xgboost_best_features))\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, xgboost_best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_xgboost_params_truncated = optimize_xgboost(\n",
    "#     f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\",\n",
    "#     f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\"\n",
    "# ) # much worse than using all features  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13ba89",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ef415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm_importance_threshold = 20\n",
    "# lightgbm_best_features = [\n",
    "#     f for f in lightgbm_feature_importances if lightgbm_feature_importances[f] > lightgbm_importance_threshold\n",
    "# ] + [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"]\n",
    "# print(len(lightgbm_best_features))\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, lightgbm_best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_lightgbm_params_truncated = optimize_lightgbm(\n",
    "#     f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\",\n",
    "#     f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\"\n",
    "# )\n",
    "# # also much worse "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6953fd8",
   "metadata": {},
   "source": [
    "#### Fourth Iteration: a common truncated version using good features across all models + popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ebb508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6] [8, 9, 10, 11]\n",
      "[4, 5, 6, 7] [9, 10, 11, 12]\n",
      "[5, 6, 7, 8] [10, 11, 12, 1]\n",
      "[6, 7, 8, 9] [11, 12, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "                  'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137'] + \\\n",
    "                [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c7f75",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d3ed407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 12:34:59,392] Using an existing study with name 'xgboost_2_4_101_2000_common_truncated_20_study' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 12:35:24,764] Trial 101 finished with value: 0.10743372615580032 and parameters: {'max_depth': 2, 'learning_rate': 0.03026725893727348, 'subsample': 0.5558806601267801, 'colsample_bytree': 0.5150856657558225, 'colsample_bynode': 0.916738623303312, 'colsample_bylevel': 0.27462795798186346, 'min_child_weight': 7, 'reg_alpha': 5.553699891776308, 'reg_lambda': 56.530311219364656, 'gamma': 0.30224860560279077}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:35:48,617] Trial 100 finished with value: 0.10284833087131666 and parameters: {'max_depth': 9, 'learning_rate': 0.029519192346389084, 'subsample': 0.5699341041175158, 'colsample_bytree': 0.44185938078039644, 'colsample_bynode': 0.9311275485429649, 'colsample_bylevel': 0.19861098401612148, 'min_child_weight': 4, 'reg_alpha': 4.65993459325469, 'reg_lambda': 28.19808554018548, 'gamma': 0.8334903722759783}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:36:01,179] Trial 102 finished with value: 0.11236410595993777 and parameters: {'max_depth': 4, 'learning_rate': 0.03778681570463454, 'subsample': 0.5407976917732509, 'colsample_bytree': 0.4735459956992985, 'colsample_bynode': 0.17161165159649483, 'colsample_bylevel': 0.47585984750404225, 'min_child_weight': 4, 'reg_alpha': 12.12204312066842, 'reg_lambda': 49.195916414436105, 'gamma': 0.8726490311340975}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:36:25,683] Trial 103 finished with value: 0.11201544297727571 and parameters: {'max_depth': 4, 'learning_rate': 0.015233029784043832, 'subsample': 0.5286333792968343, 'colsample_bytree': 0.4793530328518327, 'colsample_bynode': 0.16814454347434116, 'colsample_bylevel': 0.47498733551397193, 'min_child_weight': 4, 'reg_alpha': 12.284840646227066, 'reg_lambda': 48.07676554259849, 'gamma': 1.1212492739586173}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:36:37,775] Trial 104 finished with value: 0.11240140457875561 and parameters: {'max_depth': 4, 'learning_rate': 0.0362536035282835, 'subsample': 0.5321193191373983, 'colsample_bytree': 0.5793801263519468, 'colsample_bynode': 0.16042331043069127, 'colsample_bylevel': 0.47148816721119907, 'min_child_weight': 4, 'reg_alpha': 12.213472690308105, 'reg_lambda': 40.51928504546501, 'gamma': 1.0927078851437437}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:37:06,351] Trial 105 finished with value: 0.10686419009978346 and parameters: {'max_depth': 5, 'learning_rate': 0.039058386764528205, 'subsample': 0.5419212491209592, 'colsample_bytree': 0.6927287655564964, 'colsample_bynode': 0.22688924291922988, 'colsample_bylevel': 0.5524633093662666, 'min_child_weight': 4, 'reg_alpha': 23.546194841560087, 'reg_lambda': 40.91496161453303, 'gamma': 1.3199004741296507}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:37:13,669] Trial 106 finished with value: 0.11482261177191541 and parameters: {'max_depth': 5, 'learning_rate': 0.03501084321585706, 'subsample': 0.4691594875122312, 'colsample_bytree': 0.620775178801602, 'colsample_bynode': 0.22048711562318546, 'colsample_bylevel': 0.24314746639550677, 'min_child_weight': 3, 'reg_alpha': 16.11253749001105, 'reg_lambda': 1.0238828577275214, 'gamma': 1.3375034079903227}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:37:45,591] Trial 107 finished with value: 0.11476944680840268 and parameters: {'max_depth': 4, 'learning_rate': 0.04428323017342818, 'subsample': 0.46584242874505843, 'colsample_bytree': 0.5555395992566152, 'colsample_bynode': 0.2044711242499913, 'colsample_bylevel': 0.37355764822755155, 'min_child_weight': 3, 'reg_alpha': 17.175738439414587, 'reg_lambda': 24.562072401357973, 'gamma': 0.700564657653046}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:37:57,067] Trial 108 finished with value: 0.10812316333268246 and parameters: {'max_depth': 5, 'learning_rate': 0.04579071756596668, 'subsample': 0.47296831984347165, 'colsample_bytree': 0.6232643409943982, 'colsample_bynode': 0.26339564357900325, 'colsample_bylevel': 0.2446371396285537, 'min_child_weight': 3, 'reg_alpha': 18.01017173961919, 'reg_lambda': 9.534305200050204, 'gamma': 0.6664700739325462}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:38:32,656] Trial 109 finished with value: 0.10781909573291185 and parameters: {'max_depth': 5, 'learning_rate': 0.045133699986742645, 'subsample': 0.42766613390273134, 'colsample_bytree': 0.629107852935701, 'colsample_bynode': 0.26745533492067686, 'colsample_bylevel': 0.3710043204947088, 'min_child_weight': 2, 'reg_alpha': 16.157366552239417, 'reg_lambda': 7.683109124179605, 'gamma': 0.5141486438140243}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:38:38,616] Trial 110 finished with value: 0.11159839664115209 and parameters: {'max_depth': 5, 'learning_rate': 0.02578712466266707, 'subsample': 0.4326719272315093, 'colsample_bytree': 0.5553608016187055, 'colsample_bynode': 0.20556070740185672, 'colsample_bylevel': 0.38359836965995775, 'min_child_weight': 2, 'reg_alpha': 20.502867709318263, 'reg_lambda': 4.756571633303238, 'gamma': 1.5037642335977004}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:39:10,123] Trial 111 finished with value: 0.10963211979836256 and parameters: {'max_depth': 4, 'learning_rate': 0.026848317201279972, 'subsample': 0.500671829531584, 'colsample_bytree': 0.5542967663550988, 'colsample_bynode': 0.2011755479195022, 'colsample_bylevel': 0.33185488681047604, 'min_child_weight': 3, 'reg_alpha': 31.145052587288806, 'reg_lambda': 0.3745083478401625, 'gamma': 1.2495494629635124}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:39:16,990] Trial 112 finished with value: 0.1074787530235404 and parameters: {'max_depth': 4, 'learning_rate': 0.05686766950949594, 'subsample': 0.4987321862661157, 'colsample_bytree': 0.5233714364919736, 'colsample_bynode': 0.13499587988610057, 'colsample_bylevel': 0.31429535275070075, 'min_child_weight': 3, 'reg_alpha': 28.944143307695846, 'reg_lambda': 1.9889996265390018, 'gamma': 0.41855924362905117}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:39:41,155] Trial 113 finished with value: 0.10632906224666243 and parameters: {'max_depth': 2, 'learning_rate': 0.0566145841657813, 'subsample': 0.46861919677947694, 'colsample_bytree': 0.5054784459813296, 'colsample_bynode': 0.30242331381306864, 'colsample_bylevel': 0.2923623611966741, 'min_child_weight': 3, 'reg_alpha': 2.6612617795125217, 'reg_lambda': 12.828940077127058, 'gamma': 0.40790564836450877}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:39:46,990] Trial 114 finished with value: 0.104581160906139 and parameters: {'max_depth': 3, 'learning_rate': 0.06337616313591082, 'subsample': 0.3806382693038565, 'colsample_bytree': 0.2026993371393418, 'colsample_bynode': 0.23483596211608823, 'colsample_bylevel': 0.2881593066444653, 'min_child_weight': 3, 'reg_alpha': 50.620446243375724, 'reg_lambda': 84.21708446531736, 'gamma': 0.9553495990961263}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:40:22,356] Trial 115 finished with value: 0.10486636680397568 and parameters: {'max_depth': 5, 'learning_rate': 0.032372803914730165, 'subsample': 0.38398465271408694, 'colsample_bytree': 0.6594974487398215, 'colsample_bynode': 0.22525320145781183, 'colsample_bylevel': 0.4322377874102041, 'min_child_weight': 3, 'reg_alpha': 51.021555609971244, 'reg_lambda': 28.850168326730362, 'gamma': 1.187317671893827}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:40:26,720] Trial 116 finished with value: 0.11543896199792947 and parameters: {'max_depth': 5, 'learning_rate': 0.034190490365064975, 'subsample': 0.579765465489185, 'colsample_bytree': 0.5864423741254706, 'colsample_bynode': 0.1910277590492978, 'colsample_bylevel': 0.41001200289109885, 'min_child_weight': 5, 'reg_alpha': 19.796109675038267, 'reg_lambda': 10.501074233701393, 'gamma': 1.339561212284174}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:40:51,387] Trial 118 finished with value: 0.10830697405919634 and parameters: {'max_depth': 5, 'learning_rate': 0.04040109143839752, 'subsample': 0.6480082607639885, 'colsample_bytree': 0.5883598729182492, 'colsample_bynode': 0.07858139979076084, 'colsample_bylevel': 0.39299081452959006, 'min_child_weight': 5, 'reg_alpha': 19.957471637758733, 'reg_lambda': 17.011575915265023, 'gamma': 4.2915396608029965}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:40:51,894] Trial 117 finished with value: 0.10480505083058933 and parameters: {'max_depth': 2, 'learning_rate': 0.06913554870396198, 'subsample': 0.641316837739831, 'colsample_bytree': 0.5951080235313682, 'colsample_bynode': 0.673439756173074, 'colsample_bylevel': 0.2324139224474161, 'min_child_weight': 5, 'reg_alpha': 19.866706079054165, 'reg_lambda': 25.102005043898437, 'gamma': 4.407553938195155}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:41:27,703] Trial 120 finished with value: 0.11298141522602262 and parameters: {'max_depth': 6, 'learning_rate': 0.03465076980616058, 'subsample': 0.5811073477961703, 'colsample_bytree': 0.6154683292900629, 'colsample_bynode': 0.05073611950141112, 'colsample_bylevel': 0.4093958800537956, 'min_child_weight': 6, 'reg_alpha': 22.648448590207337, 'reg_lambda': 7.97554433553209, 'gamma': 1.6404074621817555}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:41:28,231] Trial 119 finished with value: 0.11071501385147292 and parameters: {'max_depth': 5, 'learning_rate': 0.02354658235364578, 'subsample': 0.6046531614833482, 'colsample_bytree': 0.6142761321541338, 'colsample_bynode': 0.05165143565937307, 'colsample_bylevel': 0.4161371722285505, 'min_child_weight': 6, 'reg_alpha': 22.990082341348376, 'reg_lambda': 7.254152276970533, 'gamma': 1.4179653744973122}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:42:03,299] Trial 121 finished with value: 0.1136970976232031 and parameters: {'max_depth': 6, 'learning_rate': 0.03418258510306036, 'subsample': 0.579995922535473, 'colsample_bytree': 0.6128670306856767, 'colsample_bynode': 0.061036797430046474, 'colsample_bylevel': 0.4094289577252582, 'min_child_weight': 7, 'reg_alpha': 22.80630932686263, 'reg_lambda': 7.122665158634634, 'gamma': 1.583157065033744}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:42:06,937] Trial 122 finished with value: 0.11031415656563419 and parameters: {'max_depth': 6, 'learning_rate': 0.036399904495404756, 'subsample': 0.575828012454641, 'colsample_bytree': 0.6494622146018508, 'colsample_bynode': 0.1323188658671267, 'colsample_bylevel': 0.4432089271719678, 'min_child_weight': 7, 'reg_alpha': 24.95491903348174, 'reg_lambda': 2.5019596711316523, 'gamma': 1.7232957121787906}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:42:38,031] Trial 123 finished with value: 0.11436142665880122 and parameters: {'max_depth': 6, 'learning_rate': 0.03397970848816126, 'subsample': 0.5684488845221309, 'colsample_bytree': 0.6693061424805652, 'colsample_bynode': 0.09522171140272016, 'colsample_bylevel': 0.3507772888830653, 'min_child_weight': 7, 'reg_alpha': 17.15901492236539, 'reg_lambda': 10.271005315710319, 'gamma': 1.6725183574234213}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-03 12:42:42,768] Trial 124 finished with value: 0.11934987388752417 and parameters: {'max_depth': 6, 'learning_rate': 0.031032075739484733, 'subsample': 0.5868834877807073, 'colsample_bytree': 0.6920758192834102, 'colsample_bynode': 0.09606448721055491, 'colsample_bylevel': 0.4047238487806621, 'min_child_weight': 8, 'reg_alpha': 17.716823714627765, 'reg_lambda': 7.382905829578655, 'gamma': 1.5689358320853957}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:43:10,958] Trial 125 finished with value: 0.1146240958423757 and parameters: {'max_depth': 6, 'learning_rate': 0.04729139387525791, 'subsample': 0.5161857546254509, 'colsample_bytree': 0.6860690143507646, 'colsample_bynode': 0.11048889974512359, 'colsample_bylevel': 0.34678454009876114, 'min_child_weight': 7, 'reg_alpha': 16.06441464591739, 'reg_lambda': 10.31486178252503, 'gamma': 1.9121608838849653}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:43:16,235] Trial 126 finished with value: 0.11673519294045638 and parameters: {'max_depth': 5, 'learning_rate': 0.030802090061601343, 'subsample': 0.6084025819592712, 'colsample_bytree': 0.6989273386990134, 'colsample_bynode': 0.1150178312819233, 'colsample_bylevel': 0.34796096259031833, 'min_child_weight': 8, 'reg_alpha': 16.927806179824657, 'reg_lambda': 10.20144480145973, 'gamma': 1.5639193985568505}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:43:48,991] Trial 127 finished with value: 0.11193888214549431 and parameters: {'max_depth': 7, 'learning_rate': 0.0294301584942788, 'subsample': 0.5614371945555502, 'colsample_bytree': 0.6783177456421576, 'colsample_bynode': 0.11553306013920599, 'colsample_bylevel': 0.3459797072040426, 'min_child_weight': 8, 'reg_alpha': 16.841641400739235, 'reg_lambda': 10.50291652059853, 'gamma': 1.5774883849467785}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:43:51,516] Trial 128 finished with value: 0.1066470374766177 and parameters: {'max_depth': 6, 'learning_rate': 0.04421854547262638, 'subsample': 0.561677926016139, 'colsample_bytree': 0.6903190490523822, 'colsample_bynode': 0.09764800130026256, 'colsample_bylevel': 0.3490518708246498, 'min_child_weight': 8, 'reg_alpha': 17.468616636807067, 'reg_lambda': 15.313768805307033, 'gamma': 1.5592284821793179}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:44:21,971] Trial 129 finished with value: 0.10737591525084478 and parameters: {'max_depth': 6, 'learning_rate': 0.04384851349517199, 'subsample': 0.6157575970950651, 'colsample_bytree': 0.6980623465857668, 'colsample_bynode': 0.09651544207567699, 'colsample_bylevel': 0.3586294052879154, 'min_child_weight': 7, 'reg_alpha': 13.818668251844517, 'reg_lambda': 15.279076090395442, 'gamma': 1.8393115820925137}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:44:23,749] Trial 130 finished with value: 0.11534563614070731 and parameters: {'max_depth': 6, 'learning_rate': 0.04957191627046063, 'subsample': 0.6181484117117783, 'colsample_bytree': 0.7432657307604007, 'colsample_bynode': 0.08684141727566053, 'colsample_bylevel': 0.37786835249825707, 'min_child_weight': 7, 'reg_alpha': 14.845932878862376, 'reg_lambda': 22.262087227796172, 'gamma': 1.820550070387001}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:44:54,903] Trial 131 finished with value: 0.11398669537367397 and parameters: {'max_depth': 7, 'learning_rate': 0.04892316538664041, 'subsample': 0.6264436388339095, 'colsample_bytree': 0.7296846927095818, 'colsample_bynode': 0.07641159656810954, 'colsample_bylevel': 0.322758548558879, 'min_child_weight': 7, 'reg_alpha': 14.965824509734738, 'reg_lambda': 6.399486328080524, 'gamma': 1.7545310799941687}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:44:56,566] Trial 132 finished with value: 0.11828231195721903 and parameters: {'max_depth': 6, 'learning_rate': 0.04887759415965879, 'subsample': 0.6248635886370222, 'colsample_bytree': 0.7364229863897678, 'colsample_bynode': 0.07432260049974454, 'colsample_bylevel': 0.37166447893178456, 'min_child_weight': 8, 'reg_alpha': 14.612190122514018, 'reg_lambda': 22.76059327524004, 'gamma': 1.7025321274821974}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:45:27,020] Trial 134 finished with value: 0.11323172452378646 and parameters: {'max_depth': 7, 'learning_rate': 0.04970138041400864, 'subsample': 0.6924266715089614, 'colsample_bytree': 0.7476568294876269, 'colsample_bynode': 0.08288452895137235, 'colsample_bylevel': 0.37088262445812326, 'min_child_weight': 8, 'reg_alpha': 14.708129305431074, 'reg_lambda': 24.82461132245257, 'gamma': 1.947942986691627}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:45:31,279] Trial 133 finished with value: 0.10953752566618227 and parameters: {'max_depth': 7, 'learning_rate': 0.050241883636308785, 'subsample': 0.6313842851614598, 'colsample_bytree': 0.7509195161151246, 'colsample_bynode': 0.14289991373753463, 'colsample_bylevel': 0.31659599336714944, 'min_child_weight': 7, 'reg_alpha': 15.304227942984271, 'reg_lambda': 2.3328944026470992, 'gamma': 1.7715190410683825}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:45:58,685] Trial 135 finished with value: 0.11782273788484982 and parameters: {'max_depth': 6, 'learning_rate': 0.050929016511921985, 'subsample': 0.6576642787147984, 'colsample_bytree': 0.7822812092927595, 'colsample_bynode': 0.11783608918518736, 'colsample_bylevel': 0.3172453713020515, 'min_child_weight': 7, 'reg_alpha': 9.062184259843965, 'reg_lambda': 10.791777990790141, 'gamma': 2.121858341264089}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:46:05,923] Trial 136 finished with value: 0.1136959123056789 and parameters: {'max_depth': 6, 'learning_rate': 0.04103834259159953, 'subsample': 0.5194659262722311, 'colsample_bytree': 0.7875856255498824, 'colsample_bynode': 0.07824254389292015, 'colsample_bylevel': 0.3842940602677021, 'min_child_weight': 8, 'reg_alpha': 9.571194378594393, 'reg_lambda': 24.044453732808797, 'gamma': 2.1224896900917587}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:46:34,493] Trial 138 finished with value: 0.10673445633265466 and parameters: {'max_depth': 6, 'learning_rate': 0.06131021537646559, 'subsample': 0.6549703277173156, 'colsample_bytree': 0.7189234652858226, 'colsample_bynode': 0.09899986725932096, 'colsample_bylevel': 0.36786681597880005, 'min_child_weight': 8, 'reg_alpha': 17.526002797463384, 'reg_lambda': 22.179083885920058, 'gamma': 2.251227003377443}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:46:35,444] Trial 137 finished with value: 0.10947011825893527 and parameters: {'max_depth': 6, 'learning_rate': 0.04068719920974086, 'subsample': 0.6568951228773816, 'colsample_bytree': 0.7847064820309438, 'colsample_bynode': 0.11857893349942472, 'colsample_bylevel': 0.3913014169072119, 'min_child_weight': 8, 'reg_alpha': 8.450318724498944, 'reg_lambda': 24.71500795890228, 'gamma': 2.2960493533101047}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:47:08,130] Trial 139 finished with value: 0.10765764253761709 and parameters: {'max_depth': 6, 'learning_rate': 0.054823261620805995, 'subsample': 0.7116255050210953, 'colsample_bytree': 0.7892488772167812, 'colsample_bynode': 0.11737944099259867, 'colsample_bylevel': 0.396021873281888, 'min_child_weight': 7, 'reg_alpha': 7.982880828824795, 'reg_lambda': 4.44959793422082, 'gamma': 2.5013123278335403}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:47:11,904] Trial 140 finished with value: 0.10803660323205239 and parameters: {'max_depth': 6, 'learning_rate': 0.05498836894952225, 'subsample': 0.6011574347633926, 'colsample_bytree': 0.824254957117231, 'colsample_bynode': 0.14888827958921505, 'colsample_bylevel': 0.33465036683557237, 'min_child_weight': 7, 'reg_alpha': 6.427554004312928, 'reg_lambda': 9.8524101551314, 'gamma': 1.950734872077734}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:47:39,630] Trial 141 finished with value: 0.10266644958880142 and parameters: {'max_depth': 6, 'learning_rate': 0.07616766216352835, 'subsample': 0.5972358674474157, 'colsample_bytree': 0.8151434053184373, 'colsample_bynode': 0.14707307955455773, 'colsample_bylevel': 0.3268735152134085, 'min_child_weight': 8, 'reg_alpha': 80.46698304199843, 'reg_lambda': 11.324185462633773, 'gamma': 1.9348428673784506}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:47:40,592] Trial 142 finished with value: 0.10730366785468298 and parameters: {'max_depth': 8, 'learning_rate': 0.047759910747804564, 'subsample': 0.6310541422376583, 'colsample_bytree': 0.7212938775398516, 'colsample_bynode': 0.0739246061975057, 'colsample_bylevel': 0.32316877397212296, 'min_child_weight': 7, 'reg_alpha': 82.73564518232212, 'reg_lambda': 17.866568486672897, 'gamma': 1.7780806574555008}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:48:14,697] Trial 144 finished with value: 0.09887375982016222 and parameters: {'max_depth': 8, 'learning_rate': 0.04666723048911651, 'subsample': 0.6828751942783585, 'colsample_bytree': 0.7292217364458586, 'colsample_bynode': 0.10836959443723551, 'colsample_bylevel': 0.9242027182839216, 'min_child_weight': 7, 'reg_alpha': 17.686130716904206, 'reg_lambda': 5.6031494942948035, 'gamma': 1.8320467875517659}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:48:14,764] Trial 143 finished with value: 0.11301685788159171 and parameters: {'max_depth': 8, 'learning_rate': 0.04827820677904867, 'subsample': 0.6337743075862406, 'colsample_bytree': 0.7297315462287928, 'colsample_bynode': 0.07336274851615307, 'colsample_bylevel': 0.30573412790914883, 'min_child_weight': 7, 'reg_alpha': 14.19542657053873, 'reg_lambda': 17.034604456846456, 'gamma': 1.7173425411224212}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:48:53,280] Trial 145 finished with value: 0.11297919512502723 and parameters: {'max_depth': 6, 'learning_rate': 0.03809755367806412, 'subsample': 0.5492671746959115, 'colsample_bytree': 0.6658911460104946, 'colsample_bynode': 0.18651236207226507, 'colsample_bylevel': 0.3054964113846056, 'min_child_weight': 7, 'reg_alpha': 13.954668887796384, 'reg_lambda': 15.834385758763748, 'gamma': 1.7037715263367983}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:48:58,101] Trial 146 finished with value: 0.11263100386780664 and parameters: {'max_depth': 7, 'learning_rate': 0.03130378713072969, 'subsample': 0.5566829705640077, 'colsample_bytree': 0.6691527073142267, 'colsample_bynode': 0.19162995142173492, 'colsample_bylevel': 0.35444492654412574, 'min_child_weight': 8, 'reg_alpha': 11.29202714282436, 'reg_lambda': 14.508301317420143, 'gamma': 1.4607805639833034}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:49:27,605] Trial 148 finished with value: 0.10956757295499228 and parameters: {'max_depth': 6, 'learning_rate': 0.06741368849148113, 'subsample': 0.5829420587428505, 'colsample_bytree': 0.2601510465025277, 'colsample_bynode': 0.12230737049274196, 'colsample_bylevel': 0.37300219573696114, 'min_child_weight': 6, 'reg_alpha': 18.412878666814684, 'reg_lambda': 20.63903122745151, 'gamma': 2.1328721743081864}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:49:29,157] Trial 147 finished with value: 0.11241006933996103 and parameters: {'max_depth': 7, 'learning_rate': 0.07092105263271713, 'subsample': 0.5799191493186923, 'colsample_bytree': 0.7048187093022834, 'colsample_bynode': 0.12652676330833296, 'colsample_bylevel': 0.3619732587857645, 'min_child_weight': 6, 'reg_alpha': 10.663055164787725, 'reg_lambda': 20.456696100885424, 'gamma': 1.4328162984800672}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:49:58,601] Trial 150 finished with value: 0.11255266744166753 and parameters: {'max_depth': 6, 'learning_rate': 0.04328439689906595, 'subsample': 0.6097781764957682, 'colsample_bytree': 0.7552739062237548, 'colsample_bynode': 0.09217351187027052, 'colsample_bylevel': 0.33940133207281964, 'min_child_weight': 9, 'reg_alpha': 15.57765868565123, 'reg_lambda': 6.109650299419425, 'gamma': 2.6793920335266495}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:49:59,897] Trial 149 finished with value: 0.10479106178847356 and parameters: {'max_depth': 7, 'learning_rate': 0.08350236017857789, 'subsample': 0.5169358871030678, 'colsample_bytree': 0.7639953570467547, 'colsample_bynode': 0.09426918431431301, 'colsample_bylevel': 0.33842374304099754, 'min_child_weight': 8, 'reg_alpha': 10.86501657182091, 'reg_lambda': 12.099680651843478, 'gamma': 2.049339019907594}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:50:25,813] Trial 151 finished with value: 0.11523932107930873 and parameters: {'max_depth': 5, 'learning_rate': 0.08386883920810874, 'subsample': 0.6572611152098627, 'colsample_bytree': 0.7405065618637435, 'colsample_bynode': 0.09449741392338301, 'colsample_bylevel': 0.26247667376863365, 'min_child_weight': 7, 'reg_alpha': 19.640100058568866, 'reg_lambda': 32.283765926064746, 'gamma': 2.079795863418007}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:50:32,704] Trial 152 finished with value: 0.1155236944793698 and parameters: {'max_depth': 5, 'learning_rate': 0.03532289175227219, 'subsample': 0.6597886269677262, 'colsample_bytree': 0.6484042806865623, 'colsample_bynode': 0.13392144792788013, 'colsample_bylevel': 0.26570802952066264, 'min_child_weight': 7, 'reg_alpha': 12.492031702865162, 'reg_lambda': 3.6087116696460946, 'gamma': 1.6407012801325973}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:51:00,348] Trial 153 finished with value: 0.09880253096436821 and parameters: {'max_depth': 5, 'learning_rate': 0.007355741898148906, 'subsample': 0.6623701786395597, 'colsample_bytree': 0.7057166199363822, 'colsample_bynode': 0.07130357586469613, 'colsample_bylevel': 0.25958863103578084, 'min_child_weight': 7, 'reg_alpha': 19.766129673591387, 'reg_lambda': 30.716900569604707, 'gamma': 2.4126229528517777}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:51:03,384] Trial 154 finished with value: 0.11286572712840773 and parameters: {'max_depth': 5, 'learning_rate': 0.06180702651116206, 'subsample': 0.6613385566299577, 'colsample_bytree': 0.6461778319832003, 'colsample_bynode': 0.1491314590413087, 'colsample_bylevel': 0.26534341042406256, 'min_child_weight': 7, 'reg_alpha': 19.61601988702756, 'reg_lambda': 32.42782196500338, 'gamma': 1.6412450737353221}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:51:29,886] Trial 155 finished with value: 0.11093689161285354 and parameters: {'max_depth': 5, 'learning_rate': 0.05999146519220554, 'subsample': 0.6893572765411953, 'colsample_bytree': 0.6853274447971776, 'colsample_bynode': 0.1566527107520064, 'colsample_bylevel': 0.27174961740895637, 'min_child_weight': 7, 'reg_alpha': 12.776461682228671, 'reg_lambda': 3.751281361076045, 'gamma': 2.026407354884643}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:51:31,796] Trial 156 finished with value: 0.11464333568198448 and parameters: {'max_depth': 5, 'learning_rate': 0.07759031668225037, 'subsample': 0.6987868414628642, 'colsample_bytree': 0.7723164465642409, 'colsample_bynode': 0.10784009661996319, 'colsample_bylevel': 0.20934869739055176, 'min_child_weight': 8, 'reg_alpha': 13.138169139591906, 'reg_lambda': 9.08840794859444, 'gamma': 2.0467669104019257}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:51:58,511] Trial 157 finished with value: 0.11822408230721024 and parameters: {'max_depth': 5, 'learning_rate': 0.07831094921494458, 'subsample': 0.7280917874564938, 'colsample_bytree': 0.772117879048876, 'colsample_bynode': 0.10508906008175906, 'colsample_bylevel': 0.2196992322853791, 'min_child_weight': 8, 'reg_alpha': 16.58444562165595, 'reg_lambda': 23.006742966566044, 'gamma': 1.8627530553570526}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:52:02,680] Trial 158 finished with value: 0.1119487814974393 and parameters: {'max_depth': 5, 'learning_rate': 0.038131997049968815, 'subsample': 0.7170848080933506, 'colsample_bytree': 0.7433222358664429, 'colsample_bynode': 0.1110187647513185, 'colsample_bylevel': 0.2116972692040554, 'min_child_weight': 8, 'reg_alpha': 16.57560735518199, 'reg_lambda': 0.3349242509184194, 'gamma': 1.8840332807363844}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:52:26,748] Trial 159 finished with value: 0.10360314360064629 and parameters: {'max_depth': 5, 'learning_rate': 0.0823393993507484, 'subsample': 0.7529680650197764, 'colsample_bytree': 0.8446062002540249, 'colsample_bynode': 0.11155271954356902, 'colsample_bylevel': 0.19172241707423587, 'min_child_weight': 8, 'reg_alpha': 12.765565944500825, 'reg_lambda': 0.403766805752098, 'gamma': 1.87693097799778}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:52:31,043] Trial 160 finished with value: 0.10560169930179328 and parameters: {'max_depth': 5, 'learning_rate': 0.08707025906297415, 'subsample': 0.7579227409807607, 'colsample_bytree': 0.7695197439324325, 'colsample_bynode': 0.13352066303485888, 'colsample_bylevel': 0.2252078355868434, 'min_child_weight': 8, 'reg_alpha': 12.785923692642427, 'reg_lambda': 27.183586690249765, 'gamma': 1.8616598800371866}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:52:57,235] Trial 161 finished with value: 0.10468342385301882 and parameters: {'max_depth': 5, 'learning_rate': 0.07521588248010794, 'subsample': 0.7249739096196045, 'colsample_bytree': 0.7690919805854095, 'colsample_bynode': 0.13471408133927412, 'colsample_bylevel': 0.2408427842377349, 'min_child_weight': 8, 'reg_alpha': 21.508616253546798, 'reg_lambda': 19.07015649623482, 'gamma': 1.3532209759238385}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:53:00,338] Trial 162 finished with value: 0.10639214148236167 and parameters: {'max_depth': 5, 'learning_rate': 0.07569439502701726, 'subsample': 0.7047853075618815, 'colsample_bytree': 0.7751569143152829, 'colsample_bynode': 0.09432500799718248, 'colsample_bylevel': 0.19781217770185844, 'min_child_weight': 8, 'reg_alpha': 21.34414357999818, 'reg_lambda': 8.151655055844902, 'gamma': 1.657194795691062}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:53:28,630] Trial 163 finished with value: 0.11505380173455051 and parameters: {'max_depth': 5, 'learning_rate': 0.03082360889166635, 'subsample': 0.7318830750593799, 'colsample_bytree': 0.7078589000296027, 'colsample_bynode': 0.09926498293515808, 'colsample_bylevel': 0.20459315612164752, 'min_child_weight': 9, 'reg_alpha': 16.66189172646745, 'reg_lambda': 8.548056761808546, 'gamma': 1.6445855547310004}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:53:29,284] Trial 164 finished with value: 0.10590973647339534 and parameters: {'max_depth': 6, 'learning_rate': 0.0676023140760066, 'subsample': 0.8200110717058577, 'colsample_bytree': 0.7070088370199679, 'colsample_bynode': 0.17313459374593448, 'colsample_bylevel': 0.1668981433298793, 'min_child_weight': 9, 'reg_alpha': 18.33868355076092, 'reg_lambda': 36.515404773751825, 'gamma': 1.5171592543904053}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:53:59,245] Trial 165 finished with value: 0.10862424587672911 and parameters: {'max_depth': 5, 'learning_rate': 0.028511230484180146, 'subsample': 0.8195434701446627, 'colsample_bytree': 0.8016414805082047, 'colsample_bynode': 0.17311324118315644, 'colsample_bylevel': 0.10914270317370543, 'min_child_weight': 9, 'reg_alpha': 18.724439930087136, 'reg_lambda': 21.684679087939593, 'gamma': 1.4896953287621644}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:53:59,489] Trial 166 finished with value: 0.11236625386131993 and parameters: {'max_depth': 5, 'learning_rate': 0.031157460229896218, 'subsample': 0.6854379197350272, 'colsample_bytree': 0.7988340107058307, 'colsample_bynode': 0.06662164133055185, 'colsample_bylevel': 0.15163771370437787, 'min_child_weight': 10, 'reg_alpha': 15.696864440144163, 'reg_lambda': 22.82165229101367, 'gamma': 2.017912596951007}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:54:28,614] Trial 167 finished with value: 0.11311748923045305 and parameters: {'max_depth': 5, 'learning_rate': 0.05377121253136419, 'subsample': 0.6708547617169147, 'colsample_bytree': 0.7331107006245459, 'colsample_bynode': 0.06264312368333719, 'colsample_bylevel': 0.2519711720369734, 'min_child_weight': 10, 'reg_alpha': 14.92517673258737, 'reg_lambda': 8.512429989072407, 'gamma': 2.1415141639742}. Best is trial 124 with value: 0.11934987388752417.\n",
      "[I 2025-07-03 12:54:28,745] Trial 168 finished with value: 0.12124943127313059 and parameters: {'max_depth': 5, 'learning_rate': 0.05324614101992163, 'subsample': 0.7363611712416459, 'colsample_bytree': 0.7445764741212506, 'colsample_bynode': 0.11889793871725439, 'colsample_bylevel': 0.22391032657791518, 'min_child_weight': 9, 'reg_alpha': 6.7905100976859485, 'reg_lambda': 3.6190755408331112, 'gamma': 2.1481745857480514}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:54:56,078] Trial 170 finished with value: 0.11457124666653459 and parameters: {'max_depth': 5, 'learning_rate': 0.09096056992361586, 'subsample': 0.7351200398310416, 'colsample_bytree': 0.7551935736245543, 'colsample_bynode': 0.12531894513729736, 'colsample_bylevel': 0.22510356974771678, 'min_child_weight': 9, 'reg_alpha': 6.131788847566348, 'reg_lambda': 3.1459034291446812, 'gamma': 2.2896032575396896}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:54:56,532] Trial 169 finished with value: 0.11100223612698223 and parameters: {'max_depth': 5, 'learning_rate': 0.09268941259708573, 'subsample': 0.7390617194003112, 'colsample_bytree': 0.6832668112726654, 'colsample_bynode': 0.1116175675715494, 'colsample_bylevel': 0.21541142909468938, 'min_child_weight': 9, 'reg_alpha': 9.113949003968068, 'reg_lambda': 13.207560828954474, 'gamma': 1.9943195340689515}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:55:22,777] Trial 171 finished with value: 0.11477500952310497 and parameters: {'max_depth': 5, 'learning_rate': 0.09855368414366515, 'subsample': 0.7603844204890666, 'colsample_bytree': 0.7259921031229131, 'colsample_bynode': 0.14975991521399315, 'colsample_bylevel': 0.19748875060097265, 'min_child_weight': 9, 'reg_alpha': 5.352813108007304, 'reg_lambda': 4.2633652861130535, 'gamma': 2.180940523561675}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:55:25,079] Trial 172 finished with value: 0.1080153304385581 and parameters: {'max_depth': 5, 'learning_rate': 0.05271913339260355, 'subsample': 0.7776070584576754, 'colsample_bytree': 0.7439766979046821, 'colsample_bynode': 0.0816903478129211, 'colsample_bylevel': 0.28404464560360587, 'min_child_weight': 9, 'reg_alpha': 3.396010255267367, 'reg_lambda': 4.5631482236008925, 'gamma': 2.1596052568779114}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:55:50,826] Trial 173 finished with value: 0.11067850890278536 and parameters: {'max_depth': 5, 'learning_rate': 0.09920793986052265, 'subsample': 0.7872514465874721, 'colsample_bytree': 0.7383074190215193, 'colsample_bynode': 0.1518256128232493, 'colsample_bylevel': 0.20366810226735166, 'min_child_weight': 9, 'reg_alpha': 3.014002010554128, 'reg_lambda': 4.038030861843713, 'gamma': 2.1899713289606058}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:55:52,481] Trial 174 finished with value: 0.1080995891557526 and parameters: {'max_depth': 5, 'learning_rate': 0.09895412684343285, 'subsample': 0.759774260870443, 'colsample_bytree': 0.704488201946867, 'colsample_bynode': 0.15418916030296498, 'colsample_bylevel': 0.20119767524665372, 'min_child_weight': 9, 'reg_alpha': 7.554672078953697, 'reg_lambda': 5.920317243903815, 'gamma': 2.4649372587085865}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:56:17,588] Trial 175 finished with value: 0.10877978725488145 and parameters: {'max_depth': 5, 'learning_rate': 0.0851518374907832, 'subsample': 0.7666342784057856, 'colsample_bytree': 0.7156336174506487, 'colsample_bynode': 0.13643531339227422, 'colsample_bylevel': 0.23973821951811655, 'min_child_weight': 9, 'reg_alpha': 7.264572496743558, 'reg_lambda': 26.39676135326338, 'gamma': 2.759907961245357}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:56:25,978] Trial 176 finished with value: 0.11158580363302785 and parameters: {'max_depth': 5, 'learning_rate': 0.07788019054978658, 'subsample': 0.7027809984344119, 'colsample_bytree': 0.6397646707590436, 'colsample_bynode': 0.18949130729909136, 'colsample_bylevel': 0.23992426322998053, 'min_child_weight': 8, 'reg_alpha': 5.205749007469855, 'reg_lambda': 2.2216808097271787, 'gamma': 1.2563926385029194}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:56:53,587] Trial 178 finished with value: 0.10941055767204266 and parameters: {'max_depth': 5, 'learning_rate': 0.07026689289752909, 'subsample': 0.7308678575404925, 'colsample_bytree': 0.7732597629808121, 'colsample_bynode': 0.05212486752974371, 'colsample_bylevel': 0.18038903236906123, 'min_child_weight': 8, 'reg_alpha': 0.10763608722631357, 'reg_lambda': 8.477862400043346, 'gamma': 2.3580520254136026}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:57:02,544] Trial 177 finished with value: 0.1033774990141782 and parameters: {'max_depth': 5, 'learning_rate': 0.07955680817892422, 'subsample': 0.7043674819432694, 'colsample_bytree': 0.7977743645928463, 'colsample_bynode': 0.20499237129816042, 'colsample_bylevel': 0.16914613245996796, 'min_child_weight': 8, 'reg_alpha': 10.187414509031052, 'reg_lambda': 2.6748444934319586, 'gamma': 0.09295553977334248}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:57:29,634] Trial 179 finished with value: 0.1038363111691683 and parameters: {'max_depth': 5, 'learning_rate': 0.06053021275298358, 'subsample': 0.6456906562374707, 'colsample_bytree': 0.8383877052289269, 'colsample_bynode': 0.21123363214986052, 'colsample_bylevel': 0.25522455909764225, 'min_child_weight': 9, 'reg_alpha': 9.926629177930295, 'reg_lambda': 11.719301933596318, 'gamma': 1.5612135591379785}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:57:30,404] Trial 180 finished with value: 0.11266831278569228 and parameters: {'max_depth': 5, 'learning_rate': 0.06418474095383489, 'subsample': 0.7991678151261323, 'colsample_bytree': 0.7411063965106157, 'colsample_bynode': 0.09301665641598965, 'colsample_bylevel': 0.1348100534367881, 'min_child_weight': 9, 'reg_alpha': 12.385415799084274, 'reg_lambda': 11.952815016267643, 'gamma': 1.7863513587389042}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:58:07,423] Trial 181 finished with value: 0.09704096195938348 and parameters: {'max_depth': 5, 'learning_rate': 0.005194626819165462, 'subsample': 0.6124047346949346, 'colsample_bytree': 0.7193507570485279, 'colsample_bynode': 0.09177263085160846, 'colsample_bylevel': 0.22357073070840205, 'min_child_weight': 10, 'reg_alpha': 13.63696120330831, 'reg_lambda': 7.740859718077156, 'gamma': 1.7922862461204843}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:58:11,116] Trial 182 finished with value: 0.10051647360993708 and parameters: {'max_depth': 6, 'learning_rate': 0.005368812996998067, 'subsample': 0.45007102373417235, 'colsample_bytree': 0.6852031179013246, 'colsample_bynode': 0.10961306601451035, 'colsample_bylevel': 0.22195441783387845, 'min_child_weight': 10, 'reg_alpha': 13.956370866608353, 'reg_lambda': 6.55378843350951, 'gamma': 1.9696132046879216}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:58:40,600] Trial 183 finished with value: 0.11375037852643123 and parameters: {'max_depth': 6, 'learning_rate': 0.04365476805708307, 'subsample': 0.49104439197026545, 'colsample_bytree': 0.6778600066915494, 'colsample_bynode': 0.11274694251811868, 'colsample_bylevel': 0.2802351264998404, 'min_child_weight': 6, 'reg_alpha': 16.57179517838629, 'reg_lambda': 6.297160309292709, 'gamma': 2.00807435607161}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:58:47,376] Trial 184 finished with value: 0.1052569929668172 and parameters: {'max_depth': 6, 'learning_rate': 0.040735622649475424, 'subsample': 0.4813498568112676, 'colsample_bytree': 0.6670691632785026, 'colsample_bynode': 0.53390910992517, 'colsample_bylevel': 0.2823357060655786, 'min_child_weight': 6, 'reg_alpha': 15.894881377040019, 'reg_lambda': 9.999650709026662, 'gamma': 2.039027611544014}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:59:16,344] Trial 185 finished with value: 0.11314609654351854 and parameters: {'max_depth': 6, 'learning_rate': 0.036399362339469145, 'subsample': 0.7241700558717065, 'colsample_bytree': 0.6570739720433078, 'colsample_bynode': 0.13475630298202207, 'colsample_bylevel': 0.42519419303894623, 'min_child_weight': 8, 'reg_alpha': 19.695017701238296, 'reg_lambda': 10.761139150682782, 'gamma': 2.0885211001099147}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:59:23,772] Trial 186 finished with value: 0.113449145877363 and parameters: {'max_depth': 6, 'learning_rate': 0.0365338651467635, 'subsample': 0.6837782204689885, 'colsample_bytree': 0.8702025101837494, 'colsample_bynode': 0.12823712143011604, 'colsample_bylevel': 0.40612289214294195, 'min_child_weight': 7, 'reg_alpha': 19.531290391896192, 'reg_lambda': 0.0704056487810859, 'gamma': 1.885060940983302}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:59:48,522] Trial 188 finished with value: 0.11111852651771872 and parameters: {'max_depth': 5, 'learning_rate': 0.058244213176366647, 'subsample': 0.6381016344685414, 'colsample_bytree': 0.6971766907348821, 'colsample_bynode': 0.1055092018630375, 'colsample_bylevel': 0.37531078884642294, 'min_child_weight': 7, 'reg_alpha': 65.6260463140136, 'reg_lambda': 4.072774588934158, 'gamma': 2.580815742795249}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 12:59:54,022] Trial 187 finished with value: 0.10931183381354401 and parameters: {'max_depth': 5, 'learning_rate': 0.057340522737984415, 'subsample': 0.6436665449643658, 'colsample_bytree': 0.7627210010106551, 'colsample_bynode': 0.16424632576607284, 'colsample_bylevel': 0.40370577744888125, 'min_child_weight': 7, 'reg_alpha': 11.234075068455097, 'reg_lambda': 14.028488681413705, 'gamma': 1.379333069090797}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:00:19,627] Trial 189 finished with value: 0.10481686589070613 and parameters: {'max_depth': 5, 'learning_rate': 0.0505910953815878, 'subsample': 0.5331641156410485, 'colsample_bytree': 0.7572592726022253, 'colsample_bynode': 0.1596763066342162, 'colsample_bylevel': 0.25448239006831463, 'min_child_weight': 8, 'reg_alpha': 42.951073435234754, 'reg_lambda': 14.261999693270596, 'gamma': 1.3580484225429983}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:00:29,062] Trial 190 finished with value: 0.11564507415140478 and parameters: {'max_depth': 5, 'learning_rate': 0.05127581231746402, 'subsample': 0.5364279213003186, 'colsample_bytree': 0.7310689479112467, 'colsample_bynode': 0.09047027019587184, 'colsample_bylevel': 0.29930374386470754, 'min_child_weight': 8, 'reg_alpha': 4.193222846834134, 'reg_lambda': 9.08390203270445, 'gamma': 1.652882502368901}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:00:47,212] Trial 191 finished with value: 0.11070418421531865 and parameters: {'max_depth': 5, 'learning_rate': 0.04659369308050973, 'subsample': 0.7443416820765114, 'colsample_bytree': 0.8118492167261574, 'colsample_bynode': 0.0772240009559228, 'colsample_bylevel': 0.18103206007774875, 'min_child_weight': 8, 'reg_alpha': 17.10074584811894, 'reg_lambda': 8.683755605622133, 'gamma': 2.256638112118741}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:01:05,170] Trial 192 finished with value: 0.11302427172431342 and parameters: {'max_depth': 5, 'learning_rate': 0.04684148686790408, 'subsample': 0.5219862467869893, 'colsample_bytree': 0.7303900263081572, 'colsample_bynode': 0.07969475800509894, 'colsample_bylevel': 0.3027924964298958, 'min_child_weight': 8, 'reg_alpha': 5.014119762377847, 'reg_lambda': 9.261630381373905, 'gamma': 1.6122320824403846}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:01:24,939] Trial 193 finished with value: 0.119490130123016 and parameters: {'max_depth': 5, 'learning_rate': 0.03272675731112731, 'subsample': 0.5154977240408307, 'colsample_bytree': 0.734007157445913, 'colsample_bynode': 0.08600446240645675, 'colsample_bylevel': 0.29832274586233953, 'min_child_weight': 8, 'reg_alpha': 4.152291360578534, 'reg_lambda': 4.853546656598107, 'gamma': 1.5872476540688936}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:01:42,076] Trial 194 finished with value: 0.11337138676694677 and parameters: {'max_depth': 5, 'learning_rate': 0.032058052805747125, 'subsample': 0.5018484203277537, 'colsample_bytree': 0.785509105494323, 'colsample_bynode': 0.1206862838188954, 'colsample_bylevel': 0.2968286502102866, 'min_child_weight': 8, 'reg_alpha': 2.550723593880978, 'reg_lambda': 5.6493512816763705, 'gamma': 1.7077135248916584}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:02:01,433] Trial 195 finished with value: 0.11640592421231596 and parameters: {'max_depth': 5, 'learning_rate': 0.040365489485230055, 'subsample': 0.5877900231738912, 'colsample_bytree': 0.7812838294693459, 'colsample_bynode': 0.09313044896989701, 'colsample_bylevel': 0.29223160359758243, 'min_child_weight': 8, 'reg_alpha': 2.962138835239805, 'reg_lambda': 5.341907303683088, 'gamma': 1.6279495494062513}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:02:12,382] Trial 196 finished with value: 0.1117383464095912 and parameters: {'max_depth': 5, 'learning_rate': 0.03146695372594843, 'subsample': 0.942733694930189, 'colsample_bytree': 0.71713274512606, 'colsample_bynode': 0.05074231086604081, 'colsample_bylevel': 0.2660156851384148, 'min_child_weight': 8, 'reg_alpha': 2.200196703787796, 'reg_lambda': 2.266622457370831, 'gamma': 1.4612003418260908}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:02:36,669] Trial 197 finished with value: 0.12107085562826278 and parameters: {'max_depth': 5, 'learning_rate': 0.028555159950521693, 'subsample': 0.5997385883663288, 'colsample_bytree': 0.7143871197101477, 'colsample_bynode': 0.08856353043602043, 'colsample_bylevel': 0.2617241757130127, 'min_child_weight': 8, 'reg_alpha': 4.845783797654496, 'reg_lambda': 1.7110150392480108, 'gamma': 1.7565286283902597}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:02:46,956] Trial 198 finished with value: 0.1124541466104687 and parameters: {'max_depth': 5, 'learning_rate': 0.04004679058905631, 'subsample': 0.5909255332245759, 'colsample_bytree': 0.7381267027096579, 'colsample_bynode': 0.09400491883993796, 'colsample_bylevel': 0.31527925634428366, 'min_child_weight': 9, 'reg_alpha': 7.181663618061121, 'reg_lambda': 4.740077912100381, 'gamma': 1.581663416561014}. Best is trial 168 with value: 0.12124943127313059.\n",
      "[I 2025-07-03 13:03:07,805] Trial 199 finished with value: 0.11521958446898733 and parameters: {'max_depth': 5, 'learning_rate': 0.0283779209658151, 'subsample': 0.5942409348964425, 'colsample_bytree': 0.7432290879287689, 'colsample_bynode': 0.07909564938130474, 'colsample_bylevel': 0.3136598683949516, 'min_child_weight': 8, 'reg_alpha': 5.80023211200556, 'reg_lambda': 1.5008986159915505, 'gamma': 1.595391419125481}. Best is trial 168 with value: 0.12124943127313059.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.05324614101992163, 'subsample': 0.7363611712416459, 'colsample_bytree': 0.7445764741212506, 'colsample_bynode': 0.11889793871725439, 'colsample_bylevel': 0.22391032657791518, 'min_child_weight': 9, 'reg_alpha': 6.7905100976859485, 'reg_lambda': 3.6190755408331112, 'gamma': 2.1481745857480514}\n",
      "Best Pearson score: 0.12124943127313059\n"
     ]
    }
   ],
   "source": [
    "best_xgboost_params_common_truncated = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534cb1d",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c656479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 13:11:57,180] Using an existing study with name 'lightgbm_2_4_101_2000_common_truncated_20_study' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for LightGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 13:12:14,598] Trial 103 finished with value: 0.1027489650484839 and parameters: {'max_depth': 2, 'learning_rate': 0.0903520784165737, 'num_leaves': 630, 'subsample': 0.9567547969229264, 'colsample_bytree': 0.12408631161926094, 'min_child_weight': 0.05942108990598597, 'reg_alpha': 44.38049582652678, 'reg_lambda': 93.54058818326679}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:12:15,151] Trial 102 finished with value: 0.09789689103020144 and parameters: {'max_depth': 2, 'learning_rate': 0.0924311611512066, 'num_leaves': 527, 'subsample': 0.9240289845332577, 'colsample_bytree': 0.1312036989241076, 'min_child_weight': 0.0642271637220446, 'reg_alpha': 52.24250433915313, 'reg_lambda': 93.5818958769742}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:12:30,681] Trial 105 finished with value: 0.10089365515586847 and parameters: {'max_depth': 2, 'learning_rate': 0.08657942343255472, 'num_leaves': 648, 'subsample': 0.9546869181466302, 'colsample_bytree': 0.07110752727352213, 'min_child_weight': 0.044663957059891235, 'reg_alpha': 45.69371413676658, 'reg_lambda': 89.85792642741882}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:12:31,221] Trial 104 finished with value: 0.09989792180608759 and parameters: {'max_depth': 2, 'learning_rate': 0.08411290111208598, 'num_leaves': 642, 'subsample': 0.9676797714779944, 'colsample_bytree': 0.13504119742711218, 'min_child_weight': 0.053013287841984, 'reg_alpha': 44.470310927186816, 'reg_lambda': 92.80220763843313}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:12:46,735] Trial 106 finished with value: 0.0995023427990842 and parameters: {'max_depth': 2, 'learning_rate': 0.07593835337267438, 'num_leaves': 497, 'subsample': 0.8705024429522721, 'colsample_bytree': 0.10361353992100746, 'min_child_weight': 0.0931104960417759, 'reg_alpha': 46.2825698168528, 'reg_lambda': 98.45409167549826}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:12:47,430] Trial 107 finished with value: 0.09921125272063372 and parameters: {'max_depth': 2, 'learning_rate': 0.07728154899646192, 'num_leaves': 533, 'subsample': 0.8757102320463112, 'colsample_bytree': 0.10276991454302274, 'min_child_weight': 0.01684022593681664, 'reg_alpha': 51.53566109806107, 'reg_lambda': 98.12084579738726}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:13:04,045] Trial 108 finished with value: 0.09807003601197402 and parameters: {'max_depth': 2, 'learning_rate': 0.05645955646672668, 'num_leaves': 615, 'subsample': 0.6933849213451322, 'colsample_bytree': 0.14216447125401083, 'min_child_weight': 0.018508688780954803, 'reg_alpha': 37.84394016801102, 'reg_lambda': 95.47395709722365}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:13:05,173] Trial 109 finished with value: 0.09761012028011255 and parameters: {'max_depth': 2, 'learning_rate': 0.06434082233810712, 'num_leaves': 576, 'subsample': 0.7822159122397194, 'colsample_bytree': 0.1734195470357634, 'min_child_weight': 0.12740886035397897, 'reg_alpha': 41.252499855436604, 'reg_lambda': 95.27493659906693}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:13:31,264] Trial 110 finished with value: 0.09655121647827965 and parameters: {'max_depth': 3, 'learning_rate': 0.09647021375764646, 'num_leaves': 670, 'subsample': 0.9966907103081519, 'colsample_bytree': 0.17082825164903379, 'min_child_weight': 0.13034573588464804, 'reg_alpha': 41.093405830334945, 'reg_lambda': 89.43858610870853}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:13:33,055] Trial 111 finished with value: 0.0969168426911825 and parameters: {'max_depth': 3, 'learning_rate': 0.09543687424092111, 'num_leaves': 671, 'subsample': 0.9973967998335053, 'colsample_bytree': 0.21503162873569887, 'min_child_weight': 0.08351466828239101, 'reg_alpha': 69.59377780695725, 'reg_lambda': 88.53455439411164}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:13:48,289] Trial 113 finished with value: 0.1040621885657293 and parameters: {'max_depth': 2, 'learning_rate': 0.05444583593618477, 'num_leaves': 481, 'subsample': 0.9194822580438828, 'colsample_bytree': 0.07204251765115423, 'min_child_weight': 0.031278620076765594, 'reg_alpha': 50.01349525578175, 'reg_lambda': 99.96006165645932}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:13:55,519] Trial 112 finished with value: 0.09785366395049305 and parameters: {'max_depth': 3, 'learning_rate': 0.04762907706811095, 'num_leaves': 486, 'subsample': 0.8352291693467627, 'colsample_bytree': 0.07161738172928658, 'min_child_weight': 0.07922775104881537, 'reg_alpha': 76.13900869450927, 'reg_lambda': 88.27204257228583}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:14:05,056] Trial 114 finished with value: 0.10148967532654027 and parameters: {'max_depth': 2, 'learning_rate': 0.05408874332393123, 'num_leaves': 484, 'subsample': 0.9209317434198611, 'colsample_bytree': 0.11329266968633148, 'min_child_weight': 0.030876863515873664, 'reg_alpha': 34.54408077114917, 'reg_lambda': 96.78602803677022}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:14:10,822] Trial 115 finished with value: 0.1038690286734565 and parameters: {'max_depth': 2, 'learning_rate': 0.05343451442234226, 'num_leaves': 414, 'subsample': 0.9157403893308417, 'colsample_bytree': 0.07022519551381787, 'min_child_weight': 0.03642128817606601, 'reg_alpha': 50.092346686305625, 'reg_lambda': 99.5181934351868}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:14:20,346] Trial 116 finished with value: 0.1028293299340984 and parameters: {'max_depth': 2, 'learning_rate': 0.07384716710524662, 'num_leaves': 443, 'subsample': 0.8054915747813091, 'colsample_bytree': 0.0686212836123713, 'min_child_weight': 0.0019116863754721682, 'reg_alpha': 49.969615312665226, 'reg_lambda': 99.93187565301629}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:14:26,336] Trial 117 finished with value: 0.10430259819931 and parameters: {'max_depth': 2, 'learning_rate': 0.06323435174530224, 'num_leaves': 439, 'subsample': 0.9367670168582027, 'colsample_bytree': 0.06330718085780622, 'min_child_weight': 0.0007609706920200952, 'reg_alpha': 50.528057971414206, 'reg_lambda': 92.63969980912061}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:14:35,859] Trial 118 finished with value: 0.10312987267778706 and parameters: {'max_depth': 2, 'learning_rate': 0.06273765256035477, 'num_leaves': 442, 'subsample': 0.892209849874334, 'colsample_bytree': 0.06919613726956891, 'min_child_weight': 0.06633820053487603, 'reg_alpha': 48.375821359830084, 'reg_lambda': 98.75309560557803}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:14:51,093] Trial 120 finished with value: 0.10268866096856641 and parameters: {'max_depth': 2, 'learning_rate': 0.06356426874466999, 'num_leaves': 425, 'subsample': 0.9423817909731149, 'colsample_bytree': 0.06544307164709136, 'min_child_weight': 0.15600180884647724, 'reg_alpha': 49.66122830674698, 'reg_lambda': 99.35610643489163}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:18:08,831] Trial 119 finished with value: 0.09272639640574998 and parameters: {'max_depth': 9, 'learning_rate': 0.06381060462662098, 'num_leaves': 449, 'subsample': 0.9521010611072817, 'colsample_bytree': 0.07114530771340775, 'min_child_weight': 0.002687193896919909, 'reg_alpha': 50.56627467742039, 'reg_lambda': 99.59921267345932}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:18:25,669] Trial 122 finished with value: 0.10513447715109236 and parameters: {'max_depth': 2, 'learning_rate': 0.05361037930863339, 'num_leaves': 376, 'subsample': 0.9104648571224454, 'colsample_bytree': 0.08873794807344654, 'min_child_weight': 0.03912944027677485, 'reg_alpha': 54.17504875093297, 'reg_lambda': 91.91262528072157}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-03 13:18:40,976] Trial 123 finished with value: 0.10733157485888618 and parameters: {'max_depth': 2, 'learning_rate': 0.05331591382375438, 'num_leaves': 380, 'subsample': 0.8947163439293829, 'colsample_bytree': 0.0900873414693682, 'min_child_weight': 0.09774731738264705, 'reg_alpha': 47.36981650758352, 'reg_lambda': 91.33288674344129}. Best is trial 123 with value: 0.10733157485888618.\n",
      "[I 2025-07-03 13:18:56,730] Trial 124 finished with value: 0.10137517900325263 and parameters: {'max_depth': 2, 'learning_rate': 0.05363693810779049, 'num_leaves': 380, 'subsample': 0.8827836156644899, 'colsample_bytree': 0.0927991586296157, 'min_child_weight': 0.0970095097931377, 'reg_alpha': 47.265018334462205, 'reg_lambda': 91.79258546736673}. Best is trial 123 with value: 0.10733157485888618.\n",
      "[I 2025-07-03 13:19:11,834] Trial 125 finished with value: 0.1037356593704993 and parameters: {'max_depth': 2, 'learning_rate': 0.07433454911972548, 'num_leaves': 410, 'subsample': 0.9203106341169021, 'colsample_bytree': 0.07019215765487391, 'min_child_weight': 0.04070039496538711, 'reg_alpha': 54.77545678664217, 'reg_lambda': 95.85204716944322}. Best is trial 123 with value: 0.10733157485888618.\n",
      "[I 2025-07-03 13:19:27,212] Trial 126 finished with value: 0.10776330308450335 and parameters: {'max_depth': 2, 'learning_rate': 0.0474937926296867, 'num_leaves': 413, 'subsample': 0.9022976604966367, 'colsample_bytree': 0.08923538633171407, 'min_child_weight': 0.044912990906380866, 'reg_alpha': 56.444717400546715, 'reg_lambda': 95.14167469771623}. Best is trial 126 with value: 0.10776330308450335.\n",
      "[I 2025-07-03 13:19:35,167] Trial 121 finished with value: 0.0936129350859444 and parameters: {'max_depth': 10, 'learning_rate': 0.05295481333952278, 'num_leaves': 443, 'subsample': 0.9106226351238821, 'colsample_bytree': 0.0663533676419635, 'min_child_weight': 0.04278946562426471, 'reg_alpha': 46.94162556996654, 'reg_lambda': 95.57664019534238}. Best is trial 126 with value: 0.10776330308450335.\n",
      "[I 2025-07-03 13:19:44,874] Trial 127 finished with value: 0.10805388296058302 and parameters: {'max_depth': 2, 'learning_rate': 0.04632354721788731, 'num_leaves': 411, 'subsample': 0.9091720609417904, 'colsample_bytree': 0.08464427960433249, 'min_child_weight': 0.04058807011886545, 'reg_alpha': 55.48333135550321, 'reg_lambda': 95.67121945498346}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:19:51,225] Trial 128 finished with value: 0.10733913059506908 and parameters: {'max_depth': 2, 'learning_rate': 0.04634420487632745, 'num_leaves': 410, 'subsample': 0.897853655637765, 'colsample_bytree': 0.07969492063602128, 'min_child_weight': 0.06562442817508525, 'reg_alpha': 54.48355688905881, 'reg_lambda': 90.32613269479512}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:20:01,135] Trial 129 finished with value: 0.10401768787324767 and parameters: {'max_depth': 2, 'learning_rate': 0.04641164950155286, 'num_leaves': 413, 'subsample': 0.9825682786495367, 'colsample_bytree': 0.08737088605236516, 'min_child_weight': 0.11769608335906706, 'reg_alpha': 55.68192774566389, 'reg_lambda': 91.5883141587839}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:20:07,907] Trial 130 finished with value: 0.10113677203084212 and parameters: {'max_depth': 2, 'learning_rate': 0.046386059501148984, 'num_leaves': 410, 'subsample': 0.9214302440250683, 'colsample_bytree': 0.09540269629790996, 'min_child_weight': 0.10591953377552166, 'reg_alpha': 53.765316008733016, 'reg_lambda': 91.37668065882471}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:20:26,417] Trial 131 finished with value: 0.10532350640776023 and parameters: {'max_depth': 3, 'learning_rate': 0.04546633076951677, 'num_leaves': 377, 'subsample': 0.9777186135643703, 'colsample_bytree': 0.09330606638481204, 'min_child_weight': 0.12950453835085324, 'reg_alpha': 54.56204186927589, 'reg_lambda': 89.67672019937294}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:20:51,794] Trial 133 finished with value: 0.10109052833176976 and parameters: {'max_depth': 3, 'learning_rate': 0.04074019176521236, 'num_leaves': 366, 'subsample': 0.9773236100917727, 'colsample_bytree': 0.14468785775843318, 'min_child_weight': 0.17552279520863973, 'reg_alpha': 55.1576229640706, 'reg_lambda': 86.40062056659661}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:21:14,266] Trial 134 finished with value: 0.08529813806526311 and parameters: {'max_depth': 2, 'learning_rate': 0.04796635610962151, 'num_leaves': 382, 'subsample': 0.9715193021331323, 'colsample_bytree': 0.9822253755251504, 'min_child_weight': 0.1408029315319222, 'reg_alpha': 56.12382368405636, 'reg_lambda': 90.6883259269516}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:21:29,603] Trial 135 finished with value: 0.10521084542061562 and parameters: {'max_depth': 2, 'learning_rate': 0.05863693297846973, 'num_leaves': 364, 'subsample': 0.9445949159119162, 'colsample_bytree': 0.0868548598266159, 'min_child_weight': 0.11861265174685238, 'reg_alpha': 51.95970668747582, 'reg_lambda': 94.60963726228863}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:21:44,630] Trial 136 finished with value: 0.10705031659377845 and parameters: {'max_depth': 2, 'learning_rate': 0.05852696068152954, 'num_leaves': 343, 'subsample': 0.9378803601335722, 'colsample_bytree': 0.08950974423691038, 'min_child_weight': 0.11724726253952257, 'reg_alpha': 52.973753443040664, 'reg_lambda': 90.36412154057874}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:22:00,882] Trial 137 finished with value: 0.07461872458125639 and parameters: {'max_depth': 2, 'learning_rate': 0.0022616513702338414, 'num_leaves': 355, 'subsample': 0.9381058658393737, 'colsample_bytree': 0.054042406180082714, 'min_child_weight': 0.08726149279438486, 'reg_alpha': 52.21650668247271, 'reg_lambda': 94.32656371622969}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:22:25,750] Trial 138 finished with value: 0.1027433485941661 and parameters: {'max_depth': 3, 'learning_rate': 0.059987286479478014, 'num_leaves': 380, 'subsample': 0.889462249360276, 'colsample_bytree': 0.09439971158824692, 'min_child_weight': 0.15609191702975678, 'reg_alpha': 59.134749599061465, 'reg_lambda': 92.7556823342927}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:22:43,362] Trial 139 finished with value: 0.09992534920825263 and parameters: {'max_depth': 2, 'learning_rate': 0.057147389815908986, 'num_leaves': 357, 'subsample': 0.9381816517843719, 'colsample_bytree': 0.12647712648890796, 'min_child_weight': 0.13514176657867671, 'reg_alpha': 51.936167353436, 'reg_lambda': 89.68204048679135}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:22:59,690] Trial 140 finished with value: 0.10170942223385052 and parameters: {'max_depth': 2, 'learning_rate': 0.045852853137564625, 'num_leaves': 298, 'subsample': 0.9000444735769733, 'colsample_bytree': 0.15028646223747522, 'min_child_weight': 0.06590828066247639, 'reg_alpha': 43.237573880553185, 'reg_lambda': 86.42747797029303}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:23:15,133] Trial 141 finished with value: 0.10805119611184003 and parameters: {'max_depth': 2, 'learning_rate': 0.0423200734419978, 'num_leaves': 390, 'subsample': 0.9584888389126578, 'colsample_bytree': 0.09147152250868078, 'min_child_weight': 0.1887153254005544, 'reg_alpha': 48.42539525429502, 'reg_lambda': 95.43800387190012}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:23:33,111] Trial 132 finished with value: 0.08625880530913208 and parameters: {'max_depth': 8, 'learning_rate': 0.04054982358259423, 'num_leaves': 359, 'subsample': 0.9793612943031281, 'colsample_bytree': 0.08948853159830375, 'min_child_weight': 0.1441454864321291, 'reg_alpha': 55.36386016899071, 'reg_lambda': 90.49374466943176}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:23:40,604] Trial 142 finished with value: 0.10366967931945661 and parameters: {'max_depth': 3, 'learning_rate': 0.038904843592950426, 'num_leaves': 390, 'subsample': 0.9582569314013896, 'colsample_bytree': 0.05172390798180925, 'min_child_weight': 0.1922569879741852, 'reg_alpha': 48.32926350680029, 'reg_lambda': 94.9836843540172}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:23:56,725] Trial 144 finished with value: 0.09770166748946092 and parameters: {'max_depth': 2, 'learning_rate': 0.050161615674166646, 'num_leaves': 419, 'subsample': 0.9481083937149568, 'colsample_bytree': 0.10542717351199762, 'min_child_weight': 0.09539772830937326, 'reg_alpha': 52.970291097989715, 'reg_lambda': 96.7320798125778}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:23:58,006] Trial 143 finished with value: 0.10452427821440212 and parameters: {'max_depth': 3, 'learning_rate': 0.039328384044396, 'num_leaves': 391, 'subsample': 0.9557225311348805, 'colsample_bytree': 0.050941838038554864, 'min_child_weight': 0.18403854563020572, 'reg_alpha': 53.789902445849776, 'reg_lambda': 95.17904938926127}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:24:13,867] Trial 145 finished with value: 0.09970335614689568 and parameters: {'max_depth': 2, 'learning_rate': 0.05751065117578057, 'num_leaves': 336, 'subsample': 0.9307541286090008, 'colsample_bytree': 0.13222117109471318, 'min_child_weight': 0.17420899548338795, 'reg_alpha': 51.314881234450944, 'reg_lambda': 92.79094808123905}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:24:14,932] Trial 146 finished with value: 0.10071423445905131 and parameters: {'max_depth': 2, 'learning_rate': 0.04353343254247374, 'num_leaves': 336, 'subsample': 0.9609578184223915, 'colsample_bytree': 0.13670033833244088, 'min_child_weight': 0.2167343938059872, 'reg_alpha': 57.97560586841047, 'reg_lambda': 92.48051154157282}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:24:39,229] Trial 147 finished with value: 0.10171018331791887 and parameters: {'max_depth': 3, 'learning_rate': 0.04514604672891188, 'num_leaves': 392, 'subsample': 0.9645628208084807, 'colsample_bytree': 0.08648130190082985, 'min_child_weight': 0.1192635723651753, 'reg_alpha': 59.421714378348945, 'reg_lambda': 87.5567078190244}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:24:40,264] Trial 148 finished with value: 0.1045689753310281 and parameters: {'max_depth': 3, 'learning_rate': 0.06814066749968137, 'num_leaves': 378, 'subsample': 0.9046859817608547, 'colsample_bytree': 0.08714429047333717, 'min_child_weight': 0.19945143851852595, 'reg_alpha': 54.02514319347315, 'reg_lambda': 88.25078282115358}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:24:55,732] Trial 149 finished with value: 0.0991487212603656 and parameters: {'max_depth': 2, 'learning_rate': 0.06781200307631471, 'num_leaves': 431, 'subsample': 0.9991345782036364, 'colsample_bytree': 0.10383584815720202, 'min_child_weight': 0.18940727914219063, 'reg_alpha': 53.54537505562624, 'reg_lambda': 89.3220528111516}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:25:05,802] Trial 150 finished with value: 0.10337097809538102 and parameters: {'max_depth': 3, 'learning_rate': 0.06891684372492785, 'num_leaves': 284, 'subsample': 0.9019449603584881, 'colsample_bytree': 0.10361100792293623, 'min_child_weight': 0.19957015820007865, 'reg_alpha': 53.72588301729108, 'reg_lambda': 89.4779762766082}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:25:22,938] Trial 151 finished with value: 0.10226371679927757 and parameters: {'max_depth': 3, 'learning_rate': 0.05088909249482048, 'num_leaves': 311, 'subsample': 0.8981411988747259, 'colsample_bytree': 0.12183062971258926, 'min_child_weight': 0.24873292619571452, 'reg_alpha': 57.23186161726383, 'reg_lambda': 95.31405647339923}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:25:39,522] Trial 152 finished with value: 0.08392710824558988 and parameters: {'max_depth': 3, 'learning_rate': 0.03150568880382486, 'num_leaves': 373, 'subsample': 0.8802583418693513, 'colsample_bytree': 0.8533499395778448, 'min_child_weight': 0.2511177776220575, 'reg_alpha': 56.51216290334873, 'reg_lambda': 95.63850112416544}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:25:56,852] Trial 154 finished with value: 0.10598797911596636 and parameters: {'max_depth': 2, 'learning_rate': 0.05926772929208185, 'num_leaves': 393, 'subsample': 0.9436978587685703, 'colsample_bytree': 0.0838705926637018, 'min_child_weight': 0.16061874059479045, 'reg_alpha': 46.688473683308466, 'reg_lambda': 85.1232530796089}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:25:59,380] Trial 153 finished with value: 0.0845607009136444 and parameters: {'max_depth': 3, 'learning_rate': 0.07929803732058432, 'num_leaves': 374, 'subsample': 0.8781251028464323, 'colsample_bytree': 0.5492107724200666, 'min_child_weight': 0.14883389325209243, 'reg_alpha': 45.20875202082282, 'reg_lambda': 96.74038249410656}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:26:13,024] Trial 155 finished with value: 0.10396287248024558 and parameters: {'max_depth': 2, 'learning_rate': 0.03914285733236313, 'num_leaves': 397, 'subsample': 0.9847905653351884, 'colsample_bytree': 0.08361483642340822, 'min_child_weight': 0.1593140216778303, 'reg_alpha': 48.525803807119765, 'reg_lambda': 85.83088604548233}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:26:14,893] Trial 156 finished with value: 0.10425498191105977 and parameters: {'max_depth': 2, 'learning_rate': 0.05884949367893005, 'num_leaves': 396, 'subsample': 0.982079274053535, 'colsample_bytree': 0.052019795683511, 'min_child_weight': 0.16421831061706613, 'reg_alpha': 46.807294705922054, 'reg_lambda': 85.41123333663874}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:26:29,220] Trial 157 finished with value: 0.10751479803128425 and parameters: {'max_depth': 2, 'learning_rate': 0.05738882026122784, 'num_leaves': 343, 'subsample': 0.9465582163683669, 'colsample_bytree': 0.08914068092888497, 'min_child_weight': 0.17399732035937798, 'reg_alpha': 47.0413852693895, 'reg_lambda': 84.83784186848196}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:26:31,964] Trial 158 finished with value: 0.09864649581720422 and parameters: {'max_depth': 2, 'learning_rate': 0.05052868740456061, 'num_leaves': 349, 'subsample': 0.9469353116247883, 'colsample_bytree': 0.1543129094950884, 'min_child_weight': 0.10618379975120638, 'reg_alpha': 62.02913589067918, 'reg_lambda': 88.08237110577984}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:26:46,400] Trial 159 finished with value: 0.10099380470236145 and parameters: {'max_depth': 2, 'learning_rate': 0.04964393177286315, 'num_leaves': 345, 'subsample': 0.9097739301888768, 'colsample_bytree': 0.15315625732725083, 'min_child_weight': 0.12246062618393898, 'reg_alpha': 47.90508670316766, 'reg_lambda': 88.19602445568576}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:26:48,654] Trial 160 finished with value: 0.10118553660826468 and parameters: {'max_depth': 2, 'learning_rate': 0.057838479520450035, 'num_leaves': 312, 'subsample': 0.9155438212222015, 'colsample_bytree': 0.12322594469081023, 'min_child_weight': 0.07257069767716828, 'reg_alpha': 43.08503220416418, 'reg_lambda': 80.54761745656323}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:27:02,962] Trial 161 finished with value: 0.10211283607484015 and parameters: {'max_depth': 2, 'learning_rate': 0.05807730287970566, 'num_leaves': 329, 'subsample': 0.9286998333360007, 'colsample_bytree': 0.1174497403563507, 'min_child_weight': 0.0749559540865481, 'reg_alpha': 42.89681540700994, 'reg_lambda': 84.55964510263794}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:27:04,755] Trial 162 finished with value: 0.10372278533453998 and parameters: {'max_depth': 2, 'learning_rate': 0.07037996520873174, 'num_leaves': 248, 'subsample': 0.6036455564945854, 'colsample_bytree': 0.08622657154543541, 'min_child_weight': 0.21651625138858183, 'reg_alpha': 39.3756938803298, 'reg_lambda': 77.45561605091257}. Best is trial 127 with value: 0.10805388296058302.\n",
      "[I 2025-07-03 13:27:18,762] Trial 163 finished with value: 0.10919814247152129 and parameters: {'max_depth': 2, 'learning_rate': 0.0789325016478652, 'num_leaves': 506, 'subsample': 0.6022599048289758, 'colsample_bytree': 0.0863201404023596, 'min_child_weight': 0.12911479570672835, 'reg_alpha': 40.67885938495495, 'reg_lambda': 78.38539739116193}. Best is trial 163 with value: 0.10919814247152129.\n",
      "[I 2025-07-03 13:27:20,513] Trial 164 finished with value: 0.10692175672363637 and parameters: {'max_depth': 2, 'learning_rate': 0.044969791506061146, 'num_leaves': 506, 'subsample': 0.959924220468659, 'colsample_bytree': 0.0824409237501783, 'min_child_weight': 0.18218335209392642, 'reg_alpha': 53.96614735337962, 'reg_lambda': 93.41816095637066}. Best is trial 163 with value: 0.10919814247152129.\n",
      "[I 2025-07-03 13:27:35,192] Trial 165 finished with value: 0.09578508909439475 and parameters: {'max_depth': 2, 'learning_rate': 0.06557414194495993, 'num_leaves': 460, 'subsample': 0.8243307001552521, 'colsample_bytree': 0.09854878878262043, 'min_child_weight': 0.1334193862131804, 'reg_alpha': 44.824750692097844, 'reg_lambda': 81.26988027150603}. Best is trial 163 with value: 0.10919814247152129.\n",
      "[I 2025-07-03 13:27:36,909] Trial 166 finished with value: 0.10193452081041965 and parameters: {'max_depth': 2, 'learning_rate': 0.043714653065884526, 'num_leaves': 511, 'subsample': 0.8622292529639772, 'colsample_bytree': 0.1020217417519247, 'min_child_weight': 0.1300348373795765, 'reg_alpha': 32.79490294493635, 'reg_lambda': 90.86491083777085}. Best is trial 163 with value: 0.10919814247152129.\n",
      "[I 2025-07-03 13:27:52,260] Trial 167 finished with value: 0.099395936683607 and parameters: {'max_depth': 2, 'learning_rate': 0.04486690583376556, 'num_leaves': 503, 'subsample': 0.9641477129484769, 'colsample_bytree': 0.1355676460308242, 'min_child_weight': 0.093602102262896, 'reg_alpha': 49.15267135749155, 'reg_lambda': 90.91477786446289}. Best is trial 163 with value: 0.10919814247152129.\n",
      "[I 2025-07-03 13:27:54,028] Trial 168 finished with value: 0.10016495248044623 and parameters: {'max_depth': 2, 'learning_rate': 0.08416478342657949, 'num_leaves': 515, 'subsample': 0.9388730013218248, 'colsample_bytree': 0.13671577546496694, 'min_child_weight': 0.0943201322969407, 'reg_alpha': 35.59792107825665, 'reg_lambda': 93.16891753782772}. Best is trial 163 with value: 0.10919814247152129.\n",
      "[I 2025-07-03 13:28:08,303] Trial 169 finished with value: 0.10321691111761834 and parameters: {'max_depth': 2, 'learning_rate': 0.08162783906399412, 'num_leaves': 432, 'subsample': 0.5463498831010758, 'colsample_bytree': 0.08170725700186521, 'min_child_weight': 0.10878127037420818, 'reg_alpha': 35.72065333247675, 'reg_lambda': 93.71940641695674}. Best is trial 163 with value: 0.10919814247152129.\n",
      "[I 2025-07-03 13:28:09,911] Trial 170 finished with value: 0.10818811056267967 and parameters: {'max_depth': 2, 'learning_rate': 0.05434559317155153, 'num_leaves': 412, 'subsample': 0.3177878258232466, 'colsample_bytree': 0.07693310336683193, 'min_child_weight': 0.17138407104534595, 'reg_alpha': 40.110292032500425, 'reg_lambda': 18.176180173464218}. Best is trial 163 with value: 0.10919814247152129.\n",
      "[I 2025-07-03 13:28:24,624] Trial 171 finished with value: 0.10204518278510707 and parameters: {'max_depth': 2, 'learning_rate': 0.052505424496650965, 'num_leaves': 466, 'subsample': 0.9716189935608746, 'colsample_bytree': 0.10729898759422794, 'min_child_weight': 0.17483673857517484, 'reg_alpha': 40.28136236889129, 'reg_lambda': 97.45752152378451}. Best is trial 163 with value: 0.10919814247152129.\n",
      "[I 2025-07-03 13:28:26,084] Trial 172 finished with value: 0.11151696762828803 and parameters: {'max_depth': 2, 'learning_rate': 0.054178255965502575, 'num_leaves': 412, 'subsample': 0.33285823470339587, 'colsample_bytree': 0.07753528513171852, 'min_child_weight': 0.17142529994672606, 'reg_alpha': 23.778600902629286, 'reg_lambda': 29.97914751288801}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:28:40,647] Trial 173 finished with value: 0.10854241931850381 and parameters: {'max_depth': 2, 'learning_rate': 0.049140738076121404, 'num_leaves': 415, 'subsample': 0.35709156114662804, 'colsample_bytree': 0.07842755939299823, 'min_child_weight': 0.0551266688607754, 'reg_alpha': 51.637659592321526, 'reg_lambda': 13.9569481320814}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:28:42,168] Trial 174 finished with value: 0.1090726515919833 and parameters: {'max_depth': 2, 'learning_rate': 0.048610477696971514, 'num_leaves': 420, 'subsample': 0.311644157846286, 'colsample_bytree': 0.08063830051976417, 'min_child_weight': 0.14390876855747062, 'reg_alpha': 50.976835936777675, 'reg_lambda': 21.764094613938372}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:28:55,522] Trial 175 finished with value: 0.10599476362586344 and parameters: {'max_depth': 2, 'learning_rate': 0.049259336815493375, 'num_leaves': 413, 'subsample': 0.3074864070061779, 'colsample_bytree': 0.06940368696670167, 'min_child_weight': 0.05755945400894351, 'reg_alpha': 15.755207398909516, 'reg_lambda': 14.441252891843215}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:28:56,739] Trial 176 finished with value: 0.10429851049258881 and parameters: {'max_depth': 2, 'learning_rate': 0.04731774592855311, 'num_leaves': 416, 'subsample': 0.36261437645040223, 'colsample_bytree': 0.07023837434211454, 'min_child_weight': 0.15438783213071156, 'reg_alpha': 16.912520557541022, 'reg_lambda': 18.398010169396404}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:29:10,283] Trial 177 finished with value: 0.10661695543230634 and parameters: {'max_depth': 2, 'learning_rate': 0.048111425593428674, 'num_leaves': 422, 'subsample': 0.3222040844095061, 'colsample_bytree': 0.07159495366070084, 'min_child_weight': 0.05904582542519478, 'reg_alpha': 29.589974353024004, 'reg_lambda': 18.32323579971353}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:29:11,688] Trial 178 finished with value: 0.10471104890479148 and parameters: {'max_depth': 2, 'learning_rate': 0.0424321706448502, 'num_leaves': 436, 'subsample': 0.3165453392754732, 'colsample_bytree': 0.07276980182792331, 'min_child_weight': 0.05550387905987588, 'reg_alpha': 20.814923238662175, 'reg_lambda': 12.454100489626768}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:29:25,719] Trial 179 finished with value: 0.10320793566791107 and parameters: {'max_depth': 2, 'learning_rate': 0.04284231425824053, 'num_leaves': 432, 'subsample': 0.2981768895135548, 'colsample_bytree': 0.07039525213557862, 'min_child_weight': 0.05960459969855414, 'reg_alpha': 20.916237165748566, 'reg_lambda': 10.261764497819918}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:29:27,015] Trial 180 finished with value: 0.10873932291783368 and parameters: {'max_depth': 2, 'learning_rate': 0.05043245201984223, 'num_leaves': 420, 'subsample': 0.31921453147964496, 'colsample_bytree': 0.05246191549224143, 'min_child_weight': 0.05927787743976842, 'reg_alpha': 23.292126645470603, 'reg_lambda': 15.559155856839375}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:29:40,981] Trial 181 finished with value: 0.10803942388676652 and parameters: {'max_depth': 2, 'learning_rate': 0.03747175498525983, 'num_leaves': 410, 'subsample': 0.2665428895552822, 'colsample_bytree': 0.05067444496878284, 'min_child_weight': 0.07957069506691775, 'reg_alpha': 27.391543647447808, 'reg_lambda': 20.55019376774606}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:29:42,489] Trial 182 finished with value: 0.10685727648143493 and parameters: {'max_depth': 2, 'learning_rate': 0.03701569148608697, 'num_leaves': 468, 'subsample': 0.3128661458444941, 'colsample_bytree': 0.05794246723918474, 'min_child_weight': 0.07696944122991639, 'reg_alpha': 27.58456794499135, 'reg_lambda': 19.303715602847873}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:29:56,327] Trial 183 finished with value: 0.10955501402279835 and parameters: {'max_depth': 2, 'learning_rate': 0.0396358452128938, 'num_leaves': 484, 'subsample': 0.3298950298827439, 'colsample_bytree': 0.050107743117102685, 'min_child_weight': 0.08482173834731706, 'reg_alpha': 25.498416501362254, 'reg_lambda': 21.190670958190076}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:29:57,836] Trial 184 finished with value: 0.10584617688905978 and parameters: {'max_depth': 2, 'learning_rate': 0.035068430351119395, 'num_leaves': 472, 'subsample': 0.2673231610443454, 'colsample_bytree': 0.05032455405672668, 'min_child_weight': 0.08280332994384518, 'reg_alpha': 26.554861978235987, 'reg_lambda': 21.732007054303406}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:30:11,664] Trial 185 finished with value: 0.10755160473368931 and parameters: {'max_depth': 2, 'learning_rate': 0.03763208391641577, 'num_leaves': 474, 'subsample': 0.2697087756504563, 'colsample_bytree': 0.05139111474115825, 'min_child_weight': 0.08323617892769945, 'reg_alpha': 26.937862289736668, 'reg_lambda': 23.730228508226972}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:30:13,228] Trial 186 finished with value: 0.10677078814146754 and parameters: {'max_depth': 2, 'learning_rate': 0.03597905699847163, 'num_leaves': 462, 'subsample': 0.339906572913883, 'colsample_bytree': 0.05049466027345864, 'min_child_weight': 0.07955397433089259, 'reg_alpha': 27.693888893960803, 'reg_lambda': 25.5051233413809}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:30:26,981] Trial 187 finished with value: 0.10690873182085346 and parameters: {'max_depth': 2, 'learning_rate': 0.03734216591322173, 'num_leaves': 487, 'subsample': 0.26643708174144626, 'colsample_bytree': 0.05095418174643555, 'min_child_weight': 0.08083627042034318, 'reg_alpha': 24.26971453144371, 'reg_lambda': 24.97055466379929}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:30:28,526] Trial 188 finished with value: 0.10936018137035468 and parameters: {'max_depth': 2, 'learning_rate': 0.03860753221575113, 'num_leaves': 497, 'subsample': 0.2611970252985676, 'colsample_bytree': 0.053112944901859666, 'min_child_weight': 0.02099338303354284, 'reg_alpha': 24.96101053073472, 'reg_lambda': 21.388738200706005}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:30:42,362] Trial 189 finished with value: 0.10335303264554661 and parameters: {'max_depth': 2, 'learning_rate': 0.03046543831846205, 'num_leaves': 498, 'subsample': 0.2568434739981563, 'colsample_bytree': 0.06636680678653394, 'min_child_weight': 0.02332086375933376, 'reg_alpha': 24.479241335250133, 'reg_lambda': 24.79030762013217}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:30:44,116] Trial 190 finished with value: 0.10500616047329683 and parameters: {'max_depth': 2, 'learning_rate': 0.03125159305125265, 'num_leaves': 500, 'subsample': 0.24941709363765363, 'colsample_bytree': 0.07883836063195822, 'min_child_weight': 0.02495482678565381, 'reg_alpha': 24.05872952429911, 'reg_lambda': 21.756461979046378}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:30:58,405] Trial 191 finished with value: 0.10853214590798459 and parameters: {'max_depth': 2, 'learning_rate': 0.03993630979050299, 'num_leaves': 448, 'subsample': 0.22985171468352117, 'colsample_bytree': 0.08003399073783703, 'min_child_weight': 0.028997176198245447, 'reg_alpha': 23.728892092796862, 'reg_lambda': 21.370461752497206}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:31:00,438] Trial 192 finished with value: 0.09977902975336314 and parameters: {'max_depth': 2, 'learning_rate': 0.03890752359140468, 'num_leaves': 563, 'subsample': 0.2826600723471358, 'colsample_bytree': 0.09845449558541286, 'min_child_weight': 0.035423560137388524, 'reg_alpha': 18.4565220293089, 'reg_lambda': 27.878252204336757}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:31:14,696] Trial 193 finished with value: 0.0997219575768872 and parameters: {'max_depth': 2, 'learning_rate': 0.04200792758953374, 'num_leaves': 449, 'subsample': 0.22782289793869437, 'colsample_bytree': 0.09754215754937001, 'min_child_weight': 0.0400264247798267, 'reg_alpha': 30.66408975653963, 'reg_lambda': 28.982742087569207}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:31:16,555] Trial 194 finished with value: 0.10807625684846045 and parameters: {'max_depth': 2, 'learning_rate': 0.040874218296320555, 'num_leaves': 445, 'subsample': 0.2341134810901055, 'colsample_bytree': 0.07881532153246817, 'min_child_weight': 0.050053353174076096, 'reg_alpha': 30.35547100409429, 'reg_lambda': 14.29780389035146}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:31:30,108] Trial 195 finished with value: 0.10840081999894526 and parameters: {'max_depth': 2, 'learning_rate': 0.04137985598722264, 'num_leaves': 407, 'subsample': 0.2258908062073066, 'colsample_bytree': 0.050037281345665596, 'min_child_weight': 0.048048172650937956, 'reg_alpha': 26.257225627515947, 'reg_lambda': 17.703906785080864}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:31:31,983] Trial 196 finished with value: 0.10806559024588722 and parameters: {'max_depth': 2, 'learning_rate': 0.040302982597066134, 'num_leaves': 413, 'subsample': 0.21494616226249363, 'colsample_bytree': 0.05096206349579706, 'min_child_weight': 0.055021520571282595, 'reg_alpha': 25.98506115094425, 'reg_lambda': 14.446610681410283}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:31:45,457] Trial 197 finished with value: 0.10483262583800707 and parameters: {'max_depth': 2, 'learning_rate': 0.03442802757612319, 'num_leaves': 409, 'subsample': 0.2383209931450645, 'colsample_bytree': 0.054007708789805944, 'min_child_weight': 0.05321797850722683, 'reg_alpha': 25.231764350471828, 'reg_lambda': 15.80517613628054}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:31:47,243] Trial 198 finished with value: 0.10928027854717504 and parameters: {'max_depth': 2, 'learning_rate': 0.040387020806863204, 'num_leaves': 416, 'subsample': 0.2279126607671541, 'colsample_bytree': 0.052811672353218875, 'min_child_weight': 0.052947404357686655, 'reg_alpha': 22.977782155531116, 'reg_lambda': 14.878626228773012}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:32:00,722] Trial 199 finished with value: 0.10515245083138923 and parameters: {'max_depth': 2, 'learning_rate': 0.039674220704889206, 'num_leaves': 428, 'subsample': 0.19850410447378766, 'colsample_bytree': 0.06573698747116735, 'min_child_weight': 0.045978234746743014, 'reg_alpha': 23.021104142509646, 'reg_lambda': 10.508655759676211}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:32:02,341] Trial 200 finished with value: 0.1099273307904874 and parameters: {'max_depth': 2, 'learning_rate': 0.04120192069402787, 'num_leaves': 430, 'subsample': 0.2002906953282684, 'colsample_bytree': 0.050775800145561836, 'min_child_weight': 0.022500504993931934, 'reg_alpha': 22.39529755264418, 'reg_lambda': 8.078538181211886}. Best is trial 172 with value: 0.11151696762828803.\n",
      "[I 2025-07-03 13:32:12,014] Trial 201 finished with value: 0.10443551084734502 and parameters: {'max_depth': 2, 'learning_rate': 0.041050079959723526, 'num_leaves': 405, 'subsample': 0.2253209723296206, 'colsample_bytree': 0.06582448164463005, 'min_child_weight': 0.02790043827748054, 'reg_alpha': 30.174026105488625, 'reg_lambda': 16.769337207145107}. Best is trial 172 with value: 0.11151696762828803.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 2, 'learning_rate': 0.054178255965502575, 'num_leaves': 412, 'subsample': 0.33285823470339587, 'colsample_bytree': 0.07753528513171852, 'min_child_weight': 0.17142529994672606, 'reg_alpha': 23.778600902629286, 'reg_lambda': 29.97914751288801}\n",
      "Best Pearson score: 0.11151696762828803\n"
     ]
    }
   ],
   "source": [
    "best_lightgbm_params_common_truncated = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfaacf4",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dd9af8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 17:00:43,648] Using an existing study with name 'catboost_2_4_101_2000_common_truncated_20_study' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for CatBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 17:01:06,151] Trial 108 finished with value: 0.10367711396867467 and parameters: {'learning_rate': 0.02420604936045156, 'depth': 5, 'subsample': 0.21517577664953597, 'colsample_bylevel': 0.06493064783096923, 'min_data_in_leaf': 89, 'reg_lambda': 67.2076920688445}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:01:10,342] Trial 107 finished with value: 0.09705943867815658 and parameters: {'learning_rate': 0.024569577476054674, 'depth': 4, 'subsample': 0.21665906528361953, 'colsample_bylevel': 0.854116595054373, 'min_data_in_leaf': 89, 'reg_lambda': 51.124412504311216}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:01:28,093] Trial 109 finished with value: 0.09986085087858877 and parameters: {'learning_rate': 0.014412887214474094, 'depth': 5, 'subsample': 0.1376785905112608, 'colsample_bylevel': 0.09880863076509876, 'min_data_in_leaf': 151, 'reg_lambda': 60.6434762586522}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:01:33,895] Trial 110 finished with value: 0.10400639929360973 and parameters: {'learning_rate': 0.009509047639994538, 'depth': 5, 'subsample': 0.2665548540354012, 'colsample_bylevel': 0.09328797166596081, 'min_data_in_leaf': 126, 'reg_lambda': 60.86429490512077}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:01:46,328] Trial 111 finished with value: 0.10129869327694849 and parameters: {'learning_rate': 0.009777547435340353, 'depth': 4, 'subsample': 0.2662921317735872, 'colsample_bylevel': 0.05047408242843933, 'min_data_in_leaf': 124, 'reg_lambda': 98.19746106434425}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:01:54,969] Trial 112 finished with value: 0.1060905211138734 and parameters: {'learning_rate': 0.012788639711333387, 'depth': 4, 'subsample': 0.3703782405956977, 'colsample_bylevel': 0.06564983813054452, 'min_data_in_leaf': 116, 'reg_lambda': 45.696665763651474}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:02:04,269] Trial 113 finished with value: 0.10311605485079092 and parameters: {'learning_rate': 0.012697018376916697, 'depth': 3, 'subsample': 0.3305120021196194, 'colsample_bylevel': 0.06710773630357261, 'min_data_in_leaf': 193, 'reg_lambda': 45.7694914548125}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:02:12,002] Trial 114 finished with value: 0.10823438039541171 and parameters: {'learning_rate': 0.013073714064913727, 'depth': 3, 'subsample': 0.3240888506938318, 'colsample_bylevel': 0.06798395054326355, 'min_data_in_leaf': 112, 'reg_lambda': 45.316371551864755}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:02:22,521] Trial 115 finished with value: 0.10899625976555993 and parameters: {'learning_rate': 0.016578426038996546, 'depth': 4, 'subsample': 0.18538718917671848, 'colsample_bylevel': 0.06661320378083486, 'min_data_in_leaf': 111, 'reg_lambda': 47.95648439452826}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:02:25,717] Trial 116 finished with value: 0.10065944834933768 and parameters: {'learning_rate': 0.016127508334788022, 'depth': 2, 'subsample': 0.1860188524831493, 'colsample_bylevel': 0.12468066653237313, 'min_data_in_leaf': 35, 'reg_lambda': 51.652841109279706}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:02:36,841] Trial 117 finished with value: 0.07145094632969168 and parameters: {'learning_rate': 0.0012881462413717128, 'depth': 2, 'subsample': 0.1820683482364473, 'colsample_bylevel': 0.11271640293910652, 'min_data_in_leaf': 66, 'reg_lambda': 48.585235262381666}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:02:44,812] Trial 118 finished with value: 0.09435409676878041 and parameters: {'learning_rate': 0.015245357049210656, 'depth': 3, 'subsample': 0.11501965777722375, 'colsample_bylevel': 0.6062301561925958, 'min_data_in_leaf': 112, 'reg_lambda': 48.067122840537166}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:02:55,716] Trial 119 finished with value: 0.08972681888249259 and parameters: {'learning_rate': 0.014971651627789925, 'depth': 3, 'subsample': 0.11086356530181801, 'colsample_bylevel': 0.6110965655726265, 'min_data_in_leaf': 108, 'reg_lambda': 57.25501766204196}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:03:12,900] Trial 120 finished with value: 0.10527595603591645 and parameters: {'learning_rate': 0.01690829777973608, 'depth': 6, 'subsample': 0.23502836428791096, 'colsample_bylevel': 0.0905724662288859, 'min_data_in_leaf': 48, 'reg_lambda': 56.60973798978335}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:03:19,332] Trial 121 finished with value: 0.10967261418018535 and parameters: {'learning_rate': 0.017401539950211247, 'depth': 6, 'subsample': 0.23546792196811667, 'colsample_bylevel': 0.050380276913777645, 'min_data_in_leaf': 51, 'reg_lambda': 41.62854736323222}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:03:41,181] Trial 122 finished with value: 0.09700142118015644 and parameters: {'learning_rate': 0.020592075197081967, 'depth': 5, 'subsample': 0.20142549873549404, 'colsample_bylevel': 0.339398677758925, 'min_data_in_leaf': 78, 'reg_lambda': 43.664161001654726}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:03:42,840] Trial 123 finished with value: 0.10554393636766601 and parameters: {'learning_rate': 0.019139342715030944, 'depth': 6, 'subsample': 0.24011040532565908, 'colsample_bylevel': 0.05199128225116767, 'min_data_in_leaf': 78, 'reg_lambda': 41.033788194990755}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:04:05,557] Trial 124 finished with value: 0.1040701152428789 and parameters: {'learning_rate': 0.018527729393019596, 'depth': 6, 'subsample': 0.1474260988821844, 'colsample_bylevel': 0.08710572585975497, 'min_data_in_leaf': 135, 'reg_lambda': 40.415504524014054}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:04:06,801] Trial 125 finished with value: 0.10448342513655673 and parameters: {'learning_rate': 0.010716669595013887, 'depth': 5, 'subsample': 0.2804201314710163, 'colsample_bylevel': 0.08593790641101129, 'min_data_in_leaf': 55, 'reg_lambda': 50.81033490071551}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:04:34,281] Trial 126 finished with value: 0.10057207273225889 and parameters: {'learning_rate': 0.02668098308876686, 'depth': 6, 'subsample': 0.2812761680575338, 'colsample_bylevel': 0.10362716364986126, 'min_data_in_leaf': 54, 'reg_lambda': 52.295320880994886}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:04:34,605] Trial 127 finished with value: 0.10808894291787337 and parameters: {'learning_rate': 0.026522416474918556, 'depth': 6, 'subsample': 0.20535573186310713, 'colsample_bylevel': 0.10179786075416666, 'min_data_in_leaf': 96, 'reg_lambda': 52.62585609061189}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:05:05,514] Trial 129 finished with value: 0.1068770350914046 and parameters: {'learning_rate': 0.030858559201094853, 'depth': 6, 'subsample': 0.21417963950828617, 'colsample_bylevel': 0.1354016100422225, 'min_data_in_leaf': 141, 'reg_lambda': 36.93111620002948}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:05:26,748] Trial 128 finished with value: 0.10169623218831207 and parameters: {'learning_rate': 0.0139904346315997, 'depth': 8, 'subsample': 0.31054301331420503, 'colsample_bylevel': 0.1359089597631981, 'min_data_in_leaf': 143, 'reg_lambda': 36.80606632096577}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:05:49,502] Trial 130 finished with value: 0.10119735715066376 and parameters: {'learning_rate': 0.03488079095267277, 'depth': 6, 'subsample': 0.6885224029320454, 'colsample_bylevel': 0.13859386827176307, 'min_data_in_leaf': 28, 'reg_lambda': 35.41911936128126}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:06:09,888] Trial 131 finished with value: 0.10133587266365063 and parameters: {'learning_rate': 0.035447421876086134, 'depth': 6, 'subsample': 0.679477767369455, 'colsample_bylevel': 0.16555197110235276, 'min_data_in_leaf': 25, 'reg_lambda': 94.54680970736628}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:06:11,890] Trial 132 finished with value: 0.10870485725312273 and parameters: {'learning_rate': 0.029650152855572456, 'depth': 6, 'subsample': 0.2093252098185069, 'colsample_bylevel': 0.050355472938020104, 'min_data_in_leaf': 93, 'reg_lambda': 31.710009548570188}. Best is trial 86 with value: 0.11154154551409158.\n",
      "[I 2025-07-03 17:06:37,632] Trial 134 finished with value: 0.11283307702247866 and parameters: {'learning_rate': 0.04256193817667885, 'depth': 7, 'subsample': 0.21801566887299165, 'colsample_bylevel': 0.05101631328902893, 'min_data_in_leaf': 97, 'reg_lambda': 32.648291624243726}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:06:44,672] Trial 133 finished with value: 0.1007685472986105 and parameters: {'learning_rate': 0.04063645672572982, 'depth': 7, 'subsample': 0.21329716993209985, 'colsample_bylevel': 0.10733147354150113, 'min_data_in_leaf': 168, 'reg_lambda': 32.17281491721375}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:07:02,902] Trial 135 finished with value: 0.11274732280060365 and parameters: {'learning_rate': 0.0404333582970293, 'depth': 7, 'subsample': 0.20796229020672935, 'colsample_bylevel': 0.05077307603619323, 'min_data_in_leaf': 92, 'reg_lambda': 32.53586436676176}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:07:11,766] Trial 136 finished with value: 0.10549404917394756 and parameters: {'learning_rate': 0.02966126505154609, 'depth': 7, 'subsample': 0.23119277219326934, 'colsample_bylevel': 0.05201059076514646, 'min_data_in_leaf': 91, 'reg_lambda': 30.932550023477646}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:07:32,955] Trial 137 finished with value: 0.10955892510749071 and parameters: {'learning_rate': 0.02925823924442879, 'depth': 7, 'subsample': 0.23044694035008365, 'colsample_bylevel': 0.06878983902001252, 'min_data_in_leaf': 90, 'reg_lambda': 29.48358576312253}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:07:44,247] Trial 138 finished with value: 0.10208838045391318 and parameters: {'learning_rate': 0.04731802048938788, 'depth': 7, 'subsample': 0.2568612559947323, 'colsample_bylevel': 0.07633878334130823, 'min_data_in_leaf': 97, 'reg_lambda': 29.117865265216903}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:08:04,177] Trial 139 finished with value: 0.10907668183360766 and parameters: {'learning_rate': 0.0379485069367229, 'depth': 7, 'subsample': 0.19680243816269338, 'colsample_bylevel': 0.07395408179691011, 'min_data_in_leaf': 90, 'reg_lambda': 19.964628369606054}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:08:31,122] Trial 141 finished with value: 0.10819110618217086 and parameters: {'learning_rate': 0.039898795528574976, 'depth': 7, 'subsample': 0.16665824380775968, 'colsample_bylevel': 0.051647613662440035, 'min_data_in_leaf': 70, 'reg_lambda': 22.51390960009203}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:08:34,881] Trial 140 finished with value: 0.09274331326460288 and parameters: {'learning_rate': 0.041596574040603004, 'depth': 7, 'subsample': 0.19591773286709444, 'colsample_bylevel': 0.9905008028213205, 'min_data_in_leaf': 85, 'reg_lambda': 16.149589785171145}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:08:55,847] Trial 142 finished with value: 0.10875207785191944 and parameters: {'learning_rate': 0.03975554300556299, 'depth': 7, 'subsample': 0.15605803471748908, 'colsample_bylevel': 0.05019218053201109, 'min_data_in_leaf': 70, 'reg_lambda': 18.63212035087718}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:09:04,294] Trial 143 finished with value: 0.10189315618203956 and parameters: {'learning_rate': 0.04512643530851097, 'depth': 7, 'subsample': 0.1568218610892514, 'colsample_bylevel': 0.0800380056596005, 'min_data_in_leaf': 65, 'reg_lambda': 22.906600934235474}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:09:24,963] Trial 144 finished with value: 0.1049937122965116 and parameters: {'learning_rate': 0.058701962379343, 'depth': 7, 'subsample': 0.1589418089174221, 'colsample_bylevel': 0.07656734356133572, 'min_data_in_leaf': 41, 'reg_lambda': 20.91335983395905}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:09:29,624] Trial 145 finished with value: 0.1050073485664453 and parameters: {'learning_rate': 0.05917970417546466, 'depth': 7, 'subsample': 0.16617374989888029, 'colsample_bylevel': 0.053342989166340074, 'min_data_in_leaf': 41, 'reg_lambda': 19.083768193639106}. Best is trial 134 with value: 0.11283307702247866.\n",
      "[I 2025-07-03 17:09:48,712] Trial 146 finished with value: 0.11322854319540185 and parameters: {'learning_rate': 0.03332911986920118, 'depth': 7, 'subsample': 0.12719371066008184, 'colsample_bylevel': 0.05066245065799262, 'min_data_in_leaf': 72, 'reg_lambda': 25.842292833611047}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:10:02,926] Trial 147 finished with value: 0.10507033501258155 and parameters: {'learning_rate': 0.042892811776113114, 'depth': 7, 'subsample': 0.18928381681333478, 'colsample_bylevel': 0.10190105392167767, 'min_data_in_leaf': 69, 'reg_lambda': 12.792149207157024}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:10:12,623] Trial 148 finished with value: 0.10699835548922476 and parameters: {'learning_rate': 0.03831038022470571, 'depth': 7, 'subsample': 0.13116155756415487, 'colsample_bylevel': 0.05053234207241567, 'min_data_in_leaf': 74, 'reg_lambda': 13.078469587955166}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:10:33,495] Trial 149 finished with value: 0.11160078181457223 and parameters: {'learning_rate': 0.032637266301401964, 'depth': 7, 'subsample': 0.13206384672141164, 'colsample_bylevel': 0.0924835069186948, 'min_data_in_leaf': 85, 'reg_lambda': 21.284273172877406}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:10:45,703] Trial 150 finished with value: 0.10172191959537712 and parameters: {'learning_rate': 0.033181692347308035, 'depth': 7, 'subsample': 0.20812027430231803, 'colsample_bylevel': 0.09249915547299263, 'min_data_in_leaf': 91, 'reg_lambda': 24.617424678955473}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:11:05,595] Trial 151 finished with value: 0.10458003292215517 and parameters: {'learning_rate': 0.03231547816672644, 'depth': 7, 'subsample': 0.12847862240017197, 'colsample_bylevel': 0.11356878948132287, 'min_data_in_leaf': 86, 'reg_lambda': 25.338349493427586}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:11:18,129] Trial 152 finished with value: 0.1073552313928751 and parameters: {'learning_rate': 0.053817965288971044, 'depth': 7, 'subsample': 0.1330641009111681, 'colsample_bylevel': 0.11149682271581246, 'min_data_in_leaf': 56, 'reg_lambda': 25.727299602750747}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:11:45,390] Trial 153 finished with value: 0.10061987390538778 and parameters: {'learning_rate': 0.05300387065712132, 'depth': 8, 'subsample': 0.15502610606470354, 'colsample_bylevel': 0.07963362825459751, 'min_data_in_leaf': 60, 'reg_lambda': 20.107980347171097}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:11:59,608] Trial 154 finished with value: 0.10801301813465106 and parameters: {'learning_rate': 0.038585255538204875, 'depth': 8, 'subsample': 0.224944712713301, 'colsample_bylevel': 0.07362730563426667, 'min_data_in_leaf': 123, 'reg_lambda': 17.62663089327246}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:12:49,932] Trial 156 finished with value: 0.10438019712593205 and parameters: {'learning_rate': 0.03659328228121532, 'depth': 8, 'subsample': 0.49091883595471686, 'colsample_bylevel': 0.07246698357390371, 'min_data_in_leaf': 120, 'reg_lambda': 7.7977708195238975}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:12:53,862] Trial 155 finished with value: 0.09530340008261587 and parameters: {'learning_rate': 0.028246115336099026, 'depth': 7, 'subsample': 0.48267376649020954, 'colsample_bylevel': 0.5421593852607569, 'min_data_in_leaf': 121, 'reg_lambda': 15.773376208747454}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:13:18,301] Trial 157 finished with value: 0.10449901273672316 and parameters: {'learning_rate': 0.03873379462596323, 'depth': 6, 'subsample': 0.22997238581261026, 'colsample_bylevel': 0.09814837597062606, 'min_data_in_leaf': 77, 'reg_lambda': 15.778859578822074}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:13:22,035] Trial 158 finished with value: 0.10205011659656624 and parameters: {'learning_rate': 0.040375748425238896, 'depth': 6, 'subsample': 0.23393783296529855, 'colsample_bylevel': 0.09176352931448356, 'min_data_in_leaf': 77, 'reg_lambda': 29.742793318012314}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:13:29,534] Trial 159 finished with value: 0.09514012141119722 and parameters: {'learning_rate': 0.043032610075947275, 'depth': 1, 'subsample': 0.17566060333918895, 'colsample_bylevel': 0.06827789320249321, 'min_data_in_leaf': 88, 'reg_lambda': 29.351169002323424}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:13:58,101] Trial 161 finished with value: 0.10381025255064562 and parameters: {'learning_rate': 0.07074478993661054, 'depth': 7, 'subsample': 0.10863716312731661, 'colsample_bylevel': 0.06802977926221529, 'min_data_in_leaf': 99, 'reg_lambda': 22.711185153846294}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:14:01,038] Trial 160 finished with value: 0.1083271698722055 and parameters: {'learning_rate': 0.04495464525650334, 'depth': 8, 'subsample': 0.1945482897152167, 'colsample_bylevel': 0.06622567710832677, 'min_data_in_leaf': 99, 'reg_lambda': 18.543160614447316}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:14:26,585] Trial 163 finished with value: 0.1103632053202434 and parameters: {'learning_rate': 0.03454272978470075, 'depth': 7, 'subsample': 0.1954672959723293, 'colsample_bylevel': 0.05050155128500869, 'min_data_in_leaf': 66, 'reg_lambda': 33.33638661503676}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:14:44,164] Trial 162 finished with value: 0.101810434339392 and parameters: {'learning_rate': 0.03454402209928741, 'depth': 8, 'subsample': 0.1945467513958304, 'colsample_bylevel': 0.11229702780866285, 'min_data_in_leaf': 15, 'reg_lambda': 18.157632998164733}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:14:53,044] Trial 164 finished with value: 0.10691483929842756 and parameters: {'learning_rate': 0.030708045765303206, 'depth': 7, 'subsample': 0.20051677471414164, 'colsample_bylevel': 0.0521313060484717, 'min_data_in_leaf': 68, 'reg_lambda': 26.69939435041903}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:15:09,385] Trial 165 finished with value: 0.10756502500419897 and parameters: {'learning_rate': 0.030516537609648287, 'depth': 7, 'subsample': 0.14546976693141195, 'colsample_bylevel': 0.05474033682721638, 'min_data_in_leaf': 68, 'reg_lambda': 33.95228328819083}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:15:17,761] Trial 166 finished with value: 0.11066347313326519 and parameters: {'learning_rate': 0.045940685691515076, 'depth': 7, 'subsample': 0.1519448721174895, 'colsample_bylevel': 0.05002053756403049, 'min_data_in_leaf': 48, 'reg_lambda': 21.06619372980695}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:15:41,090] Trial 167 finished with value: 0.10174226763505656 and parameters: {'learning_rate': 0.04430535278419793, 'depth': 7, 'subsample': 0.16625010123804773, 'colsample_bylevel': 0.09415936850427556, 'min_data_in_leaf': 98, 'reg_lambda': 21.373815165312834}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:15:49,228] Trial 168 finished with value: 0.10449346151747589 and parameters: {'learning_rate': 0.04261707772478714, 'depth': 7, 'subsample': 0.17047322749664115, 'colsample_bylevel': 0.08483879837027117, 'min_data_in_leaf': 42, 'reg_lambda': 21.33056885955509}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:16:08,134] Trial 169 finished with value: 0.10434334924980815 and parameters: {'learning_rate': 0.04664634774547108, 'depth': 7, 'subsample': 0.07177811225664987, 'colsample_bylevel': 0.0800300782476166, 'min_data_in_leaf': 38, 'reg_lambda': 26.910742456258966}. Best is trial 146 with value: 0.11322854319540185.\n",
      "[I 2025-07-03 17:16:15,913] Trial 170 finished with value: 0.11688859162534788 and parameters: {'learning_rate': 0.04810253666695713, 'depth': 7, 'subsample': 0.0825564512558034, 'colsample_bylevel': 0.06866960361908792, 'min_data_in_leaf': 48, 'reg_lambda': 27.24176294125512}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:16:32,682] Trial 171 finished with value: 0.10950934362366867 and parameters: {'learning_rate': 0.05357107109479753, 'depth': 7, 'subsample': 0.1458108536494467, 'colsample_bylevel': 0.0523704779319108, 'min_data_in_leaf': 55, 'reg_lambda': 33.61255465166878}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:16:43,133] Trial 172 finished with value: 0.09813576241872812 and parameters: {'learning_rate': 0.06940220674719189, 'depth': 7, 'subsample': 0.07998527236766706, 'colsample_bylevel': 0.07192144699022611, 'min_data_in_leaf': 53, 'reg_lambda': 31.521589561689105}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:17:04,616] Trial 173 finished with value: 0.09842386883356752 and parameters: {'learning_rate': 0.06327091189916363, 'depth': 7, 'subsample': 0.10325304781612532, 'colsample_bylevel': 0.12452285835583163, 'min_data_in_leaf': 50, 'reg_lambda': 32.733284238243705}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:17:10,796] Trial 174 finished with value: 0.10765350671010403 and parameters: {'learning_rate': 0.055903809169669486, 'depth': 7, 'subsample': 0.09965957396726456, 'colsample_bylevel': 0.06832080421938944, 'min_data_in_leaf': 26, 'reg_lambda': 31.29491303136906}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:17:29,154] Trial 175 finished with value: 0.10519379681750941 and parameters: {'learning_rate': 0.050053598874224996, 'depth': 7, 'subsample': 0.11056917896058338, 'colsample_bylevel': 0.05195517217449136, 'min_data_in_leaf': 6, 'reg_lambda': 33.4618762785552}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:17:56,768] Trial 176 finished with value: 0.10660698744908202 and parameters: {'learning_rate': 0.05038751496121787, 'depth': 8, 'subsample': 0.7873903789987411, 'colsample_bylevel': 0.05332135084682929, 'min_data_in_leaf': 6, 'reg_lambda': 24.473423736713194}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:18:12,464] Trial 177 finished with value: 0.09929705522649478 and parameters: {'learning_rate': 0.08029510803369086, 'depth': 8, 'subsample': 0.14334545182105632, 'colsample_bylevel': 0.09407331709144136, 'min_data_in_leaf': 85, 'reg_lambda': 28.50215101740994}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:18:28,458] Trial 178 finished with value: 0.10249623181491993 and parameters: {'learning_rate': 0.03724908301224065, 'depth': 7, 'subsample': 0.14142809681176916, 'colsample_bylevel': 0.0879060033186276, 'min_data_in_leaf': 82, 'reg_lambda': 27.936256271337506}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:18:36,471] Trial 179 finished with value: 0.1066740766618373 and parameters: {'learning_rate': 0.04840531914335309, 'depth': 6, 'subsample': 0.12979195457014098, 'colsample_bylevel': 0.08086641929493606, 'min_data_in_leaf': 108, 'reg_lambda': 35.702249965905104}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:19:02,590] Trial 181 finished with value: 0.10793058853571005 and parameters: {'learning_rate': 0.03360949516973695, 'depth': 7, 'subsample': 0.2410788959248669, 'colsample_bylevel': 0.0500534226257605, 'min_data_in_leaf': 59, 'reg_lambda': 19.2812521243982}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:19:06,413] Trial 180 finished with value: 0.10294760574033124 and parameters: {'learning_rate': 0.046538020606646885, 'depth': 6, 'subsample': 0.8181828265274979, 'colsample_bylevel': 0.07145133079946346, 'min_data_in_leaf': 113, 'reg_lambda': 38.277856953845976}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:19:27,368] Trial 182 finished with value: 0.10597993505735478 and parameters: {'learning_rate': 0.04544271861720855, 'depth': 6, 'subsample': 0.18316145458304173, 'colsample_bylevel': 0.07152121016774841, 'min_data_in_leaf': 33, 'reg_lambda': 30.30129915762644}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:19:39,333] Trial 183 finished with value: 0.1061279418914356 and parameters: {'learning_rate': 0.036001907278554075, 'depth': 7, 'subsample': 0.1929690340776358, 'colsample_bylevel': 0.09935801584282751, 'min_data_in_leaf': 60, 'reg_lambda': 24.258910020093502}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:19:53,097] Trial 184 finished with value: 0.1041427439988476 and parameters: {'learning_rate': 0.03980018800908514, 'depth': 7, 'subsample': 0.18776848107124613, 'colsample_bylevel': 0.0523830244576562, 'min_data_in_leaf': 70, 'reg_lambda': 21.563662259184913}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:20:04,935] Trial 185 finished with value: 0.10819049276260129 and parameters: {'learning_rate': 0.03908847758160406, 'depth': 7, 'subsample': 0.12286388716482848, 'colsample_bylevel': 0.06097043770199732, 'min_data_in_leaf': 76, 'reg_lambda': 21.31056243695493}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:20:17,693] Trial 186 finished with value: 0.11189420688441548 and parameters: {'learning_rate': 0.04193418028830093, 'depth': 7, 'subsample': 0.1656554344101922, 'colsample_bylevel': 0.050295408730438806, 'min_data_in_leaf': 48, 'reg_lambda': 23.25431540643552}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:20:34,360] Trial 187 finished with value: 0.10586782698538826 and parameters: {'learning_rate': 0.02796785941217906, 'depth': 7, 'subsample': 0.1602544911886278, 'colsample_bylevel': 0.07123288026628846, 'min_data_in_leaf': 47, 'reg_lambda': 17.816566170093438}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:20:51,650] Trial 188 finished with value: 0.10210451936818281 and parameters: {'learning_rate': 0.02897517947094879, 'depth': 7, 'subsample': 0.14893236823134956, 'colsample_bylevel': 0.12013985231107932, 'min_data_in_leaf': 94, 'reg_lambda': 26.61658870865705}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:21:19,683] Trial 189 finished with value: 0.1008121733070039 and parameters: {'learning_rate': 0.052673324237567265, 'depth': 8, 'subsample': 0.1479339765250992, 'colsample_bylevel': 0.11134594854978778, 'min_data_in_leaf': 92, 'reg_lambda': 26.780661427189518}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:21:26,051] Trial 190 finished with value: 0.10039995273684543 and parameters: {'learning_rate': 0.052286516538281626, 'depth': 7, 'subsample': 0.21507845865683556, 'colsample_bylevel': 0.09072465161902858, 'min_data_in_leaf': 86, 'reg_lambda': 33.34826174599707}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:21:52,271] Trial 192 finished with value: 0.10527223175542186 and parameters: {'learning_rate': 0.034015209832673005, 'depth': 7, 'subsample': 0.2536590442345054, 'colsample_bylevel': 0.0504684227515941, 'min_data_in_leaf': 48, 'reg_lambda': 24.27679533825489}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:21:52,887] Trial 191 finished with value: 0.10245737382030567 and parameters: {'learning_rate': 0.035697301340067406, 'depth': 7, 'subsample': 0.25020587227689284, 'colsample_bylevel': 0.0863225875375671, 'min_data_in_leaf': 106, 'reg_lambda': 9.15803392127068}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:22:18,056] Trial 193 finished with value: 0.10894576244840418 and parameters: {'learning_rate': 0.04444883937543363, 'depth': 6, 'subsample': 0.21005755309709268, 'colsample_bylevel': 0.08086731937748069, 'min_data_in_leaf': 107, 'reg_lambda': 30.606187397935745}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:22:21,647] Trial 194 finished with value: 0.11057996128203246 and parameters: {'learning_rate': 0.041478169248697426, 'depth': 7, 'subsample': 0.16807394462870917, 'colsample_bylevel': 0.06765439224804999, 'min_data_in_leaf': 68, 'reg_lambda': 22.954603800597486}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:22:42,791] Trial 195 finished with value: 0.1089707952052874 and parameters: {'learning_rate': 0.04322668277637215, 'depth': 6, 'subsample': 0.21668375512766655, 'colsample_bylevel': 0.06844220436098086, 'min_data_in_leaf': 126, 'reg_lambda': 29.34189863715021}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:22:45,816] Trial 196 finished with value: 0.10281636455792278 and parameters: {'learning_rate': 0.04379209777332604, 'depth': 6, 'subsample': 0.17579014117201558, 'colsample_bylevel': 0.07190802773823352, 'min_data_in_leaf': 58, 'reg_lambda': 30.02589962071292}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:23:08,053] Trial 198 finished with value: 0.10137615940204639 and parameters: {'learning_rate': 0.062174373492844125, 'depth': 6, 'subsample': 0.21285017889579436, 'colsample_bylevel': 0.05028159383625569, 'min_data_in_leaf': 24, 'reg_lambda': 31.571686629865567}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:23:08,472] Trial 197 finished with value: 0.10121494161154501 and parameters: {'learning_rate': 0.04137674506500848, 'depth': 6, 'subsample': 0.21085505106270702, 'colsample_bylevel': 0.08308910011537349, 'min_data_in_leaf': 60, 'reg_lambda': 30.63317655347755}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:23:31,643] Trial 200 finished with value: 0.10685476101264475 and parameters: {'learning_rate': 0.03152601366253803, 'depth': 6, 'subsample': 0.06305698701893028, 'colsample_bylevel': 0.10333840653672673, 'min_data_in_leaf': 129, 'reg_lambda': 35.54062371333334}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:23:35,139] Trial 199 finished with value: 0.10294742405895049 and parameters: {'learning_rate': 0.04170438306368906, 'depth': 6, 'subsample': 0.22909879888109114, 'colsample_bylevel': 0.0901521765776615, 'min_data_in_leaf': 129, 'reg_lambda': 28.411220614646975}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:24:03,525] Trial 201 finished with value: 0.10666095091171227 and parameters: {'learning_rate': 0.0377402681913889, 'depth': 7, 'subsample': 0.22985332891676832, 'colsample_bylevel': 0.08182155076625534, 'min_data_in_leaf': 77, 'reg_lambda': 27.752645512611622}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:24:04,696] Trial 202 finished with value: 0.10446920215182229 and parameters: {'learning_rate': 0.047706009783023, 'depth': 7, 'subsample': 0.17290488354260847, 'colsample_bylevel': 0.07128846695883172, 'min_data_in_leaf': 79, 'reg_lambda': 25.395816188440676}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:24:28,213] Trial 203 finished with value: 0.10662953039938981 and parameters: {'learning_rate': 0.048651547762606696, 'depth': 7, 'subsample': 0.1809943566765659, 'colsample_bylevel': 0.0504434396680552, 'min_data_in_leaf': 551, 'reg_lambda': 23.183121664235117}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:24:33,772] Trial 204 finished with value: 0.10887107781523225 and parameters: {'learning_rate': 0.04567810144749731, 'depth': 7, 'subsample': 0.18699032295561568, 'colsample_bylevel': 0.06804213076723928, 'min_data_in_leaf': 98, 'reg_lambda': 19.950674840794424}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:24:52,958] Trial 205 finished with value: 0.10866935121167251 and parameters: {'learning_rate': 0.044764571768512465, 'depth': 6, 'subsample': 0.19818358704161612, 'colsample_bylevel': 0.0687235503094312, 'min_data_in_leaf': 103, 'reg_lambda': 19.85000394171618}. Best is trial 170 with value: 0.11688859162534788.\n",
      "[I 2025-07-03 17:25:08,201] Trial 206 finished with value: 0.10791223627826643 and parameters: {'learning_rate': 0.0556023942481627, 'depth': 7, 'subsample': 0.5778516898509523, 'colsample_bylevel': 0.06681623429780294, 'min_data_in_leaf': 37, 'reg_lambda': 19.856023137466103}. Best is trial 170 with value: 0.11688859162534788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.04810253666695713, 'depth': 7, 'subsample': 0.0825564512558034, 'colsample_bylevel': 0.06866960361908792, 'min_data_in_leaf': 48, 'reg_lambda': 27.24176294125512}\n",
      "Best Pearson score: 0.11688859162534788\n"
     ]
    }
   ],
   "source": [
    "best_catboost_params_common_truncated = optimize_catboost(\n",
    "    f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "    f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291147c",
   "metadata": {},
   "source": [
    "Analyze model performance and feature importance across train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6913016",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    xgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    xgbr_arr.append(xgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state,\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    lgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    lgbr_arr.append(lgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances = {}\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    features = xgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "    features = lgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df_common_truncated = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df_common_truncated[\"importance\"] = 1/2 * (feature_importances_df_common_truncated[\"importance_xgboost\"] + feature_importances_df_common_truncated[\"importance_lightgbm\"])\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "feature_importances_df_common_truncated[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df_common_truncated[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df_common_truncated[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922a1c7",
   "metadata": {},
   "source": [
    "#### Fifth Iteration Instead of using GBDT, can we use MLP on these features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58f11b",
   "metadata": {},
   "source": [
    "Convert from normal CV to torch type CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531',\n",
    "                 'X385', 'X23', 'X465', 'X284', 'X331', 'X95', 'X169', 'X285', 'X137', 'X31']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, cv=default_cv):\n",
    "    train_arr = []\n",
    "    test_arr = []\n",
    "    for i in range(cv):\n",
    "        # First shuffle the data\n",
    "        X_train, Y_train = X_train_arr[i], Y_train_arr[i]\n",
    "        X_train[\"label\"] = Y_train\n",
    "        # Instead of shuffle the training data when create the dataloader, try to shuffle beforehand\n",
    "        # X_train = X_train.sample(frac = 1, random_state = default_random_state)\n",
    "        # not shuffle, keep it by date\n",
    "        Y_train = X_train[\"label\"]\n",
    "        X_train = X_train.drop(\"label\", axis = 1)\n",
    "\n",
    "        # Then normalize\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train.values)\n",
    "\n",
    "        # Create train dataset\n",
    "        X_train, Y_train = torch.from_numpy(X_train), torch.from_numpy(Y_train.values)\n",
    "        train_dataset = TensorDataset(X_train, Y_train)\n",
    "        train_arr.append(train_dataset)\n",
    "\n",
    "        # Normalize X_test\n",
    "        X_test = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Create test dataset\n",
    "        X_test, Y_test = torch.from_numpy(X_test), torch.from_numpy(Y_test_arr[i].values)\n",
    "        test_dataset = TensorDataset(X_test, Y_test)\n",
    "        test_arr.append(test_dataset)\n",
    "        \n",
    "    return train_arr, test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr, test_arr = normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da5b12",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = nn.ModuleList()\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nn.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nn.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # Initialze dropout\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            if inx == len(self.layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb08f2",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e892da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp(model, criterion, optimizer, train_dataloader, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in train_dataloader:\n",
    "            # Load to device\n",
    "            inputs, targets= inputs.to(device), targets.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs)\n",
    "            # get error\n",
    "            error = criterion(outputs, targets)\n",
    "            # Zero out the past gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Backprop\n",
    "            error.backward()\n",
    "            # Gradient Descent\n",
    "            optimizer.step()\n",
    "\n",
    "def eval_mlp(model, test_dataloader):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, targets) in enumerate(test_dataloader):\n",
    "            # Load to device\n",
    "            inputs = inputs.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs).detach().cpu().numpy().flatten()\n",
    "            # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "            outputs_all = np.concatenate([outputs_all, outputs])\n",
    "            targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_torch(model, lr, cv, train_arr, test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for i in range(cv):\n",
    "        # Get the dataloader\n",
    "        train_dataset = train_arr[i]\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, num_workers=0)\n",
    "        test_dataset = test_arr[i]\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers=0)\n",
    "\n",
    "        # Reinitialize the model\n",
    "        model.reset()\n",
    "        model.to(device)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp(model, criterion, optimizer, train_dataloader, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp(model, test_dataloader)\n",
    "        print(pearson)\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bc5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process of the default config\n",
    "hidden_layers_size = [16, 8, 4]\n",
    "lr = 0.001\n",
    "batch_size = 60\n",
    "num_epochs = 10\n",
    "\n",
    "mlpr = MLP(len(best_features), hidden_layers_size=hidden_layers_size, dropout = 0.3)\n",
    "\n",
    "train_eval_cv_torch(mlpr, lr, default_cv, train_arr, test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdd235",
   "metadata": {},
   "source": [
    "#### Sixth Iteration: Change this into a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65121481",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_classification(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5950bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_classification = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_xgboost_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_classification = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_lightgbm_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31960b41",
   "metadata": {},
   "source": [
    "#### Seventh Iteration: Search for the best way to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_training_scheme(model, train_df, cv = default_cv, features = None):\n",
    "    folds_trial = [\n",
    "        # level 1\n",
    "        [[0, 1, 2, 3]], \n",
    "        [[0, 1]], [[1, 2]], [[2, 3]],\n",
    "        [[0]], [[1]], [[2]], [[3]],\n",
    "        [[0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1], [2, 3]],\n",
    "        [[0], [1], [2], [3]],\n",
    "        # level 2\n",
    "        [[0, 1, 2, 3], [0, 1]],\n",
    "        [[0, 1, 2, 3], [1, 2]],\n",
    "        [[0, 1, 2, 3], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "        # level 3\n",
    "        [[0, 1, 2, 3], [0, 1], [0]],\n",
    "        [[0, 1, 2, 3], [2, 3], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "    ]\n",
    "\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "\n",
    "    for folds in folds_trial:\n",
    "        print(f\"Current folds list is {folds}\")\n",
    "        model_lst = [deepcopy(model)] * len(folds)\n",
    "        cv_pearson = []\n",
    "        for i in range(cv):\n",
    "            train_month = list(range(3 + i, 7 + i))\n",
    "            test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "            test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "            X_test, Y_test = test.drop([\"timestamp\", \"label\"], axis = 1), test[\"label\"]\n",
    "            Y_pred = np.zeros(Y_test.shape[0])\n",
    "            for j in range(len(folds)):\n",
    "                fold = folds[j]\n",
    "                model = model_lst[j]\n",
    "                train_month_curr = [train_month[f] for f in fold]\n",
    "                train_curr = train_df[train_df[\"timestamp\"].dt.month.isin(train_month_curr)].reset_index().drop(\"index\", axis = 1)\n",
    "                X_train, Y_train = train_curr.drop([\"timestamp\", \"label\"], axis = 1), train_curr[\"label\"]\n",
    "                model.fit(X_train, Y_train)\n",
    "                Y_pred += model.predict(X_test)\n",
    "            Y_pred /= len(folds)\n",
    "            cv_pearson.append(pearson_score(Y_test, Y_pred))\n",
    "            print(f\"Finish fold {i} with score: {pearson_score(Y_test, Y_pred)}\")\n",
    "        print(f\"Finish trial with mean score: {np.mean(np.array(cv_pearson))}\")\n",
    "        print(f\"Finish trial with std score: {np.std(np.array(cv_pearson))}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df66a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "search_training_scheme(xgbr, train_added_df)\n",
    "# Notable\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [1, 2]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]] \n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ea866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "search_training_scheme(lgbr, train_added_df)\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [0]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fe3ca",
   "metadata": {},
   "source": [
    "#### Eighth Iteration: rewrite the code for MLP training using MLX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f11bdd",
   "metadata": {},
   "source": [
    "Create the data for training + custom batch iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb028760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "# best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "#                  'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137', \n",
    "#                 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301'] \n",
    "                #  'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', \n",
    "                #  'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "# best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68496448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "#     X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "#     Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "#     Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f14632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, cv=default_cv):\n",
    "    for i in range(cv):\n",
    "        # Normalize forst\n",
    "        scaler = StandardScaler()\n",
    "        X_train_arr[i] = scaler.fit_transform(X_train_arr[i].values)\n",
    "        X_test_arr[i] = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Convert to mlx format\n",
    "        X_train_arr[i] = mx.array(X_train_arr[i])\n",
    "        X_test_arr[i] = mx.array(X_test_arr[i])\n",
    "        Y_train_arr[i] = mx.array(Y_train_arr[i].values)\n",
    "        Y_test_arr[i] = mx.array(Y_test_arr[i].values)\n",
    "        \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3f916",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993631c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# We do not use the reset method this time so you have to create the model at each fold\n",
    "class MLPMLX(nnmx.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = []\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nnmx.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nnmx.ReLU()\n",
    "\n",
    "        # Initialze dropout\n",
    "        self.dropout = nnmx.Dropout(p = dropout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            if inx == len(self.layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33907ab7",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aaa51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for batch iteration\n",
    "def batch_iterate(batch_size, X, Y, shuffle = True):\n",
    "    for i in range(0, Y.size, batch_size):\n",
    "        X_curr = X[i: min(i + batch_size, Y.size), :]\n",
    "        Y_curr = Y[i: min(i + batch_size, Y.size)]\n",
    "        if shuffle:\n",
    "            inx_lst = mx.random.permutation(batch_size)\n",
    "            X_curr = X_curr[inx_lst, :]\n",
    "            Y_curr = Y_curr[inx_lst]\n",
    "        yield X_curr, Y_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            _, grads = loss_and_grad_fn(model, inputs, targets)\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            optimizer.update(model, grads)\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(model.parameters(), optimizer.state)\n",
    "\n",
    "def eval_mlp_mlx(model, X_test, Y_test, batch_size):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    for (inputs, targets) in batch_iterate(batch_size, X_test, Y_test, shuffle=False):\n",
    "        outputs = model(inputs).reshape(-1)\n",
    "        # convert back to numpy\n",
    "        outputs, targets = np.array(outputs), np.array(targets)\n",
    "        # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "        outputs_all = np.concatenate([outputs_all, outputs])\n",
    "        targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3974705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for _, (X_train, X_test, Y_train, Y_test) in enumerate(zip(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)):\n",
    "        # initialize the model\n",
    "        mx.random.seed(default_random_state)\n",
    "        model = MLPMLX(num_features, hidden_layers_size, dropout)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        def loss_fn(model, X, Y):\n",
    "            Y_pred = model(X).reshape(-1)\n",
    "            return mx.mean(nnmx.losses.mse_loss(Y_pred, Y))\n",
    "        loss_and_grad_fn = nnmx.value_and_grad(model, loss_fn)\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optimmx.Adam(learning_rate = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp_mlx(model, X_test, Y_test, batch_size)\n",
    "        print(pearson)\n",
    "        if pearson == -1:\n",
    "            return pearson\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0617236",
   "metadata": {},
   "source": [
    "Conduct training and evaluating process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training process of the default config\n",
    "# num_features = len(best_features)\n",
    "# hidden_layers_size = [8, 8, 8]\n",
    "# dropout = 0.2\n",
    "# lr = 0.001\n",
    "# batch_size = 180\n",
    "# num_epochs = 10\n",
    "\n",
    "# train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad94fa",
   "metadata": {},
   "source": [
    "Conduct Bayesian Optimization on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b347651",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp_mlx(trial):\n",
    "    # First initialize the parameters\n",
    "    num_features = len(best_features)\n",
    "    num_layers = default_num_layers\n",
    "    log_2_hidden_layers_size = []\n",
    "    for i in range(num_layers):\n",
    "        if len(log_2_hidden_layers_size) == 0:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, 6))\n",
    "        else:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, log_2_hidden_layers_size[-1]))\n",
    "    hidden_layers_size = [2**l for l in log_2_hidden_layers_size]\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.7)\n",
    "    lr = trial.suggest_float(\"lr\", 0.0001, 0.01, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [30, 60, 120, 180, 360, 720])\n",
    "    num_epochs = trial.suggest_categorical(\"num_epochs\", [10, 20, 30, 40, 50])\n",
    "    \n",
    "    # Conduct training based on those parameters\n",
    "    return train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mlp_mlx(study_name, storage_name, objective_function=objective_mlp_mlx, n_trials = 100, n_jobs = 1):\n",
    "    print(\"Conduct hyperparam opt for MLP\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "                 'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137',]\n",
    "                # 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301',] \n",
    "                #  'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', \n",
    "                #  'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)\n",
    "\n",
    "# Convert to float32\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "\n",
    "# Convert to MLX\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e30381",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_mlp_mlx(\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\",\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196766ca",
   "metadata": {},
   "source": [
    "#### Nineth Iteration: AE + MLP instead of GBDT feature selection + MLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
