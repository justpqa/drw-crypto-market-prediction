{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89ecff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justpqa/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler, GPSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import multiprocessing\n",
    "# max_n_jobs = multiprocessing.cpu_count()\n",
    "import shap\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, Sampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nnmx\n",
    "import mlx.optimizers as optimmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dce0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2025de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_version = 2\n",
    "# 1 for pc feature, \n",
    "# 2 for label correlation feature # seems to work most consistently\n",
    "# 3 for best features based on combination rank\n",
    "# 4 for including time features (in case we want to reverse engineer the masked timestamp)\n",
    "# 5 for increasing number of correlation features + only use those that are in the same cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935ee52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_random_state = 101\n",
    "random.seed(default_random_state)\n",
    "np.random.seed(default_random_state)\n",
    "torch.manual_seed(default_random_state)\n",
    "torch.mps.manual_seed(default_random_state)\n",
    "mx.random.seed(default_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731d3a4",
   "metadata": {},
   "source": [
    "#### Import train data and popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dc4e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X473</th>\n",
       "      <th>X205</th>\n",
       "      <th>X198</th>\n",
       "      <th>X444</th>\n",
       "      <th>X466</th>\n",
       "      <th>X445</th>\n",
       "      <th>X472</th>\n",
       "      <th>X26</th>\n",
       "      <th>X29</th>\n",
       "      <th>X217</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_buy_volume</th>\n",
       "      <th>normalized_sell_volume</th>\n",
       "      <th>liquidity_adjusted_imbalance</th>\n",
       "      <th>pressure_spread_interaction</th>\n",
       "      <th>trade_direction_ratio</th>\n",
       "      <th>net_buy_volume</th>\n",
       "      <th>bid_skew</th>\n",
       "      <th>ask_skew</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.201346</td>\n",
       "      <td>-1.978504</td>\n",
       "      <td>-1.700689</td>\n",
       "      <td>-0.142546</td>\n",
       "      <td>-0.163476</td>\n",
       "      <td>-0.128331</td>\n",
       "      <td>-0.126241</td>\n",
       "      <td>1.406392</td>\n",
       "      <td>1.474789</td>\n",
       "      <td>-0.981975</td>\n",
       "      <td>...</td>\n",
       "      <td>11.542564</td>\n",
       "      <td>5.339347</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>-0.230493</td>\n",
       "      <td>0.796810</td>\n",
       "      <td>131.421</td>\n",
       "      <td>0.644635</td>\n",
       "      <td>0.355365</td>\n",
       "      <td>2023-03-01 00:00:00</td>\n",
       "      <td>0.562539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186231</td>\n",
       "      <td>-1.830295</td>\n",
       "      <td>-1.669471</td>\n",
       "      <td>-0.135499</td>\n",
       "      <td>-0.159388</td>\n",
       "      <td>-0.124790</td>\n",
       "      <td>-0.115015</td>\n",
       "      <td>1.003783</td>\n",
       "      <td>1.312735</td>\n",
       "      <td>-0.940190</td>\n",
       "      <td>...</td>\n",
       "      <td>13.626484</td>\n",
       "      <td>137.821061</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>-0.549445</td>\n",
       "      <td>0.620251</td>\n",
       "      <td>203.896</td>\n",
       "      <td>0.942921</td>\n",
       "      <td>0.057079</td>\n",
       "      <td>2023-03-01 00:01:00</td>\n",
       "      <td>0.533686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.182398</td>\n",
       "      <td>-1.803540</td>\n",
       "      <td>-1.662645</td>\n",
       "      <td>-0.133705</td>\n",
       "      <td>-0.158627</td>\n",
       "      <td>-0.123891</td>\n",
       "      <td>-0.112303</td>\n",
       "      <td>0.760801</td>\n",
       "      <td>1.219124</td>\n",
       "      <td>-0.933071</td>\n",
       "      <td>...</td>\n",
       "      <td>360.242073</td>\n",
       "      <td>2.263386</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.530818</td>\n",
       "      <td>0.538664</td>\n",
       "      <td>22.858</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>2023-03-01 00:02:00</td>\n",
       "      <td>0.546505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.177415</td>\n",
       "      <td>-1.714013</td>\n",
       "      <td>-1.620037</td>\n",
       "      <td>-0.133251</td>\n",
       "      <td>-0.158334</td>\n",
       "      <td>-0.123658</td>\n",
       "      <td>-0.109113</td>\n",
       "      <td>0.955549</td>\n",
       "      <td>1.353001</td>\n",
       "      <td>-0.891216</td>\n",
       "      <td>...</td>\n",
       "      <td>69.011716</td>\n",
       "      <td>5.946089</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>0.454780</td>\n",
       "      <td>0.728757</td>\n",
       "      <td>210.779</td>\n",
       "      <td>0.187976</td>\n",
       "      <td>0.812024</td>\n",
       "      <td>2023-03-01 00:03:00</td>\n",
       "      <td>0.357703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.174164</td>\n",
       "      <td>-1.684170</td>\n",
       "      <td>-1.600188</td>\n",
       "      <td>-0.128862</td>\n",
       "      <td>-0.156668</td>\n",
       "      <td>-0.121464</td>\n",
       "      <td>-0.106383</td>\n",
       "      <td>0.905460</td>\n",
       "      <td>1.361880</td>\n",
       "      <td>-0.878711</td>\n",
       "      <td>...</td>\n",
       "      <td>3.623647</td>\n",
       "      <td>12.867864</td>\n",
       "      <td>0.081042</td>\n",
       "      <td>-0.533689</td>\n",
       "      <td>0.689066</td>\n",
       "      <td>54.004</td>\n",
       "      <td>0.887255</td>\n",
       "      <td>0.112745</td>\n",
       "      <td>2023-03-01 00:04:00</td>\n",
       "      <td>0.362452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X473      X205      X198      X444      X466      X445      X472  \\\n",
       "0 -0.201346 -1.978504 -1.700689 -0.142546 -0.163476 -0.128331 -0.126241   \n",
       "1 -0.186231 -1.830295 -1.669471 -0.135499 -0.159388 -0.124790 -0.115015   \n",
       "2 -0.182398 -1.803540 -1.662645 -0.133705 -0.158627 -0.123891 -0.112303   \n",
       "3 -0.177415 -1.714013 -1.620037 -0.133251 -0.158334 -0.123658 -0.109113   \n",
       "4 -0.174164 -1.684170 -1.600188 -0.128862 -0.156668 -0.121464 -0.106383   \n",
       "\n",
       "        X26       X29      X217  ...  normalized_buy_volume  \\\n",
       "0  1.406392  1.474789 -0.981975  ...              11.542564   \n",
       "1  1.003783  1.312735 -0.940190  ...              13.626484   \n",
       "2  0.760801  1.219124 -0.933071  ...             360.242073   \n",
       "3  0.955549  1.353001 -0.891216  ...              69.011716   \n",
       "4  0.905460  1.361880 -0.878711  ...               3.623647   \n",
       "\n",
       "   normalized_sell_volume  liquidity_adjusted_imbalance  \\\n",
       "0                5.339347                      0.063569   \n",
       "1              137.821061                      0.011610   \n",
       "2                2.263386                      0.015877   \n",
       "3                5.946089                      0.025702   \n",
       "4               12.867864                      0.081042   \n",
       "\n",
       "   pressure_spread_interaction  trade_direction_ratio  net_buy_volume  \\\n",
       "0                    -0.230493               0.796810         131.421   \n",
       "1                    -0.549445               0.620251         203.896   \n",
       "2                     0.530818               0.538664          22.858   \n",
       "3                     0.454780               0.728757         210.779   \n",
       "4                    -0.533689               0.689066          54.004   \n",
       "\n",
       "   bid_skew  ask_skew           timestamp     label  \n",
       "0  0.644635  0.355365 2023-03-01 00:00:00  0.562539  \n",
       "1  0.942921  0.057079 2023-03-01 00:01:00  0.533686  \n",
       "2  0.007283  0.992717 2023-03-01 00:02:00  0.546505  \n",
       "3  0.187976  0.812024 2023-03-01 00:03:00  0.357703  \n",
       "4  0.887255  0.112745 2023-03-01 00:04:00  0.362452  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_parquet(f\"data/cleaned/cleaned_train_{feature_version}.parquet\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766f9871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>bid_qty</th>\n",
       "      <th>ask_qty</th>\n",
       "      <th>buy_qty</th>\n",
       "      <th>sell_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221.389</td>\n",
       "      <td>15.283</td>\n",
       "      <td>8.425</td>\n",
       "      <td>176.405</td>\n",
       "      <td>44.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>847.796</td>\n",
       "      <td>38.590</td>\n",
       "      <td>2.336</td>\n",
       "      <td>525.846</td>\n",
       "      <td>321.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295.596</td>\n",
       "      <td>0.442</td>\n",
       "      <td>60.250</td>\n",
       "      <td>159.227</td>\n",
       "      <td>136.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460.705</td>\n",
       "      <td>4.865</td>\n",
       "      <td>21.016</td>\n",
       "      <td>335.742</td>\n",
       "      <td>124.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.818</td>\n",
       "      <td>27.158</td>\n",
       "      <td>3.451</td>\n",
       "      <td>98.411</td>\n",
       "      <td>44.407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    volume  bid_qty  ask_qty  buy_qty  sell_qty\n",
       "0  221.389   15.283    8.425  176.405    44.984\n",
       "1  847.796   38.590    2.336  525.846   321.950\n",
       "2  295.596    0.442   60.250  159.227   136.369\n",
       "3  460.705    4.865   21.016  335.742   124.963\n",
       "4  142.818   27.158    3.451   98.411    44.407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_features_train = pd.read_parquet(\"data/cleaned/popular_features_train.parquet\")\n",
    "popular_features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f1fe5",
   "metadata": {},
   "source": [
    "#### Implement some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb40f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to split into some fold\n",
    "train_df[\"timestamp\"] = pd.to_datetime(train_df[\"timestamp\"])\n",
    "\n",
    "default_cv = 4\n",
    "default_cv_type = \"full\"\n",
    "# NOTE: default_cv must set to 1 instead of 3 based on consistency with LB score contains 49% of test data\n",
    "# NOTE: 3 cv with gap is slightly better or almost equal\n",
    "\n",
    "def create_cv(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        # train_month = [3, 4, 5, 6, 7, 8]\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # test_month = [9, 10, 11, 12, 1, 2] # try to make a gap to see if there is any differences in cv-lb correlation\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"])\n",
    "        Y_test_arr.append(test[\"label\"])  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# def create_cv_random_test(train_df, features=None, test_cv=10):\n",
    "#     # randomize so that we have 1 train, but try it on 10 different test \n",
    "#     if features is not None:\n",
    "#         train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "#     X_train_arr = []\n",
    "#     X_test_arr = []\n",
    "#     Y_train_arr = []\n",
    "#     Y_test_arr = []\n",
    "\n",
    "#     # Create train data\n",
    "#     train_month = [3, 4, 5, 6, 7, 8]\n",
    "#     train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)] \n",
    "#     X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#     Y_train_arr.append(train[\"label\"])\n",
    "\n",
    "#     test_month = [9, 10, 11, 12, 1, 2]\n",
    "#     test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)]\n",
    "#     # Create test data\n",
    "#     for _ in range(test_cv):\n",
    "#         random_test = test.sample(frac = 0.5, random_state = default_random_state)\n",
    "#         X_test_arr.append(random_test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#         Y_test_arr.append(random_test[\"label\"])\n",
    "\n",
    "#     return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr \n",
    "\n",
    "# class [-1, 0, 1] -> [0, 1, 2] => < -0.2 => neg, > 0.2 => pos, else => neutral\n",
    "def create_classification_class(label):\n",
    "    if label < -0.4: return 0\n",
    "    elif label < 0: return 1\n",
    "    elif label < 0.4: return 2\n",
    "    return 3\n",
    "\n",
    "def create_cv_classification(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        # train_month = [3, 4, 5, 6, 7, 8]\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # test_month = [9, 10, 11, 12, 1, 2] # try to make a gap to see if there is any differences in cv-lb correlation\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"].apply(lambda x: create_classification_class(x)))\n",
    "        Y_test_arr.append(test[\"label\"].apply(lambda x: create_classification_class(x)))  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8b878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_score(Y_test, Y_pred):\n",
    "    if isinstance(Y_test, pd.Series) or isinstance(Y_test, pd.DataFrame):\n",
    "        Y_test = Y_test.values\n",
    "    if isinstance(Y_pred, pd.Series) or isinstance(Y_pred, pd.DataFrame):\n",
    "        Y_pred = Y_pred.values\n",
    "    Y_test = np.ravel(Y_test)\n",
    "    Y_pred = np.ravel(Y_pred)\n",
    "    pearson = np.corrcoef(Y_test, Y_pred)[0, 1]\n",
    "    if np.isnan(pearson):\n",
    "        if np.std(Y_pred) == 0:\n",
    "            print(Y_pred)\n",
    "            print(\"Error: zero variance prediction\")\n",
    "        elif np.isnan(Y_pred).any():\n",
    "            print(\"Error: nan prediction\")\n",
    "        return -1\n",
    "    else:\n",
    "        return pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce779cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function specifically for cross validation\n",
    "def train_eval_cv(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        cv_score += scoring_function(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_score / cv\n",
    "\n",
    "def train_eval_cv_random_test(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score, test_cv = 10):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        curr_cv_score = 0\n",
    "\n",
    "        # Conduct fitting\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        # sampling and testing\n",
    "        len_test = X_test.shape[0]\n",
    "        for seed in tqdm(range(test_cv)):\n",
    "            np.random.seed(seed)\n",
    "            test_index = np.random.choice(len_test, size = len_test // 2, replace = False) \n",
    "            X_test_sample = X_test.loc[test_index, :]\n",
    "            Y_test_sample = Y_test[test_index]\n",
    "            Y_pred_sample = model.predict(X_test_sample)\n",
    "            curr_cv_score += scoring_function(Y_test_sample, Y_pred_sample)\n",
    "        \n",
    "        cv_score += curr_cv_score / test_cv\n",
    "    \n",
    "    np.random.seed(default_random_state)\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9d975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trees = 2000\n",
    "# Finetuning XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddbb8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning XGBoost\n",
    "def objective_xgboost_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBClassifier(**params)\n",
    "    cv_acc = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_lightgbm_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMClassifier(**params)\n",
    "    cv_acc = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_catboost_classification(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_acc = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778f94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trials = 100\n",
    "default_n_jobs = 2\n",
    "\n",
    "def optimize_xgboost(study_name, storage_name, objective_function=objective_xgboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for XGBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_lightgbm(study_name, storage_name, objective_function=objective_lightgbm, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for LightGBM\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_catboost(study_name, storage_name, objective_function=objective_catboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for CatBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fd743",
   "metadata": {},
   "source": [
    "#### First iteration: training with all features from the collection, no popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5acc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb106a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_catboost = optimize_catboost(\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    "# )\n",
    "# # Need to take down as catboost might not work well in this situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e2b50",
   "metadata": {},
   "source": [
    "Analyze params - cv relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8801e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_study_df(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    study_df = []\n",
    "    for trial in study.trials:\n",
    "        trial_dict = trial.params\n",
    "        trial_dict[\"value\"] = trial.value\n",
    "        study_df.append(trial_dict)\n",
    "\n",
    "    return pd.DataFrame(study_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d57f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_value_viz(study_df):\n",
    "    nrows = (study_df.shape[1] - 1) // 3 + ((study_df.shape[1] - 1) % 3 > 0)\n",
    "    fig, ax = plt.subplots(nrows = nrows, ncols = 3, figsize = (14, 5 * nrows))\n",
    "    for inx, var in enumerate(study_df.columns):\n",
    "        x, y = inx // 3, inx % 3\n",
    "        if var != \"value\":\n",
    "            sns.regplot(study_df, x = var, y = \"value\", ax = ax[x][y], lowess=True, line_kws={'color': 'green'}, ci = 95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad954e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_xgboost = get_study_df(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")   \n",
    "params_value_viz(study_df_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717983ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_lightgbm = get_study_df(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "params_value_viz(study_df_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba067f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df_catboost = get_study_df(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# params_value_viz(study_df_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d81cc8",
   "metadata": {},
   "source": [
    "Analyze feature importance + CV performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ccea6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_from_file(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1942990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(model, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, sample_size=10000):\n",
    "    mean_abs_shap_all = np.zeros(X_train_arr[0].shape[1])\n",
    "    for i in range(default_cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        X_test_sample = X_test.sample(sample_size, random_state = default_random_state)\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        mean_abs_shap = np.mean(np.abs(shap_values), axis = 0)\n",
    "        mean_abs_shap_all += mean_abs_shap\n",
    "    mean_abs_shap_all /= default_cv\n",
    "    return mean_abs_shap_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in xgboost_feature_importances if xgboost_feature_importances[f] > 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7366dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in lightgbm_feature_importances if lightgbm_feature_importances[f] >= 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"iterations\": default_n_trees,\n",
    "#     \"verbose\": False,\n",
    "#     \"random_seed\": default_random_state\n",
    "# }\n",
    "# best_params_catboost = get_best_params_from_file(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# for p in best_params_catboost:\n",
    "#     params[p] = best_params_catboost[p]\n",
    "\n",
    "# catboost_feature_importances = {}\n",
    "\n",
    "# cbr = CatBoostRegressor(**params)\n",
    "# cv_rmse = 0\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "#     Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "#     cbr.fit(X_train, Y_train)\n",
    "#     print(pearson_score(Y_test, cbr.predict(X_test)))\n",
    "#     features = cbr.feature_names_\n",
    "#     # features_i = cbr.feature_importances_.tolist()\n",
    "#     features_i = get_shap_values(cbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "#     for inx, feat in enumerate(features):\n",
    "#         catboost_feature_importances[feat] = catboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# plt.hist(catboost_feature_importances.values())\n",
    "# # can pick up a combination of both past cod and tss, not good at picking up ph, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([f for f in catboost_feature_importances if catboost_feature_importances[f] >= 0.02])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8120d",
   "metadata": {},
   "source": [
    "Get top 20 important features in all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ed2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:49, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca490b7",
   "metadata": {},
   "source": [
    "#### Second Iteration: adding popular feature in addition to original features correlated to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93eefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_popular_feature = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_popular_feature = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d683a",
   "metadata": {},
   "source": [
    "Check for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df[~feature_importances_df[\"var\"].str.contains(\"X\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ba087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:29, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8dc1e",
   "metadata": {},
   "source": [
    "#### Third iteration: a more truncated version from the first collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7701a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "feature_importances_df[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df = feature_importances_df.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:49, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f34e76",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56532466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_importance_threshold = 0.011\n",
    "# xgboost_best_features = [\n",
    "#     f for f in xgboost_feature_importances if xgboost_feature_importances[f] > xgboost_importance_threshold\n",
    "# ] + [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"]\n",
    "# print(len(xgboost_best_features))\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, xgboost_best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_xgboost_params_truncated = optimize_xgboost(\n",
    "#     f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\",\n",
    "#     f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\"\n",
    "# ) # much worse than using all features  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13ba89",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ef415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm_importance_threshold = 20\n",
    "# lightgbm_best_features = [\n",
    "#     f for f in lightgbm_feature_importances if lightgbm_feature_importances[f] > lightgbm_importance_threshold\n",
    "# ] + [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"]\n",
    "# print(len(lightgbm_best_features))\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, lightgbm_best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_lightgbm_params_truncated = optimize_lightgbm(\n",
    "#     f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\",\n",
    "#     f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\"\n",
    "# )\n",
    "# # also much worse "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6953fd8",
   "metadata": {},
   "source": [
    "#### Fourth Iteration: a common truncated version using good features across all models + popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ebb508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6] [8, 9, 10, 11]\n",
      "[4, 5, 6, 7] [9, 10, 11, 12]\n",
      "[5, 6, 7, 8] [10, 11, 12, 1]\n",
      "[6, 7, 8, 9] [11, 12, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "                  'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137'] + \\\n",
    "                [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c7f75",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d3ed407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 20:54:23,925] A new study created in RDB with name: xgboost_2_4_101_2000_common_truncated_20_study\n",
      "[I 2025-07-02 20:54:51,794] Trial 1 finished with value: 0.09793494938121865 and parameters: {'max_depth': 5, 'learning_rate': 0.018656906454836534, 'subsample': 0.19181308263805968, 'colsample_bytree': 0.15066409256332733, 'colsample_bynode': 0.05287826801757714, 'colsample_bylevel': 0.823655955493228, 'min_child_weight': 5, 'reg_alpha': 35.2826161620323, 'reg_lambda': 95.01213794062856, 'gamma': 2.4268419241858075}. Best is trial 1 with value: 0.09793494938121865.\n",
      "[I 2025-07-02 20:55:23,779] Trial 2 finished with value: 0.1123293075996699 and parameters: {'max_depth': 4, 'learning_rate': 0.08884475009075311, 'subsample': 0.21665679403428834, 'colsample_bytree': 0.9534633689294111, 'colsample_bynode': 0.13774241885035818, 'colsample_bylevel': 0.4745559841024605, 'min_child_weight': 4, 'reg_alpha': 16.323513983279437, 'reg_lambda': 58.68540675553409, 'gamma': 1.9950807864800613}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:55:36,816] Trial 0 finished with value: 0.10182369890763075 and parameters: {'max_depth': 9, 'learning_rate': 0.005872007048389947, 'subsample': 0.8592959337476438, 'colsample_bytree': 0.5961769066308354, 'colsample_bynode': 0.23712714730260223, 'colsample_bylevel': 0.9238733867498599, 'min_child_weight': 1, 'reg_alpha': 20.553339797145476, 'reg_lambda': 97.31646546374867, 'gamma': 2.6532934828103776}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:56:01,404] Trial 4 finished with value: 0.10409997109583571 and parameters: {'max_depth': 3, 'learning_rate': 0.08042559742652644, 'subsample': 0.3224125029092023, 'colsample_bytree': 0.7121370223770149, 'colsample_bynode': 0.1023146081489403, 'colsample_bylevel': 0.613674894586932, 'min_child_weight': 6, 'reg_alpha': 77.30487684564488, 'reg_lambda': 30.40525090207823, 'gamma': 3.077705247785664}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:56:19,783] Trial 3 finished with value: 0.09995407936438422 and parameters: {'max_depth': 8, 'learning_rate': 0.011309210273360794, 'subsample': 0.9021857484706832, 'colsample_bytree': 0.1644415175100475, 'colsample_bynode': 0.6250822938934831, 'colsample_bylevel': 0.9861791090637557, 'min_child_weight': 7, 'reg_alpha': 81.17146671768093, 'reg_lambda': 44.1836137012627, 'gamma': 3.9405297338266045}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:56:29,502] Trial 5 finished with value: 0.10569791741493424 and parameters: {'max_depth': 6, 'learning_rate': 0.02566528266467349, 'subsample': 0.7844079931451333, 'colsample_bytree': 0.6053365394823016, 'colsample_bynode': 0.21582111871837406, 'colsample_bylevel': 0.1274146300575795, 'min_child_weight': 8, 'reg_alpha': 30.864441951219877, 'reg_lambda': 5.065816985916937, 'gamma': 2.9003314665751785}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:57:02,074] Trial 6 finished with value: 0.08962634041919577 and parameters: {'max_depth': 4, 'learning_rate': 0.0016099763740444002, 'subsample': 0.7401715268360355, 'colsample_bytree': 0.5463634434267154, 'colsample_bynode': 0.7363224779527984, 'colsample_bylevel': 0.43079821442213817, 'min_child_weight': 1, 'reg_alpha': 94.19239612300726, 'reg_lambda': 45.49315636140301, 'gamma': 3.8087093831277317}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:57:28,646] Trial 7 finished with value: 0.08274910914541593 and parameters: {'max_depth': 8, 'learning_rate': 0.001027705183931065, 'subsample': 0.1186206298699559, 'colsample_bytree': 0.09063899707375508, 'colsample_bynode': 0.275885206101465, 'colsample_bylevel': 0.9112693960527349, 'min_child_weight': 3, 'reg_alpha': 23.035569154128165, 'reg_lambda': 21.046640308556963, 'gamma': 0.4676681627000223}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:58:03,671] Trial 8 finished with value: 0.09160379118831252 and parameters: {'max_depth': 10, 'learning_rate': 0.012535578283038277, 'subsample': 0.6308677980581003, 'colsample_bytree': 0.5975399185010234, 'colsample_bynode': 0.8660788810395443, 'colsample_bylevel': 0.9698634881480213, 'min_child_weight': 7, 'reg_alpha': 73.57066001009879, 'reg_lambda': 69.3548761336177, 'gamma': 1.9761879127477433}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:58:04,889] Trial 9 finished with value: 0.0865335100432145 and parameters: {'max_depth': 3, 'learning_rate': 0.0026736082176533446, 'subsample': 0.8344032434649639, 'colsample_bytree': 0.8909017787529696, 'colsample_bynode': 0.8531641993661052, 'colsample_bylevel': 0.4830286412861201, 'min_child_weight': 10, 'reg_alpha': 75.17566129776415, 'reg_lambda': 50.47094795950292, 'gamma': 3.287429395574966}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:58:34,120] Trial 11 finished with value: 0.10611071274115255 and parameters: {'max_depth': 2, 'learning_rate': 0.09226233591538746, 'subsample': 0.4041212141168896, 'colsample_bytree': 0.9941649464904025, 'colsample_bynode': 0.38463431328219744, 'colsample_bylevel': 0.2454898403699476, 'min_child_weight': 4, 'reg_alpha': 0.4200030655735123, 'reg_lambda': 72.45502295620281, 'gamma': 1.3790890666659399}. Best is trial 2 with value: 0.1123293075996699.\n",
      "[I 2025-07-02 20:59:04,638] Trial 12 finished with value: 0.11240324589828969 and parameters: {'max_depth': 2, 'learning_rate': 0.08971034832987511, 'subsample': 0.40246896229048457, 'colsample_bytree': 0.9956436277900348, 'colsample_bynode': 0.42858770370941385, 'colsample_bylevel': 0.24291950416758798, 'min_child_weight': 4, 'reg_alpha': 2.1600125099964984, 'reg_lambda': 71.43459681304275, 'gamma': 1.3781560507263482}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 20:59:06,122] Trial 10 finished with value: 0.09598073371504479 and parameters: {'max_depth': 7, 'learning_rate': 0.002965158669130573, 'subsample': 0.7369534821742476, 'colsample_bytree': 0.8496993679606105, 'colsample_bynode': 0.24795503736487542, 'colsample_bylevel': 0.8373835721818444, 'min_child_weight': 1, 'reg_alpha': 72.06113278690408, 'reg_lambda': 4.522447457890433, 'gamma': 1.1123891597146245}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 20:59:33,706] Trial 14 finished with value: 0.10759743519470015 and parameters: {'max_depth': 2, 'learning_rate': 0.03544591857829797, 'subsample': 0.45991006599498296, 'colsample_bytree': 0.34116767266770276, 'colsample_bynode': 0.45680016517936517, 'colsample_bylevel': 0.31719866164029364, 'min_child_weight': 3, 'reg_alpha': 0.8518177725931677, 'reg_lambda': 70.8101516199397, 'gamma': 4.89386516286698}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 20:59:36,559] Trial 13 finished with value: 0.10582665843252706 and parameters: {'max_depth': 2, 'learning_rate': 0.041665249729814134, 'subsample': 0.45163422085538457, 'colsample_bytree': 0.8748995427151894, 'colsample_bynode': 0.4910069761171302, 'colsample_bylevel': 0.30823701335068165, 'min_child_weight': 3, 'reg_alpha': 2.310265640186008, 'reg_lambda': 69.95805892558863, 'gamma': 1.0435318192231022}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:00:18,120] Trial 15 finished with value: 0.1008164926960084 and parameters: {'max_depth': 4, 'learning_rate': 0.047879956866552845, 'subsample': 0.2691325619089906, 'colsample_bytree': 0.8015539277553411, 'colsample_bynode': 0.544707886720199, 'colsample_bylevel': 0.6454807544903269, 'min_child_weight': 3, 'reg_alpha': 54.5540482114405, 'reg_lambda': 82.67036377869448, 'gamma': 0.19555689120489816}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:00:21,371] Trial 16 finished with value: 0.1037392962619773 and parameters: {'max_depth': 4, 'learning_rate': 0.06337738076740267, 'subsample': 0.2396619046215499, 'colsample_bytree': 0.9993178215719976, 'colsample_bynode': 0.6248945675807103, 'colsample_bylevel': 0.6377165951324038, 'min_child_weight': 5, 'reg_alpha': 46.07604977485359, 'reg_lambda': 57.367635319690145, 'gamma': 0.30652942589747445}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:00:52,456] Trial 17 finished with value: 0.10466926038661363 and parameters: {'max_depth': 5, 'learning_rate': 0.06548956583193401, 'subsample': 0.058946717875962396, 'colsample_bytree': 0.991583767384106, 'colsample_bynode': 0.3825403375502058, 'colsample_bylevel': 0.05755228370708493, 'min_child_weight': 5, 'reg_alpha': 14.330123861521997, 'reg_lambda': 56.66194606374399, 'gamma': 1.7197095974299228}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:00:53,978] Trial 18 finished with value: 0.09916744687463476 and parameters: {'max_depth': 5, 'learning_rate': 0.09880322551332384, 'subsample': 0.057628576420041544, 'colsample_bytree': 0.33962621010359106, 'colsample_bynode': 0.9896129215180236, 'colsample_bylevel': 0.05093034702964652, 'min_child_weight': 4, 'reg_alpha': 13.566010545005401, 'reg_lambda': 57.52926587754941, 'gamma': 1.8701523260232502}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:01:27,388] Trial 19 finished with value: 0.10254754125198737 and parameters: {'max_depth': 3, 'learning_rate': 0.006179715467405346, 'subsample': 0.5716989804731613, 'colsample_bytree': 0.42774979807955504, 'colsample_bynode': 0.975027848886727, 'colsample_bylevel': 0.3955525960253979, 'min_child_weight': 4, 'reg_alpha': 14.390030118151723, 'reg_lambda': 84.68627904834719, 'gamma': 2.022229653486142}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:01:28,741] Trial 20 finished with value: 0.0993174611833615 and parameters: {'max_depth': 3, 'learning_rate': 0.006536787223965019, 'subsample': 0.639850142129598, 'colsample_bytree': 0.728512497808241, 'colsample_bynode': 0.15086080121266465, 'colsample_bylevel': 0.3807979433210552, 'min_child_weight': 2, 'reg_alpha': 45.18777279450664, 'reg_lambda': 84.35127657194585, 'gamma': 0.7632508794322326}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:02:01,159] Trial 22 finished with value: 0.09987285177203255 and parameters: {'max_depth': 2, 'learning_rate': 0.038149656037533126, 'subsample': 0.39526198349174374, 'colsample_bytree': 0.2998846889994895, 'colsample_bynode': 0.4091344230246484, 'colsample_bylevel': 0.2633625501301887, 'min_child_weight': 2, 'reg_alpha': 6.573018711193609, 'reg_lambda': 65.95846788117875, 'gamma': 4.374869233430035}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:02:21,280] Trial 21 finished with value: 0.10702625310438516 and parameters: {'max_depth': 6, 'learning_rate': 0.021399005318180404, 'subsample': 0.36888801049371467, 'colsample_bytree': 0.7375239289689184, 'colsample_bynode': 0.12966751557223954, 'colsample_bylevel': 0.223715208232234, 'min_child_weight': 2, 'reg_alpha': 54.73755186281674, 'reg_lambda': 36.69104282690827, 'gamma': 0.8815534109608003}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:02:32,987] Trial 23 finished with value: 0.09936329737708229 and parameters: {'max_depth': 2, 'learning_rate': 0.027041177231062516, 'subsample': 0.48473391209383787, 'colsample_bytree': 0.4535819270907653, 'colsample_bynode': 0.31568657841586933, 'colsample_bylevel': 0.16587889427812813, 'min_child_weight': 3, 'reg_alpha': 6.872457493869574, 'reg_lambda': 36.26302389695671, 'gamma': 2.370781552954134}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:02:48,543] Trial 24 finished with value: 0.1060588452921673 and parameters: {'max_depth': 2, 'learning_rate': 0.029674991186692604, 'subsample': 0.49572050049786065, 'colsample_bytree': 0.41764465835348785, 'colsample_bynode': 0.33520572765396023, 'colsample_bylevel': 0.5386681585238081, 'min_child_weight': 4, 'reg_alpha': 9.919692554879955, 'reg_lambda': 77.42506304743577, 'gamma': 4.852511505101683}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:03:01,934] Trial 25 finished with value: 0.10644022936689689 and parameters: {'max_depth': 3, 'learning_rate': 0.055699833199983666, 'subsample': 0.5306911741197508, 'colsample_bytree': 0.2802802656646246, 'colsample_bynode': 0.48885829588854524, 'colsample_bylevel': 0.5436966227415639, 'min_child_weight': 6, 'reg_alpha': 27.880849795062016, 'reg_lambda': 79.23092479894837, 'gamma': 3.4447342576018114}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:03:19,719] Trial 26 finished with value: 0.1014681539621389 and parameters: {'max_depth': 4, 'learning_rate': 0.05490919105101602, 'subsample': 0.17758493498725353, 'colsample_bytree': 0.3317830202548141, 'colsample_bynode': 0.49072020676770955, 'colsample_bylevel': 0.32346561066783386, 'min_child_weight': 6, 'reg_alpha': 23.434220117209232, 'reg_lambda': 63.2321885902961, 'gamma': 4.947187769465083}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:03:47,152] Trial 27 finished with value: 0.10450666241550215 and parameters: {'max_depth': 4, 'learning_rate': 0.01666881422051438, 'subsample': 0.30806556994687423, 'colsample_bytree': 0.8990251899375674, 'colsample_bynode': 0.5593709370299986, 'colsample_bylevel': 0.3284772646499507, 'min_child_weight': 4, 'reg_alpha': 19.82167874915136, 'reg_lambda': 64.34608929782347, 'gamma': 1.4297121491164506}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:03:53,289] Trial 28 finished with value: 0.10245540953587287 and parameters: {'max_depth': 3, 'learning_rate': 0.03855402199087123, 'subsample': 0.30760239796005767, 'colsample_bytree': 0.8939173887423891, 'colsample_bynode': 0.6459878167170789, 'colsample_bylevel': 0.33339755929360126, 'min_child_weight': 4, 'reg_alpha': 39.53481646178881, 'reg_lambda': 91.07348248909847, 'gamma': 1.4388055724110866}. Best is trial 12 with value: 0.11240324589828969.\n",
      "[I 2025-07-02 21:04:17,473] Trial 30 finished with value: 0.11561790385876741 and parameters: {'max_depth': 2, 'learning_rate': 0.07860313064371964, 'subsample': 0.6028890579746968, 'colsample_bytree': 0.23677007723404678, 'colsample_bynode': 0.1906636156759822, 'colsample_bylevel': 0.4798831657723993, 'min_child_weight': 2, 'reg_alpha': 1.6730701260920546, 'reg_lambda': 75.15592665483437, 'gamma': 2.6823790241104173}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:04:20,225] Trial 29 finished with value: 0.10829739672229624 and parameters: {'max_depth': 3, 'learning_rate': 0.03679669913168577, 'subsample': 0.33180428338714074, 'colsample_bytree': 0.21002570543025512, 'colsample_bynode': 0.7102232866106528, 'colsample_bylevel': 0.45746028566154423, 'min_child_weight': 2, 'reg_alpha': 37.28489535908927, 'reg_lambda': 89.32148505203169, 'gamma': 1.5190004651747966}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:04:42,186] Trial 31 finished with value: 0.10868629745051897 and parameters: {'max_depth': 5, 'learning_rate': 0.07491485055538827, 'subsample': 0.9788887430930666, 'colsample_bytree': 0.2328366840325285, 'colsample_bynode': 0.19483179444036158, 'colsample_bylevel': 0.7221732185340601, 'min_child_weight': 2, 'reg_alpha': 18.739817602847694, 'reg_lambda': 99.98194251040636, 'gamma': 2.695616034218122}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:04:47,396] Trial 32 finished with value: 0.11431045992621118 and parameters: {'max_depth': 3, 'learning_rate': 0.07525796565503845, 'subsample': 0.6410839199844075, 'colsample_bytree': 0.2173945238740298, 'colsample_bynode': 0.21091241959941662, 'colsample_bylevel': 0.47420174230627876, 'min_child_weight': 1, 'reg_alpha': 18.49379453419921, 'reg_lambda': 98.29483336214462, 'gamma': 2.1658101626034965}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:05:07,901] Trial 33 finished with value: 0.10675866742842097 and parameters: {'max_depth': 5, 'learning_rate': 0.07566559005834106, 'subsample': 0.9650448703489825, 'colsample_bytree': 0.23403451326714472, 'colsample_bynode': 0.1806557012817826, 'colsample_bylevel': 0.732111081793701, 'min_child_weight': 1, 'reg_alpha': 18.278190282339235, 'reg_lambda': 95.62139887969549, 'gamma': 2.606356195201389}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:05:12,648] Trial 34 finished with value: 0.11140193445160128 and parameters: {'max_depth': 2, 'learning_rate': 0.09395155502638818, 'subsample': 0.6278960760586386, 'colsample_bytree': 0.1307835268206679, 'colsample_bynode': 0.17214609346228998, 'colsample_bylevel': 0.5782808031771032, 'min_child_weight': 1, 'reg_alpha': 9.690023394243175, 'reg_lambda': 93.60205528280127, 'gamma': 2.272250216307166}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:05:31,791] Trial 35 finished with value: 0.10575184783956407 and parameters: {'max_depth': 2, 'learning_rate': 0.09985580145330376, 'subsample': 0.6520851836702823, 'colsample_bytree': 0.10336428619811938, 'colsample_bynode': 0.06574760513594334, 'colsample_bylevel': 0.5921977280802875, 'min_child_weight': 1, 'reg_alpha': 7.6715100288898315, 'reg_lambda': 78.11330649426601, 'gamma': 2.207584563308521}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:05:37,617] Trial 36 finished with value: 0.10498246733430976 and parameters: {'max_depth': 3, 'learning_rate': 0.05294913800531481, 'subsample': 0.6872934523391735, 'colsample_bytree': 0.07594736391403079, 'colsample_bynode': 0.06320065459012097, 'colsample_bylevel': 0.48508711633267537, 'min_child_weight': 5, 'reg_alpha': 28.08769239858638, 'reg_lambda': 50.3687861105747, 'gamma': 2.1855880066388935}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:05:56,910] Trial 37 finished with value: 0.10402082184841233 and parameters: {'max_depth': 3, 'learning_rate': 0.054772650504851216, 'subsample': 0.5742993385161816, 'colsample_bytree': 0.5005735252644761, 'colsample_bynode': 0.08623970207303323, 'colsample_bylevel': 0.4703563135363383, 'min_child_weight': 5, 'reg_alpha': 30.218965107770064, 'reg_lambda': 53.33771861092747, 'gamma': 2.9165778916640694}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:06:06,362] Trial 38 finished with value: 0.10811922685692145 and parameters: {'max_depth': 4, 'learning_rate': 0.07048540963167062, 'subsample': 0.5658614689673088, 'colsample_bytree': 0.16673960073289457, 'colsample_bynode': 0.2756724599966053, 'colsample_bylevel': 0.40348717596729433, 'min_child_weight': 7, 'reg_alpha': 4.964351064359954, 'reg_lambda': 74.65312217337726, 'gamma': 2.738381984310941}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:06:27,371] Trial 39 finished with value: 0.10313364609298437 and parameters: {'max_depth': 4, 'learning_rate': 0.06755021911209669, 'subsample': 0.20807602230888853, 'colsample_bytree': 0.6730780685621123, 'colsample_bynode': 0.28048347476328567, 'colsample_bylevel': 0.4228530648362423, 'min_child_weight': 10, 'reg_alpha': 64.47429479992795, 'reg_lambda': 18.504117297052957, 'gamma': 1.7035015670326359}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:06:47,736] Trial 40 finished with value: 0.1005910836774969 and parameters: {'max_depth': 6, 'learning_rate': 0.009260728915966543, 'subsample': 0.17866056915880185, 'colsample_bytree': 0.6816757373595421, 'colsample_bynode': 0.22540662585538557, 'colsample_bylevel': 0.14701415494225262, 'min_child_weight': 10, 'reg_alpha': 12.065818893018815, 'reg_lambda': 43.975373487653044, 'gamma': 1.7845330554941377}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:07:00,310] Trial 41 finished with value: 0.09831242538457469 and parameters: {'max_depth': 7, 'learning_rate': 0.008248576984915231, 'subsample': 0.7966150493165851, 'colsample_bytree': 0.6612067616578806, 'colsample_bynode': 0.2132528658961101, 'colsample_bylevel': 0.1859543934468294, 'min_child_weight': 8, 'reg_alpha': 24.42268682719827, 'reg_lambda': 41.704230819250554, 'gamma': 3.20736222054918}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:07:12,757] Trial 42 finished with value: 0.11060497644325343 and parameters: {'max_depth': 2, 'learning_rate': 0.0842264816844306, 'subsample': 0.7149810349648076, 'colsample_bytree': 0.17560895681112806, 'colsample_bynode': 0.1478965043691976, 'colsample_bylevel': 0.5812543352834492, 'min_child_weight': 1, 'reg_alpha': 11.266022562306478, 'reg_lambda': 91.47465668369098, 'gamma': 2.1924992215397734}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:07:26,995] Trial 43 finished with value: 0.1073050403644527 and parameters: {'max_depth': 2, 'learning_rate': 0.08403310605718049, 'subsample': 0.7426511002473914, 'colsample_bytree': 0.9426796878850807, 'colsample_bynode': 0.12322466373471364, 'colsample_bylevel': 0.5777247859852096, 'min_child_weight': 1, 'reg_alpha': 96.67918223299381, 'reg_lambda': 92.8862144426828, 'gamma': 2.4815322371305877}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:07:41,578] Trial 44 finished with value: 0.08476649769983492 and parameters: {'max_depth': 2, 'learning_rate': 0.0036219222307219477, 'subsample': 0.6102593312966648, 'colsample_bytree': 0.9406835665504163, 'colsample_bynode': 0.12580613149106157, 'colsample_bylevel': 0.5356785779144351, 'min_child_weight': 1, 'reg_alpha': 3.639155503438772, 'reg_lambda': 96.23680621002745, 'gamma': 2.4148049579148534}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:07:51,138] Trial 45 finished with value: 0.10114770662596984 and parameters: {'max_depth': 2, 'learning_rate': 0.045542657288626845, 'subsample': 0.6137324777226337, 'colsample_bytree': 0.11317165583082946, 'colsample_bynode': 0.32962866591323636, 'colsample_bylevel': 0.7308572488855553, 'min_child_weight': 2, 'reg_alpha': 0.3158127179713732, 'reg_lambda': 86.57544264704461, 'gamma': 2.8817893849958933}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:08:05,011] Trial 46 finished with value: 0.09740040310992847 and parameters: {'max_depth': 3, 'learning_rate': 0.04342464954714854, 'subsample': 0.5266693097773656, 'colsample_bytree': 0.050496394409223155, 'colsample_bynode': 0.3407482789270244, 'colsample_bylevel': 0.6953823172463065, 'min_child_weight': 2, 'reg_alpha': 89.80651371467266, 'reg_lambda': 86.93177921238906, 'gamma': 3.684002227426893}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:08:27,841] Trial 47 finished with value: 0.09751314665645916 and parameters: {'max_depth': 10, 'learning_rate': 0.09972430756047808, 'subsample': 0.5277329679440859, 'colsample_bytree': 0.05599253442386409, 'colsample_bynode': 0.175648336580481, 'colsample_bylevel': 0.6614003668763339, 'min_child_weight': 3, 'reg_alpha': 16.54052701514364, 'reg_lambda': 80.01758037643214, 'gamma': 1.1746813143548465}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:09:00,051] Trial 49 finished with value: 0.10147130565736068 and parameters: {'max_depth': 3, 'learning_rate': 0.062410206205024604, 'subsample': 0.8944523923968226, 'colsample_bytree': 0.8278604365267515, 'colsample_bynode': 0.24744128218023156, 'colsample_bylevel': 0.810229400032551, 'min_child_weight': 3, 'reg_alpha': 9.359021028738463, 'reg_lambda': 61.72730532844773, 'gamma': 1.966335397799709}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:09:02,590] Trial 48 finished with value: 0.10283320135914076 and parameters: {'max_depth': 10, 'learning_rate': 0.015622992403762354, 'subsample': 0.884421518230281, 'colsample_bytree': 0.8150172258119651, 'colsample_bynode': 0.17726829311129103, 'colsample_bylevel': 0.6720328120812158, 'min_child_weight': 3, 'reg_alpha': 17.63952263245581, 'reg_lambda': 99.36313211230299, 'gamma': 2.0663471734392784}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:09:28,628] Trial 50 finished with value: 0.10124525484838354 and parameters: {'max_depth': 2, 'learning_rate': 0.014226736213274381, 'subsample': 0.4430301910871801, 'colsample_bytree': 0.7720384576069406, 'colsample_bynode': 0.42490838908722905, 'colsample_bylevel': 0.4915764959858232, 'min_child_weight': 1, 'reg_alpha': 34.25999814214019, 'reg_lambda': 67.97023861580351, 'gamma': 0.605985252549613}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:09:35,068] Trial 51 finished with value: 0.08826688821845004 and parameters: {'max_depth': 3, 'learning_rate': 0.0012808453205835903, 'subsample': 0.11841970830366934, 'colsample_bytree': 0.3740734736957293, 'colsample_bynode': 0.42085599928891493, 'colsample_bylevel': 0.48903078547902934, 'min_child_weight': 1, 'reg_alpha': 3.0459304939553746, 'reg_lambda': 68.44320465341495, 'gamma': 0.5849379265012173}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:09:52,715] Trial 52 finished with value: 0.11050486932375807 and parameters: {'max_depth': 2, 'learning_rate': 0.08376843218046033, 'subsample': 0.6941300821497232, 'colsample_bytree': 0.1971319617472338, 'colsample_bynode': 0.10671730486136399, 'colsample_bylevel': 0.5928764715472957, 'min_child_weight': 1, 'reg_alpha': 11.926846467782678, 'reg_lambda': 91.99750373239183, 'gamma': 2.1945048547801256}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:09:59,080] Trial 53 finished with value: 0.10902128026701978 and parameters: {'max_depth': 2, 'learning_rate': 0.08660529112733041, 'subsample': 0.704216397478986, 'colsample_bytree': 0.15342873553095374, 'colsample_bynode': 0.10266463234603036, 'colsample_bylevel': 0.6106035007902999, 'min_child_weight': 1, 'reg_alpha': 9.77387978564246, 'reg_lambda': 92.95046307173966, 'gamma': 2.1926840205735854}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:10:16,551] Trial 54 finished with value: 0.10364715711594294 and parameters: {'max_depth': 2, 'learning_rate': 0.08146351656371874, 'subsample': 0.7231483551861485, 'colsample_bytree': 0.12150060763887546, 'colsample_bynode': 0.28635641539225387, 'colsample_bylevel': 0.36667319914468377, 'min_child_weight': 2, 'reg_alpha': 22.903433456855314, 'reg_lambda': 75.66358934992483, 'gamma': 1.5977001863098899}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:10:23,525] Trial 55 finished with value: 0.11100892652343879 and parameters: {'max_depth': 2, 'learning_rate': 0.07763247614131373, 'subsample': 0.7768978696380084, 'colsample_bytree': 0.2723026940839837, 'colsample_bynode': 0.2832254704516325, 'colsample_bylevel': 0.4405233615411772, 'min_child_weight': 2, 'reg_alpha': 5.35362967911746, 'reg_lambda': 73.06232161179548, 'gamma': 1.6382413092121562}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:10:47,642] Trial 56 finished with value: 0.11116304132114288 and parameters: {'max_depth': 3, 'learning_rate': 0.0327097309115085, 'subsample': 0.6694280855509982, 'colsample_bytree': 0.2958580505332425, 'colsample_bynode': 0.16034554560043554, 'colsample_bylevel': 0.5647569440205028, 'min_child_weight': 2, 'reg_alpha': 6.012996380617722, 'reg_lambda': 81.9503287196793, 'gamma': 1.2156942429532984}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:10:53,646] Trial 57 finished with value: 0.10807292848103925 and parameters: {'max_depth': 3, 'learning_rate': 0.032451031947944874, 'subsample': 0.7756550785010936, 'colsample_bytree': 0.2931504305178463, 'colsample_bynode': 0.2089527853098395, 'colsample_bylevel': 0.43496588407885894, 'min_child_weight': 2, 'reg_alpha': 0.25525803943551395, 'reg_lambda': 60.06698508026724, 'gamma': 1.1449173478027705}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:11:22,642] Trial 58 finished with value: 0.1116940996084593 and parameters: {'max_depth': 4, 'learning_rate': 0.02182020689845827, 'subsample': 0.6727345364447426, 'colsample_bytree': 0.24350676879221408, 'colsample_bynode': 0.239204197778267, 'colsample_bylevel': 0.5065535230732564, 'min_child_weight': 3, 'reg_alpha': 0.6362449874339209, 'reg_lambda': 81.84742416678095, 'gamma': 1.0927316345780729}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:11:29,948] Trial 59 finished with value: 0.11205266668834396 and parameters: {'max_depth': 4, 'learning_rate': 0.02278211912575062, 'subsample': 0.6674946976943944, 'colsample_bytree': 0.5436393747340758, 'colsample_bynode': 0.1514953353831296, 'colsample_bylevel': 0.5139772945306834, 'min_child_weight': 3, 'reg_alpha': 16.28175805530022, 'reg_lambda': 79.79177153745069, 'gamma': 1.312643649976027}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:12:07,011] Trial 60 finished with value: 0.10797178247574798 and parameters: {'max_depth': 5, 'learning_rate': 0.021755405065520667, 'subsample': 0.592349844648065, 'colsample_bytree': 0.5608624514519746, 'colsample_bynode': 0.23609424425361006, 'colsample_bylevel': 0.5085343233877019, 'min_child_weight': 4, 'reg_alpha': 3.7690291533501323, 'reg_lambda': 87.54797819169156, 'gamma': 0.9174250319903359}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:12:09,083] Trial 61 finished with value: 0.10817994564503289 and parameters: {'max_depth': 4, 'learning_rate': 0.022621154905489226, 'subsample': 0.5838010741271906, 'colsample_bytree': 0.5656727046357515, 'colsample_bynode': 0.3789358066440106, 'colsample_bylevel': 0.36077066065863184, 'min_child_weight': 4, 'reg_alpha': 14.739676953673534, 'reg_lambda': 72.21271920930671, 'gamma': 0.9129276641443418}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:12:44,270] Trial 62 finished with value: 0.10814359956781697 and parameters: {'max_depth': 4, 'learning_rate': 0.012046013965301866, 'subsample': 0.6465139012729167, 'colsample_bytree': 0.23659090841457942, 'colsample_bynode': 0.371782355493935, 'colsample_bylevel': 0.5409806494865693, 'min_child_weight': 3, 'reg_alpha': 21.948963270522107, 'reg_lambda': 81.92638672430625, 'gamma': 1.271700325728038}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:12:48,087] Trial 63 finished with value: 0.10345879168877119 and parameters: {'max_depth': 4, 'learning_rate': 0.011213778097558335, 'subsample': 0.6444655360196276, 'colsample_bytree': 0.9508953177691642, 'colsample_bynode': 0.2526900120221578, 'colsample_bylevel': 0.5255733033017477, 'min_child_weight': 3, 'reg_alpha': 22.00464105842775, 'reg_lambda': 84.87067894105617, 'gamma': 1.275036831597976}. Best is trial 30 with value: 0.11561790385876741.\n",
      "[I 2025-07-02 21:13:19,553] Trial 65 finished with value: 0.11776482837424804 and parameters: {'max_depth': 5, 'learning_rate': 0.06195449728524362, 'subsample': 0.5452663566957877, 'colsample_bytree': 0.510148572055214, 'colsample_bynode': 0.13546115445837226, 'colsample_bylevel': 0.41141839053052753, 'min_child_weight': 3, 'reg_alpha': 14.975314628896754, 'reg_lambda': 79.18273698704866, 'gamma': 1.9622610322138838}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:13:21,007] Trial 64 finished with value: 0.08853146707131632 and parameters: {'max_depth': 4, 'learning_rate': 0.004397679252012612, 'subsample': 0.5465719326242924, 'colsample_bytree': 0.9504667902821756, 'colsample_bynode': 0.14443541681828204, 'colsample_bylevel': 0.0969486930882611, 'min_child_weight': 3, 'reg_alpha': 14.875816121834848, 'reg_lambda': 84.15487958942437, 'gamma': 1.9458375509819943}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:13:51,074] Trial 66 finished with value: 0.11333158585908457 and parameters: {'max_depth': 5, 'learning_rate': 0.06303967482351112, 'subsample': 0.48506837865145574, 'colsample_bytree': 0.49055668985665746, 'colsample_bynode': 0.05466252072093483, 'colsample_bylevel': 0.2990197361192154, 'min_child_weight': 4, 'reg_alpha': 25.169885423444825, 'reg_lambda': 67.49716941435858, 'gamma': 1.8944975550550807}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:13:55,599] Trial 67 finished with value: 0.11633144598572807 and parameters: {'max_depth': 5, 'learning_rate': 0.060812405916827884, 'subsample': 0.49328744636045213, 'colsample_bytree': 0.5077799572964892, 'colsample_bynode': 0.08671587583754647, 'colsample_bylevel': 0.2609819054821548, 'min_child_weight': 4, 'reg_alpha': 25.118083236544003, 'reg_lambda': 76.44416897389672, 'gamma': 1.3927736857207549}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:14:26,889] Trial 69 finished with value: 0.10646768590755672 and parameters: {'max_depth': 5, 'learning_rate': 0.06026299562336765, 'subsample': 0.48828626323961544, 'colsample_bytree': 0.4870679435089122, 'colsample_bynode': 0.05554329828177795, 'colsample_bylevel': 0.25644866677841816, 'min_child_weight': 5, 'reg_alpha': 26.272982233190653, 'reg_lambda': 54.53777958007205, 'gamma': 1.8170596226197395}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:14:37,539] Trial 68 finished with value: 0.11134211174538071 and parameters: {'max_depth': 5, 'learning_rate': 0.048644057169595564, 'subsample': 0.4838165858223021, 'colsample_bytree': 0.5150420519346368, 'colsample_bynode': 0.05407534859837845, 'colsample_bylevel': 0.2859104998635654, 'min_child_weight': 4, 'reg_alpha': 26.347719093666868, 'reg_lambda': 53.647057766335124, 'gamma': 0.005506432384283055}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:14:56,692] Trial 70 finished with value: 0.10721797839168204 and parameters: {'max_depth': 6, 'learning_rate': 0.04761096453764363, 'subsample': 0.4230140604484837, 'colsample_bytree': 0.6275869807318722, 'colsample_bynode': 0.08850049673769791, 'colsample_bylevel': 0.2892766162115738, 'min_child_weight': 4, 'reg_alpha': 29.895640380580893, 'reg_lambda': 65.22044745301318, 'gamma': 2.6029570282016925}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:15:12,572] Trial 71 finished with value: 0.11047316800597001 and parameters: {'max_depth': 6, 'learning_rate': 0.06793143872323093, 'subsample': 0.42300327927395526, 'colsample_bytree': 0.6381172191913475, 'colsample_bynode': 0.08954457986200057, 'colsample_bylevel': 0.21336806444344347, 'min_child_weight': 5, 'reg_alpha': 29.75796153221131, 'reg_lambda': 65.75232540298005, 'gamma': 1.5088151458610115}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:15:27,534] Trial 72 finished with value: 0.1058063862227463 and parameters: {'max_depth': 5, 'learning_rate': 0.06784538003206218, 'subsample': 0.3534349442769462, 'colsample_bytree': 0.454744027306452, 'colsample_bynode': 0.08481226213160424, 'colsample_bylevel': 0.2132701055716409, 'min_child_weight': 5, 'reg_alpha': 41.41920851924834, 'reg_lambda': 69.98015504078614, 'gamma': 1.6031680776918122}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:15:46,826] Trial 73 finished with value: 0.11107331907063364 and parameters: {'max_depth': 5, 'learning_rate': 0.05972529326761217, 'subsample': 0.5604276496745203, 'colsample_bytree': 0.46504849047463515, 'colsample_bynode': 0.12113302523710895, 'colsample_bylevel': 0.3543181531949175, 'min_child_weight': 4, 'reg_alpha': 19.96287226111088, 'reg_lambda': 70.7861565902793, 'gamma': 1.4111622357238602}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:16:06,274] Trial 74 finished with value: 0.10526558120148781 and parameters: {'max_depth': 6, 'learning_rate': 0.05688056709958754, 'subsample': 0.37736251549740446, 'colsample_bytree': 0.38433346117207023, 'colsample_bynode': 0.12116356976991795, 'colsample_bylevel': 0.3493154052216126, 'min_child_weight': 4, 'reg_alpha': 18.764225449337033, 'reg_lambda': 75.89179623533522, 'gamma': 1.395318626769824}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:16:22,524] Trial 75 finished with value: 0.10662771494726628 and parameters: {'max_depth': 6, 'learning_rate': 0.052561760605748555, 'subsample': 0.28196040526314914, 'colsample_bytree': 0.3715764947385246, 'colsample_bynode': 0.19619848715599492, 'colsample_bylevel': 0.3965568913394456, 'min_child_weight': 4, 'reg_alpha': 16.890063506879528, 'reg_lambda': 76.94053332585493, 'gamma': 1.7709874315464178}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:16:40,949] Trial 76 finished with value: 0.10912790606475425 and parameters: {'max_depth': 4, 'learning_rate': 0.04159920481030182, 'subsample': 0.5127548833505322, 'colsample_bytree': 0.5364085428448746, 'colsample_bynode': 0.2028561854575761, 'colsample_bylevel': 0.4066095650648275, 'min_child_weight': 3, 'reg_alpha': 32.62492999838517, 'reg_lambda': 59.65176691657658, 'gamma': 1.8298460983460383}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:17:00,826] Trial 77 finished with value: 0.10535145898271028 and parameters: {'max_depth': 5, 'learning_rate': 0.041508747851188514, 'subsample': 0.5051461099695075, 'colsample_bytree': 0.41665921014202256, 'colsample_bynode': 0.7757179405943446, 'colsample_bylevel': 0.46115476190433513, 'min_child_weight': 3, 'reg_alpha': 12.968623215791673, 'reg_lambda': 61.53589265845703, 'gamma': 2.056449815911301}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:17:27,687] Trial 78 finished with value: 0.0994483730018408 and parameters: {'max_depth': 5, 'learning_rate': 0.0022077127985070007, 'subsample': 0.6087333890124436, 'colsample_bytree': 0.4050304824648805, 'colsample_bynode': 0.8246411193479923, 'colsample_bylevel': 0.3009411405544324, 'min_child_weight': 3, 'reg_alpha': 62.234675339369176, 'reg_lambda': 73.78038475594253, 'gamma': 2.039521730536925}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:17:46,686] Trial 79 finished with value: 0.09920620175191897 and parameters: {'max_depth': 5, 'learning_rate': 0.002135640471161816, 'subsample': 0.13855485172388124, 'colsample_bytree': 0.606181047619131, 'colsample_bynode': 0.5874465539002636, 'colsample_bylevel': 0.3106558350042506, 'min_child_weight': 5, 'reg_alpha': 7.851152338505495, 'reg_lambda': 72.65655426359963, 'gamma': 2.817996302197997}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:17:58,590] Trial 80 finished with value: 0.1094690524095902 and parameters: {'max_depth': 7, 'learning_rate': 0.07032208771198883, 'subsample': 0.5468767895866206, 'colsample_bytree': 0.9785706310007154, 'colsample_bynode': 0.13973797959986806, 'colsample_bylevel': 0.2438053929067767, 'min_child_weight': 5, 'reg_alpha': 8.045887057652902, 'reg_lambda': 67.51319716150006, 'gamma': 2.545003136575555}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:18:16,074] Trial 81 finished with value: 0.10995625368112749 and parameters: {'max_depth': 7, 'learning_rate': 0.09117179613978595, 'subsample': 0.47541163118614777, 'colsample_bytree': 0.980682700562162, 'colsample_bynode': 0.15371804640117356, 'colsample_bylevel': 0.22771296435234395, 'min_child_weight': 6, 'reg_alpha': 24.85382181426654, 'reg_lambda': 48.11413651087477, 'gamma': 2.381042979445916}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:18:35,544] Trial 82 finished with value: 0.11266026320323455 and parameters: {'max_depth': 4, 'learning_rate': 0.026629374750514828, 'subsample': 0.6759068050308681, 'colsample_bytree': 0.5741410319636129, 'colsample_bynode': 0.1693110284817651, 'colsample_bylevel': 0.5108385595156493, 'min_child_weight': 4, 'reg_alpha': 25.61588995291507, 'reg_lambda': 80.4716489801524, 'gamma': 1.0697944671868527}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:18:55,950] Trial 83 finished with value: 0.10879545838017893 and parameters: {'max_depth': 4, 'learning_rate': 0.02534016321396101, 'subsample': 0.6700424376738392, 'colsample_bytree': 0.8550698615377756, 'colsample_bynode': 0.2568993867301587, 'colsample_bylevel': 0.5106653378822208, 'min_child_weight': 3, 'reg_alpha': 1.5701402776960744, 'reg_lambda': 79.67888105515732, 'gamma': 1.0031421030483372}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:19:15,111] Trial 84 finished with value: 0.11359867429858289 and parameters: {'max_depth': 4, 'learning_rate': 0.025264694440833946, 'subsample': 0.46240253535317605, 'colsample_bytree': 0.574277236616231, 'colsample_bynode': 0.18072880940959693, 'colsample_bylevel': 0.4355350321878858, 'min_child_weight': 4, 'reg_alpha': 20.90011508415897, 'reg_lambda': 79.27695875462727, 'gamma': 0.7967740496735695}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:19:27,040] Trial 85 finished with value: 0.10604427112529165 and parameters: {'max_depth': 4, 'learning_rate': 0.07422734531915814, 'subsample': 0.45980027546123736, 'colsample_bytree': 0.5817577681805277, 'colsample_bynode': 0.1849626412270104, 'colsample_bylevel': 0.45055597451507, 'min_child_weight': 4, 'reg_alpha': 35.80330774168053, 'reg_lambda': 78.66527007971462, 'gamma': 1.908626934206409}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:19:47,949] Trial 86 finished with value: 0.10461491560632431 and parameters: {'max_depth': 3, 'learning_rate': 0.07856114654247022, 'subsample': 0.45568450501485885, 'colsample_bytree': 0.5728889289876706, 'colsample_bynode': 0.18416454227161955, 'colsample_bylevel': 0.4458858270800909, 'min_child_weight': 4, 'reg_alpha': 34.37377899300637, 'reg_lambda': 89.10528782925219, 'gamma': 0.7394298936817026}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:20:01,502] Trial 87 finished with value: 0.10769766731580767 and parameters: {'max_depth': 3, 'learning_rate': 0.05109603179463421, 'subsample': 0.40310802496109216, 'colsample_bytree': 0.4926218126705946, 'colsample_bynode': 0.3104536349347419, 'colsample_bylevel': 0.382374251246658, 'min_child_weight': 4, 'reg_alpha': 33.32033976643302, 'reg_lambda': 63.162439389197715, 'gamma': 0.43011189714272424}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:20:13,226] Trial 88 finished with value: 0.10667442274287692 and parameters: {'max_depth': 3, 'learning_rate': 0.0522843368417007, 'subsample': 0.40269177175000087, 'colsample_bytree': 0.49043948581540847, 'colsample_bynode': 0.07099337301163514, 'colsample_bylevel': 0.42019878871611815, 'min_child_weight': 4, 'reg_alpha': 21.50410284966944, 'reg_lambda': 76.41626713445865, 'gamma': 2.9980155029997793}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:20:42,993] Trial 89 finished with value: 0.10650206350754847 and parameters: {'max_depth': 5, 'learning_rate': 0.09597516565227603, 'subsample': 0.23645607032925114, 'colsample_bytree': 0.9116836810853983, 'colsample_bynode': 0.06952739021970673, 'colsample_bylevel': 0.42186755579245655, 'min_child_weight': 6, 'reg_alpha': 20.87616782646466, 'reg_lambda': 74.79828967172315, 'gamma': 0.7145311637302467}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:20:45,308] Trial 90 finished with value: 0.10628929303848264 and parameters: {'max_depth': 5, 'learning_rate': 0.09136682556752801, 'subsample': 0.4380210308570228, 'colsample_bytree': 0.7132070685896897, 'colsample_bynode': 0.11013839570545456, 'colsample_bylevel': 0.1818224009200776, 'min_child_weight': 5, 'reg_alpha': 26.873823562943052, 'reg_lambda': 19.752221896008848, 'gamma': 1.5160589827595707}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:21:13,407] Trial 91 finished with value: 0.10810736496901219 and parameters: {'max_depth': 6, 'learning_rate': 0.06266176925000815, 'subsample': 0.33863713214586066, 'colsample_bytree': 0.3290699657156527, 'colsample_bynode': 0.4655797480098961, 'colsample_bylevel': 0.17623183973498174, 'min_child_weight': 5, 'reg_alpha': 26.340565702712844, 'reg_lambda': 67.24249437389744, 'gamma': 2.310262958926966}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:21:23,148] Trial 92 finished with value: 0.10848574876081327 and parameters: {'max_depth': 4, 'learning_rate': 0.02803272334897714, 'subsample': 0.7498231390435683, 'colsample_bytree': 0.5284262326056458, 'colsample_bynode': 0.16118289763144084, 'colsample_bylevel': 0.49702753569430086, 'min_child_weight': 4, 'reg_alpha': 24.355996730689256, 'reg_lambda': 80.16796414403504, 'gamma': 1.0362336608322023}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:21:51,732] Trial 93 finished with value: 0.11362411517673159 and parameters: {'max_depth': 4, 'learning_rate': 0.016942285820947502, 'subsample': 0.596600510581006, 'colsample_bytree': 0.5462507666249962, 'colsample_bynode': 0.16257106371650787, 'colsample_bylevel': 0.4734136399836996, 'min_child_weight': 9, 'reg_alpha': 15.89150174594745, 'reg_lambda': 10.127924761638205, 'gamma': 1.3359211566025406}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:22:02,169] Trial 94 finished with value: 0.10732509677876612 and parameters: {'max_depth': 4, 'learning_rate': 0.019011343999087507, 'subsample': 0.5936434237580626, 'colsample_bytree': 0.5454826607419065, 'colsample_bynode': 0.2190228609798443, 'colsample_bylevel': 0.4722696762760644, 'min_child_weight': 8, 'reg_alpha': 15.27432482293947, 'reg_lambda': 70.80927238368305, 'gamma': 1.6791812131442934}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:22:31,059] Trial 95 finished with value: 0.10743205811827454 and parameters: {'max_depth': 4, 'learning_rate': 0.033695864487711884, 'subsample': 0.5960823308336491, 'colsample_bytree': 0.7581139737822906, 'colsample_bynode': 0.13436737757541145, 'colsample_bylevel': 0.5631132930532018, 'min_child_weight': 9, 'reg_alpha': 13.811920363645836, 'reg_lambda': 13.484723279277622, 'gamma': 0.7861388348517908}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:22:34,052] Trial 96 finished with value: 0.11396059294453345 and parameters: {'max_depth': 3, 'learning_rate': 0.034283722583384434, 'subsample': 0.6211806856350235, 'colsample_bytree': 0.6233207878010242, 'colsample_bynode': 0.13348315398774926, 'colsample_bylevel': 0.26866096358146296, 'min_child_weight': 4, 'reg_alpha': 11.697248912771538, 'reg_lambda': 56.11006254894359, 'gamma': 0.8319585609434228}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:22:59,449] Trial 97 finished with value: 0.10215578398449307 and parameters: {'max_depth': 3, 'learning_rate': 0.02539468881161966, 'subsample': 0.6263116254838689, 'colsample_bytree': 0.5996908151413723, 'colsample_bynode': 0.11128647370529801, 'colsample_bylevel': 0.33890040059074034, 'min_child_weight': 2, 'reg_alpha': 10.46220589788366, 'reg_lambda': 12.790209287100176, 'gamma': 2.089994817643627}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:23:06,583] Trial 98 finished with value: 0.10495336070800537 and parameters: {'max_depth': 3, 'learning_rate': 0.019408525304606173, 'subsample': 0.6229910534016166, 'colsample_bytree': 0.6022448068779913, 'colsample_bynode': 0.10290511949679845, 'colsample_bylevel': 0.2699332899827948, 'min_child_weight': 9, 'reg_alpha': 9.301946749942202, 'reg_lambda': 89.02089199987745, 'gamma': 0.9819543746000277}. Best is trial 65 with value: 0.11776482837424804.\n",
      "[I 2025-07-02 21:23:31,522] Trial 99 finished with value: 0.10234139277441395 and parameters: {'max_depth': 3, 'learning_rate': 0.017689818430075617, 'subsample': 0.5127447595845949, 'colsample_bytree': 0.6476921761273978, 'colsample_bynode': 0.09012510167126828, 'colsample_bylevel': 0.14637170805798067, 'min_child_weight': 9, 'reg_alpha': 18.786349156159957, 'reg_lambda': 33.517115479697246, 'gamma': 0.5473210582618954}. Best is trial 65 with value: 0.11776482837424804.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 5, 'learning_rate': 0.06195449728524362, 'subsample': 0.5452663566957877, 'colsample_bytree': 0.510148572055214, 'colsample_bynode': 0.13546115445837226, 'colsample_bylevel': 0.41141839053052753, 'min_child_weight': 3, 'reg_alpha': 14.975314628896754, 'reg_lambda': 79.18273698704866, 'gamma': 1.9622610322138838}\n",
      "Best Pearson score: 0.11776482837424804\n"
     ]
    }
   ],
   "source": [
    "best_xgboost_params_common_truncated = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534cb1d",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c656479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 21:23:31,569] A new study created in RDB with name: lightgbm_2_4_101_2000_common_truncated_20_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for LightGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 21:24:57,916] Trial 1 finished with value: 0.09094418377879827 and parameters: {'max_depth': 7, 'learning_rate': 0.09875576000888552, 'num_leaves': 27, 'subsample': 0.27825402120937015, 'colsample_bytree': 0.37736564877132284, 'min_child_weight': 0.24448601907755185, 'reg_alpha': 27.786458788597056, 'reg_lambda': 4.907003547375943}. Best is trial 1 with value: 0.09094418377879827.\n",
      "[I 2025-07-02 21:26:03,417] Trial 2 finished with value: 0.10011680782995411 and parameters: {'max_depth': 5, 'learning_rate': 0.014270130590368076, 'num_leaves': 144, 'subsample': 0.9324459969079301, 'colsample_bytree': 0.11532164071570468, 'min_child_weight': 0.3750098968798342, 'reg_alpha': 78.25311387529233, 'reg_lambda': 78.22128588750084}. Best is trial 2 with value: 0.10011680782995411.\n",
      "[I 2025-07-02 21:26:33,651] Trial 3 finished with value: 0.07995473240348837 and parameters: {'max_depth': 3, 'learning_rate': 0.054410927207001504, 'num_leaves': 756, 'subsample': 0.28864165129980396, 'colsample_bytree': 0.9552196922985892, 'min_child_weight': 0.41005447889575775, 'reg_alpha': 37.493297890342866, 'reg_lambda': 40.845486340162694}. Best is trial 2 with value: 0.10011680782995411.\n",
      "[I 2025-07-02 21:30:51,129] Trial 0 finished with value: 0.08805825788871516 and parameters: {'max_depth': 10, 'learning_rate': 0.03710642876308968, 'num_leaves': 549, 'subsample': 0.663523828560818, 'colsample_bytree': 0.7549115757356883, 'min_child_weight': 0.8647413359948042, 'reg_alpha': 28.140016428334256, 'reg_lambda': 71.21313785825618}. Best is trial 2 with value: 0.10011680782995411.\n",
      "[I 2025-07-02 21:31:35,098] Trial 4 finished with value: 0.0865830895195881 and parameters: {'max_depth': 9, 'learning_rate': 0.021607792605050493, 'num_leaves': 286, 'subsample': 0.6295141930369634, 'colsample_bytree': 0.20092597995907313, 'min_child_weight': 0.47235266803419906, 'reg_alpha': 49.73369348114228, 'reg_lambda': 3.8803672238682863}. Best is trial 2 with value: 0.10011680782995411.\n",
      "[I 2025-07-02 21:33:43,554] Trial 6 finished with value: 0.09344379737054977 and parameters: {'max_depth': 9, 'learning_rate': 0.09963253567445263, 'num_leaves': 754, 'subsample': 0.5813871401829998, 'colsample_bytree': 0.05877211225261751, 'min_child_weight': 0.19537651277576384, 'reg_alpha': 87.33878170743957, 'reg_lambda': 36.374587836765635}. Best is trial 2 with value: 0.10011680782995411.\n",
      "[I 2025-07-02 21:40:49,029] Trial 5 finished with value: 0.09150686035420598 and parameters: {'max_depth': 10, 'learning_rate': 0.005822325196396254, 'num_leaves': 501, 'subsample': 0.951690092078987, 'colsample_bytree': 0.6255777114634276, 'min_child_weight': 0.6602169295945644, 'reg_alpha': 26.570354114053508, 'reg_lambda': 73.94503860745554}. Best is trial 2 with value: 0.10011680782995411.\n",
      "[I 2025-07-02 21:41:17,820] Trial 7 finished with value: 0.08731497848753456 and parameters: {'max_depth': 9, 'learning_rate': 0.0013773543785240365, 'num_leaves': 716, 'subsample': 0.6584784822089672, 'colsample_bytree': 0.4039948799001058, 'min_child_weight': 0.08989854066387482, 'reg_alpha': 49.34928826975936, 'reg_lambda': 58.73203351890483}. Best is trial 2 with value: 0.10011680782995411.\n",
      "[I 2025-07-02 21:43:21,932] Trial 8 finished with value: 0.08462950065397264 and parameters: {'max_depth': 10, 'learning_rate': 0.002256860538579473, 'num_leaves': 52, 'subsample': 0.7789705895399549, 'colsample_bytree': 0.6499864953236244, 'min_child_weight': 0.9313399972705125, 'reg_alpha': 83.89590695127083, 'reg_lambda': 41.90359988503919}. Best is trial 2 with value: 0.10011680782995411.\n",
      "[I 2025-07-02 21:45:32,267] Trial 10 finished with value: 0.09094516138921349 and parameters: {'max_depth': 6, 'learning_rate': 0.0044280355570544775, 'num_leaves': 294, 'subsample': 0.6082244507034271, 'colsample_bytree': 0.5698324376364688, 'min_child_weight': 0.2663809988095719, 'reg_alpha': 66.15757392513208, 'reg_lambda': 66.52104319907421}. Best is trial 2 with value: 0.10011680782995411.\n",
      "[I 2025-07-02 21:45:49,668] Trial 11 finished with value: 0.10069245591182832 and parameters: {'max_depth': 2, 'learning_rate': 0.014682819238525534, 'num_leaves': 976, 'subsample': 0.05306216811848058, 'colsample_bytree': 0.2097166349040313, 'min_child_weight': 0.6763918627214341, 'reg_alpha': 99.46587806053006, 'reg_lambda': 90.43676865399966}. Best is trial 11 with value: 0.10069245591182832.\n",
      "[I 2025-07-02 21:46:06,247] Trial 12 finished with value: 0.09502571032733949 and parameters: {'max_depth': 2, 'learning_rate': 0.013975740074790929, 'num_leaves': 1008, 'subsample': 0.055693773545455495, 'colsample_bytree': 0.1667107778728786, 'min_child_weight': 0.6450302323055621, 'reg_alpha': 98.79484229431522, 'reg_lambda': 94.57733155813197}. Best is trial 11 with value: 0.10069245591182832.\n",
      "[I 2025-07-02 21:46:53,145] Trial 13 finished with value: 0.09244198285698624 and parameters: {'max_depth': 4, 'learning_rate': 0.00929590303303349, 'num_leaves': 1004, 'subsample': 0.9596214798864304, 'colsample_bytree': 0.29389157638818497, 'min_child_weight': 0.6677988832113578, 'reg_alpha': 5.275042001609705, 'reg_lambda': 99.49713636102953}. Best is trial 11 with value: 0.10069245591182832.\n",
      "[I 2025-07-02 21:48:00,252] Trial 14 finished with value: 0.10081462093369947 and parameters: {'max_depth': 5, 'learning_rate': 0.02110153934671178, 'num_leaves': 231, 'subsample': 0.34347012856012793, 'colsample_bytree': 0.08585462198369209, 'min_child_weight': 0.7894838723692186, 'reg_alpha': 71.81796297724492, 'reg_lambda': 85.23756297652163}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:48:18,283] Trial 15 finished with value: 0.09792434260561753 and parameters: {'max_depth': 2, 'learning_rate': 0.03203016944850082, 'num_leaves': 367, 'subsample': 0.33246251925747816, 'colsample_bytree': 0.2791245158074952, 'min_child_weight': 0.7766865601674746, 'reg_alpha': 66.51842679545496, 'reg_lambda': 88.9961047055664}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:49:07,395] Trial 16 finished with value: 0.09033235120032584 and parameters: {'max_depth': 4, 'learning_rate': 0.006195215761119682, 'num_leaves': 597, 'subsample': 0.0755546841812208, 'colsample_bytree': 0.45027509915571806, 'min_child_weight': 0.9872161812757619, 'reg_alpha': 97.44700498992715, 'reg_lambda': 83.69145914352788}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:50:50,579] Trial 17 finished with value: 0.09624569100961611 and parameters: {'max_depth': 6, 'learning_rate': 0.019820305965132273, 'num_leaves': 859, 'subsample': 0.4320794157647211, 'colsample_bytree': 0.06036711179603706, 'min_child_weight': 0.5740762703928727, 'reg_alpha': 69.58001060723896, 'reg_lambda': 54.32538038657931}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:51:28,965] Trial 9 finished with value: 0.09054431220860477 and parameters: {'max_depth': 10, 'learning_rate': 0.010696130441887067, 'num_leaves': 310, 'subsample': 0.57686852847375, 'colsample_bytree': 0.504906230412577, 'min_child_weight': 0.678575067119537, 'reg_alpha': 43.95595023684915, 'reg_lambda': 42.070154626466724}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:51:36,280] Trial 18 finished with value: 0.09430296427586876 and parameters: {'max_depth': 4, 'learning_rate': 0.009184854860824862, 'num_leaves': 437, 'subsample': 0.16680884707870594, 'colsample_bytree': 0.22516072488329486, 'min_child_weight': 0.783633328549394, 'reg_alpha': 75.42266992599983, 'reg_lambda': 25.81573021459141}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:54:41,926] Trial 20 finished with value: 0.09340264455352126 and parameters: {'max_depth': 7, 'learning_rate': 0.04612369658757372, 'num_leaves': 207, 'subsample': 0.43619164318828735, 'colsample_bytree': 0.349261995284931, 'min_child_weight': 0.7969257705636605, 'reg_alpha': 59.78016107160728, 'reg_lambda': 86.09601467211321}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:54:49,903] Trial 19 finished with value: 0.0938421293290147 and parameters: {'max_depth': 7, 'learning_rate': 0.0033422233584123238, 'num_leaves': 434, 'subsample': 0.17674659756989972, 'colsample_bytree': 0.26907276129096824, 'min_child_weight': 0.7880497442650644, 'reg_alpha': 59.50570472757542, 'reg_lambda': 21.391979888947795}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:55:13,467] Trial 21 finished with value: 0.07452088985452071 and parameters: {'max_depth': 3, 'learning_rate': 0.00349240235124219, 'num_leaves': 898, 'subsample': 0.19549882484253803, 'colsample_bytree': 0.8705551420303479, 'min_child_weight': 0.5424149605943498, 'reg_alpha': 91.9523273421095, 'reg_lambda': 64.06906939411815}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:55:53,007] Trial 22 finished with value: 0.09568208187540914 and parameters: {'max_depth': 5, 'learning_rate': 0.018457864076800293, 'num_leaves': 173, 'subsample': 0.8210792238714499, 'colsample_bytree': 0.13443991530317836, 'min_child_weight': 0.3708880293919083, 'reg_alpha': 83.18469240348138, 'reg_lambda': 77.26615609156426}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:56:16,609] Trial 23 finished with value: 0.09605649677201908 and parameters: {'max_depth': 5, 'learning_rate': 0.01909101658572069, 'num_leaves': 164, 'subsample': 0.4540299392086499, 'colsample_bytree': 0.13416939168912387, 'min_child_weight': 0.40978385208176266, 'reg_alpha': 78.94659400938392, 'reg_lambda': 79.51672394996996}. Best is trial 14 with value: 0.10081462093369947.\n",
      "[I 2025-07-02 21:56:57,986] Trial 24 finished with value: 0.10276521614055886 and parameters: {'max_depth': 5, 'learning_rate': 0.026001147556285104, 'num_leaves': 136, 'subsample': 0.44080381199894814, 'colsample_bytree': 0.12162518897571328, 'min_child_weight': 0.3447478383830984, 'reg_alpha': 78.53672987479898, 'reg_lambda': 79.91409782228745}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 21:57:20,937] Trial 25 finished with value: 0.09480638668500528 and parameters: {'max_depth': 5, 'learning_rate': 0.029887027921959256, 'num_leaves': 142, 'subsample': 0.7819166750969857, 'colsample_bytree': 0.06411041642956788, 'min_child_weight': 0.032804922379164214, 'reg_alpha': 90.93169396883579, 'reg_lambda': 91.93013594960652}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 21:57:23,028] Trial 26 finished with value: 0.09533947657847536 and parameters: {'max_depth': 3, 'learning_rate': 0.029292252598643053, 'num_leaves': 630, 'subsample': 0.35369848688333383, 'colsample_bytree': 0.06254086920701507, 'min_child_weight': 0.5767658907367598, 'reg_alpha': 90.24649651511163, 'reg_lambda': 94.98854194001576}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 21:57:47,654] Trial 27 finished with value: 0.09380284643400573 and parameters: {'max_depth': 3, 'learning_rate': 0.06057939028191787, 'num_leaves': 644, 'subsample': 0.3759527549196591, 'colsample_bytree': 0.2105367825085123, 'min_child_weight': 0.5854324627143526, 'reg_alpha': 72.52223232045654, 'reg_lambda': 99.87066346119437}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 21:58:50,257] Trial 29 finished with value: 0.09415874851025065 and parameters: {'max_depth': 6, 'learning_rate': 0.013205746219525676, 'num_leaves': 18, 'subsample': 0.5062783816201555, 'colsample_bytree': 0.2940517271115467, 'min_child_weight': 0.8842745206538624, 'reg_alpha': 58.235602190341396, 'reg_lambda': 84.15791099972782}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 21:59:09,025] Trial 28 finished with value: 0.09601578924071827 and parameters: {'max_depth': 6, 'learning_rate': 0.07083682895312311, 'num_leaves': 79, 'subsample': 0.5173932947742661, 'colsample_bytree': 0.22206264242157647, 'min_child_weight': 0.8590537096961864, 'reg_alpha': 72.43372136388041, 'reg_lambda': 65.9084122971256}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:00:54,993] Trial 30 finished with value: 0.08889367580398358 and parameters: {'max_depth': 8, 'learning_rate': 0.04489273561707197, 'num_leaves': 496, 'subsample': 0.24633353574024033, 'colsample_bytree': 0.7226704911824977, 'min_child_weight': 0.4661455680514518, 'reg_alpha': 98.26227365384264, 'reg_lambda': 61.93820030778909}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:01:57,255] Trial 32 finished with value: 0.09747170589751158 and parameters: {'max_depth': 5, 'learning_rate': 0.013234395542750698, 'num_leaves': 237, 'subsample': 0.7221371784290256, 'colsample_bytree': 0.13349690781329668, 'min_child_weight': 0.3394486110935697, 'reg_alpha': 80.54138896074352, 'reg_lambda': 71.83259154155948}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:02:19,751] Trial 31 finished with value: 0.09178306654024146 and parameters: {'max_depth': 8, 'learning_rate': 0.0394173562134802, 'num_leaves': 226, 'subsample': 0.24315146573513757, 'colsample_bytree': 0.14311339260175987, 'min_child_weight': 0.485410960775724, 'reg_alpha': 98.36472131797042, 'reg_lambda': 73.38751075840503}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:02:36,897] Trial 33 finished with value: 0.10011961573160322 and parameters: {'max_depth': 4, 'learning_rate': 0.025184128544785432, 'num_leaves': 106, 'subsample': 0.11111977811929902, 'colsample_bytree': 0.11917823067764698, 'min_child_weight': 0.30176133174627295, 'reg_alpha': 75.0732093127225, 'reg_lambda': 79.28348692378977}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:03:06,798] Trial 34 finished with value: 0.09274542183999424 and parameters: {'max_depth': 4, 'learning_rate': 0.024758568460141798, 'num_leaves': 94, 'subsample': 0.8988533580228595, 'colsample_bytree': 0.3487792860788751, 'min_child_weight': 0.3088670461815527, 'reg_alpha': 77.6562897317773, 'reg_lambda': 82.93853859551312}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:03:18,197] Trial 36 finished with value: 0.0913103467021751 and parameters: {'max_depth': 2, 'learning_rate': 0.025002411784971097, 'num_leaves': 2, 'subsample': 0.10981444131037348, 'colsample_bytree': 0.1005548475302005, 'min_child_weight': 0.17761034205729298, 'reg_alpha': 54.75744570008527, 'reg_lambda': 79.24362494081366}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:03:24,355] Trial 35 finished with value: 0.0931002022060773 and parameters: {'max_depth': 4, 'learning_rate': 0.02487409789368171, 'num_leaves': 105, 'subsample': 0.13643031511936415, 'colsample_bytree': 0.33245877790295186, 'min_child_weight': 0.2652420160909854, 'reg_alpha': 66.05157781755976, 'reg_lambda': 87.8692939365244}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:03:51,512] Trial 38 finished with value: 0.09393046521385134 and parameters: {'max_depth': 3, 'learning_rate': 0.007082845418573657, 'num_leaves': 362, 'subsample': 0.27279999958044365, 'colsample_bytree': 0.1824927025763794, 'min_child_weight': 0.1970515756653775, 'reg_alpha': 87.15868466025096, 'reg_lambda': 70.86067105745994}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:04:02,544] Trial 37 finished with value: 0.09516601670399746 and parameters: {'max_depth': 4, 'learning_rate': 0.01651919353337672, 'num_leaves': 360, 'subsample': 0.12871623404359628, 'colsample_bytree': 0.17837421088024952, 'min_child_weight': 0.7311398718187152, 'reg_alpha': 84.52447722563907, 'reg_lambda': 89.98800108021575}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:05:10,817] Trial 39 finished with value: 0.09215870392784661 and parameters: {'max_depth': 5, 'learning_rate': 0.01736741638489315, 'num_leaves': 257, 'subsample': 0.3103405700776387, 'colsample_bytree': 0.42420032300177574, 'min_child_weight': 0.7267551394405746, 'reg_alpha': 21.620363203090584, 'reg_lambda': 53.976083091479694}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:06:27,408] Trial 40 finished with value: 0.09261358649385293 and parameters: {'max_depth': 7, 'learning_rate': 0.07742297500422121, 'num_leaves': 265, 'subsample': 0.2167031284468143, 'colsample_bytree': 0.43876706462601595, 'min_child_weight': 0.43139199641211634, 'reg_alpha': 41.76493205659574, 'reg_lambda': 51.40259180138553}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:07:36,323] Trial 42 finished with value: 0.0968977093960494 and parameters: {'max_depth': 5, 'learning_rate': 0.010787932650791608, 'num_leaves': 126, 'subsample': 0.3746920576334122, 'colsample_bytree': 0.09805969563434916, 'min_child_weight': 0.3804637264040279, 'reg_alpha': 74.41712479291381, 'reg_lambda': 69.43300982353227}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:07:59,229] Trial 41 finished with value: 0.08059732258795936 and parameters: {'max_depth': 7, 'learning_rate': 0.08075750508232485, 'num_leaves': 852, 'subsample': 0.3834809273871472, 'colsample_bytree': 0.2427726864558043, 'min_child_weight': 0.44526989186536886, 'reg_alpha': 38.969287139946914, 'reg_lambda': 13.078274237190037}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:09:37,269] Trial 43 finished with value: 0.08952438567140668 and parameters: {'max_depth': 6, 'learning_rate': 0.0375369473121868, 'num_leaves': 55, 'subsample': 0.5591273403378094, 'colsample_bytree': 0.24046255344707254, 'min_child_weight': 0.31236324455941444, 'reg_alpha': 67.72118391401216, 'reg_lambda': 75.7190446977063}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:09:38,263] Trial 44 finished with value: 0.09953251578270286 and parameters: {'max_depth': 6, 'learning_rate': 0.015060111407621101, 'num_leaves': 68, 'subsample': 0.4922094172818432, 'colsample_bytree': 0.11158855845954924, 'min_child_weight': 0.315209065872183, 'reg_alpha': 93.1868952891179, 'reg_lambda': 77.38638078251623}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:10:03,730] Trial 46 finished with value: 0.09239698091487754 and parameters: {'max_depth': 3, 'learning_rate': 0.007935577785696325, 'num_leaves': 186, 'subsample': 0.6815987779297009, 'colsample_bytree': 0.17306776961969433, 'min_child_weight': 0.1429319066736222, 'reg_alpha': 63.184609866450444, 'reg_lambda': 95.85165069623636}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:10:43,622] Trial 45 finished with value: 0.09562534094641606 and parameters: {'max_depth': 5, 'learning_rate': 0.014064363031505694, 'num_leaves': 170, 'subsample': 0.08483505496877403, 'colsample_bytree': 0.09845817741134638, 'min_child_weight': 0.1526403641677305, 'reg_alpha': 93.7478282043474, 'reg_lambda': 80.00898172861416}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:11:05,025] Trial 48 finished with value: 0.050045804614319636 and parameters: {'max_depth': 2, 'learning_rate': 0.0010899770322037438, 'num_leaves': 692, 'subsample': 0.9982120888234391, 'colsample_bytree': 0.9554208672754481, 'min_child_weight': 0.6294266477222478, 'reg_alpha': 48.24003778697909, 'reg_lambda': 60.57474518352754}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:11:16,088] Trial 47 finished with value: 0.09830848017968308 and parameters: {'max_depth': 5, 'learning_rate': 0.010820655176733609, 'num_leaves': 319, 'subsample': 0.08782634723600488, 'colsample_bytree': 0.09295268329815833, 'min_child_weight': 0.5337422124341342, 'reg_alpha': 49.034093425077884, 'reg_lambda': 81.052375664625}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:11:43,915] Trial 49 finished with value: 0.10041787584827691 and parameters: {'max_depth': 4, 'learning_rate': 0.022941880201095975, 'num_leaves': 328, 'subsample': 0.2858919474278919, 'colsample_bytree': 0.05126733619525189, 'min_child_weight': 0.2241345508893797, 'reg_alpha': 81.07933261034339, 'reg_lambda': 45.057253442711534}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:11:55,845] Trial 50 finished with value: 0.0998317115249648 and parameters: {'max_depth': 4, 'learning_rate': 0.022071793263401505, 'num_leaves': 547, 'subsample': 0.15349519670059855, 'colsample_bytree': 0.052126034152070275, 'min_child_weight': 0.23953645980464558, 'reg_alpha': 81.55930464689308, 'reg_lambda': 47.225002403246606}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:12:34,750] Trial 51 finished with value: 0.08869661394993786 and parameters: {'max_depth': 4, 'learning_rate': 0.022628346419852015, 'num_leaves': 428, 'subsample': 0.2905415247749039, 'colsample_bytree': 0.5157458945927841, 'min_child_weight': 0.2274992631484992, 'reg_alpha': 82.48159011802655, 'reg_lambda': 45.55428231337301}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:12:39,606] Trial 52 finished with value: 0.09783059002163888 and parameters: {'max_depth': 4, 'learning_rate': 0.0319657369088644, 'num_leaves': 421, 'subsample': 0.2884001262939476, 'colsample_bytree': 0.15654521219630324, 'min_child_weight': 0.22769692908389066, 'reg_alpha': 85.90633985673878, 'reg_lambda': 38.427227628164985}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:13:05,339] Trial 54 finished with value: 0.09450363438932285 and parameters: {'max_depth': 3, 'learning_rate': 0.011351661503805092, 'num_leaves': 309, 'subsample': 0.3990822283416989, 'colsample_bytree': 0.19838975836804673, 'min_child_weight': 0.36158069401507176, 'reg_alpha': 76.66780213274306, 'reg_lambda': 91.12721836794215}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:13:15,755] Trial 53 finished with value: 0.09493256664946205 and parameters: {'max_depth': 4, 'learning_rate': 0.03314135909854095, 'num_leaves': 314, 'subsample': 0.41004057038818853, 'colsample_bytree': 0.15433662630489697, 'min_child_weight': 0.3743554997666202, 'reg_alpha': 87.13083227131906, 'reg_lambda': 32.658273077322946}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:14:12,124] Trial 55 finished with value: 0.0988113705069145 and parameters: {'max_depth': 5, 'learning_rate': 0.04912169892530341, 'num_leaves': 123, 'subsample': 0.47173436992521617, 'colsample_bytree': 0.12610489550523188, 'min_child_weight': 0.10429275916521241, 'reg_alpha': 70.47135966168496, 'reg_lambda': 33.34034470756905}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:14:35,535] Trial 56 finished with value: 0.08209770578602191 and parameters: {'max_depth': 5, 'learning_rate': 0.05060536508573068, 'num_leaves': 205, 'subsample': 0.4575183844025374, 'colsample_bytree': 0.87689261683022, 'min_child_weight': 0.28331820828195015, 'reg_alpha': 69.99560327732334, 'reg_lambda': 32.644437494455715}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:14:59,286] Trial 58 finished with value: 0.09061576006500334 and parameters: {'max_depth': 2, 'learning_rate': 0.02702687638782721, 'num_leaves': 942, 'subsample': 0.05566621449758567, 'colsample_bytree': 0.5837163260041851, 'min_child_weight': 0.8310764820882133, 'reg_alpha': 32.27694826656235, 'reg_lambda': 86.52237808290948}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:16:03,543] Trial 57 finished with value: 0.09619147069934444 and parameters: {'max_depth': 6, 'learning_rate': 0.0275406530436691, 'num_leaves': 143, 'subsample': 0.20819146698605617, 'colsample_bytree': 0.0813308054545149, 'min_child_weight': 0.29705267982551575, 'reg_alpha': 62.19244139964243, 'reg_lambda': 57.09390458052675}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:16:30,988] Trial 60 finished with value: 0.09352521601415051 and parameters: {'max_depth': 3, 'learning_rate': 0.018151765945200436, 'num_leaves': 45, 'subsample': 0.34018723035815995, 'colsample_bytree': 0.25058252530907865, 'min_child_weight': 0.9305227411191295, 'reg_alpha': 94.88370715714505, 'reg_lambda': 68.02847824227419}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:16:35,870] Trial 59 finished with value: 0.09877401069314429 and parameters: {'max_depth': 6, 'learning_rate': 0.020292005292600744, 'num_leaves': 151, 'subsample': 0.20787789242251875, 'colsample_bytree': 0.05057019699771517, 'min_child_weight': 0.7186103247372613, 'reg_alpha': 78.58755473131708, 'reg_lambda': 68.82523110126307}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:17:15,517] Trial 62 finished with value: 0.09825473462519474 and parameters: {'max_depth': 4, 'learning_rate': 0.021620123828941604, 'num_leaves': 769, 'subsample': 0.15813288612169424, 'colsample_bytree': 0.05410884149514594, 'min_child_weight': 0.2506730479982226, 'reg_alpha': 89.59212374692771, 'reg_lambda': 45.32092721539844}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:17:33,993] Trial 61 finished with value: 0.09563651868882207 and parameters: {'max_depth': 5, 'learning_rate': 0.00556081320323567, 'num_leaves': 795, 'subsample': 0.6364732983461863, 'colsample_bytree': 0.051669384992953885, 'min_child_weight': 0.714556402268894, 'reg_alpha': 74.78602251024448, 'reg_lambda': 0.20261938322227735}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:17:56,733] Trial 63 finished with value: 0.09997751853637422 and parameters: {'max_depth': 4, 'learning_rate': 0.016233105432765384, 'num_leaves': 583, 'subsample': 0.1552057915772993, 'colsample_bytree': 0.0779945946453145, 'min_child_weight': 0.416272917250956, 'reg_alpha': 81.42031593117379, 'reg_lambda': 47.061626396683955}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:18:14,333] Trial 64 finished with value: 0.09878733567913794 and parameters: {'max_depth': 4, 'learning_rate': 0.01614259659289399, 'num_leaves': 513, 'subsample': 0.15661643143373932, 'colsample_bytree': 0.13297658450144334, 'min_child_weight': 0.3388015505855536, 'reg_alpha': 81.48401287273822, 'reg_lambda': 43.53091884205319}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:18:22,061] Trial 65 finished with value: 0.0961007713377322 and parameters: {'max_depth': 3, 'learning_rate': 0.01549481599011781, 'num_leaves': 957, 'subsample': 0.11525962613560276, 'colsample_bytree': 0.20179243959128856, 'min_child_weight': 0.5162022349651815, 'reg_alpha': 79.93140036044636, 'reg_lambda': 41.61173372196293}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:19:18,568] Trial 66 finished with value: 0.09623720347385967 and parameters: {'max_depth': 5, 'learning_rate': 0.012381149439469812, 'num_leaves': 214, 'subsample': 0.5549646071869722, 'colsample_bytree': 0.19947261834782465, 'min_child_weight': 0.5251650870096369, 'reg_alpha': 72.22954688362927, 'reg_lambda': 96.04581359766352}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:19:30,506] Trial 67 finished with value: 0.1001988126264871 and parameters: {'max_depth': 5, 'learning_rate': 0.012213557971199232, 'num_leaves': 219, 'subsample': 0.8621621204751253, 'colsample_bytree': 0.08817058149975714, 'min_child_weight': 0.3955533372350768, 'reg_alpha': 53.32449252294805, 'reg_lambda': 49.45662878779343}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:19:59,710] Trial 68 finished with value: 0.0996482418984844 and parameters: {'max_depth': 4, 'learning_rate': 0.041267852159677605, 'num_leaves': 266, 'subsample': 0.056093816813739164, 'colsample_bytree': 0.08768518163186155, 'min_child_weight': 0.40615803371078396, 'reg_alpha': 56.535331875065445, 'reg_lambda': 73.85318660711155}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:21:16,609] Trial 70 finished with value: 0.09512766108875605 and parameters: {'max_depth': 5, 'learning_rate': 0.009740981058245278, 'num_leaves': 99, 'subsample': 0.8883781999423597, 'colsample_bytree': 0.3208497025788154, 'min_child_weight': 0.45643850589201496, 'reg_alpha': 52.64203888230954, 'reg_lambda': 84.9874873059328}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:21:38,074] Trial 69 finished with value: 0.09652642875173041 and parameters: {'max_depth': 6, 'learning_rate': 0.010035384806247933, 'num_leaves': 282, 'subsample': 0.8923592039344487, 'colsample_bytree': 0.47907916795882843, 'min_child_weight': 0.3407989331105432, 'reg_alpha': 53.71206838344455, 'reg_lambda': 50.46033131452933}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:22:41,469] Trial 72 finished with value: 0.09877406627119617 and parameters: {'max_depth': 5, 'learning_rate': 0.01929683921340286, 'num_leaves': 191, 'subsample': 0.8439420309649491, 'colsample_bytree': 0.1255084341811954, 'min_child_weight': 0.3829307945051253, 'reg_alpha': 63.32453552419453, 'reg_lambda': 55.22276416484844}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:23:24,756] Trial 73 finished with value: 0.09552347683741785 and parameters: {'max_depth': 4, 'learning_rate': 0.007984075654656751, 'num_leaves': 231, 'subsample': 0.251549663981121, 'colsample_bytree': 0.1659025196516091, 'min_child_weight': 0.42137151509710685, 'reg_alpha': 8.857966692500476, 'reg_lambda': 36.849491158648505}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:23:30,708] Trial 71 finished with value: 0.09532972316967324 and parameters: {'max_depth': 6, 'learning_rate': 0.019771327870923238, 'num_leaves': 389, 'subsample': 0.9107384026503791, 'colsample_bytree': 0.3818856309548838, 'min_child_weight': 0.6208646501799201, 'reg_alpha': 13.637823973504325, 'reg_lambda': 91.46944283244318}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:24:32,296] Trial 74 finished with value: 0.09788306509399204 and parameters: {'max_depth': 5, 'learning_rate': 0.017132699385891167, 'num_leaves': 596, 'subsample': 0.9372066674615978, 'colsample_bytree': 0.08536061550728223, 'min_child_weight': 0.481116098932156, 'reg_alpha': 89.01560963166692, 'reg_lambda': 91.66069630234229}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:24:37,469] Trial 75 finished with value: 0.09793130952844814 and parameters: {'max_depth': 5, 'learning_rate': 0.01223925852753017, 'num_leaves': 471, 'subsample': 0.9371769658005198, 'colsample_bytree': 0.08513315356532968, 'min_child_weight': 0.40559860288482674, 'reg_alpha': 88.78212986303599, 'reg_lambda': 48.91693380339287}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:25:01,979] Trial 77 finished with value: 0.10185877978340989 and parameters: {'max_depth': 3, 'learning_rate': 0.03461494734337024, 'num_leaves': 119, 'subsample': 0.18561876486987225, 'colsample_bytree': 0.11245305895392504, 'min_child_weight': 0.28243180534607093, 'reg_alpha': 66.96702642213788, 'reg_lambda': 82.56348557135891}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:25:11,584] Trial 76 finished with value: 0.10245403534640254 and parameters: {'max_depth': 4, 'learning_rate': 0.012419730549482618, 'num_leaves': 475, 'subsample': 0.8427836343897418, 'colsample_bytree': 0.11305945045453455, 'min_child_weight': 0.39613078866681656, 'reg_alpha': 74.90039226907908, 'reg_lambda': 82.62079990745221}. Best is trial 24 with value: 0.10276521614055886.\n",
      "[I 2025-07-02 22:25:17,863] Trial 78 finished with value: 0.10480921921355155 and parameters: {'max_depth': 2, 'learning_rate': 0.056711401259453356, 'num_leaves': 123, 'subsample': 0.8200489647607984, 'colsample_bytree': 0.11588882938965726, 'min_child_weight': 0.20376561214352829, 'reg_alpha': 68.3674164440674, 'reg_lambda': 81.76767052052783}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:25:28,356] Trial 79 finished with value: 0.10027183985965803 and parameters: {'max_depth': 2, 'learning_rate': 0.033366117638526524, 'num_leaves': 117, 'subsample': 0.8064137997372326, 'colsample_bytree': 0.14785538831868958, 'min_child_weight': 0.19267926914980266, 'reg_alpha': 67.40750854936871, 'reg_lambda': 83.52925183602461}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:25:34,870] Trial 80 finished with value: 0.10084134936670104 and parameters: {'max_depth': 2, 'learning_rate': 0.03472639523002267, 'num_leaves': 331, 'subsample': 0.7481941656217918, 'colsample_bytree': 0.1597640236399266, 'min_child_weight': 0.028243384837246865, 'reg_alpha': 67.78125591545098, 'reg_lambda': 82.89876555526496}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:25:45,017] Trial 81 finished with value: 0.09874171196748002 and parameters: {'max_depth': 2, 'learning_rate': 0.06039725896576676, 'num_leaves': 38, 'subsample': 0.7435024484616967, 'colsample_bytree': 0.14854230971006477, 'min_child_weight': 0.07498951293864584, 'reg_alpha': 66.9694139442037, 'reg_lambda': 81.83557493319007}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:25:52,467] Trial 82 finished with value: 0.09848848632412173 and parameters: {'max_depth': 2, 'learning_rate': 0.05821026225206923, 'num_leaves': 342, 'subsample': 0.793653399519138, 'colsample_bytree': 0.16111707892276186, 'min_child_weight': 0.026792081594131434, 'reg_alpha': 67.23126608636657, 'reg_lambda': 83.20436186827426}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:26:03,110] Trial 83 finished with value: 0.10192422218780176 and parameters: {'max_depth': 2, 'learning_rate': 0.036729873833683396, 'num_leaves': 341, 'subsample': 0.7991019275163934, 'colsample_bytree': 0.17777856623762348, 'min_child_weight': 0.032937282186880634, 'reg_alpha': 60.75564346909101, 'reg_lambda': 83.99237442899387}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:26:11,780] Trial 84 finished with value: 0.09974858171968497 and parameters: {'max_depth': 2, 'learning_rate': 0.034972608814053265, 'num_leaves': 80, 'subsample': 0.8181388923099372, 'colsample_bytree': 0.2688981376471445, 'min_child_weight': 0.20761593980956677, 'reg_alpha': 60.50732524050738, 'reg_lambda': 75.7320099704071}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:26:22,652] Trial 85 finished with value: 0.09555865302051118 and parameters: {'max_depth': 2, 'learning_rate': 0.04272302572661467, 'num_leaves': 480, 'subsample': 0.7706661366908902, 'colsample_bytree': 0.27021609560118715, 'min_child_weight': 0.07857975503035569, 'reg_alpha': 62.10070099484503, 'reg_lambda': 88.00361133911602}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:26:40,280] Trial 86 finished with value: 0.09403364686855464 and parameters: {'max_depth': 3, 'learning_rate': 0.04318423322760657, 'num_leaves': 398, 'subsample': 0.7369442235957021, 'colsample_bytree': 0.2282494293025297, 'min_child_weight': 0.05193051421973914, 'reg_alpha': 72.66417616822945, 'reg_lambda': 87.79251711679801}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:26:50,581] Trial 87 finished with value: 0.08976817756264527 and parameters: {'max_depth': 3, 'learning_rate': 0.029035516932932444, 'num_leaves': 401, 'subsample': 0.7193188098629133, 'colsample_bytree': 0.2215969218482477, 'min_child_weight': 0.05238096141837159, 'reg_alpha': 71.61475916731118, 'reg_lambda': 93.94563725853578}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:26:57,558] Trial 88 finished with value: 0.10306904025652733 and parameters: {'max_depth': 2, 'learning_rate': 0.03698764647269775, 'num_leaves': 456, 'subsample': 0.8454637926880542, 'colsample_bytree': 0.17867467780597115, 'min_child_weight': 0.003818337887009731, 'reg_alpha': 64.10727396166926, 'reg_lambda': 93.46735381227842}. Best is trial 78 with value: 0.10480921921355155.\n",
      "[I 2025-07-02 22:27:06,906] Trial 89 finished with value: 0.10600307171030333 and parameters: {'max_depth': 2, 'learning_rate': 0.06567886347622917, 'num_leaves': 457, 'subsample': 0.3127309057691313, 'colsample_bytree': 0.11650354457923662, 'min_child_weight': 0.1171396860390492, 'reg_alpha': 75.39285471430357, 'reg_lambda': 97.67258252798777}. Best is trial 89 with value: 0.10600307171030333.\n",
      "[I 2025-07-02 22:27:15,154] Trial 90 finished with value: 0.095205328865728 and parameters: {'max_depth': 2, 'learning_rate': 0.07102208598761087, 'num_leaves': 461, 'subsample': 0.8313544426829524, 'colsample_bytree': 0.1840366802879274, 'min_child_weight': 0.16696262085179744, 'reg_alpha': 65.21337129094466, 'reg_lambda': 85.79585193890657}. Best is trial 89 with value: 0.10600307171030333.\n",
      "[I 2025-07-02 22:27:24,458] Trial 91 finished with value: 0.10153372817610808 and parameters: {'max_depth': 2, 'learning_rate': 0.06870384663050268, 'num_leaves': 459, 'subsample': 0.8457293110096049, 'colsample_bytree': 0.18299199032111665, 'min_child_weight': 0.0014637909770273336, 'reg_alpha': 64.77854894950181, 'reg_lambda': 98.52000667136736}. Best is trial 89 with value: 0.10600307171030333.\n",
      "[I 2025-07-02 22:27:31,493] Trial 92 finished with value: 0.10693754298062133 and parameters: {'max_depth': 2, 'learning_rate': 0.05106316847822283, 'num_leaves': 453, 'subsample': 0.8604707542195162, 'colsample_bytree': 0.11305785641973935, 'min_child_weight': 0.0008202390746506888, 'reg_alpha': 57.34226732836154, 'reg_lambda': 97.34989117474919}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-02 22:27:40,237] Trial 93 finished with value: 0.10246892199571242 and parameters: {'max_depth': 2, 'learning_rate': 0.09413839883115344, 'num_leaves': 544, 'subsample': 0.8581482715352323, 'colsample_bytree': 0.11418314925098585, 'min_child_weight': 0.008989023783109918, 'reg_alpha': 68.68936669310787, 'reg_lambda': 98.2098497520187}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-02 22:27:47,289] Trial 94 finished with value: 0.09835791710745477 and parameters: {'max_depth': 2, 'learning_rate': 0.08564984994222445, 'num_leaves': 548, 'subsample': 0.8535879937262391, 'colsample_bytree': 0.11401178462182916, 'min_child_weight': 0.008245331395309754, 'reg_alpha': 56.26459558243836, 'reg_lambda': 97.04409612494172}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-02 22:27:56,400] Trial 95 finished with value: 0.1031003075313949 and parameters: {'max_depth': 2, 'learning_rate': 0.09680709508393583, 'num_leaves': 543, 'subsample': 0.8619318331141521, 'colsample_bytree': 0.11059449439131472, 'min_child_weight': 0.004084985376158053, 'reg_alpha': 57.71290119232984, 'reg_lambda': 98.0863115012268}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-02 22:28:03,982] Trial 96 finished with value: 0.09583586328305982 and parameters: {'max_depth': 2, 'learning_rate': 0.06746319867469999, 'num_leaves': 449, 'subsample': 0.8719683309902709, 'colsample_bytree': 0.18744652388967137, 'min_child_weight': 0.10744980337123342, 'reg_alpha': 57.813836595436385, 'reg_lambda': 97.15117688679537}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-02 22:28:12,514] Trial 97 finished with value: 0.10174366018863856 and parameters: {'max_depth': 2, 'learning_rate': 0.09715409140327466, 'num_leaves': 567, 'subsample': 0.9763685580784888, 'colsample_bytree': 0.11168827686650004, 'min_child_weight': 0.10981232777509346, 'reg_alpha': 58.31409959486347, 'reg_lambda': 93.70663254461616}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-02 22:28:19,922] Trial 98 finished with value: 0.10483067890380984 and parameters: {'max_depth': 2, 'learning_rate': 0.0959578110550932, 'num_leaves': 513, 'subsample': 0.976592497290632, 'colsample_bytree': 0.11363003016324975, 'min_child_weight': 0.13043336165953032, 'reg_alpha': 51.027378478641786, 'reg_lambda': 93.44223539565941}. Best is trial 92 with value: 0.10693754298062133.\n",
      "[I 2025-07-02 22:28:38,389] Trial 99 finished with value: 0.0912213517759905 and parameters: {'max_depth': 3, 'learning_rate': 0.05114251558716993, 'num_leaves': 516, 'subsample': 0.9043489113087411, 'colsample_bytree': 0.663120769521529, 'min_child_weight': 0.12782626301994687, 'reg_alpha': 61.13646481099276, 'reg_lambda': 99.54028305256661}. Best is trial 92 with value: 0.10693754298062133.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 2, 'learning_rate': 0.05106316847822283, 'num_leaves': 453, 'subsample': 0.8604707542195162, 'colsample_bytree': 0.11305785641973935, 'min_child_weight': 0.0008202390746506888, 'reg_alpha': 57.34226732836154, 'reg_lambda': 97.34989117474919}\n",
      "Best Pearson score: 0.10693754298062133\n"
     ]
    }
   ],
   "source": [
    "best_lightgbm_params_common_truncated = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291147c",
   "metadata": {},
   "source": [
    "Analyze model performance and feature importance across train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6913016",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    xgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    xgbr_arr.append(xgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state,\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    lgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    lgbr_arr.append(lgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances = {}\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    features = xgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "    features = lgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df_common_truncated = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df_common_truncated[\"importance\"] = 1/2 * (feature_importances_df_common_truncated[\"importance_xgboost\"] + feature_importances_df_common_truncated[\"importance_lightgbm\"])\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "feature_importances_df_common_truncated[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df_common_truncated[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df_common_truncated[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922a1c7",
   "metadata": {},
   "source": [
    "#### Fifth Iteration Instead of using GBDT, can we use MLP on these features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58f11b",
   "metadata": {},
   "source": [
    "Convert from normal CV to torch type CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531',\n",
    "                 'X385', 'X23', 'X465', 'X284', 'X331', 'X95', 'X169', 'X285', 'X137', 'X31']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, cv=default_cv):\n",
    "    train_arr = []\n",
    "    test_arr = []\n",
    "    for i in range(cv):\n",
    "        # First shuffle the data\n",
    "        X_train, Y_train = X_train_arr[i], Y_train_arr[i]\n",
    "        X_train[\"label\"] = Y_train\n",
    "        # Instead of shuffle the training data when create the dataloader, try to shuffle beforehand\n",
    "        # X_train = X_train.sample(frac = 1, random_state = default_random_state)\n",
    "        # not shuffle, keep it by date\n",
    "        Y_train = X_train[\"label\"]\n",
    "        X_train = X_train.drop(\"label\", axis = 1)\n",
    "\n",
    "        # Then normalize\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train.values)\n",
    "\n",
    "        # Create train dataset\n",
    "        X_train, Y_train = torch.from_numpy(X_train), torch.from_numpy(Y_train.values)\n",
    "        train_dataset = TensorDataset(X_train, Y_train)\n",
    "        train_arr.append(train_dataset)\n",
    "\n",
    "        # Normalize X_test\n",
    "        X_test = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Create test dataset\n",
    "        X_test, Y_test = torch.from_numpy(X_test), torch.from_numpy(Y_test_arr[i].values)\n",
    "        test_dataset = TensorDataset(X_test, Y_test)\n",
    "        test_arr.append(test_dataset)\n",
    "        \n",
    "    return train_arr, test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr, test_arr = normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da5b12",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = nn.ModuleList()\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nn.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nn.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # Initialze dropout\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            if inx == len(self.layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb08f2",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e892da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp(model, criterion, optimizer, train_dataloader, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in train_dataloader:\n",
    "            # Load to device\n",
    "            inputs, targets= inputs.to(device), targets.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs)\n",
    "            # get error\n",
    "            error = criterion(outputs, targets)\n",
    "            # Zero out the past gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Backprop\n",
    "            error.backward()\n",
    "            # Gradient Descent\n",
    "            optimizer.step()\n",
    "\n",
    "def eval_mlp(model, test_dataloader):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, targets) in enumerate(test_dataloader):\n",
    "            # Load to device\n",
    "            inputs = inputs.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs).detach().cpu().numpy().flatten()\n",
    "            # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "            outputs_all = np.concatenate([outputs_all, outputs])\n",
    "            targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_torch(model, lr, cv, train_arr, test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for i in range(cv):\n",
    "        # Get the dataloader\n",
    "        train_dataset = train_arr[i]\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, num_workers=0)\n",
    "        test_dataset = test_arr[i]\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers=0)\n",
    "\n",
    "        # Reinitialize the model\n",
    "        model.reset()\n",
    "        model.to(device)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp(model, criterion, optimizer, train_dataloader, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp(model, test_dataloader)\n",
    "        print(pearson)\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bc5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process of the default config\n",
    "hidden_layers_size = [16, 8, 4]\n",
    "lr = 0.001\n",
    "batch_size = 60\n",
    "num_epochs = 10\n",
    "\n",
    "mlpr = MLP(len(best_features), hidden_layers_size=hidden_layers_size, dropout = 0.3)\n",
    "\n",
    "train_eval_cv_torch(mlpr, lr, default_cv, train_arr, test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdd235",
   "metadata": {},
   "source": [
    "#### Sixth Iteration: Change this into a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65121481",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_classification(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5950bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_classification = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_xgboost_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_classification = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_lightgbm_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31960b41",
   "metadata": {},
   "source": [
    "#### Seventh Iteration: Search for the best way to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_training_scheme(model, train_df, cv = default_cv, features = None):\n",
    "    folds_trial = [\n",
    "        # level 1\n",
    "        [[0, 1, 2, 3]], \n",
    "        [[0, 1]], [[1, 2]], [[2, 3]],\n",
    "        [[0]], [[1]], [[2]], [[3]],\n",
    "        [[0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1], [2, 3]],\n",
    "        [[0], [1], [2], [3]],\n",
    "        # level 2\n",
    "        [[0, 1, 2, 3], [0, 1]],\n",
    "        [[0, 1, 2, 3], [1, 2]],\n",
    "        [[0, 1, 2, 3], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "        # level 3\n",
    "        [[0, 1, 2, 3], [0, 1], [0]],\n",
    "        [[0, 1, 2, 3], [2, 3], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "    ]\n",
    "\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "\n",
    "    for folds in folds_trial:\n",
    "        print(f\"Current folds list is {folds}\")\n",
    "        model_lst = [deepcopy(model)] * len(folds)\n",
    "        cv_pearson = []\n",
    "        for i in range(cv):\n",
    "            train_month = list(range(3 + i, 7 + i))\n",
    "            test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "            test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "            X_test, Y_test = test.drop([\"timestamp\", \"label\"], axis = 1), test[\"label\"]\n",
    "            Y_pred = np.zeros(Y_test.shape[0])\n",
    "            for j in range(len(folds)):\n",
    "                fold = folds[j]\n",
    "                model = model_lst[j]\n",
    "                train_month_curr = [train_month[f] for f in fold]\n",
    "                train_curr = train_df[train_df[\"timestamp\"].dt.month.isin(train_month_curr)].reset_index().drop(\"index\", axis = 1)\n",
    "                X_train, Y_train = train_curr.drop([\"timestamp\", \"label\"], axis = 1), train_curr[\"label\"]\n",
    "                model.fit(X_train, Y_train)\n",
    "                Y_pred += model.predict(X_test)\n",
    "            Y_pred /= len(folds)\n",
    "            cv_pearson.append(pearson_score(Y_test, Y_pred))\n",
    "            print(f\"Finish fold {i} with score: {pearson_score(Y_test, Y_pred)}\")\n",
    "        print(f\"Finish trial with mean score: {np.mean(np.array(cv_pearson))}\")\n",
    "        print(f\"Finish trial with std score: {np.std(np.array(cv_pearson))}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df66a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "search_training_scheme(xgbr, train_added_df)\n",
    "# Notable\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [1, 2]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]] \n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ea866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "search_training_scheme(lgbr, train_added_df)\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [0]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fe3ca",
   "metadata": {},
   "source": [
    "#### Eighth Iteration: rewrite the code for MLP training using MLX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f11bdd",
   "metadata": {},
   "source": [
    "Create the data for training + custom batch iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb028760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "# best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "#                  'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137', \n",
    "#                 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301'] \n",
    "                #  'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', \n",
    "                #  'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "# best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68496448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "#     X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "#     Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "#     Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02f14632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, cv=default_cv):\n",
    "    for i in range(cv):\n",
    "        # Normalize forst\n",
    "        scaler = StandardScaler()\n",
    "        X_train_arr[i] = scaler.fit_transform(X_train_arr[i].values)\n",
    "        X_test_arr[i] = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Convert to mlx format\n",
    "        X_train_arr[i] = mx.array(X_train_arr[i])\n",
    "        X_test_arr[i] = mx.array(X_test_arr[i])\n",
    "        Y_train_arr[i] = mx.array(Y_train_arr[i].values)\n",
    "        Y_test_arr[i] = mx.array(Y_test_arr[i].values)\n",
    "        \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3f916",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "993631c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# We do not use the reset method this time so you have to create the model at each fold\n",
    "class MLPMLX(nnmx.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = []\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nnmx.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nnmx.ReLU()\n",
    "\n",
    "        # Initialze dropout\n",
    "        self.dropout = nnmx.Dropout(p = dropout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            if inx == len(self.layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33907ab7",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78aaa51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for batch iteration\n",
    "def batch_iterate(batch_size, X, Y, shuffle = True):\n",
    "    for i in range(0, Y.size, batch_size):\n",
    "        X_curr = X[i: min(i + batch_size, Y.size), :]\n",
    "        Y_curr = Y[i: min(i + batch_size, Y.size)]\n",
    "        if shuffle:\n",
    "            inx_lst = mx.random.permutation(batch_size)\n",
    "            X_curr = X_curr[inx_lst, :]\n",
    "            Y_curr = Y_curr[inx_lst]\n",
    "        yield X_curr, Y_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a72a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            _, grads = loss_and_grad_fn(model, inputs, targets)\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            optimizer.update(model, grads)\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(model.parameters(), optimizer.state)\n",
    "\n",
    "def eval_mlp_mlx(model, X_test, Y_test, batch_size):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    for (inputs, targets) in batch_iterate(batch_size, X_test, Y_test, shuffle=False):\n",
    "        outputs = model(inputs).reshape(-1)\n",
    "        # convert back to numpy\n",
    "        outputs, targets = np.array(outputs), np.array(targets)\n",
    "        # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "        outputs_all = np.concatenate([outputs_all, outputs])\n",
    "        targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3974705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for _, (X_train, X_test, Y_train, Y_test) in enumerate(zip(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)):\n",
    "        # initialize the model\n",
    "        mx.random.seed(default_random_state)\n",
    "        model = MLPMLX(num_features, hidden_layers_size, dropout)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        def loss_fn(model, X, Y):\n",
    "            Y_pred = model(X).reshape(-1)\n",
    "            return mx.mean(nnmx.losses.mse_loss(Y_pred, Y))\n",
    "        loss_and_grad_fn = nnmx.value_and_grad(model, loss_fn)\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optimmx.Adam(learning_rate = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp_mlx(model, X_test, Y_test, batch_size)\n",
    "        print(pearson)\n",
    "        if pearson == -1:\n",
    "            return pearson\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0617236",
   "metadata": {},
   "source": [
    "Conduct training and evaluating process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a75900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training process of the default config\n",
    "# num_features = len(best_features)\n",
    "# hidden_layers_size = [8, 8, 8]\n",
    "# dropout = 0.2\n",
    "# lr = 0.001\n",
    "# batch_size = 180\n",
    "# num_epochs = 10\n",
    "\n",
    "# train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad94fa",
   "metadata": {},
   "source": [
    "Conduct Bayesian Optimization on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b347651",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "820f5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp_mlx(trial):\n",
    "    # First initialize the parameters\n",
    "    num_features = len(best_features)\n",
    "    num_layers = default_num_layers\n",
    "    log_2_hidden_layers_size = []\n",
    "    for i in range(num_layers):\n",
    "        if len(log_2_hidden_layers_size) == 0:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, 6))\n",
    "        else:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, log_2_hidden_layers_size[-1]))\n",
    "    hidden_layers_size = [2**l for l in log_2_hidden_layers_size]\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.7)\n",
    "    lr = trial.suggest_float(\"lr\", 0.0001, 0.01, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [30, 60, 120, 180, 360, 720])\n",
    "    num_epochs = trial.suggest_categorical(\"num_epochs\", [10, 20, 30, 40, 50])\n",
    "    \n",
    "    # Conduct training based on those parameters\n",
    "    return train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e305bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mlp_mlx(study_name, storage_name, objective_function=objective_mlp_mlx, n_trials = 100, n_jobs = 1):\n",
    "    print(\"Conduct hyperparam opt for MLP\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcca3193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6] [8, 9, 10, 11]\n",
      "[4, 5, 6, 7] [9, 10, 11, 12]\n",
      "[5, 6, 7, 8] [10, 11, 12, 1]\n",
      "[6, 7, 8, 9] [11, 12, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "                 'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137',]\n",
    "                # 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301',] \n",
    "                #  'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', \n",
    "                #  'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)\n",
    "\n",
    "# Convert to float32\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "\n",
    "# Convert to MLX\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e30381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-02 22:28:38,926] A new study created in RDB with name: mlp_mlx_2_4_101_2_common_truncated_20_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:36<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10983381197033755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:36<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12240635713916953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:36<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07925566175009038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:35<00:00,  1.40it/s]\n",
      "[I 2025-07-02 22:31:04,864] Trial 0 finished with value: 0.10356606688975666 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 3, 'dropout': 0.21423711323904848, 'lr': 0.00022031461731919204, 'batch_size': 180, 'num_epochs': 50}. Best is trial 0 with value: 0.10356606688975666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1027684366994292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11054063164738312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10447695678738769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0682639701557989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.10s/it]\n",
      "[I 2025-07-02 22:32:33,367] Trial 1 finished with value: 0.08897967473240725 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 2, 'dropout': 0.5017742111456093, 'lr': 0.0028706848318266727, 'batch_size': 60, 'num_epochs': 10}. Best is trial 0 with value: 0.10356606688975666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07263714033905933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [02:06<00:52,  4.76s/it]"
     ]
    }
   ],
   "source": [
    "optimize_mlp_mlx(\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\",\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196766ca",
   "metadata": {},
   "source": [
    "#### Nineth Iteration: AE + MLP instead of GBDT feature selection + MLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
