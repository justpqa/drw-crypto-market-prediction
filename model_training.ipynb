{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89ecff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justpqa/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler, GPSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import multiprocessing\n",
    "# max_n_jobs = multiprocessing.cpu_count()\n",
    "import shap\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, Sampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nnmx\n",
    "import mlx.optimizers as optimmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dce0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2025de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_version = 2\n",
    "# 1 for pc feature, \n",
    "# 2 for label correlation feature # seems to work most consistently\n",
    "# 3 for best features based on combination rank\n",
    "# 4 for including time features (in case we want to reverse engineer the masked timestamp)\n",
    "# 5 for increasing number of correlation features + only use those that are in the same cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935ee52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_random_state = 101\n",
    "random.seed(default_random_state)\n",
    "np.random.seed(default_random_state)\n",
    "torch.manual_seed(default_random_state)\n",
    "torch.mps.manual_seed(default_random_state)\n",
    "mx.random.seed(default_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731d3a4",
   "metadata": {},
   "source": [
    "#### Import train data and popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dc4e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X473</th>\n",
       "      <th>X205</th>\n",
       "      <th>X198</th>\n",
       "      <th>X444</th>\n",
       "      <th>X466</th>\n",
       "      <th>X445</th>\n",
       "      <th>X472</th>\n",
       "      <th>X26</th>\n",
       "      <th>X29</th>\n",
       "      <th>X217</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_buy_volume</th>\n",
       "      <th>normalized_sell_volume</th>\n",
       "      <th>liquidity_adjusted_imbalance</th>\n",
       "      <th>pressure_spread_interaction</th>\n",
       "      <th>trade_direction_ratio</th>\n",
       "      <th>net_buy_volume</th>\n",
       "      <th>bid_skew</th>\n",
       "      <th>ask_skew</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.201346</td>\n",
       "      <td>-1.978504</td>\n",
       "      <td>-1.700689</td>\n",
       "      <td>-0.142546</td>\n",
       "      <td>-0.163476</td>\n",
       "      <td>-0.128331</td>\n",
       "      <td>-0.126241</td>\n",
       "      <td>1.406392</td>\n",
       "      <td>1.474789</td>\n",
       "      <td>-0.981975</td>\n",
       "      <td>...</td>\n",
       "      <td>11.542564</td>\n",
       "      <td>5.339347</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>-0.230493</td>\n",
       "      <td>0.796810</td>\n",
       "      <td>131.421</td>\n",
       "      <td>0.644635</td>\n",
       "      <td>0.355365</td>\n",
       "      <td>2023-03-01 00:00:00</td>\n",
       "      <td>0.562539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186231</td>\n",
       "      <td>-1.830295</td>\n",
       "      <td>-1.669471</td>\n",
       "      <td>-0.135499</td>\n",
       "      <td>-0.159388</td>\n",
       "      <td>-0.124790</td>\n",
       "      <td>-0.115015</td>\n",
       "      <td>1.003783</td>\n",
       "      <td>1.312735</td>\n",
       "      <td>-0.940190</td>\n",
       "      <td>...</td>\n",
       "      <td>13.626484</td>\n",
       "      <td>137.821061</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>-0.549445</td>\n",
       "      <td>0.620251</td>\n",
       "      <td>203.896</td>\n",
       "      <td>0.942921</td>\n",
       "      <td>0.057079</td>\n",
       "      <td>2023-03-01 00:01:00</td>\n",
       "      <td>0.533686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.182398</td>\n",
       "      <td>-1.803540</td>\n",
       "      <td>-1.662645</td>\n",
       "      <td>-0.133705</td>\n",
       "      <td>-0.158627</td>\n",
       "      <td>-0.123891</td>\n",
       "      <td>-0.112303</td>\n",
       "      <td>0.760801</td>\n",
       "      <td>1.219124</td>\n",
       "      <td>-0.933071</td>\n",
       "      <td>...</td>\n",
       "      <td>360.242073</td>\n",
       "      <td>2.263386</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.530818</td>\n",
       "      <td>0.538664</td>\n",
       "      <td>22.858</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>2023-03-01 00:02:00</td>\n",
       "      <td>0.546505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.177415</td>\n",
       "      <td>-1.714013</td>\n",
       "      <td>-1.620037</td>\n",
       "      <td>-0.133251</td>\n",
       "      <td>-0.158334</td>\n",
       "      <td>-0.123658</td>\n",
       "      <td>-0.109113</td>\n",
       "      <td>0.955549</td>\n",
       "      <td>1.353001</td>\n",
       "      <td>-0.891216</td>\n",
       "      <td>...</td>\n",
       "      <td>69.011716</td>\n",
       "      <td>5.946089</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>0.454780</td>\n",
       "      <td>0.728757</td>\n",
       "      <td>210.779</td>\n",
       "      <td>0.187976</td>\n",
       "      <td>0.812024</td>\n",
       "      <td>2023-03-01 00:03:00</td>\n",
       "      <td>0.357703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.174164</td>\n",
       "      <td>-1.684170</td>\n",
       "      <td>-1.600188</td>\n",
       "      <td>-0.128862</td>\n",
       "      <td>-0.156668</td>\n",
       "      <td>-0.121464</td>\n",
       "      <td>-0.106383</td>\n",
       "      <td>0.905460</td>\n",
       "      <td>1.361880</td>\n",
       "      <td>-0.878711</td>\n",
       "      <td>...</td>\n",
       "      <td>3.623647</td>\n",
       "      <td>12.867864</td>\n",
       "      <td>0.081042</td>\n",
       "      <td>-0.533689</td>\n",
       "      <td>0.689066</td>\n",
       "      <td>54.004</td>\n",
       "      <td>0.887255</td>\n",
       "      <td>0.112745</td>\n",
       "      <td>2023-03-01 00:04:00</td>\n",
       "      <td>0.362452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X473      X205      X198      X444      X466      X445      X472  \\\n",
       "0 -0.201346 -1.978504 -1.700689 -0.142546 -0.163476 -0.128331 -0.126241   \n",
       "1 -0.186231 -1.830295 -1.669471 -0.135499 -0.159388 -0.124790 -0.115015   \n",
       "2 -0.182398 -1.803540 -1.662645 -0.133705 -0.158627 -0.123891 -0.112303   \n",
       "3 -0.177415 -1.714013 -1.620037 -0.133251 -0.158334 -0.123658 -0.109113   \n",
       "4 -0.174164 -1.684170 -1.600188 -0.128862 -0.156668 -0.121464 -0.106383   \n",
       "\n",
       "        X26       X29      X217  ...  normalized_buy_volume  \\\n",
       "0  1.406392  1.474789 -0.981975  ...              11.542564   \n",
       "1  1.003783  1.312735 -0.940190  ...              13.626484   \n",
       "2  0.760801  1.219124 -0.933071  ...             360.242073   \n",
       "3  0.955549  1.353001 -0.891216  ...              69.011716   \n",
       "4  0.905460  1.361880 -0.878711  ...               3.623647   \n",
       "\n",
       "   normalized_sell_volume  liquidity_adjusted_imbalance  \\\n",
       "0                5.339347                      0.063569   \n",
       "1              137.821061                      0.011610   \n",
       "2                2.263386                      0.015877   \n",
       "3                5.946089                      0.025702   \n",
       "4               12.867864                      0.081042   \n",
       "\n",
       "   pressure_spread_interaction  trade_direction_ratio  net_buy_volume  \\\n",
       "0                    -0.230493               0.796810         131.421   \n",
       "1                    -0.549445               0.620251         203.896   \n",
       "2                     0.530818               0.538664          22.858   \n",
       "3                     0.454780               0.728757         210.779   \n",
       "4                    -0.533689               0.689066          54.004   \n",
       "\n",
       "   bid_skew  ask_skew           timestamp     label  \n",
       "0  0.644635  0.355365 2023-03-01 00:00:00  0.562539  \n",
       "1  0.942921  0.057079 2023-03-01 00:01:00  0.533686  \n",
       "2  0.007283  0.992717 2023-03-01 00:02:00  0.546505  \n",
       "3  0.187976  0.812024 2023-03-01 00:03:00  0.357703  \n",
       "4  0.887255  0.112745 2023-03-01 00:04:00  0.362452  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_parquet(f\"data/cleaned/cleaned_train_{feature_version}.parquet\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766f9871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>bid_qty</th>\n",
       "      <th>ask_qty</th>\n",
       "      <th>buy_qty</th>\n",
       "      <th>sell_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221.389</td>\n",
       "      <td>15.283</td>\n",
       "      <td>8.425</td>\n",
       "      <td>176.405</td>\n",
       "      <td>44.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>847.796</td>\n",
       "      <td>38.590</td>\n",
       "      <td>2.336</td>\n",
       "      <td>525.846</td>\n",
       "      <td>321.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295.596</td>\n",
       "      <td>0.442</td>\n",
       "      <td>60.250</td>\n",
       "      <td>159.227</td>\n",
       "      <td>136.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460.705</td>\n",
       "      <td>4.865</td>\n",
       "      <td>21.016</td>\n",
       "      <td>335.742</td>\n",
       "      <td>124.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.818</td>\n",
       "      <td>27.158</td>\n",
       "      <td>3.451</td>\n",
       "      <td>98.411</td>\n",
       "      <td>44.407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    volume  bid_qty  ask_qty  buy_qty  sell_qty\n",
       "0  221.389   15.283    8.425  176.405    44.984\n",
       "1  847.796   38.590    2.336  525.846   321.950\n",
       "2  295.596    0.442   60.250  159.227   136.369\n",
       "3  460.705    4.865   21.016  335.742   124.963\n",
       "4  142.818   27.158    3.451   98.411    44.407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_features_train = pd.read_parquet(\"data/cleaned/popular_features_train.parquet\")\n",
    "popular_features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f1fe5",
   "metadata": {},
   "source": [
    "#### Implement some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb40f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to split into some fold\n",
    "train_df[\"timestamp\"] = pd.to_datetime(train_df[\"timestamp\"])\n",
    "\n",
    "default_cv = 4\n",
    "default_cv_type = \"full\"\n",
    "# NOTE: default_cv must set to 1 instead of 3 based on consistency with LB score contains 49% of test data\n",
    "# NOTE: 3 cv with gap is slightly better or almost equal\n",
    "\n",
    "def create_cv(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        # train_month = [3, 4, 5, 6, 7, 8]\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # test_month = [9, 10, 11, 12, 1, 2] # try to make a gap to see if there is any differences in cv-lb correlation\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"])\n",
    "        Y_test_arr.append(test[\"label\"])  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# def create_cv_random_test(train_df, features=None, test_cv=10):\n",
    "#     # randomize so that we have 1 train, but try it on 10 different test \n",
    "#     if features is not None:\n",
    "#         train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "#     X_train_arr = []\n",
    "#     X_test_arr = []\n",
    "#     Y_train_arr = []\n",
    "#     Y_test_arr = []\n",
    "\n",
    "#     # Create train data\n",
    "#     train_month = [3, 4, 5, 6, 7, 8]\n",
    "#     train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)] \n",
    "#     X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#     Y_train_arr.append(train[\"label\"])\n",
    "\n",
    "#     test_month = [9, 10, 11, 12, 1, 2]\n",
    "#     test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)]\n",
    "#     # Create test data\n",
    "#     for _ in range(test_cv):\n",
    "#         random_test = test.sample(frac = 0.5, random_state = default_random_state)\n",
    "#         X_test_arr.append(random_test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#         Y_test_arr.append(random_test[\"label\"])\n",
    "\n",
    "#     return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr \n",
    "\n",
    "# class [-1, 0, 1] -> [0, 1, 2] => < -0.2 => neg, > 0.2 => pos, else => neutral\n",
    "def create_classification_class(label):\n",
    "    if label < -0.4: return 0\n",
    "    elif label < 0: return 1\n",
    "    elif label < 0.4: return 2\n",
    "    return 3\n",
    "\n",
    "def create_cv_classification(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        # train_month = [3, 4, 5, 6, 7, 8]\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # test_month = [9, 10, 11, 12, 1, 2] # try to make a gap to see if there is any differences in cv-lb correlation\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"].apply(lambda x: create_classification_class(x)))\n",
    "        Y_test_arr.append(test[\"label\"].apply(lambda x: create_classification_class(x)))  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8b878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_score(Y_test, Y_pred):\n",
    "    if isinstance(Y_test, pd.Series) or isinstance(Y_test, pd.DataFrame):\n",
    "        Y_test = Y_test.values\n",
    "    if isinstance(Y_pred, pd.Series) or isinstance(Y_pred, pd.DataFrame):\n",
    "        Y_pred = Y_pred.values\n",
    "    Y_test = np.ravel(Y_test)\n",
    "    Y_pred = np.ravel(Y_pred)\n",
    "    pearson = np.corrcoef(Y_test, Y_pred)[0, 1]\n",
    "    if np.isnan(pearson):\n",
    "        if np.std(Y_pred) == 0:\n",
    "            print(Y_pred)\n",
    "            print(\"Error: zero variance prediction\")\n",
    "        elif np.isnan(Y_pred).any():\n",
    "            print(\"Error: nan prediction\")\n",
    "        return -1\n",
    "    else:\n",
    "        return pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce779cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function specifically for cross validation\n",
    "def train_eval_cv(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        cv_score += scoring_function(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_score / cv\n",
    "\n",
    "def train_eval_cv_random_test(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score, test_cv = 10):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        curr_cv_score = 0\n",
    "\n",
    "        # Conduct fitting\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        # sampling and testing\n",
    "        len_test = X_test.shape[0]\n",
    "        for seed in tqdm(range(test_cv)):\n",
    "            np.random.seed(seed)\n",
    "            test_index = np.random.choice(len_test, size = len_test // 2, replace = False) \n",
    "            X_test_sample = X_test.loc[test_index, :]\n",
    "            Y_test_sample = Y_test[test_index]\n",
    "            Y_pred_sample = model.predict(X_test_sample)\n",
    "            curr_cv_score += scoring_function(Y_test_sample, Y_pred_sample)\n",
    "        \n",
    "        cv_score += curr_cv_score / test_cv\n",
    "    \n",
    "    np.random.seed(default_random_state)\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9d975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trees = 2000\n",
    "# Finetuning XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddbb8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning XGBoost\n",
    "def objective_xgboost_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBClassifier(**params)\n",
    "    cv_acc = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_lightgbm_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMClassifier(**params)\n",
    "    cv_acc = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_catboost_classification(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_acc = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778f94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trials = 100\n",
    "default_n_jobs = 1\n",
    "\n",
    "def optimize_xgboost(study_name, storage_name, objective_function=objective_xgboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for XGBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_lightgbm(study_name, storage_name, objective_function=objective_lightgbm, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for LightGBM\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_catboost(study_name, storage_name, objective_function=objective_catboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for CatBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fd743",
   "metadata": {},
   "source": [
    "#### First iteration: training with all features from the collection, no popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c5acc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6] [8, 9, 10, 11]\n",
      "[4, 5, 6, 7] [9, 10, 11, 12]\n",
      "[5, 6, 7, 8] [10, 11, 12, 1]\n",
      "[6, 7, 8, 9] [11, 12, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb106a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_catboost = optimize_catboost(\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    "# )\n",
    "# # Need to take down as catboost might not work well in this situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e2b50",
   "metadata": {},
   "source": [
    "Analyze params - cv relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae8801e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_study_df(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    study_df = []\n",
    "    for trial in study.trials:\n",
    "        trial_dict = trial.params\n",
    "        trial_dict[\"value\"] = trial.value\n",
    "        study_df.append(trial_dict)\n",
    "\n",
    "    return pd.DataFrame(study_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d57f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_value_viz(study_df):\n",
    "    nrows = (study_df.shape[1] - 1) // 3 + ((study_df.shape[1] - 1) % 3 > 0)\n",
    "    fig, ax = plt.subplots(nrows = nrows, ncols = 3, figsize = (14, 5 * nrows))\n",
    "    for inx, var in enumerate(study_df.columns):\n",
    "        x, y = inx // 3, inx % 3\n",
    "        if var != \"value\":\n",
    "            sns.regplot(study_df, x = var, y = \"value\", ax = ax[x][y], lowess=True, line_kws={'color': 'green'}, ci = 95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad954e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_xgboost = get_study_df(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")   \n",
    "params_value_viz(study_df_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717983ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_lightgbm = get_study_df(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "params_value_viz(study_df_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba067f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df_catboost = get_study_df(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# params_value_viz(study_df_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d81cc8",
   "metadata": {},
   "source": [
    "Analyze feature importance + CV performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ccea6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_from_file(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1942990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(model, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, sample_size=10000):\n",
    "    mean_abs_shap_all = np.zeros(X_train_arr[0].shape[1])\n",
    "    for i in range(default_cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        X_test_sample = X_test.sample(sample_size, random_state = default_random_state)\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        mean_abs_shap = np.mean(np.abs(shap_values), axis = 0)\n",
    "        mean_abs_shap_all += mean_abs_shap\n",
    "    mean_abs_shap_all /= default_cv\n",
    "    return mean_abs_shap_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in xgboost_feature_importances if xgboost_feature_importances[f] > 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7366dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in lightgbm_feature_importances if lightgbm_feature_importances[f] >= 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"iterations\": default_n_trees,\n",
    "#     \"verbose\": False,\n",
    "#     \"random_seed\": default_random_state\n",
    "# }\n",
    "# best_params_catboost = get_best_params_from_file(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# for p in best_params_catboost:\n",
    "#     params[p] = best_params_catboost[p]\n",
    "\n",
    "# catboost_feature_importances = {}\n",
    "\n",
    "# cbr = CatBoostRegressor(**params)\n",
    "# cv_rmse = 0\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "#     Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "#     cbr.fit(X_train, Y_train)\n",
    "#     print(pearson_score(Y_test, cbr.predict(X_test)))\n",
    "#     features = cbr.feature_names_\n",
    "#     # features_i = cbr.feature_importances_.tolist()\n",
    "#     features_i = get_shap_values(cbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "#     for inx, feat in enumerate(features):\n",
    "#         catboost_feature_importances[feat] = catboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# plt.hist(catboost_feature_importances.values())\n",
    "# # can pick up a combination of both past cod and tss, not good at picking up ph, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([f for f in catboost_feature_importances if catboost_feature_importances[f] >= 0.02])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8120d",
   "metadata": {},
   "source": [
    "Get top 20 important features in all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ed2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:49, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca490b7",
   "metadata": {},
   "source": [
    "#### Second Iteration: adding popular feature in addition to original features correlated to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93eefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_popular_feature = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_popular_feature = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d683a",
   "metadata": {},
   "source": [
    "Check for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df[~feature_importances_df[\"var\"].str.contains(\"X\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ba087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:29, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8dc1e",
   "metadata": {},
   "source": [
    "#### Third iteration: a more truncated version from the first collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7701a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "feature_importances_df[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df = feature_importances_df.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:49, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f34e76",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56532466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_importance_threshold = 0.011\n",
    "# xgboost_best_features = [\n",
    "#     f for f in xgboost_feature_importances if xgboost_feature_importances[f] > xgboost_importance_threshold\n",
    "# ] + [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"]\n",
    "# print(len(xgboost_best_features))\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, xgboost_best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_xgboost_params_truncated = optimize_xgboost(\n",
    "#     f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\",\n",
    "#     f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\"\n",
    "# ) # much worse than using all features  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13ba89",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ef415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm_importance_threshold = 20\n",
    "# lightgbm_best_features = [\n",
    "#     f for f in lightgbm_feature_importances if lightgbm_feature_importances[f] > lightgbm_importance_threshold\n",
    "# ] + [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"]\n",
    "# print(len(lightgbm_best_features))\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, lightgbm_best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_lightgbm_params_truncated = optimize_lightgbm(\n",
    "#     f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\",\n",
    "#     f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_truncated_study\"\n",
    "# )\n",
    "# # also much worse "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6953fd8",
   "metadata": {},
   "source": [
    "#### Fourth Iteration: a common truncated version using good features across all models + popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "                  'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137'] + \\\n",
    "                [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c7f75",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ed407",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_params_common_truncated = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534cb1d",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c656479",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lightgbm_params_common_truncated = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfaacf4",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_catboost_params_common_truncated = optimize_catboost(\n",
    "    f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "    f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291147c",
   "metadata": {},
   "source": [
    "Analyze model performance and feature importance across train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6913016",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    xgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    xgbr_arr.append(xgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state,\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    lgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    lgbr_arr.append(lgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances = {}\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    features = xgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "    features = lgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df_common_truncated = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df_common_truncated[\"importance\"] = 1/2 * (feature_importances_df_common_truncated[\"importance_xgboost\"] + feature_importances_df_common_truncated[\"importance_lightgbm\"])\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "feature_importances_df_common_truncated[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df_common_truncated[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df_common_truncated[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922a1c7",
   "metadata": {},
   "source": [
    "#### Fifth Iteration Instead of using GBDT, can we use MLP on these features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58f11b",
   "metadata": {},
   "source": [
    "Convert from normal CV to torch type CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531',\n",
    "                 'X385', 'X23', 'X465', 'X284', 'X331', 'X95', 'X169', 'X285', 'X137', 'X31']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, cv=default_cv):\n",
    "    train_arr = []\n",
    "    test_arr = []\n",
    "    for i in range(cv):\n",
    "        # First shuffle the data\n",
    "        X_train, Y_train = X_train_arr[i], Y_train_arr[i]\n",
    "        X_train[\"label\"] = Y_train\n",
    "        # Instead of shuffle the training data when create the dataloader, try to shuffle beforehand\n",
    "        # X_train = X_train.sample(frac = 1, random_state = default_random_state)\n",
    "        # not shuffle, keep it by date\n",
    "        Y_train = X_train[\"label\"]\n",
    "        X_train = X_train.drop(\"label\", axis = 1)\n",
    "\n",
    "        # Then normalize\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train.values)\n",
    "\n",
    "        # Create train dataset\n",
    "        X_train, Y_train = torch.from_numpy(X_train), torch.from_numpy(Y_train.values)\n",
    "        train_dataset = TensorDataset(X_train, Y_train)\n",
    "        train_arr.append(train_dataset)\n",
    "\n",
    "        # Normalize X_test\n",
    "        X_test = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Create test dataset\n",
    "        X_test, Y_test = torch.from_numpy(X_test), torch.from_numpy(Y_test_arr[i].values)\n",
    "        test_dataset = TensorDataset(X_test, Y_test)\n",
    "        test_arr.append(test_dataset)\n",
    "        \n",
    "    return train_arr, test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr, test_arr = normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da5b12",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = nn.ModuleList()\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nn.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nn.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # Initialze dropout\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            if inx == len(self.layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb08f2",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e892da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp(model, criterion, optimizer, train_dataloader, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in train_dataloader:\n",
    "            # Load to device\n",
    "            inputs, targets= inputs.to(device), targets.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs)\n",
    "            # get error\n",
    "            error = criterion(outputs, targets)\n",
    "            # Zero out the past gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Backprop\n",
    "            error.backward()\n",
    "            # Gradient Descent\n",
    "            optimizer.step()\n",
    "\n",
    "def eval_mlp(model, test_dataloader):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, targets) in enumerate(test_dataloader):\n",
    "            # Load to device\n",
    "            inputs = inputs.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs).detach().cpu().numpy().flatten()\n",
    "            # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "            outputs_all = np.concatenate([outputs_all, outputs])\n",
    "            targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_torch(model, lr, cv, train_arr, test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for i in range(cv):\n",
    "        # Get the dataloader\n",
    "        train_dataset = train_arr[i]\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, num_workers=0)\n",
    "        test_dataset = test_arr[i]\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers=0)\n",
    "\n",
    "        # Reinitialize the model\n",
    "        model.reset()\n",
    "        model.to(device)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp(model, criterion, optimizer, train_dataloader, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp(model, test_dataloader)\n",
    "        print(pearson)\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bc5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process of the default config\n",
    "hidden_layers_size = [16, 8, 4]\n",
    "lr = 0.001\n",
    "batch_size = 60\n",
    "num_epochs = 10\n",
    "\n",
    "mlpr = MLP(len(best_features), hidden_layers_size=hidden_layers_size, dropout = 0.3)\n",
    "\n",
    "train_eval_cv_torch(mlpr, lr, default_cv, train_arr, test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdd235",
   "metadata": {},
   "source": [
    "#### Sixth Iteration: Change this into a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65121481",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_classification(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5950bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_classification = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_xgboost_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_classification = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_lightgbm_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31960b41",
   "metadata": {},
   "source": [
    "#### Seventh Iteration: Search for the best way to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_training_scheme(model, train_df, cv = default_cv, features = None):\n",
    "    folds_trial = [\n",
    "        # level 1\n",
    "        [[0, 1, 2, 3]], \n",
    "        [[0, 1]], [[1, 2]], [[2, 3]],\n",
    "        [[0]], [[1]], [[2]], [[3]],\n",
    "        [[0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1], [2, 3]],\n",
    "        [[0], [1], [2], [3]],\n",
    "        # level 2\n",
    "        [[0, 1, 2, 3], [0, 1]],\n",
    "        [[0, 1, 2, 3], [1, 2]],\n",
    "        [[0, 1, 2, 3], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "        # level 3\n",
    "        [[0, 1, 2, 3], [0, 1], [0]],\n",
    "        [[0, 1, 2, 3], [2, 3], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "    ]\n",
    "\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "\n",
    "    for folds in folds_trial:\n",
    "        print(f\"Current folds list is {folds}\")\n",
    "        model_lst = [deepcopy(model)] * len(folds)\n",
    "        cv_pearson = []\n",
    "        for i in range(cv):\n",
    "            train_month = list(range(3 + i, 7 + i))\n",
    "            test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "            test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "            X_test, Y_test = test.drop([\"timestamp\", \"label\"], axis = 1), test[\"label\"]\n",
    "            Y_pred = np.zeros(Y_test.shape[0])\n",
    "            for j in range(len(folds)):\n",
    "                fold = folds[j]\n",
    "                model = model_lst[j]\n",
    "                train_month_curr = [train_month[f] for f in fold]\n",
    "                train_curr = train_df[train_df[\"timestamp\"].dt.month.isin(train_month_curr)].reset_index().drop(\"index\", axis = 1)\n",
    "                X_train, Y_train = train_curr.drop([\"timestamp\", \"label\"], axis = 1), train_curr[\"label\"]\n",
    "                model.fit(X_train, Y_train)\n",
    "                Y_pred += model.predict(X_test)\n",
    "            Y_pred /= len(folds)\n",
    "            cv_pearson.append(pearson_score(Y_test, Y_pred))\n",
    "            print(f\"Finish fold {i} with score: {pearson_score(Y_test, Y_pred)}\")\n",
    "        print(f\"Finish trial with mean score: {np.mean(np.array(cv_pearson))}\")\n",
    "        print(f\"Finish trial with std score: {np.std(np.array(cv_pearson))}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df66a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "search_training_scheme(xgbr, train_added_df)\n",
    "# Notable\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [1, 2]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]] \n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ea866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "search_training_scheme(lgbr, train_added_df)\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [0]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fe3ca",
   "metadata": {},
   "source": [
    "#### Eighth Iteration: rewrite the code for MLP training using MLX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f11bdd",
   "metadata": {},
   "source": [
    "Create the data for training + custom batch iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb028760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "# best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "#                  'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137', \n",
    "#                 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301'] \n",
    "                #  'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', \n",
    "                #  'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "# best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68496448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "#     X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "#     Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "#     Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02f14632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, cv=default_cv):\n",
    "    for i in range(cv):\n",
    "        # Normalize forst\n",
    "        scaler = StandardScaler()\n",
    "        X_train_arr[i] = scaler.fit_transform(X_train_arr[i].values)\n",
    "        X_test_arr[i] = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Convert to mlx format\n",
    "        X_train_arr[i] = mx.array(X_train_arr[i])\n",
    "        X_test_arr[i] = mx.array(X_test_arr[i])\n",
    "        Y_train_arr[i] = mx.array(Y_train_arr[i].values)\n",
    "        Y_test_arr[i] = mx.array(Y_test_arr[i].values)\n",
    "        \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3f916",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "993631c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# We do not use the reset method this time so you have to create the model at each fold\n",
    "class MLPMLX(nnmx.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = []\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nnmx.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nnmx.ReLU()\n",
    "\n",
    "        # Initialize dropout\n",
    "        self.dropout = nnmx.Dropout(p = dropout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if inx != len(self.layers) - 1:\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33907ab7",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78aaa51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for batch iteration\n",
    "def batch_iterate(batch_size, X, Y, shuffle = True):\n",
    "    for i in range(0, Y.size, batch_size):\n",
    "        X_curr = X[i: min(i + batch_size, Y.size), :]\n",
    "        Y_curr = Y[i: min(i + batch_size, Y.size)]\n",
    "        if shuffle:\n",
    "            inx_lst = mx.random.permutation(batch_size)\n",
    "            X_curr = X_curr[inx_lst, :]\n",
    "            Y_curr = Y_curr[inx_lst]\n",
    "        yield X_curr, Y_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a72a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            _, grads = loss_and_grad_fn(model, inputs, targets)\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            optimizer.update(model, grads)\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(model.parameters(), optimizer.state)\n",
    "\n",
    "def eval_mlp_mlx(model, X_test, Y_test, batch_size):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    for (inputs, targets) in batch_iterate(batch_size, X_test, Y_test, shuffle=False):\n",
    "        outputs = model(inputs).reshape(-1)\n",
    "        # convert back to numpy\n",
    "        outputs, targets = np.array(outputs), np.array(targets)\n",
    "        # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "        outputs_all = np.concatenate([outputs_all, outputs])\n",
    "        targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3974705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for _, (X_train, X_test, Y_train, Y_test) in enumerate(zip(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)):\n",
    "        # initialize the model\n",
    "        mx.random.seed(default_random_state)\n",
    "        model = MLPMLX(num_features, hidden_layers_size, dropout)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        def loss_fn(model, X, Y):\n",
    "            Y_pred = model(X).reshape(-1)\n",
    "            return mx.mean(nnmx.losses.mse_loss(Y_pred, Y))\n",
    "        loss_and_grad_fn = nnmx.value_and_grad(model, loss_fn)\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optimmx.Adam(learning_rate = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp_mlx(model, X_test, Y_test, batch_size)\n",
    "        print(pearson)\n",
    "        if pearson == -1:\n",
    "            return pearson\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0617236",
   "metadata": {},
   "source": [
    "Conduct training and evaluating process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a75900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training process of the default config\n",
    "# num_features = len(best_features)\n",
    "# hidden_layers_size = [8, 8, 8]\n",
    "# dropout = 0.2\n",
    "# lr = 0.001\n",
    "# batch_size = 180\n",
    "# num_epochs = 10\n",
    "\n",
    "# train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad94fa",
   "metadata": {},
   "source": [
    "Conduct Bayesian Optimization on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b347651",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "820f5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp_mlx(trial):\n",
    "    # First initialize the parameters\n",
    "    num_features = len(best_features)\n",
    "    num_layers = default_num_layers\n",
    "    log_2_hidden_layers_size = []\n",
    "    for i in range(num_layers):\n",
    "        if len(log_2_hidden_layers_size) == 0:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, 6))\n",
    "        else:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, log_2_hidden_layers_size[-1]))\n",
    "    hidden_layers_size = [2**l for l in log_2_hidden_layers_size]\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.7)\n",
    "    lr = trial.suggest_float(\"lr\", 0.0001, 0.01, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [30, 60, 120, 180, 360, 720])\n",
    "    num_epochs = trial.suggest_categorical(\"num_epochs\", [10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "    \n",
    "    # Conduct training based on those parameters\n",
    "    return train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e305bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mlp_mlx(study_name, storage_name, objective_function=objective_mlp_mlx, n_trials = 100, n_jobs = 1):\n",
    "    print(\"Conduct hyperparam opt for MLP\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcca3193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6] [8, 9, 10, 11]\n",
      "[4, 5, 6, 7] [9, 10, 11, 12]\n",
      "[5, 6, 7, 8] [10, 11, 12, 1]\n",
      "[6, 7, 8, 9] [11, 12, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "                 'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137',]\n",
    "                # 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301',] \n",
    "                #  'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', \n",
    "                #  'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features)\n",
    "\n",
    "# Convert to float32\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "\n",
    "# Convert to MLX\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08e30381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-08 12:47:28,373] A new study created in RDB with name: mlp_mlx_2_4_101_1_common_truncated_20_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:17<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1354244937447434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:17<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15794843671552705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:18<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11990150297965195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.64it/s]\n",
      "[I 2025-07-08 12:48:38,226] Trial 0 finished with value: 0.12760028768572979 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.48533379343406985, 'lr': 0.00011401144576866207, 'batch_size': 360, 'num_epochs': 60}. Best is trial 0 with value: 0.12760028768572979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09712671730299671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:36<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12654283329769164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:35<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13679583381196705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:35<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04961185550472564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:35<00:00,  1.96it/s]\n",
      "[I 2025-07-08 12:51:02,262] Trial 1 finished with value: 0.09584544514565954 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.5426531643900891, 'lr': 0.0010857627761370686, 'batch_size': 180, 'num_epochs': 70}. Best is trial 0 with value: 0.12760028768572979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07043125796825386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13251954890938447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16303848445345395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1328321987574123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.31it/s]\n",
      "[I 2025-07-08 12:52:05,129] Trial 2 finished with value: 0.13371565200910307 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6612346862836118, 'lr': 0.00015642024418779235, 'batch_size': 120, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10647237591616154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:39<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08180821224960928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:39<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10020222571973178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:41<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09151585367619679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.28it/s]\n",
      "[I 2025-07-08 12:54:45,960] Trial 3 finished with value: 0.08211748190020414 and parameters: {'log2_hidden_layer_0': 2, 'dropout': 0.22640420054463312, 'lr': 0.00022727614012638906, 'batch_size': 120, 'num_epochs': 50}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054943635955278666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09794925651346865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11198483684818133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0726175050073553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.44it/s]\n",
      "[I 2025-07-08 12:55:13,267] Trial 4 finished with value: 0.08828709410878775 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.4648116993765072, 'lr': 0.003140803308225737, 'batch_size': 720, 'num_epochs': 50}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07059677806614571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07579310445248721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:31<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11655509044266833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04085231728782849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.06s/it]\n",
      "[I 2025-07-08 12:57:21,490] Trial 5 finished with value: 0.07571581673407579 and parameters: {'log2_hidden_layer_0': 6, 'dropout': 0.3924688730312222, 'lr': 0.0012686203981887116, 'batch_size': 30, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06966275475331915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:09<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12459213059544945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:09<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1369229372897704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:09<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09062738627227766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:09<00:00,  7.11it/s]\n",
      "[I 2025-07-08 12:58:00,476] Trial 6 finished with value: 0.11295463472946025 and parameters: {'log2_hidden_layer_0': 6, 'dropout': 0.5682456656339292, 'lr': 0.0002998670698625724, 'batch_size': 720, 'num_epochs': 70}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0996760847603435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10345023125448581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14585027371107356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07130139165247941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:39<00:00,  1.28it/s]\n",
      "[I 2025-07-08 13:00:36,700] Trial 7 finished with value: 0.08857291627436752 and parameters: {'log2_hidden_layer_0': 6, 'dropout': 0.21165274619931057, 'lr': 0.0012478457141046418, 'batch_size': 120, 'num_epochs': 50}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03368976847943129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08223043647263979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10981231453942253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08952583780349228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27it/s]\n",
      "[I 2025-07-08 13:01:10,033] Trial 8 finished with value: 0.08797435414886179 and parameters: {'log2_hidden_layer_0': 2, 'dropout': 0.642520594272805, 'lr': 0.000357143245968115, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07032882777989259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:21<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0427030596599554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:22<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1153749929587024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:21<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055262951413567456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:21<00:00,  3.72it/s]\n",
      "[I 2025-07-08 13:02:37,553] Trial 9 finished with value: 0.06846679918968351 and parameters: {'log2_hidden_layer_0': 6, 'dropout': 0.35131190089149067, 'lr': 0.0016540298012824451, 'batch_size': 360, 'num_epochs': 80}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060526192726508804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05703333439716173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17176934902354848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02387997650567019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.52s/it]\n",
      "[I 2025-07-08 13:04:42,875] Trial 10 finished with value: 0.06414438381222973 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6926149132172468, 'lr': 0.0070899951046823765, 'batch_size': 60, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0038948753225385335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13532862688667924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15788726870200426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12140716346179681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.93it/s]\n",
      "[I 2025-07-08 13:05:45,829] Trial 11 finished with value: 0.12822353598885952 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5624231307674092, 'lr': 0.00010547614465309742, 'batch_size': 360, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09827108490495774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11879358087506876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12921615502083894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09495908600828067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.85it/s]\n",
      "[I 2025-07-08 13:06:06,935] Trial 12 finished with value: 0.10063068430296998 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.6108716449880092, 'lr': 0.00010640347180264444, 'batch_size': 360, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059553915307691566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [02:58<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12360864973788237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [02:55<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13635626039770904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [02:56<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06963762475419139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [02:52<00:00,  2.87s/it]\n",
      "[I 2025-07-08 13:17:55,094] Trial 13 finished with value: 0.10235460173855032 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.6913290970275929, 'lr': 0.0004648786307758226, 'batch_size': 30, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07981587206441845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:14<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12510873333650563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:14<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13967908108061258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:14<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11182465355504795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:14<00:00,  2.06it/s]\n",
      "[I 2025-07-08 13:18:54,477] Trial 14 finished with value: 0.11822078277985068 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.5418030881644968, 'lr': 0.00019921244619599797, 'batch_size': 180, 'num_epochs': 30}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09627066314723659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [02:11<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13900682866563419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [02:11<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1506326687490932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [02:13<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07075306987567664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [02:11<00:00,  1.46s/it]\n",
      "[I 2025-07-08 13:27:44,886] Trial 15 finished with value: 0.10978834013429827 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.6160187840759288, 'lr': 0.0004611282767574715, 'batch_size': 60, 'num_epochs': 90}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07876079324678904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1350814142981342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15923191547478974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12835072353903443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.38it/s]\n",
      "[I 2025-07-08 13:29:42,636] Trial 16 finished with value: 0.13189130654229445 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.39970061968974435, 'lr': 0.00014763021858201237, 'batch_size': 120, 'num_epochs': 40}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10490117285721948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1216728848077518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12544864786790885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06889894366746709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:28<00:00,  1.38it/s]\n",
      "[I 2025-07-08 13:31:40,128] Trial 17 finished with value: 0.10274877087095431 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.34034451512035274, 'lr': 0.0006608902651086694, 'batch_size': 120, 'num_epochs': 40}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09497460714068952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12491877429441146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13169895920494465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10203156194253041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.38it/s]\n",
      "[I 2025-07-08 13:33:37,955] Trial 18 finished with value: 0.11354034340819 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.41025583641707525, 'lr': 0.00017997715671745228, 'batch_size': 120, 'num_epochs': 40}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0955120781908735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0987740146721907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13376157818751228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08942110410900074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:29<00:00,  1.37it/s]\n",
      "[I 2025-07-08 13:35:36,331] Trial 19 finished with value: 0.10443539517861883 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.27534033898794075, 'lr': 0.0006899733919241115, 'batch_size': 120, 'num_epochs': 40}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09578488374577158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:12<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12251391188244072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:12<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13484352550747628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:13<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07666744728991688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:12<00:00,  1.39it/s]\n",
      "[I 2025-07-08 13:40:27,732] Trial 20 finished with value: 0.10799141567384357 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.4892620635779577, 'lr': 0.00017052214186931875, 'batch_size': 120, 'num_epochs': 100}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09794077801554038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12809537674573646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15311338517944598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12352402105235315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.04it/s]\n",
      "[I 2025-07-08 13:40:48,135] Trial 21 finished with value: 0.12419620317942803 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5822138124688291, 'lr': 0.0001168390788948932, 'batch_size': 360, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0920520297401766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:14<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13565537853320603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:14<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15748938242569344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12079621285951829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:14<00:00,  4.01it/s]\n",
      "[I 2025-07-08 13:41:48,489] Trial 22 finished with value: 0.12765905145552453 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5161547028800869, 'lr': 0.00010119759610130922, 'batch_size': 360, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09669523200368037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:21<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11866564527081826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13021599704144185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:22<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10059616156178458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:21<00:00,  1.37it/s]\n",
      "[I 2025-07-08 13:43:17,416] Trial 23 finished with value: 0.11148034552170732 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.4301781808479258, 'lr': 0.0002773118607905075, 'batch_size': 120, 'num_epochs': 30}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09644357821278463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13274645421602094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.156051321085285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11943713500691558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  7.98it/s]\n",
      "[I 2025-07-08 13:44:02,929] Trial 24 finished with value: 0.12834113187525512 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6465513259692508, 'lr': 0.00015330185399132728, 'batch_size': 720, 'num_epochs': 90}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10512961719279905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13225136423649653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1560516466450809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11833274931315875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  7.97it/s]\n",
      "[I 2025-07-08 13:44:48,444] Trial 25 finished with value: 0.12806220484240322 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6625886285245972, 'lr': 0.00015769833767767283, 'batch_size': 720, 'num_epochs': 90}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10561305917487669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11575833152575894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12393800545522975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07687678680626193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:11<00:00,  8.03it/s]\n",
      "[I 2025-07-08 13:45:33,748] Trial 26 finished with value: 0.10145748342510055 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.3183009364531869, 'lr': 0.00040435874307540465, 'batch_size': 720, 'num_epochs': 90}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08925680991315162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:09<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1386696755572118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:10<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1404402116416906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:10<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049583268318181384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:10<00:00,  7.96it/s]\n",
      "[I 2025-07-08 13:46:14,215] Trial 27 finished with value: 0.10076619691874189 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6413669956338547, 'lr': 0.00281501098346779, 'batch_size': 720, 'num_epochs': 80}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07437163215788378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:48<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09940397017693207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:47<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1442361447409763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:50<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06636362284891006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:59<00:00,  2.99s/it]\n",
      "[I 2025-07-08 14:05:44,392] Trial 28 finished with value: 0.09841164672350558 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.3748104178197583, 'lr': 0.00024492779076705967, 'batch_size': 30, 'num_epochs': 100}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08364284912720389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:47<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12679376008431956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:45<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15906997959010222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:45<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10465484933745929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:45<00:00,  1.98it/s]\n",
      "[I 2025-07-08 14:08:49,687] Trial 29 finished with value: 0.12275669396880698 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.49086181614628965, 'lr': 0.00014171408734057927, 'batch_size': 180, 'num_epochs': 90}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10050818686334685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:00<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.011874893287056685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:00<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11243760152500237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024079603489844253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:00<00:00,  1.51s/it]\n",
      "[I 2025-07-08 14:12:54,524] Trial 30 finished with value: -0.02148426767100166 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.45876978424712833, 'lr': 0.00906904035227868, 'batch_size': 60, 'num_epochs': 40}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01429582063820817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13363531699686806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1584983446565978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12446631282070401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.84it/s]\n",
      "[I 2025-07-08 14:13:57,863] Trial 31 finished with value: 0.13056185088808026 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5986839523495175, 'lr': 0.00014481383816607505, 'batch_size': 360, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10564742907815111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12495602115500704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15047304279859158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12348800515845945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.37it/s]\n",
      "[I 2025-07-08 14:14:08,903] Trial 32 finished with value: 0.12162151860136625 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6085094741222699, 'lr': 0.00013981083197038688, 'batch_size': 720, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08756900529340694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:45<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12068583666442502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:45<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15237291368881584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:46<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09648544287039908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:45<00:00,  1.31it/s]\n",
      "[I 2025-07-08 14:17:13,563] Trial 33 finished with value: 0.11894135631616193 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6598247769850475, 'lr': 0.00020873349055787067, 'batch_size': 120, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10622123204100781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:18<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12220232028665999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:18<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1320921094583992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:18<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06994526693881749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:18<00:00,  3.82it/s]\n",
      "[I 2025-07-08 14:18:27,666] Trial 34 finished with value: 0.10457033743607504 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.5321799620159445, 'lr': 0.0006094867566869692, 'batch_size': 360, 'num_epochs': 70}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09404165306042352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:45<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12410843139503305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:45<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1396670628049336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:45<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06322657564920962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:45<00:00,  1.97it/s]\n",
      "[I 2025-07-08 14:21:31,170] Trial 35 finished with value: 0.10546676858078262 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.5907173121903424, 'lr': 0.0003200231721150614, 'batch_size': 180, 'num_epochs': 90}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09486500447395417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:05<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13368488337589945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:05<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15744026146643633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:05<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12111965957843775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:05<00:00,  7.44it/s]\n",
      "[I 2025-07-08 14:21:52,895] Trial 36 finished with value: 0.12807817359033188 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6996006891037465, 'lr': 0.0002283094032864045, 'batch_size': 720, 'num_epochs': 40}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10006788994055404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1301877844681106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1568292570100989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13038030424759062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30it/s]\n",
      "[I 2025-07-08 14:22:25,144] Trial 37 finished with value: 0.12924284569416603 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6656823851551276, 'lr': 0.00013817991364382227, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09957403705086394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09240331354116717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09500022245603226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05964259332057927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.31it/s]\n",
      "[I 2025-07-08 14:22:57,170] Trial 38 finished with value: 0.07331729418428087 and parameters: {'log2_hidden_layer_0': 2, 'dropout': 0.6754653817286873, 'lr': 0.000132008915924904, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046223047419344784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12276863282807556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1306888541502155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11203169423921656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.31it/s]\n",
      "[I 2025-07-08 14:23:29,261] Trial 39 finished with value: 0.11292009285058274 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.289700702592649, 'lr': 0.0002624394802125138, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08619119018482334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12594580182534235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15245988998158266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08302361999702633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.30it/s]\n",
      "[I 2025-07-08 14:26:04,295] Trial 40 finished with value: 0.11204637890780457 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.625066458099046, 'lr': 0.000903331103359946, 'batch_size': 120, 'num_epochs': 50}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08675620382726697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13142974299906504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16036644828714028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1318778312450848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]\n",
      "[I 2025-07-08 14:26:36,820] Trial 41 finished with value: 0.13146661019841105 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6470235225841743, 'lr': 0.00017048516021811837, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10219241826235406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1315972910279485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16106108331698885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1320126528821304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.31it/s]\n",
      "[I 2025-07-08 14:27:09,173] Trial 42 finished with value: 0.131505394467535 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.635019848757596, 'lr': 0.00017739000041033776, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10135055064307225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13230320946722965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16205450669477423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13316850831318758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27it/s]\n",
      "[I 2025-07-08 14:27:42,017] Trial 43 finished with value: 0.13134473097342342 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5851864115945808, 'lr': 0.00019668752552389737, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09785269941850215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11751966825931706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1461724298392277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11459692878974381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30it/s]\n",
      "[I 2025-07-08 14:28:14,145] Trial 44 finished with value: 0.12002482321683762 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.6322104820837163, 'lr': 0.0003486562478104974, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10181026597906188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1228154720009866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1408876471750822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11293969473146141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]\n",
      "[I 2025-07-08 14:28:46,769] Trial 45 finished with value: 0.1147324251838388 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.5654527325431701, 'lr': 0.00019915789067294115, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08228688682782498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10247305806303222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13199638000035638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059233898758244696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]\n",
      "[I 2025-07-08 14:29:19,326] Trial 46 finished with value: 0.0908037128855991 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.43931875922752084, 'lr': 0.0019313066192562605, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06951151472076313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07087168272442612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.116955569414986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04058562602204814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.28it/s]\n",
      "[I 2025-07-08 14:29:51,967] Trial 47 finished with value: 0.07046645323037214 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5779702259829143, 'lr': 0.005120343690285784, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05345293476002826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1260901805145974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1478254264096473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12173709415904484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:30<00:00,  3.07s/it]\n",
      "[I 2025-07-08 14:31:59,849] Trial 48 finished with value: 0.12393360345486365 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.5177046461262229, 'lr': 0.00018453708291305253, 'batch_size': 30, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1000817127361651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1167671145703395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1276722378855821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10539072145840672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.28it/s]\n",
      "[I 2025-07-08 14:33:03,831] Trial 49 finished with value: 0.11094424291536936 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.3897073294193937, 'lr': 0.00028567395590886125, 'batch_size': 120, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09394689774714914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:54<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07007156073810941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:55<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12447910289046898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:55<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047602856336522475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:53<00:00,  1.30it/s]\n",
      "[I 2025-07-08 14:36:44,367] Trial 50 finished with value: 0.07781313432028764 and parameters: {'log2_hidden_layer_0': 2, 'dropout': 0.687421846597532, 'lr': 0.0005310547185663014, 'batch_size': 120, 'num_epochs': 70}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0690990173160497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13479304315466226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15825560722622434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12779704853275822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.70it/s]\n",
      "[I 2025-07-08 14:37:49,338] Trial 51 finished with value: 0.1311621185205162 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.599817296539226, 'lr': 0.00011971887233370113, 'batch_size': 360, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10380277516842011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:04<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11723022681523437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:04<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15277571046553604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:05<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09073886373063164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:03<00:00,  1.54s/it]\n",
      "[I 2025-07-08 14:46:08,766] Trial 52 finished with value: 0.11583795126099611 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6218311397563053, 'lr': 0.00012192215962417914, 'batch_size': 60, 'num_epochs': 80}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10260700403258241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13169139760048781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15775398094263476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:39<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12360876628955596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:38<00:00,  1.29it/s]\n",
      "[I 2025-07-08 14:48:46,080] Trial 53 finished with value: 0.12993726731340013 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5546529106570303, 'lr': 0.00010369628992252433, 'batch_size': 120, 'num_epochs': 50}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10669492442092199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:07<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13179151274857873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:07<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15988610186719024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:07<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12872584430374923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:07<00:00,  3.82it/s]\n",
      "[I 2025-07-08 14:49:18,218] Trial 54 finished with value: 0.13016821884489477 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6500568573540949, 'lr': 0.00017172319030216913, 'batch_size': 360, 'num_epochs': 30}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10026941646006089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.128696775235558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16218323753490527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:18<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12786765479159312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:16<00:00,  1.20it/s]\n",
      "[I 2025-07-08 14:50:25,661] Trial 55 finished with value: 0.13032994306251114 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.600113408318019, 'lr': 0.00022024185186880706, 'batch_size': 120, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10257210468798818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:53<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12781087475301736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:46<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1569780184085816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:46<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11888224696776334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:51<00:00,  1.18it/s]\n",
      "[I 2025-07-08 14:53:44,966] Trial 56 finished with value: 0.12788194867281627 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6751466603525904, 'lr': 0.00011406806499386118, 'batch_size': 120, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10785665456190277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12792083353211117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1575655706379337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1276681541499048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.63it/s]\n",
      "[I 2025-07-08 14:54:10,229] Trial 57 finished with value: 0.1269584924205644 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.41793076104118876, 'lr': 0.0003866619248464587, 'batch_size': 180, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09467941136230795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12337139008544447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1392475067708556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:13<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11322508941096344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:12<00:00,  3.27it/s]\n",
      "[I 2025-07-08 14:55:00,931] Trial 58 finished with value: 0.1179351923212921 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.640608648687016, 'lr': 0.00018907820226998805, 'batch_size': 360, 'num_epochs': 40}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09589678301790487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:36<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11726763300483142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:34<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14592376929159584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:36<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10587842463893894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:46<00:00,  4.70s/it]\n",
      "[I 2025-07-08 14:57:44,365] Trial 59 finished with value: 0.11688319503471195 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.46908559388520316, 'lr': 0.00016643349364551014, 'batch_size': 30, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09846295320348164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13283466340852199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:27<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15751406299884477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:18<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10862827410797947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:25<00:00,  1.17it/s]\n",
      "[I 2025-07-08 15:04:08,685] Trial 60 finished with value: 0.12504483811741404 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.35439377662958366, 'lr': 0.00012251157062988545, 'batch_size': 120, 'num_epochs': 100}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10120235195430995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13337593851091795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15840900186876725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12347422952310086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:17<00:00,  3.37it/s]\n",
      "[I 2025-07-08 15:05:15,946] Trial 61 finished with value: 0.12973459994029912 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.595437005106563, 'lr': 0.0001503738248100814, 'batch_size': 360, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10367922985841047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:17<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12413698630540729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:15<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.159250346784831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10895156051206659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.64it/s]\n",
      "[I 2025-07-08 15:06:21,869] Trial 62 finished with value: 0.12435828730474444 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6163474119389707, 'lr': 0.0002490821835166894, 'batch_size': 360, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10509425561667284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:17<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13460295345642428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15828444959187313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:17<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12711327956619467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:18<00:00,  3.29it/s]\n",
      "[I 2025-07-08 15:07:32,465] Trial 63 finished with value: 0.13023600933642232 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5773086525552491, 'lr': 0.00012733863069967346, 'batch_size': 360, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10094335473119724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:19<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13549213661952716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:18<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15755769110590537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:17<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12116793621555683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:16<00:00,  3.57it/s]\n",
      "[I 2025-07-08 15:08:44,981] Trial 64 finished with value: 0.1278791594749057 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.546040263357854, 'lr': 0.00010068842680770796, 'batch_size': 360, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09729887395863338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12800689721534494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:16<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13712054108469338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:15<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11544061392018222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:17<00:00,  1.17it/s]\n",
      "[I 2025-07-08 15:09:51,382] Trial 65 finished with value: 0.12067447633116396 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.6087613978221642, 'lr': 0.00015620157678051773, 'batch_size': 120, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10212985310443531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:10<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11876887150754989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:11<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1484948449512405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:11<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09673262748839218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [01:11<00:00,  1.79s/it]\n",
      "[I 2025-07-08 15:14:39,124] Trial 66 finished with value: 0.11754003625707707 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6527393145213072, 'lr': 0.00021705535217685597, 'batch_size': 60, 'num_epochs': 40}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10616380108112573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13069554284653598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:24<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15681985745654378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:22<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10996269538506086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:23<00:00,  3.43it/s]\n",
      "[I 2025-07-08 15:16:13,577] Trial 67 finished with value: 0.12561093806855428 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6760973537269692, 'lr': 0.00016950720066340966, 'batch_size': 360, 'num_epochs': 80}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10496565658607644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:52<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11749781850404513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13562677209575882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:02<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07567743965455576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [01:02<00:00,  1.04s/it]\n",
      "[I 2025-07-08 15:20:14,152] Trial 68 finished with value: 0.10681545106106825 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.6340655089967363, 'lr': 0.00029985660506859, 'batch_size': 120, 'num_epochs': 60}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0984597739899133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [01:06<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12165240993754974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [01:08<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1375364933571128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [01:12<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10045154682432962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [01:13<00:00,  1.06s/it]\n",
      "[I 2025-07-08 15:24:57,584] Trial 69 finished with value: 0.11432794182529352 and parameters: {'log2_hidden_layer_0': 3, 'dropout': 0.5273888059171326, 'lr': 0.00014156845769122805, 'batch_size': 120, 'num_epochs': 70}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0976713171821819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13125352745521812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16366590225804473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:21<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12218363262622435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:20<00:00,  1.45it/s]\n",
      "[I 2025-07-08 15:26:22,037] Trial 70 finished with value: 0.12951609265059008 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5895144945979736, 'lr': 0.00019726743968479182, 'batch_size': 180, 'num_epochs': 30}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10096130826287318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12838885217743196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15933137786060378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12681429024506072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.06s/it]\n",
      "[I 2025-07-08 15:27:49,186] Trial 71 finished with value: 0.12986313253154988 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.594563695279104, 'lr': 0.00022473024564800863, 'batch_size': 120, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1049180098431031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12702392308798502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15889889682522124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1253025979569769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:20<00:00,  1.05s/it]\n",
      "[I 2025-07-08 15:29:15,810] Trial 72 finished with value: 0.12933172511311544 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6079891095464981, 'lr': 0.00023729149100236362, 'batch_size': 120, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10610148258227865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1349799889070742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15876772097389358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1287703288589505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:20<00:00,  1.05s/it]\n",
      "[I 2025-07-08 15:30:42,167] Trial 73 finished with value: 0.13029130130268748 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.5571445226201693, 'lr': 0.0001148672535816629, 'batch_size': 120, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09864716647083167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13364397447646556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1625897786063801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1339488848432667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:20<00:00,  1.04s/it]\n",
      "[I 2025-07-08 15:32:08,603] Trial 74 finished with value: 0.13298969829700807 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6266821039913443, 'lr': 0.00014610880910106093, 'batch_size': 120, 'num_epochs': 20}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10177615526191995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11939261945079482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14842990569569864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11240341641806668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.87it/s]\n",
      "[I 2025-07-08 15:32:22,972] Trial 75 finished with value: 0.11391170025800892 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6652058914516523, 'lr': 0.00013048434447137774, 'batch_size': 360, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07542085946747554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:40<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12710881446982333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:41<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15919861360404788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:41<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12117293925398569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:40<00:00,  1.02s/it]\n",
      "[I 2025-07-08 15:35:08,431] Trial 76 finished with value: 0.12837184260799075 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6346498866005631, 'lr': 0.00015688612720118162, 'batch_size': 120, 'num_epochs': 40}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10600700310410613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:51<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12114600782631907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:49<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15720949061422046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:51<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10843360304495862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:50<00:00,  1.01s/it]\n",
      "[I 2025-07-08 15:38:33,072] Trial 77 finished with value: 0.12265666454003568 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6269444947521061, 'lr': 0.00017889910231869187, 'batch_size': 120, 'num_epochs': 50}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10383755667464456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [06:07<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09379497126734952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [06:25<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15253599363960008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [06:28<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0665718607181914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [06:33<00:00,  3.93s/it]\n",
      "[I 2025-07-08 16:04:13,339] Trial 78 finished with value: 0.09310092166010413 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6861744353058394, 'lr': 0.0009459221505201601, 'batch_size': 30, 'num_epochs': 100}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05950086101527545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1299623398320896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1305455583607906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11896505877935072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.04s/it]\n",
      "[I 2025-07-08 16:04:56,921] Trial 79 finished with value: 0.11628973400195507 and parameters: {'log2_hidden_layer_0': 5, 'dropout': 0.39387874194769823, 'lr': 0.00014225854121123566, 'batch_size': 120, 'num_epochs': 10}. Best is trial 2 with value: 0.13371565200910307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08568597903558933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:40<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13141584902562586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:36<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16392214356704873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:35<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13705952408288613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.54s/it]\n",
      "[I 2025-07-08 16:07:22,679] Trial 80 finished with value: 0.13573289974055264 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6481374864980073, 'lr': 0.00011089472820919897, 'batch_size': 60, 'num_epochs': 20}. Best is trial 80 with value: 0.13573289974055264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1105340822866499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13111147646032123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16378114173661545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:34<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13680498321521117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.63s/it]\n",
      "[I 2025-07-08 16:09:36,017] Trial 81 finished with value: 0.13554167101682704 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6529710849048741, 'lr': 0.00011253742273971315, 'batch_size': 60, 'num_epochs': 20}. Best is trial 80 with value: 0.13573289974055264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11046908265516035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1306282484255283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16367651031424915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13582330514842952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.55s/it]\n",
      "[I 2025-07-08 16:11:47,094] Trial 82 finished with value: 0.13510878376465565 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.649869808719525, 'lr': 0.00011802397033884457, 'batch_size': 60, 'num_epochs': 20}. Best is trial 80 with value: 0.13573289974055264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11030707117041556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1314870929360196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16383458520469132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13705520971167506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.59s/it]\n",
      "[I 2025-07-08 16:13:54,929] Trial 83 finished with value: 0.13578952147540216 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6484428133617176, 'lr': 0.00011088807292761746, 'batch_size': 60, 'num_epochs': 20}. Best is trial 83 with value: 0.13578952147540216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11078119804922264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1323311465850472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16440662917548385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13843117840845845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.57s/it]\n",
      "[I 2025-07-08 16:16:02,134] Trial 84 finished with value: 0.1363927058009744 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6564983391745214, 'lr': 0.00010302965349528251, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11040186903490817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1314952354932313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:36<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16410448872947606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:37<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1377615949816473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.67s/it]\n",
      "[I 2025-07-08 16:18:24,151] Trial 85 finished with value: 0.13597616422144174 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6595728307115691, 'lr': 0.00010799408778210877, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11054333768141225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:34<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13145884674108896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:37<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16397227512233348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:35<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13756375602448812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:35<00:00,  1.76s/it]\n",
      "[I 2025-07-08 16:20:50,345] Trial 86 finished with value: 0.13589191496523917 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6590067468771843, 'lr': 0.0001092385581219941, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11057278197304606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:34<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12005965001473755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13333068974506296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09862917711162665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.64s/it]\n",
      "[I 2025-07-08 16:23:06,231] Trial 87 finished with value: 0.11438997074971025 and parameters: {'log2_hidden_layer_0': 6, 'dropout': 0.65856821238203, 'lr': 0.0001079450721433277, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10554036612741381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.131754143945742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16425836546756417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13815723557666015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.69s/it]\n",
      "[I 2025-07-08 16:25:20,384] Trial 88 finished with value: 0.13601485187826284 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6993734711167882, 'lr': 0.00010158738525449899, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10988966252308512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1317331477401004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16427958992841238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13789794379070125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:35<00:00,  1.77s/it]\n",
      "[I 2025-07-08 16:27:37,665] Trial 89 finished with value: 0.13597887526600722 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6987731127759808, 'lr': 0.00010254890412084444, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11000481960481484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13159617376634794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1642976859288331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:30<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1379531609237338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.55s/it]\n",
      "[I 2025-07-08 16:29:47,784] Trial 90 finished with value: 0.1359516885996195 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6993640050247971, 'lr': 0.00010286025318453452, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10995973377956322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:34<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13190503623290942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16416339812531427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1382336592979158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.65s/it]\n",
      "[I 2025-07-08 16:32:04,201] Trial 91 finished with value: 0.136097349473497 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6963767840381105, 'lr': 0.00010166769719790664, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11008730423784846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13188883008143398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16418891967804586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13809889759564023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.64s/it]\n",
      "[I 2025-07-08 16:34:18,054] Trial 92 finished with value: 0.13613624483417489 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6904999880324129, 'lr': 0.00010131464460118073, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11036833198157943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:31<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13200434348500747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:33<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16419692694183888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:35<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13834348829420134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:36<00:00,  1.85s/it]\n",
      "[I 2025-07-08 16:36:38,627] Trial 93 finished with value: 0.1362171851533347 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6918959052495159, 'lr': 0.0001010769262936787, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11032398189229112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13182465480939856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:36<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16421235207258095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:43<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13831863066366315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:41<00:00,  2.09s/it]\n",
      "[I 2025-07-08 16:39:15,539] Trial 94 finished with value: 0.13607741370519613 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6986318426808387, 'lr': 0.00010120128631771748, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10995401727514188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:41<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1318299810261119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:41<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16420005348109257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1383784920668416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.99s/it]\n",
      "[I 2025-07-08 16:42:00,350] Trial 95 finished with value: 0.13608540701942123 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6998840989109383, 'lr': 0.00010068586548952529, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10993310150363889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1289749597748769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16413093647448065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13368606855263893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:40<00:00,  2.01s/it]\n",
      "[I 2025-07-08 16:44:42,286] Trial 96 finished with value: 0.13447015213879454 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6965611207006063, 'lr': 0.00012922363915374702, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11108864375318166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:40<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13172274218046362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:40<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16391969791207311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13770000205022204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:38<00:00,  1.94s/it]\n",
      "[I 2025-07-08 16:47:25,158] Trial 97 finished with value: 0.13589359835002016 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6822658876936356, 'lr': 0.00010507293369832689, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11023195125732184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1319674038790983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16427290160045205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13841333665351888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:39<00:00,  1.95s/it]\n",
      "[I 2025-07-08 16:50:05,139] Trial 98 finished with value: 0.1361774938535733 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6983469572106482, 'lr': 0.00010052293343784851, 'batch_size': 60, 'num_epochs': 20}. Best is trial 84 with value: 0.1363927058009744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11005633328122401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13242163480736827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:29<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16454169535873153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:29<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1385079986964512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:29<00:00,  1.46s/it]\n",
      "[I 2025-07-08 16:52:08,009] Trial 99 finished with value: 0.13647459350718286 and parameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6743230512784762, 'lr': 0.00010024548511849526, 'batch_size': 60, 'num_epochs': 20}. Best is trial 99 with value: 0.13647459350718286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11042704516618043\n",
      "Best hyperparameters: {'log2_hidden_layer_0': 4, 'dropout': 0.6743230512784762, 'lr': 0.00010024548511849526, 'batch_size': 60, 'num_epochs': 20}\n",
      "Best Pearson score: 0.13647459350718286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'log2_hidden_layer_0': 4,\n",
       " 'dropout': 0.6743230512784762,\n",
       " 'lr': 0.00010024548511849526,\n",
       " 'batch_size': 60,\n",
       " 'num_epochs': 20}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_mlp_mlx(\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\",\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196766ca",
   "metadata": {},
   "source": [
    "#### Nineth Iteration: AE + MLP instead of GBDT feature selection + MLP (train together)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c02845",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gaussian noise for autoencoder\n",
    "class GaussianNoise(nnmx.Module):\n",
    "    def __init__(self, mean: float = 0.0, stddev: float = 0.01):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self, x, training = True):\n",
    "        if training:\n",
    "            x += mx.random.normal(loc=self.mean, scale=self.stddev, shape=x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568359d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# We do not use the reset method this time so you have to create the model at each fold\n",
    "class AEMLX(nnmx.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, latent_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers for encoder\n",
    "        last_layer = num_features\n",
    "        self.encoder_layers = []\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.encoder_layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.encoder_layers.append(nnmx.Linear(last_layer, latent_size))\n",
    "\n",
    "        # Initialize layers for decoder\n",
    "        last_layer = latent_size\n",
    "        self.decoder_layers = []\n",
    "        for current_layer in hidden_layers_size[::-1]:\n",
    "            self.decoder_layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.decoder_layers.append(nnmx.Linear(last_layer, num_features))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nnmx.ReLU()\n",
    "\n",
    "        # Initialze gaussian noise to apply upon training\n",
    "        self.gaussian_noise = GaussianNoise()\n",
    "\n",
    "        # Initialize dropout\n",
    "        self.dropout = nnmx.Dropout(p = dropout)\n",
    "\n",
    "    def __call__(self, x, training = True):\n",
    "        if training:\n",
    "            x = self.gaussian_noise(x)\n",
    "        for inx, layer in enumerate(self.encoder_layers):\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "        for inx, layer in enumerate(self.decoder_layers):\n",
    "            if inx == len(self.decoder_layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def get_latent(self, x):\n",
    "        for inx, layer in enumerate(self.encoder_layers):\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aef2af",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae44b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_aemlp_mlx(ae_model, ae_loss_and_grad_fn, ae_optimizer, ae_num_epochs,\n",
    "                     mlp_model, mlp_loss_and_grad_fn, mlp_optimizer, mlp_num_epochs,\n",
    "                     X_train, Y_train, batch_size):\n",
    "    # Train ae first\n",
    "    ae_model.train()\n",
    "    for _ in tqdm(range(ae_num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            # get gradients for ae, output is the inputs itself\n",
    "            _, ae_grads = ae_loss_and_grad_fn(ae_model, inputs, inputs)\n",
    "\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            ae_optimizer.update(ae_model, ae_grads)\n",
    "\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(ae_model.parameters(), ae_optimizer.state)\n",
    "\n",
    "    # Train mlp later\n",
    "    mlp_model.train()\n",
    "    for _ in tqdm(range(mlp_num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            # get the latent representation for X_train\n",
    "            latent_inputs = ae_model.get_latent(inputs)\n",
    "            used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "            # get gradients for mlp\n",
    "            _, mlp_grads = mlp_loss_and_grad_fn(mlp_model, used_inputs, targets)\n",
    "\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            mlp_optimizer.update(mlp_model, mlp_grads)\n",
    "\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(mlp_model.parameters(), mlp_optimizer.state)\n",
    "\n",
    "    # # Train ae and mlp together\n",
    "    # ae_model.train()\n",
    "    # mlp_model.train()\n",
    "    # for _ in tqdm(range(ae_num_epochs)):\n",
    "    #     for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "    #         # get gradients for ae, output is the inputs itself\n",
    "    #         _, ae_grads = ae_loss_and_grad_fn(ae_model, inputs, inputs)\n",
    "\n",
    "    #         # Update the optimizer state and model parameters in a single call\n",
    "    #         ae_optimizer.update(ae_model, ae_grads)\n",
    "\n",
    "    #         # Force a graph evaluation\n",
    "    #         mx.eval(ae_model.parameters(), ae_optimizer.state)\n",
    "\n",
    "    #         # get gradients for mlp\n",
    "    #         latent_inputs = ae_model.get_latent(inputs)\n",
    "    #         used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "    #         _, mlp_grads = mlp_loss_and_grad_fn(mlp_model, used_inputs, targets)\n",
    "\n",
    "    #         # Update the optimizer state and model parameters in a single call\n",
    "    #         mlp_optimizer.update(mlp_model, mlp_grads)\n",
    "\n",
    "    #         # Force a graph evaluation\n",
    "    #         mx.eval(mlp_model.parameters(), mlp_optimizer.state)\n",
    "\n",
    "def eval_aemlp_mlx(ae_model, mlp_model, X_test, Y_test, batch_size):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    ae_model.eval()\n",
    "    mlp_model.eval()\n",
    "    for (inputs, targets) in batch_iterate(batch_size, X_test, Y_test, shuffle=False):\n",
    "        latent_inputs = ae_model.get_latent(inputs)\n",
    "        used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "        outputs = mlp_model(used_inputs).reshape(-1)\n",
    "        # convert back to numpy\n",
    "        outputs, targets = np.array(outputs), np.array(targets)\n",
    "        # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "        outputs_all = np.concatenate([outputs_all, outputs])\n",
    "        targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6679261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_mlx_aemlp(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout, ae_lr, ae_num_epochs,\n",
    "                            mlp_hidden_layers_size, mlp_dropout, mlp_lr, mlp_num_epochs,\n",
    "                            cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size):\n",
    "    cv_pearson = 0\n",
    "    for _, (X_train, X_test, Y_train, Y_test) in enumerate(zip(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)):\n",
    "        # initialize the model\n",
    "        mx.random.seed(default_random_state)\n",
    "        ae_model = AEMLX(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout)\n",
    "\n",
    "        mx.random.seed(default_random_state)\n",
    "        mlp_model = MLPMLX(ae_latent_size + num_features, mlp_hidden_layers_size, mlp_dropout)\n",
    "\n",
    "        # Initialize the loss function (both use same loss function)\n",
    "        def loss_fn(model, X, Y):\n",
    "            Y_pred = model(X).reshape(-1)\n",
    "            Y = Y.reshape(-1)\n",
    "            return mx.mean(nnmx.losses.mse_loss(Y_pred, Y))\n",
    "        ae_loss_and_grad_fn = nnmx.value_and_grad(ae_model, loss_fn)\n",
    "        mlp_loss_and_grad_fn = nnmx.value_and_grad(mlp_model, loss_fn)\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        ae_optimizer = optimmx.Adam(learning_rate = ae_lr)\n",
    "        mlp_optimizer = optimmx.Adam(learning_rate = mlp_lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_aemlp_mlx(ae_model, ae_loss_and_grad_fn, ae_optimizer, ae_num_epochs,\n",
    "                        mlp_model, mlp_loss_and_grad_fn, mlp_optimizer, mlp_num_epochs,\n",
    "                        X_train, Y_train, batch_size)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_aemlp_mlx(ae_model, mlp_model, X_test, Y_test, batch_size)\n",
    "        print(pearson)\n",
    "        if pearson == -1:\n",
    "            return pearson\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4959ed6",
   "metadata": {},
   "source": [
    "Conduct training and evaluating process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b892fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the CV data, seems to be better with only anonymized features\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col] + \\\n",
    "#                 [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "#                 [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)\n",
    "# for i in range(default_cv):\n",
    "#     X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "#     X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "#     Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "#     Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Training process of the default config\n",
    "# num_features = len(best_features)\n",
    "# ae_hidden_layers_size = [64]\n",
    "# ae_latent_size = 16\n",
    "# mlp_hidden_layers_size = [4, 2]\n",
    "# lr = 0.0005\n",
    "# dropout = 0.5\n",
    "# batch_size = 180\n",
    "# num_epochs = 30\n",
    "\n",
    "# train_eval_cv_mlx_aemlp(num_features, ae_hidden_layers_size, ae_latent_size, \n",
    "#                         mlp_hidden_layers_size, dropout, \n",
    "#                         lr, default_cv,\n",
    "#                         X_train_arr, X_test_arr, Y_train_arr, Y_test_arr,\n",
    "#                         batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477b9b9",
   "metadata": {},
   "source": [
    "Optimize with bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_default_num_layers = 2\n",
    "mlp_default_num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c60d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_aemlp_mlx(trial):\n",
    "    # First initialize the parameters\n",
    "    num_features = len(best_features)\n",
    "\n",
    "    # initialize ae layers\n",
    "    ae_num_layers = ae_default_num_layers\n",
    "    ae_log_2_hidden_layers_size = []\n",
    "    for i in range(ae_num_layers):\n",
    "        if len(ae_log_2_hidden_layers_size) == 0:\n",
    "            ae_log_2_hidden_layers_size.append(trial.suggest_int(f\"ae_log2_hidden_layer_{i}\", 3, int(math.ceil(math.log2(num_features)))))\n",
    "        else:\n",
    "            ae_log_2_hidden_layers_size.append(trial.suggest_int(f\"ae_log2_hidden_layer_{i}\", 3, ae_log_2_hidden_layers_size[-1]))\n",
    "    ae_hidden_layers_size = [2**i for i in ae_log_2_hidden_layers_size]\n",
    "    ae_latent_size = 2**trial.suggest_int(\"ae_log2_latent_size\", 3, ae_log_2_hidden_layers_size[-1])\n",
    "    ae_dropout = trial.suggest_float(\"ae_dropout\", 0.2, 0.7)\n",
    "    ae_lr = trial.suggest_float(\"ae_lr\", 0.0001, 0.01, log=True)\n",
    "    ae_num_epochs = trial.suggest_categorical(\"num_epochs\", [20, 40, 60, 80, 100])\n",
    "\n",
    "    # initialize mlp layers\n",
    "    mlp_num_layers = mlp_default_num_layers\n",
    "    mlp_log_2_hidden_layers_size = []\n",
    "    for i in range(mlp_num_layers):\n",
    "        if len(mlp_log_2_hidden_layers_size) == 0:\n",
    "            mlp_log_2_hidden_layers_size.append(trial.suggest_int(f\"mlp_log2_hidden_layer_{i}\", 2, int(math.ceil(math.log2(ae_latent_size + num_features)))))\n",
    "        else:\n",
    "            mlp_log_2_hidden_layers_size.append(trial.suggest_int(f\"mlp_log2_hidden_layer_{i}\", 2, mlp_log_2_hidden_layers_size[-1]))\n",
    "    mlp_hidden_layers_size = [2**i for i in mlp_log_2_hidden_layers_size]\n",
    "    mlp_dropout = trial.suggest_float(\"mlp_dropout\", 0.2, 0.7)\n",
    "    mlp_lr = trial.suggest_float(\"mlp_lr\", 0.0001, 0.01, log=True)\n",
    "    mlp_num_epochs = trial.suggest_categorical(\"mlp_num_epochs\", [10, 20, 30, 40, 50])\n",
    "    # mlp_num_epochs = ae_num_epochs\n",
    "\n",
    "    # batch size\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [30, 60, 120, 180, 360, 720, 1440])\n",
    "    \n",
    "    # Conduct training based on those parameters\n",
    "    cv_pearson = train_eval_cv_mlx_aemlp(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout, ae_lr, ae_num_epochs,\n",
    "                                         mlp_hidden_layers_size, mlp_dropout, mlp_lr, mlp_num_epochs,\n",
    "                                         default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr,\n",
    "                                         batch_size)\n",
    "    \n",
    "    return cv_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_aemlp_mlx(study_name, storage_name, objective_function=objective_aemlp_mlx, n_trials = 100, n_jobs = 1):\n",
    "    print(\"Conduct hyperparam opt for AE-MLP\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features)\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_aemlp_mlx(\n",
    "    f\"aemlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{ae_default_num_layers}_{mlp_default_num_layers}_study\",\n",
    "    f\"aemlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{ae_default_num_layers}_{mlp_default_num_layers}_study\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
