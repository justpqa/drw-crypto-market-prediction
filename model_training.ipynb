{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89ecff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justpqa/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler, GPSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import multiprocessing\n",
    "# max_n_jobs = multiprocessing.cpu_count()\n",
    "import shap\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, Sampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nnmx\n",
    "import mlx.optimizers as optimmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dce0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2025de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_version = 2\n",
    "# 1 for pc feature, \n",
    "# 2 for label correlation feature # seems to work most consistently\n",
    "# 3 for best features based on combination rank\n",
    "# 4 for including time features (in case we want to reverse engineer the masked timestamp)\n",
    "# 5 for increasing number of correlation features + only use those that are in the same cluster\n",
    "# 6 is for 2 but more features, use when I want to use more features for larger models or AE approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935ee52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_random_state = 101\n",
    "random.seed(default_random_state)\n",
    "np.random.seed(default_random_state)\n",
    "torch.manual_seed(default_random_state)\n",
    "torch.mps.manual_seed(default_random_state)\n",
    "mx.random.seed(default_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731d3a4",
   "metadata": {},
   "source": [
    "#### Import train data and popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6dc4e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X751</th>\n",
       "      <th>X473</th>\n",
       "      <th>X472</th>\n",
       "      <th>X451</th>\n",
       "      <th>X226</th>\n",
       "      <th>X219</th>\n",
       "      <th>X205</th>\n",
       "      <th>X445</th>\n",
       "      <th>X444</th>\n",
       "      <th>X27</th>\n",
       "      <th>...</th>\n",
       "      <th>X181_X762_X286_exp_interaction</th>\n",
       "      <th>X181_X272_X286_exp_interaction</th>\n",
       "      <th>X181_X272_X288_exp_interaction</th>\n",
       "      <th>X181_X272_X285_exp_interaction</th>\n",
       "      <th>X204_X758_X286_exp_interaction</th>\n",
       "      <th>X204_X758_X288_exp_interaction</th>\n",
       "      <th>X204_X758_X290_exp_interaction</th>\n",
       "      <th>X204_X758_X292_exp_interaction</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.362816</td>\n",
       "      <td>0.255354</td>\n",
       "      <td>0.625153</td>\n",
       "      <td>-0.893206</td>\n",
       "      <td>-0.654146</td>\n",
       "      <td>-1.250753</td>\n",
       "      <td>0.755891</td>\n",
       "      <td>0.625328</td>\n",
       "      <td>1.714323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469463</td>\n",
       "      <td>0.264951</td>\n",
       "      <td>0.248992</td>\n",
       "      <td>0.391404</td>\n",
       "      <td>0.129056</td>\n",
       "      <td>0.121283</td>\n",
       "      <td>0.108972</td>\n",
       "      <td>0.091955</td>\n",
       "      <td>2023-03-01 00:00:00</td>\n",
       "      <td>0.562539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.378391</td>\n",
       "      <td>0.274621</td>\n",
       "      <td>0.637250</td>\n",
       "      <td>-0.738291</td>\n",
       "      <td>-0.634723</td>\n",
       "      <td>-1.100357</td>\n",
       "      <td>0.760472</td>\n",
       "      <td>0.633046</td>\n",
       "      <td>1.396133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443526</td>\n",
       "      <td>0.250629</td>\n",
       "      <td>0.238075</td>\n",
       "      <td>0.374853</td>\n",
       "      <td>0.149914</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>0.128732</td>\n",
       "      <td>0.107978</td>\n",
       "      <td>2023-03-01 00:01:00</td>\n",
       "      <td>0.533686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016807</td>\n",
       "      <td>0.382337</td>\n",
       "      <td>0.279272</td>\n",
       "      <td>0.640437</td>\n",
       "      <td>-0.713420</td>\n",
       "      <td>-0.631882</td>\n",
       "      <td>-1.073226</td>\n",
       "      <td>0.761631</td>\n",
       "      <td>0.635009</td>\n",
       "      <td>1.205921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442458</td>\n",
       "      <td>0.247697</td>\n",
       "      <td>0.235061</td>\n",
       "      <td>0.373425</td>\n",
       "      <td>0.154606</td>\n",
       "      <td>0.146719</td>\n",
       "      <td>0.133283</td>\n",
       "      <td>0.111113</td>\n",
       "      <td>2023-03-01 00:02:00</td>\n",
       "      <td>0.546505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.036622</td>\n",
       "      <td>0.387473</td>\n",
       "      <td>0.284750</td>\n",
       "      <td>0.642831</td>\n",
       "      <td>-0.644172</td>\n",
       "      <td>-0.612901</td>\n",
       "      <td>-0.982398</td>\n",
       "      <td>0.761936</td>\n",
       "      <td>0.635508</td>\n",
       "      <td>1.419536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430054</td>\n",
       "      <td>0.245878</td>\n",
       "      <td>0.234839</td>\n",
       "      <td>0.364263</td>\n",
       "      <td>0.171042</td>\n",
       "      <td>0.163363</td>\n",
       "      <td>0.147668</td>\n",
       "      <td>0.124220</td>\n",
       "      <td>2023-03-01 00:03:00</td>\n",
       "      <td>0.357703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.053322</td>\n",
       "      <td>0.390820</td>\n",
       "      <td>0.289431</td>\n",
       "      <td>0.648175</td>\n",
       "      <td>-0.628840</td>\n",
       "      <td>-0.607648</td>\n",
       "      <td>-0.952145</td>\n",
       "      <td>0.764770</td>\n",
       "      <td>0.640311</td>\n",
       "      <td>1.408936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432521</td>\n",
       "      <td>0.249067</td>\n",
       "      <td>0.237772</td>\n",
       "      <td>0.370813</td>\n",
       "      <td>0.178625</td>\n",
       "      <td>0.170524</td>\n",
       "      <td>0.154702</td>\n",
       "      <td>0.129949</td>\n",
       "      <td>2023-03-01 00:04:00</td>\n",
       "      <td>0.362452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X751      X473      X472      X451      X226      X219      X205  \\\n",
       "0  0.000617  0.362816  0.255354  0.625153 -0.893206 -0.654146 -1.250753   \n",
       "1  0.013388  0.378391  0.274621  0.637250 -0.738291 -0.634723 -1.100357   \n",
       "2 -0.016807  0.382337  0.279272  0.640437 -0.713420 -0.631882 -1.073226   \n",
       "3 -0.036622  0.387473  0.284750  0.642831 -0.644172 -0.612901 -0.982398   \n",
       "4 -0.053322  0.390820  0.289431  0.648175 -0.628840 -0.607648 -0.952145   \n",
       "\n",
       "       X445      X444       X27  ...  X181_X762_X286_exp_interaction  \\\n",
       "0  0.755891  0.625328  1.714323  ...                        0.469463   \n",
       "1  0.760472  0.633046  1.396133  ...                        0.443526   \n",
       "2  0.761631  0.635009  1.205921  ...                        0.442458   \n",
       "3  0.761936  0.635508  1.419536  ...                        0.430054   \n",
       "4  0.764770  0.640311  1.408936  ...                        0.432521   \n",
       "\n",
       "   X181_X272_X286_exp_interaction  X181_X272_X288_exp_interaction  \\\n",
       "0                        0.264951                        0.248992   \n",
       "1                        0.250629                        0.238075   \n",
       "2                        0.247697                        0.235061   \n",
       "3                        0.245878                        0.234839   \n",
       "4                        0.249067                        0.237772   \n",
       "\n",
       "   X181_X272_X285_exp_interaction  X204_X758_X286_exp_interaction  \\\n",
       "0                        0.391404                        0.129056   \n",
       "1                        0.374853                        0.149914   \n",
       "2                        0.373425                        0.154606   \n",
       "3                        0.364263                        0.171042   \n",
       "4                        0.370813                        0.178625   \n",
       "\n",
       "   X204_X758_X288_exp_interaction  X204_X758_X290_exp_interaction  \\\n",
       "0                        0.121283                        0.108972   \n",
       "1                        0.142404                        0.128732   \n",
       "2                        0.146719                        0.133283   \n",
       "3                        0.163363                        0.147668   \n",
       "4                        0.170524                        0.154702   \n",
       "\n",
       "   X204_X758_X292_exp_interaction   __index_level_0__     label  \n",
       "0                        0.091955 2023-03-01 00:00:00  0.562539  \n",
       "1                        0.107978 2023-03-01 00:01:00  0.533686  \n",
       "2                        0.111113 2023-03-01 00:02:00  0.546505  \n",
       "3                        0.124220 2023-03-01 00:03:00  0.357703  \n",
       "4                        0.129949 2023-03-01 00:04:00  0.362452  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_parquet(f\"data/cleaned/cleaned_train_{feature_version}.parquet\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766f9871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>bid_qty</th>\n",
       "      <th>ask_qty</th>\n",
       "      <th>buy_qty</th>\n",
       "      <th>sell_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221.389</td>\n",
       "      <td>15.283</td>\n",
       "      <td>8.425</td>\n",
       "      <td>176.405</td>\n",
       "      <td>44.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>847.796</td>\n",
       "      <td>38.590</td>\n",
       "      <td>2.336</td>\n",
       "      <td>525.846</td>\n",
       "      <td>321.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295.596</td>\n",
       "      <td>0.442</td>\n",
       "      <td>60.250</td>\n",
       "      <td>159.227</td>\n",
       "      <td>136.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460.705</td>\n",
       "      <td>4.865</td>\n",
       "      <td>21.016</td>\n",
       "      <td>335.742</td>\n",
       "      <td>124.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.818</td>\n",
       "      <td>27.158</td>\n",
       "      <td>3.451</td>\n",
       "      <td>98.411</td>\n",
       "      <td>44.407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    volume  bid_qty  ask_qty  buy_qty  sell_qty\n",
       "0  221.389   15.283    8.425  176.405    44.984\n",
       "1  847.796   38.590    2.336  525.846   321.950\n",
       "2  295.596    0.442   60.250  159.227   136.369\n",
       "3  460.705    4.865   21.016  335.742   124.963\n",
       "4  142.818   27.158    3.451   98.411    44.407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_features_train = pd.read_parquet(\"data/cleaned/popular_features_train.parquet\")\n",
    "popular_features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f1fe5",
   "metadata": {},
   "source": [
    "#### Implement some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb40f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to split into some fold\n",
    "train_df[\"__index_level_0__\"] = pd.to_datetime(train_df[\"__index_level_0__\"])\n",
    "\n",
    "default_cv = 4\n",
    "default_cv_type = \"full\"\n",
    "# NOTE: default_cv must set to 1 instead of 3 based on consistency with LB score contains 49% of test data\n",
    "# NOTE: 3 cv with gap is slightly better or almost equal\n",
    "\n",
    "def create_cv(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"__index_level_0__\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"__index_level_0__\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"__index_level_0__\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"__index_level_0__\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"__index_level_0__\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"])\n",
    "        Y_test_arr.append(test[\"label\"])  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# def create_cv_random_test(train_df, features=None, test_cv=10):\n",
    "#     # randomize so that we have 1 train, but try it on 10 different test \n",
    "#     if features is not None:\n",
    "#         train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "#     X_train_arr = []\n",
    "#     X_test_arr = []\n",
    "#     Y_train_arr = []\n",
    "#     Y_test_arr = []\n",
    "\n",
    "#     # Create train data\n",
    "#     train_month = [3, 4, 5, 6, 7, 8]\n",
    "#     train = train_df[train_df[\"timestamp\"].dt.month.isin(train_month)] \n",
    "#     X_train_arr.append(train.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#     Y_train_arr.append(train[\"label\"])\n",
    "\n",
    "#     test_month = [9, 10, 11, 12, 1, 2]\n",
    "#     test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)]\n",
    "#     # Create test data\n",
    "#     for _ in range(test_cv):\n",
    "#         random_test = test.sample(frac = 0.5, random_state = default_random_state)\n",
    "#         X_test_arr.append(random_test.drop([\"timestamp\", \"label\"], axis = 1))\n",
    "#         Y_test_arr.append(random_test[\"label\"])\n",
    "\n",
    "#     return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr \n",
    "\n",
    "# class [-1, 0, 1] -> [0, 1, 2] => < -0.2 => neg, > 0.2 => pos, else => neutral\n",
    "def create_classification_class(label):\n",
    "    if label < -0.4: return 0\n",
    "    elif label < 0: return 1\n",
    "    elif label < 0.4: return 2\n",
    "    return 3\n",
    "\n",
    "def create_cv_classification(train_df, features=None, cv=default_cv):\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"__index_level_0__\", \"label\"]]\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    for i in range(cv):\n",
    "        train_month = list(range(3 + i, 7 + i))\n",
    "        # train_month = [3, 4, 5, 6, 7, 8]\n",
    "        test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "        print(train_month, test_month)\n",
    "        # test_month = [9, 10, 11, 12, 1, 2] # try to make a gap to see if there is any differences in cv-lb correlation\n",
    "        # print(train_month, test_month)\n",
    "        train = train_df[train_df[\"__index_level_0__\"].dt.month.isin(train_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        test = train_df[train_df[\"__index_level_0__\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "        X_train_arr.append(train.drop([\"__index_level_0__\", \"label\"], axis = 1))\n",
    "        X_test_arr.append(test.drop([\"__index_level_0__\", \"label\"], axis = 1))\n",
    "        Y_train_arr.append(train[\"label\"].apply(lambda x: create_classification_class(x)))\n",
    "        Y_test_arr.append(test[\"label\"].apply(lambda x: create_classification_class(x)))  \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8b878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_score(Y_test, Y_pred):\n",
    "    if isinstance(Y_test, pd.Series) or isinstance(Y_test, pd.DataFrame):\n",
    "        Y_test = Y_test.values\n",
    "    if isinstance(Y_pred, pd.Series) or isinstance(Y_pred, pd.DataFrame):\n",
    "        Y_pred = Y_pred.values\n",
    "    Y_test = np.ravel(Y_test)\n",
    "    Y_pred = np.ravel(Y_pred)\n",
    "    pearson = np.corrcoef(Y_test, Y_pred)[0, 1]\n",
    "    if np.isnan(pearson):\n",
    "        if np.std(Y_pred) == 0:\n",
    "            print(Y_pred)\n",
    "            print(\"Error: zero variance prediction\")\n",
    "        elif np.isnan(Y_pred).any():\n",
    "            print(\"Error: nan prediction\")\n",
    "        return -1\n",
    "    else:\n",
    "        return pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce779cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function specifically for cross validation\n",
    "def train_eval_cv(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        cv_score += scoring_function(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_score / cv\n",
    "\n",
    "def train_eval_cv_random_test(model, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, scoring_function=pearson_score, test_cv = 10):\n",
    "    cv_score = 0\n",
    "\n",
    "    for i in range(cv):\n",
    "        curr_cv_score = 0\n",
    "\n",
    "        # Conduct fitting\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        # sampling and testing\n",
    "        len_test = X_test.shape[0]\n",
    "        for seed in tqdm(range(test_cv)):\n",
    "            np.random.seed(seed)\n",
    "            test_index = np.random.choice(len_test, size = len_test // 2, replace = False) \n",
    "            X_test_sample = X_test.loc[test_index, :]\n",
    "            Y_test_sample = Y_test[test_index]\n",
    "            Y_pred_sample = model.predict(X_test_sample)\n",
    "            curr_cv_score += scoring_function(Y_test_sample, Y_pred_sample)\n",
    "        \n",
    "        cv_score += curr_cv_score / test_cv\n",
    "    \n",
    "    np.random.seed(default_random_state)\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9d975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trees = 1000\n",
    "# Finetuning XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_pearson = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, pearson_score)\n",
    "    return cv_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddbb8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning XGBoost\n",
    "def objective_xgboost_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True), # 0.001 - 0.1 -> 0.01 - 0.05 \n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0), # 1.0 -> 0.2\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.05, 1), \n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1), \n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    xgbr = XGBClassifier(**params)\n",
    "    cv_acc = train_eval_cv(xgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_lightgbm_classification(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": default_n_trees,\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10), # 1 - 10 => 1 - 5\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 -> 0.005 - 0.02\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0, 1),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_state\": default_random_state\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMClassifier(**params)\n",
    "    cv_acc = train_eval_cv(lgbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc\n",
    "\n",
    "def objective_catboost_classification(trial):\n",
    "    params = {\n",
    "        \"iterations\": default_n_trees,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True), # 0.001 - 0.1 => 0.01 - 0.1\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10), #  1 - 10 => 5 - 15\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 100),\n",
    "        \"random_seed\": default_random_state\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_acc = train_eval_cv(cbr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, accuracy_score)\n",
    "    return cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778f94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_n_trials = 100\n",
    "default_n_jobs = 1\n",
    "\n",
    "def optimize_xgboost(study_name, storage_name, objective_function=objective_xgboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for XGBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_lightgbm(study_name, storage_name, objective_function=objective_lightgbm, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for LightGBM\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_catboost(study_name, storage_name, objective_function=objective_catboost, n_trials = default_n_trials, n_jobs = default_n_jobs):\n",
    "    print(\"Conduct hyperparam opt for CatBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fd743",
   "metadata": {},
   "source": [
    "#### First iteration: training with all features from the collection, no popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5acc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb106a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_catboost = optimize_catboost(\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\",\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\"\n",
    "# )\n",
    "# # Need to take down as catboost might not work well in this situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e2b50",
   "metadata": {},
   "source": [
    "Analyze params - cv relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8801e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_study_df(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    study_df = []\n",
    "    for trial in study.trials:\n",
    "        trial_dict = trial.params\n",
    "        trial_dict[\"value\"] = trial.value\n",
    "        study_df.append(trial_dict)\n",
    "\n",
    "    return pd.DataFrame(study_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d57f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_value_viz(study_df):\n",
    "    nrows = (study_df.shape[1] - 1) // 3 + ((study_df.shape[1] - 1) % 3 > 0)\n",
    "    fig, ax = plt.subplots(nrows = nrows, ncols = 3, figsize = (14, 5 * nrows))\n",
    "    for inx, var in enumerate(study_df.columns):\n",
    "        x, y = inx // 3, inx % 3\n",
    "        if var != \"value\":\n",
    "            sns.regplot(study_df, x = var, y = \"value\", ax = ax[x][y], lowess=True, line_kws={'color': 'green'}, ci = 95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad954e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_xgboost = get_study_df(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")   \n",
    "params_value_viz(study_df_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717983ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df_lightgbm = get_study_df(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "params_value_viz(study_df_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba067f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_df_catboost = get_study_df(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# params_value_viz(study_df_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d81cc8",
   "metadata": {},
   "source": [
    "Analyze feature importance + CV performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ccea6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_from_file(filename):\n",
    "    study = optuna.load_study(\n",
    "        study_name = filename,\n",
    "        storage = f\"sqlite:///{filename}.db\"\n",
    "    )\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1942990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(model, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, sample_size=-1):\n",
    "    mean_abs_shap_all = np.zeros(X_train_arr[0].shape[1])\n",
    "    for i in range(default_cv):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        model.fit(X_train, Y_train)\n",
    "        if sample_size != -1:\n",
    "            X_test_sample = X_test.sample(sample_size, random_state = default_random_state)\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_test_sample)\n",
    "            mean_abs_shap = np.mean(np.abs(shap_values), axis = 0)\n",
    "            mean_abs_shap_all += mean_abs_shap\n",
    "        else:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_test)\n",
    "            mean_abs_shap = np.mean(np.abs(shap_values), axis = 0)\n",
    "            mean_abs_shap_all += mean_abs_shap\n",
    "    mean_abs_shap_all /= default_cv\n",
    "    return mean_abs_shap_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in xgboost_feature_importances if xgboost_feature_importances[f] > 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7366dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([f for f in lightgbm_feature_importances if lightgbm_feature_importances[f] >= 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"iterations\": default_n_trees,\n",
    "#     \"verbose\": False,\n",
    "#     \"random_seed\": default_random_state\n",
    "# }\n",
    "# best_params_catboost = get_best_params_from_file(f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_study\")\n",
    "# for p in best_params_catboost:\n",
    "#     params[p] = best_params_catboost[p]\n",
    "\n",
    "# catboost_feature_importances = {}\n",
    "\n",
    "# cbr = CatBoostRegressor(**params)\n",
    "# cv_rmse = 0\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "#     Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "#     cbr.fit(X_train, Y_train)\n",
    "#     print(pearson_score(Y_test, cbr.predict(X_test)))\n",
    "#     features = cbr.feature_names_\n",
    "#     # features_i = cbr.feature_importances_.tolist()\n",
    "#     features_i = get_shap_values(cbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "#     for inx, feat in enumerate(features):\n",
    "#         catboost_feature_importances[feat] = catboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# plt.hist(catboost_feature_importances.values())\n",
    "# # can pick up a combination of both past cod and tss, not good at picking up ph, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([f for f in catboost_feature_importances if catboost_feature_importances[f] >= 0.02])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8120d",
   "metadata": {},
   "source": [
    "Get top 20 important features in all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ed2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.loc[:49, \"var\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca490b7",
   "metadata": {},
   "source": [
    "#### Second Iteration: adding popular feature in addition to original features correlated to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93eefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56349c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_popular_feature = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_popular_feature = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d683a",
   "metadata": {},
   "source": [
    "Check for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d18fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_popular_feature_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_popular_feature_study.db\"\n",
    ").best_value\n",
    "feature_importances_df[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df = feature_importances_df.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd11a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = pd.read_csv(\"feature_importances_df.csv\")\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df[~feature_importances_df[\"var\"].str.contains(\"X\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ba087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.sort_values(\"importance\", ignore_index=True, ascending=False).head(30)[\"var\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cec354",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importances_df.sort_values(\"weighted_importance\", ignore_index=True, ascending=False).head(30)[\"var\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8bbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(feature_importances_df.sort_values(\"importance\", ignore_index=True, ascending=False).head(20)[\"var\"].tolist())\n",
    "s2 = set(feature_importances_df.sort_values(\"weighted_importance\", ignore_index=True, ascending=False).head(20)[\"var\"].tolist())\n",
    "print(s1 - s2)\n",
    "print(s2 - s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79548519",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.sort_values(\"importance\", ignore_index=True, ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.sort_values(\"weighted_importance\", ignore_index=True, ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6953fd8",
   "metadata": {},
   "source": [
    "#### Third Iteration: a common truncated version using good features across all models + popular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', \n",
    "                 'X466', 'X95', 'X23', 'X219', 'X31', 'X373', 'X379', 'X284', 'X750', 'X652', \n",
    "                 'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X272', 'X271', 'X218']\n",
    "# Best is at 30 features with no popular features\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c7f75",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ed407",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_params_common_truncated = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features)}_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features)}_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534cb1d",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c656479",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lightgbm_params_common_truncated = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features)}_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features)}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfaacf4",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_catboost_params_common_truncated = optimize_catboost(\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\",\n",
    "#     f\"catboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291147c",
   "metadata": {},
   "source": [
    "Analyze model performance and feature importance across train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6913016",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    xgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    xgbr_arr.append(xgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state,\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lgbr_arr = []\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    lgbr.fit(X_train_arr[i], Y_train_arr[i])\n",
    "    lgbr_arr.append(lgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances = {}\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "for i in tqdm(range(default_cv)):\n",
    "    features = xgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "    features = lgbr_arr[i].feature_names_in_.tolist()\n",
    "    features_i = get_shap_values(xgbr_arr[i], X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "lightgbm_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    ")\n",
    "lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "feature_importances_df_common_truncated = xgboost_feature_importances_df.merge(\n",
    "    lightgbm_feature_importances_df,\n",
    "    on=\"var\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    ")\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "feature_importances_df_common_truncated[\"importance\"] = 1/2 * (feature_importances_df_common_truncated[\"importance_xgboost\"] + feature_importances_df_common_truncated[\"importance_lightgbm\"])\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(by=\"importance\", ascending=False).reset_index().drop(\"index\", axis = 1)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_score = optuna.load_study(\n",
    "    study_name = \"xgboost_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///xgboost_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "best_lightgbm_score = optuna.load_study(\n",
    "    study_name = \"lightgbm_2_4_101_1000_common_truncated_20_study\",\n",
    "    storage = f\"sqlite:///lightgbm_2_4_101_1000_common_truncated_20_study.db\"\n",
    ").best_value\n",
    "feature_importances_df_common_truncated[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df_common_truncated[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df_common_truncated[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "feature_importances_df_common_truncated = feature_importances_df_common_truncated.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df_common_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f13d6b",
   "metadata": {},
   "source": [
    "#### Fourth iteration: Adding popular feature on top of truncated X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', \n",
    "                 'X466', 'X95', 'X23', 'X219', 'X31', 'X373', 'X379', 'X284', 'X750', 'X652', \n",
    "                 'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X272', 'X271', 'X218'] + \\\n",
    "                [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] \n",
    "# Since the features are already normalized, we cannot use the newly created features like order_flow_imbalance,\n",
    "# since they lose their meanings already, but we can still use the old popular features\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c758740",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_params_common_truncated_popular_feature = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features) - 5}_popular_feature_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_{len(best_features) - 5}_popular_feature_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f517360",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lightgbm_params_common_truncated_popular_feature = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_popular_feature_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_20_popular_feature_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922a1c7",
   "metadata": {},
   "source": [
    "#### Fifth Iteration Instead of using GBDT, can we use MLP on these features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f58f11b",
   "metadata": {},
   "source": [
    "Convert from normal CV to torch type CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531',\n",
    "                 'X385', 'X23', 'X465', 'X284', 'X331', 'X95', 'X169', 'X285', 'X137', 'X31']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, cv=default_cv):\n",
    "    train_arr = []\n",
    "    test_arr = []\n",
    "    for i in range(cv):\n",
    "        # First shuffle the data\n",
    "        X_train, Y_train = X_train_arr[i], Y_train_arr[i]\n",
    "        X_train[\"label\"] = Y_train\n",
    "        # Instead of shuffle the training data when create the dataloader, try to shuffle beforehand\n",
    "        # X_train = X_train.sample(frac = 1, random_state = default_random_state)\n",
    "        # not shuffle, keep it by date\n",
    "        Y_train = X_train[\"label\"]\n",
    "        X_train = X_train.drop(\"label\", axis = 1)\n",
    "\n",
    "        # Then normalize\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train.values)\n",
    "\n",
    "        # Create train dataset\n",
    "        X_train, Y_train = torch.from_numpy(X_train), torch.from_numpy(Y_train.values)\n",
    "        train_dataset = TensorDataset(X_train, Y_train)\n",
    "        train_arr.append(train_dataset)\n",
    "\n",
    "        # Normalize X_test\n",
    "        X_test = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Create test dataset\n",
    "        X_test, Y_test = torch.from_numpy(X_test), torch.from_numpy(Y_test_arr[i].values)\n",
    "        test_dataset = TensorDataset(X_test, Y_test)\n",
    "        test_arr.append(test_dataset)\n",
    "        \n",
    "    return train_arr, test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr, test_arr = normal_cv_to_torch_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da5b12",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = nn.ModuleList()\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nn.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nn.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # Initialze dropout\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            if inx == len(self.layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb08f2",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e892da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp(model, criterion, optimizer, train_dataloader, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in train_dataloader:\n",
    "            # Load to device\n",
    "            inputs, targets= inputs.to(device), targets.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs)\n",
    "            # get error\n",
    "            error = criterion(outputs, targets)\n",
    "            # Zero out the past gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Backprop\n",
    "            error.backward()\n",
    "            # Gradient Descent\n",
    "            optimizer.step()\n",
    "\n",
    "def eval_mlp(model, test_dataloader):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, targets) in enumerate(test_dataloader):\n",
    "            # Load to device\n",
    "            inputs = inputs.to(device)\n",
    "            # Forward step\n",
    "            outputs = model(inputs).detach().cpu().numpy().flatten()\n",
    "            # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "            outputs_all = np.concatenate([outputs_all, outputs])\n",
    "            targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_torch(model, lr, cv, train_arr, test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for i in range(cv):\n",
    "        # Get the dataloader\n",
    "        train_dataset = train_arr[i]\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, num_workers=0)\n",
    "        test_dataset = test_arr[i]\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size = batch_size, num_workers=0)\n",
    "\n",
    "        # Reinitialize the model\n",
    "        model.reset()\n",
    "        model.to(device)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp(model, criterion, optimizer, train_dataloader, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp(model, test_dataloader)\n",
    "        print(pearson)\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bc5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process of the default config\n",
    "hidden_layers_size = [16, 8, 4]\n",
    "lr = 0.001\n",
    "batch_size = 60\n",
    "num_epochs = 10\n",
    "\n",
    "mlpr = MLP(len(best_features), hidden_layers_size=hidden_layers_size, dropout = 0.3)\n",
    "\n",
    "train_eval_cv_torch(mlpr, lr, default_cv, train_arr, test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdd235",
   "metadata": {},
   "source": [
    "#### Sixth Iteration: Change this into a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65121481",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = [f for f in train_df.columns if \"X\" in f]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_classification(train_df, original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5950bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_classification = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_xgboost_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_classification = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_classification_study\",\n",
    "    objective_lightgbm_classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31960b41",
   "metadata": {},
   "source": [
    "#### Seventh Iteration: Search for the best way to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_training_scheme(model, train_df, cv = default_cv, features = None):\n",
    "    folds_trial = [\n",
    "        # level 1\n",
    "        [[0, 1, 2, 3]], \n",
    "        [[0, 1]], [[1, 2]], [[2, 3]],\n",
    "        [[0]], [[1]], [[2]], [[3]],\n",
    "        [[0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1], [2, 3]],\n",
    "        [[0], [1], [2], [3]],\n",
    "        # level 2\n",
    "        [[0, 1, 2, 3], [0, 1]],\n",
    "        [[0, 1, 2, 3], [1, 2]],\n",
    "        [[0, 1, 2, 3], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]],\n",
    "        [[0, 1, 2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "        # level 3\n",
    "        [[0, 1, 2, 3], [0, 1], [0]],\n",
    "        [[0, 1, 2, 3], [2, 3], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]],\n",
    "        [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]],\n",
    "    ]\n",
    "\n",
    "    if features is not None:\n",
    "        train_df = train_df[features + [\"timestamp\", \"label\"]]\n",
    "\n",
    "    for folds in folds_trial:\n",
    "        print(f\"Current folds list is {folds}\")\n",
    "        model_lst = [deepcopy(model)] * len(folds)\n",
    "        cv_pearson = []\n",
    "        for i in range(cv):\n",
    "            train_month = list(range(3 + i, 7 + i))\n",
    "            test_month = list(map(lambda x: x % 12 if x > 12 else x, list(range(8 + i, 12 + i))))\n",
    "            test = train_df[train_df[\"timestamp\"].dt.month.isin(test_month)].reset_index().drop(\"index\", axis = 1)\n",
    "            X_test, Y_test = test.drop([\"timestamp\", \"label\"], axis = 1), test[\"label\"]\n",
    "            Y_pred = np.zeros(Y_test.shape[0])\n",
    "            for j in range(len(folds)):\n",
    "                fold = folds[j]\n",
    "                model = model_lst[j]\n",
    "                train_month_curr = [train_month[f] for f in fold]\n",
    "                train_curr = train_df[train_df[\"timestamp\"].dt.month.isin(train_month_curr)].reset_index().drop(\"index\", axis = 1)\n",
    "                X_train, Y_train = train_curr.drop([\"timestamp\", \"label\"], axis = 1), train_curr[\"label\"]\n",
    "                model.fit(X_train, Y_train)\n",
    "                Y_pred += model.predict(X_test)\n",
    "            Y_pred /= len(folds)\n",
    "            cv_pearson.append(pearson_score(Y_test, Y_pred))\n",
    "            print(f\"Finish fold {i} with score: {pearson_score(Y_test, Y_pred)}\")\n",
    "        print(f\"Finish trial with mean score: {np.mean(np.array(cv_pearson))}\")\n",
    "        print(f\"Finish trial with std score: {np.std(np.array(cv_pearson))}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df66a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost_popular_feature = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_xgboost_popular_feature:\n",
    "    params[p] = best_params_xgboost_popular_feature[p]\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "search_training_scheme(xgbr, train_added_df)\n",
    "# Notable\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [1, 2]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]] \n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [1, 2], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ea866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_added_df = pd.concat([train_df, popular_features_train], axis = 1)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm_popular_feature = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_popular_feature_study\")\n",
    "for p in best_params_lightgbm_popular_feature:\n",
    "    params[p] = best_params_lightgbm_popular_feature[p]\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "search_training_scheme(lgbr, train_added_df)\n",
    "# [[0, 1, 2, 3]]\n",
    "# [[0, 1, 2, 3], [0, 1]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3]]\n",
    "# [[0, 1, 2, 3], [0], [1], [2], [3]]\n",
    "# [[0, 1, 2, 3], [0, 1], [0]]\n",
    "# [[0, 1, 2, 3], [0, 1], [2, 3], [0], [1], [2], [3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fe3ca",
   "metadata": {},
   "source": [
    "#### Eighth Iteration: rewrite the code for MLP training using MLX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f11bdd",
   "metadata": {},
   "source": [
    "Create the data for training + custom batch iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb028760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "# best_features = ['X862', 'X598', 'X863', 'X856', 'X612', 'X466', 'X533', 'X861', 'X445', 'X531', \n",
    "#                  'X385', 'X23', 'X284', 'X465', 'X331', 'X95', 'X285', 'X31', 'X169', 'X137', \n",
    "#                 'X379', 'X186', 'X852', 'X302', 'X868', 'X89', 'X219', 'X855', 'X540', 'X301'] \n",
    "                #  'X198', 'X373', 'X524', 'X291', 'X444', 'X279', 'X300', 'X181', 'X367', 'X538', \n",
    "                #  'X288', 'X226', 'X857', 'X860', 'X205', 'X298', 'X272', 'X472', 'X28', 'X754']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "# best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68496448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to \"reduce\" from float64 to float32\n",
    "def float64_to_float32(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = data[col].astype(\"float32\")\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "# for i in range(default_cv):\n",
    "#     X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "#     X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "#     Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "#     Y_test_arr[i] = float64_to_float32(Y_test_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02f14632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_cv_to_mlx_cv(X_train_arr = None, X_test_arr = None, Y_train_arr = None, Y_test_arr = None, cv=default_cv):\n",
    "    for i in range(cv):\n",
    "        # Normalize first\n",
    "        if X_train_arr is not None and X_test_arr is not None:\n",
    "            scaler = StandardScaler()\n",
    "            X_train_arr[i] = scaler.fit_transform(X_train_arr[i].values)\n",
    "            X_test_arr[i] = scaler.transform(X_test_arr[i].values)\n",
    "\n",
    "        # Convert to mlx format\n",
    "        if X_train_arr is not None: X_train_arr[i] = mx.array(X_train_arr[i])\n",
    "        if X_test_arr is not None: X_test_arr[i] = mx.array(X_test_arr[i])\n",
    "        if Y_train_arr is not None: Y_train_arr[i] = mx.array(Y_train_arr[i].values)\n",
    "        if Y_test_arr is not None: Y_test_arr[i] = mx.array(Y_test_arr[i].values)\n",
    "        \n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3f916",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "993631c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# We do not use the reset method this time so you have to create the model at each fold\n",
    "class MLPMLX(nnmx.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers & batchnorm\n",
    "        last_layer = num_features\n",
    "        self.layers = []\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.layers.append(nnmx.Linear(last_layer, 1))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nnmx.ReLU()\n",
    "\n",
    "        # Initialize dropout\n",
    "        self.dropout = nnmx.Dropout(p = dropout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for inx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if inx != len(self.layers) - 1:\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33907ab7",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78aaa51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for batch iteration\n",
    "def batch_iterate(batch_size, X, Y, shuffle = True):\n",
    "    for i in range(0, Y.size, batch_size):\n",
    "        X_curr = X[i: min(i + batch_size, Y.size), :]\n",
    "        Y_curr = Y[i: min(i + batch_size, Y.size)]\n",
    "        if shuffle:\n",
    "            inx_lst = mx.random.permutation(batch_size)\n",
    "            X_curr = X_curr[inx_lst, :]\n",
    "            Y_curr = Y_curr[inx_lst]\n",
    "        yield X_curr, Y_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a72a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs):\n",
    "    model.train()\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            _, grads = loss_and_grad_fn(model, inputs, targets)\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            optimizer.update(model, grads)\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(model.parameters(), optimizer.state)\n",
    "\n",
    "def eval_mlp_mlx(model, X_test, Y_test, batch_size):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    model.eval()\n",
    "    for (inputs, targets) in batch_iterate(batch_size, X_test, Y_test, shuffle=False):\n",
    "        outputs = model(inputs).reshape(-1)\n",
    "        # convert back to numpy\n",
    "        outputs, targets = np.array(outputs), np.array(targets)\n",
    "        # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "        outputs_all = np.concatenate([outputs_all, outputs])\n",
    "        targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3974705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs):\n",
    "    cv_pearson = 0\n",
    "    for _, (X_train, X_test, Y_train, Y_test) in enumerate(zip(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)):\n",
    "        # initialize the model\n",
    "        mx.random.seed(default_random_state)\n",
    "        model = MLPMLX(num_features, hidden_layers_size, dropout)\n",
    "\n",
    "        # Initialize the loss function\n",
    "        def loss_fn(model, X, Y):\n",
    "            Y_pred = model(X).reshape(-1)\n",
    "            return mx.mean(nnmx.losses.mse_loss(Y_pred, Y))\n",
    "            # Y_centered = Y - mx.mean(Y)\n",
    "            # Y_pred_centered = Y_pred - mx.mean(Y_pred)\n",
    "            # return mx.sum(Y_centered * Y_pred_centered) / mx.sqrt(mx.sum(Y_centered ** 2) * mx.sum(Y_pred_centered ** 2))\n",
    "        loss_and_grad_fn = nnmx.value_and_grad(model, loss_fn)\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        optimizer = optimmx.Adam(learning_rate = lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_mlp_mlx(model, X_test, Y_test, batch_size)\n",
    "        print(pearson)\n",
    "        if pearson == -1:\n",
    "            return pearson\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0617236",
   "metadata": {},
   "source": [
    "Conduct training and evaluating process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a75900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training process of the default config\n",
    "# num_features = len(best_features)\n",
    "# hidden_layers_size = [8, 8, 8]\n",
    "# dropout = 0.2\n",
    "# lr = 0.001\n",
    "# batch_size = 180\n",
    "# num_epochs = 10\n",
    "\n",
    "# train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad94fa",
   "metadata": {},
   "source": [
    "Conduct Bayesian Optimization on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b347651",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "820f5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp_mlx(trial):\n",
    "    # First initialize the parameters\n",
    "    num_features = len(best_features)\n",
    "    num_layers = default_num_layers\n",
    "    log_2_hidden_layers_size = []\n",
    "    for i in range(num_layers):\n",
    "        if len(log_2_hidden_layers_size) == 0:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, 7))\n",
    "        else:\n",
    "            log_2_hidden_layers_size.append(trial.suggest_int(f\"log2_hidden_layer_{i}\", 2, log_2_hidden_layers_size[-1]))\n",
    "    hidden_layers_size = [2**l for l in log_2_hidden_layers_size]\n",
    "    # dropout = trial.suggest_categorical(\"dropout\", [0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "    dropout = 0\n",
    "    lr = trial.suggest_float(\"lr\", 0.0001, 0.01, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [30, 60, 120, 180, 360, 720])\n",
    "    num_epochs = trial.suggest_categorical(\"num_epochs\", [5 * i for i in range(1, 7)])\n",
    "    \n",
    "    # Conduct training based on those parameters\n",
    "    return train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e305bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mlp_mlx(study_name, storage_name, objective_function=objective_mlp_mlx, n_trials = 100, n_jobs = 1):\n",
    "    print(\"Conduct hyperparam opt for MLP\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = ['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', \n",
    "                 'X466', 'X95', 'X23', 'X219', 'X31', 'X373', 'X379', 'X284', 'X750', 'X652', \n",
    "                 'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X272', 'X271', 'X218']\n",
    "                # [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "                # [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "best_features = list(set(best_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features)\n",
    "\n",
    "# Convert to float32\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "\n",
    "# Convert to MLX\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e30381",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_mlp_mlx(\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\",\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_{len(best_features)}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196766ca",
   "metadata": {},
   "source": [
    "#### Nineth Iteration: AE + MLP instead of GBDT feature selection + MLP (train together)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c02845",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gaussian noise for autoencoder\n",
    "class GaussianNoise(nnmx.Module):\n",
    "    def __init__(self, mean: float = 0.0, stddev: float = 0.01):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self, x, training = True):\n",
    "        if training:\n",
    "            x += mx.random.normal(loc=self.mean, scale=self.stddev, shape=x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568359d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# We do not use the reset method this time so you have to create the model at each fold\n",
    "class AEMLX(nnmx.Module):\n",
    "    def __init__(self, num_features, hidden_layers_size, latent_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers for encoder\n",
    "        last_layer = num_features\n",
    "        self.encoder_layers = []\n",
    "        for current_layer in hidden_layers_size:\n",
    "            self.encoder_layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.encoder_layers.append(nnmx.Linear(last_layer, latent_size))\n",
    "\n",
    "        # Initialize layers for decoder\n",
    "        last_layer = latent_size\n",
    "        self.decoder_layers = []\n",
    "        for current_layer in hidden_layers_size[::-1]:\n",
    "            self.decoder_layers.append(nnmx.Linear(last_layer, current_layer))\n",
    "            last_layer = current_layer\n",
    "        self.decoder_layers.append(nnmx.Linear(last_layer, num_features))\n",
    "\n",
    "        # Initialize activation\n",
    "        self.activation = nnmx.ReLU()\n",
    "\n",
    "        # Initialze gaussian noise to apply upon training\n",
    "        # self.gaussian_noise = GaussianNoise()\n",
    "\n",
    "        # Initialize dropout\n",
    "        self.dropout = nnmx.Dropout(p = dropout)\n",
    "\n",
    "    def __call__(self, x, training = True):\n",
    "        # if training:\n",
    "        #     x = self.gaussian_noise(x)\n",
    "            \n",
    "        for inx, layer in enumerate(self.encoder_layers):\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "        for inx, layer in enumerate(self.decoder_layers):\n",
    "            if inx == len(self.decoder_layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                x = self.activation(x)\n",
    "                x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "    def get_latent(self, x):\n",
    "        for inx, layer in enumerate(self.encoder_layers):\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aef2af",
   "metadata": {},
   "source": [
    "Train model with CV and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae44b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_aemlp_mlx(ae_model, ae_loss_and_grad_fn, ae_optimizer, ae_num_epochs,\n",
    "                     mlp_model, mlp_loss_and_grad_fn, mlp_optimizer, mlp_num_epochs,\n",
    "                     X_train, Y_train, batch_size):\n",
    "    # Train ae first\n",
    "    ae_model.train()\n",
    "    for _ in tqdm(range(ae_num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            # get gradients for ae, output is the inputs itself\n",
    "            _, ae_grads = ae_loss_and_grad_fn(ae_model, inputs, inputs)\n",
    "\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            ae_optimizer.update(ae_model, ae_grads)\n",
    "\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(ae_model.parameters(), ae_optimizer.state)\n",
    "\n",
    "    # Train mlp later\n",
    "    mlp_model.train()\n",
    "    for _ in tqdm(range(mlp_num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            # get the latent representation for X_train\n",
    "            latent_inputs = ae_model.get_latent(inputs)\n",
    "            used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "            # get gradients for mlp\n",
    "            _, mlp_grads = mlp_loss_and_grad_fn(mlp_model, used_inputs, targets)\n",
    "\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            mlp_optimizer.update(mlp_model, mlp_grads)\n",
    "\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(mlp_model.parameters(), mlp_optimizer.state)\n",
    "\n",
    "    # # Train ae and mlp together\n",
    "    # ae_model.train()\n",
    "    # mlp_model.train()\n",
    "    # for _ in tqdm(range(ae_num_epochs)):\n",
    "    #     for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "    #         # get gradients for ae, output is the inputs itself\n",
    "    #         _, ae_grads = ae_loss_and_grad_fn(ae_model, inputs, inputs)\n",
    "\n",
    "    #         # Update the optimizer state and model parameters in a single call\n",
    "    #         ae_optimizer.update(ae_model, ae_grads)\n",
    "\n",
    "    #         # Force a graph evaluation\n",
    "    #         mx.eval(ae_model.parameters(), ae_optimizer.state)\n",
    "\n",
    "    #         # get gradients for mlp\n",
    "    #         latent_inputs = ae_model.get_latent(inputs)\n",
    "    #         used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "    #         _, mlp_grads = mlp_loss_and_grad_fn(mlp_model, used_inputs, targets)\n",
    "\n",
    "    #         # Update the optimizer state and model parameters in a single call\n",
    "    #         mlp_optimizer.update(mlp_model, mlp_grads)\n",
    "\n",
    "    #         # Force a graph evaluation\n",
    "    #         mx.eval(mlp_model.parameters(), mlp_optimizer.state)\n",
    "\n",
    "def eval_aemlp_mlx(ae_model, mlp_model, X_test, Y_test, batch_size):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    ae_model.eval()\n",
    "    mlp_model.eval()\n",
    "    for (inputs, targets) in batch_iterate(batch_size, X_test, Y_test, shuffle=False):\n",
    "        latent_inputs = ae_model.get_latent(inputs)\n",
    "        used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "        outputs = mlp_model(used_inputs).reshape(-1)\n",
    "        # convert back to numpy\n",
    "        outputs, targets = np.array(outputs), np.array(targets)\n",
    "        # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "        outputs_all = np.concatenate([outputs_all, outputs])\n",
    "        targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6679261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_mlx_aemlp(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout, ae_lr, ae_num_epochs,\n",
    "                            mlp_hidden_layers_size, mlp_dropout, mlp_lr, mlp_num_epochs,\n",
    "                            cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size):\n",
    "    cv_pearson = 0\n",
    "    for _, (X_train, X_test, Y_train, Y_test) in enumerate(zip(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)):\n",
    "        # initialize the model\n",
    "        mx.random.seed(default_random_state)\n",
    "        ae_model = AEMLX(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout)\n",
    "\n",
    "        mx.random.seed(default_random_state)\n",
    "        mlp_model = MLPMLX(ae_latent_size + num_features, mlp_hidden_layers_size, mlp_dropout)\n",
    "\n",
    "        # Initialize the loss function (both use same loss function)\n",
    "        def loss_fn(model, X, Y):\n",
    "            Y_pred = model(X).reshape(-1)\n",
    "            Y = Y.reshape(-1)\n",
    "            return mx.mean(nnmx.losses.mse_loss(Y_pred, Y))\n",
    "        ae_loss_and_grad_fn = nnmx.value_and_grad(ae_model, loss_fn)\n",
    "        mlp_loss_and_grad_fn = nnmx.value_and_grad(mlp_model, loss_fn)\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        ae_optimizer = optimmx.Adam(learning_rate = ae_lr)\n",
    "        mlp_optimizer = optimmx.Adam(learning_rate = mlp_lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_aemlp_mlx(ae_model, ae_loss_and_grad_fn, ae_optimizer, ae_num_epochs,\n",
    "                        mlp_model, mlp_loss_and_grad_fn, mlp_optimizer, mlp_num_epochs,\n",
    "                        X_train, Y_train, batch_size)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_aemlp_mlx(ae_model, mlp_model, X_test, Y_test, batch_size)\n",
    "        print(pearson)\n",
    "        if pearson == -1:\n",
    "            return pearson\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4959ed6",
   "metadata": {},
   "source": [
    "Conduct training and evaluating process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b892fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the CV data, seems to be better with only anonymized features\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col] + \\\n",
    "#                 [\"volume\", \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\"] + \\\n",
    "#                 [col for col in train_df.columns.tolist() if \"X\" not in col and col not in [\"timestamp\", \"label\"]]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_added_df, best_features)\n",
    "# for i in range(default_cv):\n",
    "#     X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "#     X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "#     Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "#     Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "# X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Training process of the default config\n",
    "# num_features = len(best_features)\n",
    "# ae_hidden_layers_size = [64]\n",
    "# ae_latent_size = 16\n",
    "# mlp_hidden_layers_size = [4, 2]\n",
    "# lr = 0.0005\n",
    "# dropout = 0.5\n",
    "# batch_size = 180\n",
    "# num_epochs = 30\n",
    "\n",
    "# train_eval_cv_mlx_aemlp(num_features, ae_hidden_layers_size, ae_latent_size, \n",
    "#                         mlp_hidden_layers_size, dropout, \n",
    "#                         lr, default_cv,\n",
    "#                         X_train_arr, X_test_arr, Y_train_arr, Y_test_arr,\n",
    "#                         batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477b9b9",
   "metadata": {},
   "source": [
    "Optimize with bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_default_num_layers = 2\n",
    "mlp_default_num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c60d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_aemlp_mlx(trial):\n",
    "    # First initialize the parameters\n",
    "    num_features = len(best_features)\n",
    "\n",
    "    # initialize ae layers\n",
    "    ae_num_layers = ae_default_num_layers\n",
    "    ae_log_2_hidden_layers_size = []\n",
    "    for i in range(ae_num_layers):\n",
    "        if len(ae_log_2_hidden_layers_size) == 0:\n",
    "            ae_log_2_hidden_layers_size.append(trial.suggest_int(f\"ae_log2_hidden_layer_{i}\", 3, int(math.ceil(math.log2(num_features)))))\n",
    "        else:\n",
    "            ae_log_2_hidden_layers_size.append(trial.suggest_int(f\"ae_log2_hidden_layer_{i}\", 3, ae_log_2_hidden_layers_size[-1]))\n",
    "    ae_hidden_layers_size = [2**i for i in ae_log_2_hidden_layers_size]\n",
    "    ae_latent_size = 2**trial.suggest_int(\"ae_log2_latent_size\", 3, ae_log_2_hidden_layers_size[-1])\n",
    "    ae_dropout = trial.suggest_categorical(\"ae_dropout\", [0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "    ae_lr = trial.suggest_float(\"ae_lr\", 0.0001, 0.01, log=True)\n",
    "    ae_num_epochs = trial.suggest_categorical(\"num_epochs\", [5 * i for i in range(1, 7)])\n",
    "\n",
    "    # initialize mlp layers\n",
    "    mlp_num_layers = mlp_default_num_layers\n",
    "    mlp_log_2_hidden_layers_size = []\n",
    "    for i in range(mlp_num_layers):\n",
    "        if len(mlp_log_2_hidden_layers_size) == 0:\n",
    "            mlp_log_2_hidden_layers_size.append(trial.suggest_int(f\"mlp_log2_hidden_layer_{i}\", 2, int(math.ceil(math.log2(ae_latent_size + num_features)))))\n",
    "        else:\n",
    "            mlp_log_2_hidden_layers_size.append(trial.suggest_int(f\"mlp_log2_hidden_layer_{i}\", 2, mlp_log_2_hidden_layers_size[-1]))\n",
    "    mlp_hidden_layers_size = [2**i for i in mlp_log_2_hidden_layers_size]\n",
    "    mlp_dropout = trial.suggest_categorical(\"mle_dropout\", [0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "    mlp_lr = trial.suggest_float(\"mlp_lr\", 0.0001, 0.01, log=True)\n",
    "    # mlp_num_epochs = trial.suggest_categorical(\"mlp_num_epochs\", [10, 20, 30, 40, 50])\n",
    "    mlp_num_epochs = ae_num_epochs\n",
    "\n",
    "    # batch size\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [30, 60, 120, 180, 360, 720, 1440])\n",
    "    \n",
    "    # Conduct training based on those parameters\n",
    "    cv_pearson = train_eval_cv_mlx_aemlp(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout, ae_lr, ae_num_epochs,\n",
    "                                         mlp_hidden_layers_size, mlp_dropout, mlp_lr, mlp_num_epochs,\n",
    "                                         default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr,\n",
    "                                         batch_size)\n",
    "    \n",
    "    return cv_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_aemlp_mlx(study_name, storage_name, objective_function=objective_aemlp_mlx, n_trials = 100, n_jobs = 1):\n",
    "    print(\"Conduct hyperparam opt for AE-MLP\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='maximize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = TPESampler(seed = 101, n_startup_trials=10),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best Pearson score:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = [col for col in train_df.columns if \"X\" in col and \"interaction\" not in col]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features)\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_aemlp_mlx(\n",
    "    f\"aemlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{ae_default_num_layers}_{mlp_default_num_layers}_study\",\n",
    "    f\"aemlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{ae_default_num_layers}_{mlp_default_num_layers}_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af3671",
   "metadata": {},
   "source": [
    "#### Tenth Trial: Adding interaction terms to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bc9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', \n",
    "                 'X466', 'X95', 'X23', 'X219', 'X31', 'X373', 'X379', 'X284', 'X750', 'X652', \n",
    "                 'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X272', 'X271', 'X218']\n",
    "best_interaction_features = [\n",
    "    'X205_X131_X294_interaction', 'X205_X131_X296_interaction', 'X205_X169_X291_interaction', \n",
    "    'X205_X169_X289_interaction', 'X205_X169_X298_interaction', 'X205_X169_X292_interaction', \n",
    "    'X205_X169_X294_interaction', 'X205_X169_X296_interaction', 'X205_X89_X290_interaction', \n",
    "    'X205_X89_X292_interaction', 'X205_X89_X294_interaction', 'X205_X83_X288_interaction', \n",
    "    'X205_X83_X290_interaction', 'X205_X83_X292_interaction', 'X205_X83_X294_interaction', \n",
    "    'X205_X83_X296_interaction', 'X198_X175_X294_interaction', 'X198_X175_X296_interaction', \n",
    "    'X198_X131_X292_interaction', 'X198_X131_X294_interaction', 'X198_X131_X296_interaction', \n",
    "    'X198_X169_X292_interaction', 'X198_X169_X294_interaction', 'X198_X169_X296_interaction', \n",
    "    'X198_X89_X290_interaction', 'X198_X89_X292_interaction', 'X198_X89_X294_interaction', \n",
    "    'X198_X89_X296_interaction', 'X198_X83_X288_interaction', 'X198_X83_X290_interaction', \n",
    "    'X198_X83_X292_interaction', 'X198_X83_X294_interaction', 'X198_X83_X296_interaction', \n",
    "    'X204_X83_X296_interaction'\n",
    "]\n",
    "best_exp_interaction_features = [\n",
    "    'X181_X285_exp_interaction', 'X473_X181_X285_exp_interaction', 'X205_X181_X286_exp_interaction',\n",
    "    'X205_X181_X288_exp_interaction', 'X205_X181_X290_exp_interaction', 'X205_X758_X286_exp_interaction',\n",
    "    'X205_X758_X288_exp_interaction', 'X205_X758_X290_exp_interaction', 'X205_X758_X292_exp_interaction',\n",
    "    'X205_X758_X294_exp_interaction', 'X205_X758_X296_exp_interaction', 'X205_X758_X271_exp_interaction',\n",
    "    'X205_X175_X286_exp_interaction', 'X205_X175_X288_exp_interaction', 'X205_X175_X292_exp_interaction',\n",
    "    'X205_X175_X294_exp_interaction', 'X205_X175_X296_exp_interaction', 'X205_X614_X285_exp_interaction', \n",
    "    'X198_X758_X286_exp_interaction', 'X198_X758_X288_exp_interaction', 'X198_X758_X290_exp_interaction',\n",
    "    'X181_X762_X286_exp_interaction', 'X181_X272_X286_exp_interaction', 'X181_X272_X288_exp_interaction', \n",
    "    'X181_X272_X285_exp_interaction', 'X204_X758_X286_exp_interaction', 'X204_X758_X288_exp_interaction',\n",
    "    'X204_X758_X290_exp_interaction', 'X204_X758_X292_exp_interaction'\n",
    "]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features + best_interaction_features + best_exp_interaction_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd6718",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgboost_params_common_truncated_with_interaction = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6b477",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lightgbm_params_common_truncated_with_interaction = optimize_lightgbm(\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study\",\n",
    "    f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study\",\n",
    "    n_trials = 64\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac44f8a5",
   "metadata": {},
   "source": [
    "Analyze importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d35707",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_xgboost = get_best_params_from_file(f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study\")\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "xgboost_feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, xgbr.predict(X_test)))\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    # features_i = xgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(xgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "    for inx, feat in enumerate(features):\n",
    "        xgboost_feature_importances[feat] = xgboost_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# print(feature_importances)\n",
    "plt.hist(xgboost_feature_importances.values())\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c3dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": default_n_trees,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": default_random_state\n",
    "}\n",
    "best_params_lightgbm = get_best_params_from_file(f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study\")\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "lightgbm_feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(default_cv):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    print(pearson_score(Y_test, lgbr.predict(X_test)))\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    # features_i = lgbr.feature_importances_.tolist()\n",
    "    features_i = get_shap_values(lgbr, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, 10000)\n",
    "    for inx, feat in enumerate(features):\n",
    "        lightgbm_feature_importances[feat] = lightgbm_feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "plt.hist(lightgbm_feature_importances.values())\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_importances_df = pd.DataFrame(\n",
    "    {\"var\": xgboost_feature_importances.keys(), \"importance\": xgboost_feature_importances.values()}\n",
    ")\n",
    "xgboost_feature_importances_df[\"importance\"] /= default_cv\n",
    "# xgboost_feature_importances_df[\"rank_importance\"] = xgboost_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# lightgbm_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": lightgbm_feature_importances.keys(), \"importance\": lightgbm_feature_importances.values()}\n",
    "# )\n",
    "# lightgbm_feature_importances_df[\"importance\"] /= default_cv\n",
    "# lightgbm_feature_importances_df[\"rank_importance\"] = lightgbm_feature_importances_df[\"importance\"].rank(ascending=False)\n",
    "# catboost_feature_importances_df = pd.DataFrame(\n",
    "#     {\"var\": catboost_feature_importances.keys(), \"importance_catboost\": catboost_feature_importances.values()}\n",
    "# )\n",
    "# catboost_feature_importances_df[\"rank_importance\"] = catboost_feature_importances_df[\"importance_catboost\"].rank(ascending=False)\n",
    "# feature_importances_df = xgboost_feature_importances_df.merge(\n",
    "#     lightgbm_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"_xgboost\", \"_lightgbm\")\n",
    "# )\n",
    "feature_importances_df = xgboost_feature_importances_df\n",
    "# feature_importances_df = feature_importances_df.merge(\n",
    "#     catboost_feature_importances_df,\n",
    "#     on=\"var\",\n",
    "#     how=\"inner\",\n",
    "#     suffixes=(\"\", \"_catboost\")\n",
    "# )\n",
    "# feature_importances_df = feature_importances_df[[\"var\", \"rank_importance_xgboost\", \"rank_importance_lightgbm\", \"rank_importance_catboost\"]]\n",
    "# feature_importances_df[\"rank\"] = 1/3 * (feature_importances_df[\"rank_importance_xgboost\"] + feature_importances_df[\"rank_importance_lightgbm\"] + feature_importances_df[\"rank_importance_catboost\"])\n",
    "\n",
    "# feature_importances_df[\"importance\"] = 1/2 * (feature_importances_df[\"importance_xgboost\"] + feature_importances_df[\"importance_lightgbm\"])\n",
    "# best_xgboost_score = optuna.load_study(\n",
    "#     study_name = f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study\",\n",
    "#     storage = f\"sqlite:///xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study.db\"\n",
    "# ).best_value\n",
    "# best_lightgbm_score = optuna.load_study(\n",
    "#     study_name = f\"lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study\",\n",
    "#     storage = f\"sqlite:///lightgbm_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_interaction_study.db\"\n",
    "# ).best_value\n",
    "# feature_importances_df[\"weighted_importance\"] = (best_xgboost_score * feature_importances_df[\"importance_xgboost\"] + best_lightgbm_score * feature_importances_df[\"importance_lightgbm\"]) / (best_xgboost_score + best_lightgbm_score)\n",
    "# feature_importances_df = feature_importances_df.sort_values(\"weighted_importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df = feature_importances_df.sort_values(\"importance\", ascending=False, ignore_index=True)\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec656c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df.to_csv(\"feature_importances_with_interaction_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbcc48e",
   "metadata": {},
   "source": [
    "#### Eleventh Trial: Adding MLP and only good (features + interaction features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4494dde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6] [8, 9, 10, 11]\n",
      "[4, 5, 6, 7] [9, 10, 11, 12]\n",
      "[5, 6, 7, 8] [10, 11, 12, 1]\n",
      "[6, 7, 8, 9] [11, 12, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "best_features = ['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', \n",
    "                 'X466', 'X95', 'X23', 'X219', 'X31', 'X373', 'X379', 'X284', 'X750', 'X652', \n",
    "                 'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X272', 'X271', 'X218']\n",
    "best_interaction_features = [\n",
    "    'X205_X169_X298_interaction', 'X198_X131_X292_interaction', 'X205_X169_X291_interaction',\n",
    "    'X198_X89_X290_interaction', 'X198_X175_X294_interaction'\n",
    "]\n",
    "best_exp_interaction_features = [\n",
    "    'X205_X614_X285_exp_interaction', 'X181_X762_X286_exp_interaction', 'X473_X181_X285_exp_interaction',\n",
    "    'X205_X758_X271_exp_interaction', 'X181_X285_exp_interaction', 'X198_X758_X286_exp_interaction'\n",
    "]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features + best_interaction_features + best_exp_interaction_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ebd9c",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d62c5a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-21 00:03:21,744] A new study created in RDB with name: xgboost_2_4_101_1000_common_truncated_30_with_less_interaction_study\n",
      "[I 2025-07-21 00:03:35,169] Trial 0 finished with value: 0.09621960912322612 and parameters: {'max_depth': 6, 'learning_rate': 0.013846345806771068, 'subsample': 0.0770505151541921, 'colsample_bytree': 0.2129455734138479, 'colsample_bynode': 0.7010131326124469, 'colsample_bylevel': 0.8422020195042726, 'min_child_weight': 4, 'reg_alpha': 89.36130796833973, 'reg_lambda': 72.15438617683047, 'gamma': 0.9496947710239839}. Best is trial 0 with value: 0.09621960912322612.\n",
      "[I 2025-07-21 00:03:50,439] Trial 1 finished with value: 0.10096098699314132 and parameters: {'max_depth': 6, 'learning_rate': 0.0050613213026475335, 'subsample': 0.22279778252707472, 'colsample_bytree': 0.7963216737711408, 'colsample_bynode': 0.9672090612913707, 'colsample_bylevel': 0.27073597872402266, 'min_child_weight': 1, 'reg_alpha': 60.35484222912185, 'reg_lambda': 72.89927572876178, 'gamma': 1.381194142486314}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:04:03,522] Trial 2 finished with value: 0.0935618247269779 and parameters: {'max_depth': 8, 'learning_rate': 0.010857627761370678, 'subsample': 0.09606031055508055, 'colsample_bytree': 0.1809757756840008, 'colsample_bynode': 0.227619054831025, 'colsample_bylevel': 0.9946020060963922, 'min_child_weight': 6, 'reg_alpha': 57.87895354754169, 'reg_lambda': 73.48190582693819, 'gamma': 2.709808861147968}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:04:14,777] Trial 3 finished with value: 0.09323249604854499 and parameters: {'max_depth': 10, 'learning_rate': 0.04128956447911593, 'subsample': 0.43284793915909797, 'colsample_bytree': 0.38936312567974846, 'colsample_bynode': 0.9552328789753295, 'colsample_bylevel': 0.3764499989979318, 'min_child_weight': 9, 'reg_alpha': 83.0277712198797, 'reg_lambda': 53.81614492475574, 'gamma': 4.612346862836118}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:04:22,367] Trial 4 finished with value: 0.09233487764804128 and parameters: {'max_depth': 2, 'learning_rate': 0.0016058130623353558, 'subsample': 0.7164319309110344, 'colsample_bytree': 0.8959558756720097, 'colsample_bynode': 0.20158228585329385, 'colsample_bylevel': 0.3117939176521059, 'min_child_weight': 7, 'reg_alpha': 16.430312402017023, 'reg_lambda': 70.13711366090864, 'gamma': 2.4381761110286404}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:04:40,395] Trial 5 finished with value: 0.09964813825376478 and parameters: {'max_depth': 8, 'learning_rate': 0.011043236795269145, 'subsample': 0.09122685971238012, 'colsample_bytree': 0.26273977332687876, 'colsample_bynode': 0.5964448325246123, 'colsample_bylevel': 0.16441197712092778, 'min_child_weight': 6, 'reg_alpha': 13.8009568258896, 'reg_lambda': 5.280840108926621, 'gamma': 0.8913846126807584}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:04:50,038] Trial 6 finished with value: 0.07652788614892495 and parameters: {'max_depth': 5, 'learning_rate': 0.05690817380795722, 'subsample': 0.9518009225359342, 'colsample_bytree': 0.504259045950091, 'colsample_bynode': 0.48806337517211296, 'colsample_bylevel': 0.6554245794664891, 'min_child_weight': 4, 'reg_alpha': 11.757809302799405, 'reg_lambda': 5.110099639577459, 'gamma': 3.1882932640891264}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:05:12,258] Trial 7 finished with value: 0.08996834577236953 and parameters: {'max_depth': 9, 'learning_rate': 0.021903869365420096, 'subsample': 0.6691793183025508, 'colsample_bytree': 0.45334049638369517, 'colsample_bynode': 0.6737655693895496, 'colsample_bylevel': 0.24870342391787859, 'min_child_weight': 7, 'reg_alpha': 52.962339875301446, 'reg_lambda': 74.85203698504924, 'gamma': 0.46878427934628986}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:05:25,457] Trial 8 finished with value: 0.09210499073477035 and parameters: {'max_depth': 9, 'learning_rate': 0.023685582791520273, 'subsample': 0.7103245716826961, 'colsample_bytree': 0.5220231936169049, 'colsample_bynode': 0.976593070682431, 'colsample_bylevel': 0.24335123957144503, 'min_child_weight': 3, 'reg_alpha': 22.765589279419316, 'reg_lambda': 4.816888544201381, 'gamma': 4.51985678726306}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:05:33,627] Trial 9 finished with value: 0.09966395778138487 and parameters: {'max_depth': 2, 'learning_rate': 0.016384475510214467, 'subsample': 0.6493043684499376, 'colsample_bytree': 0.4090448353015824, 'colsample_bynode': 0.0625789605320767, 'colsample_bylevel': 0.8501084412583794, 'min_child_weight': 4, 'reg_alpha': 55.16658450763543, 'reg_lambda': 71.05381400635508, 'gamma': 3.3763942535951474}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:05:45,131] Trial 10 finished with value: 0.09420375614097137 and parameters: {'max_depth': 4, 'learning_rate': 0.0027178192479451095, 'subsample': 0.4049052035457443, 'colsample_bytree': 0.8021294368194642, 'colsample_bynode': 0.8220267555544318, 'colsample_bylevel': 0.05938218120156841, 'min_child_weight': 2, 'reg_alpha': 33.35394143921389, 'reg_lambda': 94.94392617599553, 'gamma': 1.7147753066597438}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:05:53,321] Trial 11 finished with value: 0.09028554119171621 and parameters: {'max_depth': 2, 'learning_rate': 0.0042861575776398245, 'subsample': 0.3118024798952855, 'colsample_bytree': 0.7078542254547716, 'colsample_bynode': 0.3917497408580698, 'colsample_bylevel': 0.5203252590841206, 'min_child_weight': 1, 'reg_alpha': 66.99629608693513, 'reg_lambda': 36.50022632369131, 'gamma': 3.5626415885979075}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:06:05,029] Trial 12 finished with value: 0.09161549704145219 and parameters: {'max_depth': 4, 'learning_rate': 0.005528869541213948, 'subsample': 0.5797213856648571, 'colsample_bytree': 0.6745408328320431, 'colsample_bynode': 0.10116928094764971, 'colsample_bylevel': 0.6767265683781778, 'min_child_weight': 1, 'reg_alpha': 41.487962578257054, 'reg_lambda': 93.4598913134817, 'gamma': 1.8781394471852626}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:06:14,930] Trial 13 finished with value: 0.08730354093477191 and parameters: {'max_depth': 3, 'learning_rate': 0.005326730223313553, 'subsample': 0.9146097180026009, 'colsample_bytree': 0.9624151930057832, 'colsample_bynode': 0.3668701360638915, 'colsample_bylevel': 0.4690111162287336, 'min_child_weight': 4, 'reg_alpha': 77.9372557553035, 'reg_lambda': 48.82463211181627, 'gamma': 3.9630456609793208}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:06:30,917] Trial 14 finished with value: 0.08907938962736384 and parameters: {'max_depth': 6, 'learning_rate': 0.0013705552520168979, 'subsample': 0.25716317472049405, 'colsample_bytree': 0.6670108443420993, 'colsample_bynode': 0.8043001289848128, 'colsample_bylevel': 0.7225363474801311, 'min_child_weight': 2, 'reg_alpha': 98.65943468487627, 'reg_lambda': 55.566427493049474, 'gamma': 1.6125669444666035}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:06:48,199] Trial 15 finished with value: 0.09233767405846678 and parameters: {'max_depth': 7, 'learning_rate': 0.025235952879500707, 'subsample': 0.8470610696680199, 'colsample_bytree': 0.07833672515547874, 'colsample_bynode': 0.09178764809574669, 'colsample_bylevel': 0.9235429518472067, 'min_child_weight': 9, 'reg_alpha': 67.77310259545787, 'reg_lambda': 30.24354923355677, 'gamma': 0.04818759465424316}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:06:59,837] Trial 16 finished with value: 0.09474503848635105 and parameters: {'max_depth': 4, 'learning_rate': 0.003520134486928512, 'subsample': 0.5571660875001399, 'colsample_bytree': 0.3351440494484884, 'colsample_bynode': 0.4168740436476589, 'colsample_bylevel': 0.4134486954640585, 'min_child_weight': 5, 'reg_alpha': 59.72581344792256, 'reg_lambda': 88.09801776935174, 'gamma': 2.491847110189848}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:07:09,590] Trial 17 finished with value: 0.09231691344743559 and parameters: {'max_depth': 3, 'learning_rate': 0.0068684919572500405, 'subsample': 0.2747838115308975, 'colsample_bytree': 0.605364848353677, 'colsample_bynode': 0.29227249947683653, 'colsample_bylevel': 0.597019302202469, 'min_child_weight': 2, 'reg_alpha': 40.657530946380675, 'reg_lambda': 83.29104589344257, 'gamma': 3.3204727680401063}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:07:18,289] Trial 18 finished with value: 0.08343352725454577 and parameters: {'max_depth': 5, 'learning_rate': 0.0884857606289278, 'subsample': 0.42570286301867416, 'colsample_bytree': 0.8153014044225133, 'colsample_bynode': 0.805179183123482, 'colsample_bylevel': 0.7942173301256144, 'min_child_weight': 3, 'reg_alpha': 0.7556774300634572, 'reg_lambda': 63.22981641512065, 'gamma': 4.008615687194461}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:07:34,915] Trial 19 finished with value: 0.09406189670412929 and parameters: {'max_depth': 7, 'learning_rate': 0.002227901222700398, 'subsample': 0.18966079933211258, 'colsample_bytree': 0.7993701006725833, 'colsample_bynode': 0.5382730922344257, 'colsample_bylevel': 0.06405566883447605, 'min_child_weight': 1, 'reg_alpha': 44.447342741949996, 'reg_lambda': 42.08486409889731, 'gamma': 1.341244996712319}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:07:49,010] Trial 20 finished with value: 0.08450882333907109 and parameters: {'max_depth': 5, 'learning_rate': 0.007463456807958848, 'subsample': 0.8190875945899139, 'colsample_bytree': 0.6037773413687659, 'colsample_bynode': 0.8997771595468487, 'colsample_bylevel': 0.5479128531642952, 'min_child_weight': 8, 'reg_alpha': 70.57653443018238, 'reg_lambda': 23.420384722379982, 'gamma': 2.7940713203363283}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:08:07,379] Trial 21 finished with value: 0.09951737852848629 and parameters: {'max_depth': 8, 'learning_rate': 0.013167087770366393, 'subsample': 0.15635909838429826, 'colsample_bytree': 0.28456802174242596, 'colsample_bynode': 0.685175282487386, 'colsample_bylevel': 0.1622360411310907, 'min_child_weight': 6, 'reg_alpha': 30.085138736514104, 'reg_lambda': 18.920427545288913, 'gamma': 0.8782788726240255}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:08:19,913] Trial 22 finished with value: 0.10026820834024597 and parameters: {'max_depth': 10, 'learning_rate': 0.008989037859555158, 'subsample': 0.055592585862689475, 'colsample_bytree': 0.40695759847892593, 'colsample_bynode': 0.5841434687839352, 'colsample_bylevel': 0.16494861365902014, 'min_child_weight': 5, 'reg_alpha': 50.596368599547674, 'reg_lambda': 62.16322271863535, 'gamma': 2.0465539191285886}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:08:39,897] Trial 23 finished with value: 0.09792353751330471 and parameters: {'max_depth': 10, 'learning_rate': 0.015598584435411934, 'subsample': 0.3506009156599001, 'colsample_bytree': 0.42540286628091317, 'colsample_bynode': 0.05187547508914486, 'colsample_bylevel': 0.15277435337500142, 'min_child_weight': 5, 'reg_alpha': 52.592664025032605, 'reg_lambda': 64.32255247699388, 'gamma': 2.219228145607779}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:08:56,829] Trial 24 finished with value: 0.09810268413998881 and parameters: {'max_depth': 7, 'learning_rate': 0.00796701952285428, 'subsample': 0.485581959392289, 'colsample_bytree': 0.36445091761268766, 'colsample_bynode': 0.501668888436508, 'colsample_bylevel': 0.2753089141832349, 'min_child_weight': 3, 'reg_alpha': 61.21501718751044, 'reg_lambda': 81.08860784568819, 'gamma': 2.1814376496613828}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:09:07,333] Trial 25 finished with value: 0.09479584475280335 and parameters: {'max_depth': 3, 'learning_rate': 0.03350912648264602, 'subsample': 0.20633851697734462, 'colsample_bytree': 0.5794478909945827, 'colsample_bynode': 0.591558044002305, 'colsample_bylevel': 0.35862686363591406, 'min_child_weight': 5, 'reg_alpha': 46.50134134657129, 'reg_lambda': 61.25714856124196, 'gamma': 1.1902104840070094}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:09:26,840] Trial 26 finished with value: 0.09536251083965445 and parameters: {'max_depth': 9, 'learning_rate': 0.0181352256083752, 'subsample': 0.6235321930179436, 'colsample_bytree': 0.48058389722390765, 'colsample_bynode': 0.21038093919662856, 'colsample_bylevel': 0.444943570592363, 'min_child_weight': 10, 'reg_alpha': 33.91722309891903, 'reg_lambda': 99.98030076591253, 'gamma': 2.9992940597185638}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:09:42,404] Trial 27 finished with value: 0.0938626048296741 and parameters: {'max_depth': 6, 'learning_rate': 0.0032848809314839854, 'subsample': 0.5022639242302802, 'colsample_bytree': 0.08007651744146721, 'colsample_bynode': 0.8778336269976392, 'colsample_bylevel': 0.12374949902775043, 'min_child_weight': 4, 'reg_alpha': 74.74240242449801, 'reg_lambda': 45.08596714594222, 'gamma': 2.0020180573476343}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:09:50,939] Trial 28 finished with value: 0.09684043148293711 and parameters: {'max_depth': 2, 'learning_rate': 0.008085301847273001, 'subsample': 0.13791610033215673, 'colsample_bytree': 0.9748701314548209, 'colsample_bynode': 0.7466043570233016, 'colsample_bylevel': 0.21469481563308795, 'min_child_weight': 7, 'reg_alpha': 50.416458165873486, 'reg_lambda': 80.43819225075501, 'gamma': 4.939266604966361}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:10:05,223] Trial 29 finished with value: 0.08815575878486846 and parameters: {'max_depth': 6, 'learning_rate': 0.0010707309891665648, 'subsample': 0.05587183148972235, 'colsample_bytree': 0.25025109571637005, 'colsample_bynode': 0.320781959773291, 'colsample_bylevel': 0.8171506429842024, 'min_child_weight': 3, 'reg_alpha': 91.2368743163768, 'reg_lambda': 68.05338071066038, 'gamma': 1.4473991799570909}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:10:29,105] Trial 30 finished with value: 0.0920444612032725 and parameters: {'max_depth': 10, 'learning_rate': 0.005138162715057938, 'subsample': 0.7726485220213486, 'colsample_bytree': 0.1781835752326321, 'colsample_bynode': 0.6253635409603624, 'colsample_bylevel': 0.3417190675486137, 'min_child_weight': 5, 'reg_alpha': 63.32384634685672, 'reg_lambda': 56.10045568808422, 'gamma': 3.6913572509040913}. Best is trial 1 with value: 0.10096098699314132.\n",
      "[I 2025-07-21 00:10:49,407] Trial 31 finished with value: 0.10217994931322091 and parameters: {'max_depth': 8, 'learning_rate': 0.010682111861323467, 'subsample': 0.08983006380342352, 'colsample_bytree': 0.3125795203796713, 'colsample_bynode': 0.6079855791671256, 'colsample_bylevel': 0.19071445397236875, 'min_child_weight': 6, 'reg_alpha': 2.349343632391779, 'reg_lambda': 11.736095230742437, 'gamma': 0.7288906811679872}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:11:12,328] Trial 32 finished with value: 0.09432164104129881 and parameters: {'max_depth': 9, 'learning_rate': 0.011208344035111848, 'subsample': 0.12025313187651171, 'colsample_bytree': 0.3361920286070085, 'colsample_bynode': 0.7175101642927133, 'colsample_bylevel': 0.9830332545547503, 'min_child_weight': 6, 'reg_alpha': 53.28997576024674, 'reg_lambda': 75.43810053844987, 'gamma': 0.48134487163673756}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:11:26,662] Trial 33 finished with value: 0.09573568651984675 and parameters: {'max_depth': 8, 'learning_rate': 0.015604830258248817, 'subsample': 0.05240911360652101, 'colsample_bytree': 0.41982976532474814, 'colsample_bynode': 0.45564192574825735, 'colsample_bylevel': 0.20321678251103678, 'min_child_weight': 8, 'reg_alpha': 57.274118235316074, 'reg_lambda': 14.083341775316898, 'gamma': 0.5374269174882255}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:11:49,248] Trial 34 finished with value: 0.09598818249268659 and parameters: {'max_depth': 10, 'learning_rate': 0.008827005442913824, 'subsample': 0.23195298935573067, 'colsample_bytree': 0.1740323695724643, 'colsample_bynode': 0.6407184481172815, 'colsample_bylevel': 0.3054465286960243, 'min_child_weight': 4, 'reg_alpha': 36.914856975126256, 'reg_lambda': 57.771756059760996, 'gamma': 1.1972410225806265}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:12:08,354] Trial 35 finished with value: 0.09546870245504113 and parameters: {'max_depth': 8, 'learning_rate': 0.011385754080985121, 'subsample': 0.1673257590195733, 'colsample_bytree': 0.29163774177872204, 'colsample_bynode': 0.5691102273134403, 'colsample_bylevel': 0.1041473627840103, 'min_child_weight': 6, 'reg_alpha': 28.985052991231246, 'reg_lambda': 72.0798269689967, 'gamma': 0.9630526364766039}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:12:25,641] Trial 36 finished with value: 0.09829111437810642 and parameters: {'max_depth': 7, 'learning_rate': 0.033196731164107825, 'subsample': 0.1129805833689589, 'colsample_bytree': 0.39000404221363494, 'colsample_bynode': 0.15322734085522022, 'colsample_bylevel': 0.8921403463318426, 'min_child_weight': 7, 'reg_alpha': 5.696439448985315, 'reg_lambda': 66.95779955667349, 'gamma': 0.06531326815568628}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:12:43,247] Trial 37 finished with value: 0.0955845472034764 and parameters: {'max_depth': 9, 'learning_rate': 0.017324227345838772, 'subsample': 0.3494189485857053, 'colsample_bytree': 0.553533305517095, 'colsample_bynode': 0.2852943871588324, 'colsample_bylevel': 0.2863623969894885, 'min_child_weight': 8, 'reg_alpha': 81.74729440481096, 'reg_lambda': 36.24294653357859, 'gamma': 2.65179193238358}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:12:56,842] Trial 38 finished with value: 0.09639004889499168 and parameters: {'max_depth': 10, 'learning_rate': 0.010176334520729814, 'subsample': 0.07719805766176327, 'colsample_bytree': 0.2253044354426636, 'colsample_bynode': 0.7483354467214315, 'colsample_bylevel': 0.2054451264384441, 'min_child_weight': 4, 'reg_alpha': 47.79284808702859, 'reg_lambda': 48.48733839041814, 'gamma': 2.292463912853613}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:13:17,770] Trial 39 finished with value: 0.09811059066743585 and parameters: {'max_depth': 8, 'learning_rate': 0.002122496966069384, 'subsample': 0.6656643279167584, 'colsample_bytree': 0.48306048175549754, 'colsample_bynode': 0.9923440874678477, 'colsample_bylevel': 0.12100188453296873, 'min_child_weight': 5, 'reg_alpha': 22.816156260122074, 'reg_lambda': 0.9768366447711774, 'gamma': 0.7487429991299338}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:13:31,764] Trial 40 finished with value: 0.09537510419024475 and parameters: {'max_depth': 5, 'learning_rate': 0.006638365791341743, 'subsample': 0.3102310323066374, 'colsample_bytree': 0.7518944609112985, 'colsample_bynode': 0.8984692492630345, 'colsample_bylevel': 0.3840822106820413, 'min_child_weight': 6, 'reg_alpha': 57.44382985530921, 'reg_lambda': 86.8540360134862, 'gamma': 1.866931845900468}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:13:51,362] Trial 41 finished with value: 0.0964427065579002 and parameters: {'max_depth': 9, 'learning_rate': 0.012745080710292228, 'subsample': 0.10823576203472468, 'colsample_bytree': 0.1338815053960934, 'colsample_bynode': 0.44284858202694977, 'colsample_bylevel': 0.17015531285548846, 'min_child_weight': 7, 'reg_alpha': 10.933984841463397, 'reg_lambda': 14.03204335812762, 'gamma': 1.0639633265394892}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:14:08,508] Trial 42 finished with value: 0.09766361316799767 and parameters: {'max_depth': 7, 'learning_rate': 0.004154429906190615, 'subsample': 0.1939177614810892, 'colsample_bytree': 0.28832927123580226, 'colsample_bynode': 0.5458774372465055, 'colsample_bylevel': 0.0761702287940663, 'min_child_weight': 6, 'reg_alpha': 16.214769910836285, 'reg_lambda': 11.534767371686957, 'gamma': 1.4768887955807546}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:14:27,524] Trial 43 finished with value: 0.09676576750484274 and parameters: {'max_depth': 8, 'learning_rate': 0.021274063937783298, 'subsample': 0.08902314583590921, 'colsample_bytree': 0.35559653471845665, 'colsample_bynode': 0.6348282551604721, 'colsample_bylevel': 0.2261982090657999, 'min_child_weight': 5, 'reg_alpha': 2.417067744319965, 'reg_lambda': 7.801598475643765, 'gamma': 0.7579360724417978}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:14:50,793] Trial 44 finished with value: 0.101283695952316 and parameters: {'max_depth': 9, 'learning_rate': 0.009735578819417185, 'subsample': 0.15226795153895153, 'colsample_bytree': 0.8907562183068274, 'colsample_bynode': 0.5960889060874262, 'colsample_bylevel': 0.24785335824136392, 'min_child_weight': 2, 'reg_alpha': 6.630271729422887, 'reg_lambda': 75.99580640772349, 'gamma': 1.6482320217737587}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:15:14,843] Trial 45 finished with value: 0.09758923384851087 and parameters: {'max_depth': 10, 'learning_rate': 0.009626089976767985, 'subsample': 0.13882646314569833, 'colsample_bytree': 0.900427815162401, 'colsample_bynode': 0.49493622185659825, 'colsample_bylevel': 0.26497297453277185, 'min_child_weight': 2, 'reg_alpha': 22.447459710478526, 'reg_lambda': 76.99288776017829, 'gamma': 1.704872226172877}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:15:39,186] Trial 46 finished with value: 0.09369674762759145 and parameters: {'max_depth': 9, 'learning_rate': 0.005034886947209239, 'subsample': 0.2352683055570614, 'colsample_bytree': 0.9143991006171631, 'colsample_bynode': 0.37153483141291754, 'colsample_bylevel': 0.7500495365083749, 'min_child_weight': 1, 'reg_alpha': 7.625076998377747, 'reg_lambda': 69.72881327882706, 'gamma': 2.0839441369528586}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:16:07,949] Trial 47 finished with value: 0.08951118437231503 and parameters: {'max_depth': 10, 'learning_rate': 0.006542922938548438, 'subsample': 0.7142939325479302, 'colsample_bytree': 0.8538992273301582, 'colsample_bynode': 0.8494962003858839, 'colsample_bylevel': 0.5282728501116772, 'min_child_weight': 2, 'reg_alpha': 64.91051971032948, 'reg_lambda': 60.60719994995474, 'gamma': 1.8091352080661873}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:16:31,356] Trial 48 finished with value: 0.09075625173755036 and parameters: {'max_depth': 9, 'learning_rate': 0.02797288036642773, 'subsample': 0.5648528114403187, 'colsample_bytree': 0.9962231092159659, 'colsample_bynode': 0.6706211702893075, 'colsample_bylevel': 0.3376798179838048, 'min_child_weight': 3, 'reg_alpha': 55.114982908811875, 'reg_lambda': 52.27775902826957, 'gamma': 0.2970702276358272}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:16:43,031] Trial 49 finished with value: 0.09533978490479716 and parameters: {'max_depth': 4, 'learning_rate': 0.020965162685721312, 'subsample': 0.27103663458286764, 'colsample_bytree': 0.7337114467627224, 'colsample_bynode': 0.9343924731267912, 'colsample_bylevel': 0.6500933354836377, 'min_child_weight': 1, 'reg_alpha': 42.58379898489167, 'reg_lambda': 90.35533852881244, 'gamma': 3.020108644908523}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:16:55,137] Trial 50 finished with value: 0.09531458764917916 and parameters: {'max_depth': 6, 'learning_rate': 0.04390649752127504, 'subsample': 0.38564039664156846, 'colsample_bytree': 0.4464612731328216, 'colsample_bynode': 0.7820847890689675, 'colsample_bylevel': 0.4634338384110447, 'min_child_weight': 4, 'reg_alpha': 72.75687613832193, 'reg_lambda': 77.5872964049018, 'gamma': 2.4625246124437656}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:17:14,383] Trial 51 finished with value: 0.0971782823666605 and parameters: {'max_depth': 8, 'learning_rate': 0.00599401709820502, 'subsample': 0.15922723334031594, 'colsample_bytree': 0.31077796030604, 'colsample_bynode': 0.5920532579406882, 'colsample_bylevel': 0.18364697788443604, 'min_child_weight': 2, 'reg_alpha': 15.705980422139078, 'reg_lambda': 1.3700727649618258, 'gamma': 1.5836726848564835}. Best is trial 31 with value: 0.10217994931322091.\n",
      "[I 2025-07-21 00:17:22,580] Trial 52 finished with value: 0.10627525889669527 and parameters: {'max_depth': 2, 'learning_rate': 0.01451225130909297, 'subsample': 0.09674855104145334, 'colsample_bytree': 0.23515054488702938, 'colsample_bynode': 0.5286603055784903, 'colsample_bylevel': 0.2484567071851006, 'min_child_weight': 6, 'reg_alpha': 6.18648185411528, 'reg_lambda': 25.16367998274342, 'gamma': 1.244054097289789}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:17:30,786] Trial 53 finished with value: 0.10536702430937625 and parameters: {'max_depth': 2, 'learning_rate': 0.01386494061179171, 'subsample': 0.09115818291413524, 'colsample_bytree': 0.22812863283501075, 'colsample_bynode': 0.4601832058131908, 'colsample_bylevel': 0.24709975802986595, 'min_child_weight': 7, 'reg_alpha': 8.632943947275516, 'reg_lambda': 24.591790686340666, 'gamma': 1.3021821585226565}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:17:39,077] Trial 54 finished with value: 0.10083461369601732 and parameters: {'max_depth': 2, 'learning_rate': 0.014401304265907251, 'subsample': 0.08120843288412032, 'colsample_bytree': 0.24972094676007708, 'colsample_bynode': 0.46236845351356837, 'colsample_bylevel': 0.2541242775290074, 'min_child_weight': 7, 'reg_alpha': 9.046178125311945, 'reg_lambda': 23.622502263663595, 'gamma': 1.3169932336633705}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:17:47,351] Trial 55 finished with value: 0.10005638479535557 and parameters: {'max_depth': 2, 'learning_rate': 0.013512074720370243, 'subsample': 0.09696215857692553, 'colsample_bytree': 0.21239113810080634, 'colsample_bynode': 0.45215279721357904, 'colsample_bylevel': 0.239755257818714, 'min_child_weight': 7, 'reg_alpha': 9.926820048106649, 'reg_lambda': 25.758432376378984, 'gamma': 1.2789658572539764}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:17:57,039] Trial 56 finished with value: 0.10301618959674963 and parameters: {'max_depth': 3, 'learning_rate': 0.011806547227959964, 'subsample': 0.19722800662414908, 'colsample_bytree': 0.05130765735100032, 'colsample_bynode': 0.410316825470933, 'colsample_bylevel': 0.3187077066089368, 'min_child_weight': 8, 'reg_alpha': 3.749714799226669, 'reg_lambda': 31.205042739298886, 'gamma': 0.7387631212042618}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:18:06,973] Trial 57 finished with value: 0.10005800424937593 and parameters: {'max_depth': 3, 'learning_rate': 0.012081696730735824, 'subsample': 0.19552044376326866, 'colsample_bytree': 0.11637229703948668, 'colsample_bynode': 0.4189004005270713, 'colsample_bylevel': 0.3227189103958164, 'min_child_weight': 9, 'reg_alpha': 4.32006688948009, 'reg_lambda': 30.058796099330547, 'gamma': 0.6729519948247293}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:18:16,853] Trial 58 finished with value: 0.09546592801860353 and parameters: {'max_depth': 3, 'learning_rate': 0.018677060006177967, 'subsample': 0.28877985468242773, 'colsample_bytree': 0.14276988559002948, 'colsample_bynode': 0.3422847949416023, 'colsample_bylevel': 0.3744807583827333, 'min_child_weight': 8, 'reg_alpha': 0.24299087727541835, 'reg_lambda': 18.11390140996189, 'gamma': 1.062772736745111}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:18:25,153] Trial 59 finished with value: 0.08949373034958279 and parameters: {'max_depth': 2, 'learning_rate': 0.026601938853365696, 'subsample': 0.24253644110411235, 'colsample_bytree': 0.9355785284923333, 'colsample_bynode': 0.25802192325291395, 'colsample_bylevel': 0.29645363615752074, 'min_child_weight': 9, 'reg_alpha': 22.49133859119159, 'reg_lambda': 37.71841342661561, 'gamma': 0.2867882824154927}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:18:34,717] Trial 60 finished with value: 0.10394756946608255 and parameters: {'max_depth': 3, 'learning_rate': 0.004246842759182195, 'subsample': 0.9973212700691432, 'colsample_bytree': 0.05287470211428013, 'colsample_bynode': 0.5370731445237407, 'colsample_bylevel': 0.4198903102292664, 'min_child_weight': 10, 'reg_alpha': 13.003670901908102, 'reg_lambda': 31.223341237067707, 'gamma': 0.95745205178833}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:18:44,659] Trial 61 finished with value: 0.10184498169323347 and parameters: {'max_depth': 3, 'learning_rate': 0.003983452975407863, 'subsample': 0.1639993026249616, 'colsample_bytree': 0.059990837788853724, 'colsample_bynode': 0.5244120270550573, 'colsample_bylevel': 0.4222747620774547, 'min_child_weight': 10, 'reg_alpha': 13.344819628363803, 'reg_lambda': 32.36647382615234, 'gamma': 0.9388989696765095}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:18:54,549] Trial 62 finished with value: 0.0985255603054579 and parameters: {'max_depth': 3, 'learning_rate': 0.004272382064022626, 'subsample': 0.9460303670650332, 'colsample_bytree': 0.07660572096455055, 'colsample_bynode': 0.5155226608465118, 'colsample_bylevel': 0.43445359350762786, 'min_child_weight': 10, 'reg_alpha': 13.37229396197141, 'reg_lambda': 31.484872288688706, 'gamma': 0.9882889861091743}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:19:04,170] Trial 63 finished with value: 0.09837186738554972 and parameters: {'max_depth': 3, 'learning_rate': 0.003078697747453986, 'subsample': 0.17024712155685595, 'colsample_bytree': 0.09510560104983301, 'colsample_bynode': 0.5255724535046691, 'colsample_bylevel': 0.48890110150685984, 'min_child_weight': 10, 'reg_alpha': 18.477964173387367, 'reg_lambda': 26.883510066180843, 'gamma': 0.8244456632576975}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:19:15,483] Trial 64 finished with value: 0.10131399371350108 and parameters: {'max_depth': 4, 'learning_rate': 0.0026341076310381047, 'subsample': 0.14732130696615225, 'colsample_bytree': 0.1988612190128184, 'colsample_bynode': 0.5507412933084342, 'colsample_bylevel': 0.37992410584934705, 'min_child_weight': 9, 'reg_alpha': 5.017693167119944, 'reg_lambda': 20.04802787139518, 'gamma': 0.6600065202242695}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:19:26,704] Trial 65 finished with value: 0.10141416924795865 and parameters: {'max_depth': 4, 'learning_rate': 0.0019661267331242257, 'subsample': 0.1268919611886184, 'colsample_bytree': 0.05636870912893475, 'colsample_bynode': 0.5505356551691698, 'colsample_bylevel': 0.39883441182534063, 'min_child_weight': 9, 'reg_alpha': 3.2248167816149773, 'reg_lambda': 19.89099858563113, 'gamma': 0.271923796787762}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:19:35,162] Trial 66 finished with value: 0.10052363683779392 and parameters: {'max_depth': 2, 'learning_rate': 0.0015795935819068654, 'subsample': 0.8609765031657302, 'colsample_bytree': 0.051027806171451084, 'colsample_bynode': 0.39510323151211724, 'colsample_bylevel': 0.4001951767189399, 'min_child_weight': 10, 'reg_alpha': 19.60012403771091, 'reg_lambda': 35.21049308898124, 'gamma': 0.2734427216264373}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:19:45,342] Trial 67 finished with value: 0.10207893317575761 and parameters: {'max_depth': 3, 'learning_rate': 0.0019378544185271497, 'subsample': 0.21153910948389243, 'colsample_bytree': 0.15878255247172207, 'colsample_bynode': 0.47587423620585007, 'colsample_bylevel': 0.5739099773944147, 'min_child_weight': 8, 'reg_alpha': 12.666217306936275, 'reg_lambda': 42.04937445997125, 'gamma': 0.13004739261845633}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:19:55,344] Trial 68 finished with value: 0.09837967252682203 and parameters: {'max_depth': 3, 'learning_rate': 0.0010450398290474938, 'subsample': 0.2023866878246433, 'colsample_bytree': 0.15946297177078117, 'colsample_bynode': 0.4206416166143327, 'colsample_bylevel': 0.5723552789555565, 'min_child_weight': 8, 'reg_alpha': 10.651573222443547, 'reg_lambda': 41.07009243933707, 'gamma': 0.002923746898004176}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:20:05,036] Trial 69 finished with value: 0.09675642841771914 and parameters: {'max_depth': 3, 'learning_rate': 0.0018334685576603187, 'subsample': 0.22019198722462868, 'colsample_bytree': 0.11769379518565534, 'colsample_bynode': 0.4747528740759227, 'colsample_bylevel': 0.4959077756240672, 'min_child_weight': 8, 'reg_alpha': 26.47627851173852, 'reg_lambda': 40.89059338516564, 'gamma': 0.45115324836482984}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:20:13,255] Trial 70 finished with value: 0.10370527506718077 and parameters: {'max_depth': 2, 'learning_rate': 0.002823240094036621, 'subsample': 0.9918842657134634, 'colsample_bytree': 0.1038403353334203, 'colsample_bynode': 0.5007402911780215, 'colsample_bylevel': 0.612114961182172, 'min_child_weight': 10, 'reg_alpha': 19.20959305876636, 'reg_lambda': 33.17219535867554, 'gamma': 0.5656313568100204}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:20:21,487] Trial 71 finished with value: 0.10388577968899765 and parameters: {'max_depth': 2, 'learning_rate': 0.002567367494453474, 'subsample': 0.9785395371593834, 'colsample_bytree': 0.10555850330284652, 'colsample_bynode': 0.49146092630231974, 'colsample_bylevel': 0.6201296159961562, 'min_child_weight': 10, 'reg_alpha': 14.5294750040885, 'reg_lambda': 32.82005895505403, 'gamma': 0.5753013350283784}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:20:29,774] Trial 72 finished with value: 0.1037108153497921 and parameters: {'max_depth': 2, 'learning_rate': 0.002495850591862623, 'subsample': 0.9936144006623552, 'colsample_bytree': 0.10801463890006001, 'colsample_bynode': 0.49605521986693213, 'colsample_bylevel': 0.6166063025196041, 'min_child_weight': 10, 'reg_alpha': 19.093733523763817, 'reg_lambda': 28.61324115680288, 'gamma': 0.570291695138446}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:20:37,933] Trial 73 finished with value: 0.09791831998248436 and parameters: {'max_depth': 2, 'learning_rate': 0.0024101990657503193, 'subsample': 0.9910664815198108, 'colsample_bytree': 0.09345413183786531, 'colsample_bynode': 0.49258649558427897, 'colsample_bylevel': 0.6450278610801616, 'min_child_weight': 10, 'reg_alpha': 19.39259130717695, 'reg_lambda': 28.61622171160701, 'gamma': 0.5752232504918351}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:20:45,953] Trial 74 finished with value: 0.10359917474343275 and parameters: {'max_depth': 2, 'learning_rate': 0.003008481727280596, 'subsample': 0.9868202768230204, 'colsample_bytree': 0.11771291670588233, 'colsample_bynode': 0.3842049554949292, 'colsample_bylevel': 0.6159165399189039, 'min_child_weight': 10, 'reg_alpha': 7.611177062252888, 'reg_lambda': 22.873776017785758, 'gamma': 0.4105342339894363}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:20:53,773] Trial 75 finished with value: 0.10377442736489094 and parameters: {'max_depth': 2, 'learning_rate': 0.002986321773417594, 'subsample': 0.9964758514117612, 'colsample_bytree': 0.11095170477304038, 'colsample_bynode': 0.38999937521776984, 'colsample_bylevel': 0.6148532584140078, 'min_child_weight': 10, 'reg_alpha': 8.271755908630976, 'reg_lambda': 33.486212638502074, 'gamma': 0.3567904803525359}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:21:01,992] Trial 76 finished with value: 0.10366887817395554 and parameters: {'max_depth': 2, 'learning_rate': 0.0030258669148248638, 'subsample': 0.9993455622731116, 'colsample_bytree': 0.11583301458948173, 'colsample_bynode': 0.34066436544548584, 'colsample_bylevel': 0.606623393416009, 'min_child_weight': 10, 'reg_alpha': 25.82108284395789, 'reg_lambda': 24.02102655053129, 'gamma': 0.3955315424018491}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:21:10,360] Trial 77 finished with value: 0.09596472608385798 and parameters: {'max_depth': 2, 'learning_rate': 0.003628859752968633, 'subsample': 0.8996996539895732, 'colsample_bytree': 0.19533828999354208, 'colsample_bynode': 0.32833620413509323, 'colsample_bylevel': 0.6883802888764562, 'min_child_weight': 9, 'reg_alpha': 26.26018562574128, 'reg_lambda': 34.27051745412997, 'gamma': 1.1093381327204348}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:21:18,522] Trial 78 finished with value: 0.096159312489012 and parameters: {'max_depth': 2, 'learning_rate': 0.002704194059098965, 'subsample': 0.9498139452465133, 'colsample_bytree': 0.2340766496703861, 'colsample_bynode': 0.34911230547395355, 'colsample_bylevel': 0.7403338173037574, 'min_child_weight': 10, 'reg_alpha': 16.24160320742977, 'reg_lambda': 37.87360577773167, 'gamma': 0.5591535388277538}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:21:27,309] Trial 79 finished with value: 0.09491769532327578 and parameters: {'max_depth': 2, 'learning_rate': 0.0013133693954283253, 'subsample': 0.911729951359013, 'colsample_bytree': 0.13499741387697528, 'colsample_bynode': 0.43852947846871704, 'colsample_bylevel': 0.7031410413040101, 'min_child_weight': 10, 'reg_alpha': 31.330497767023395, 'reg_lambda': 26.571774479094856, 'gamma': 0.37291796285979667}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:21:35,546] Trial 80 finished with value: 0.10430967669645647 and parameters: {'max_depth': 2, 'learning_rate': 0.002376610855864849, 'subsample': 0.9720575746590278, 'colsample_bytree': 0.0986777091694223, 'colsample_bynode': 0.27599310120796927, 'colsample_bylevel': 0.616617114056014, 'min_child_weight': 9, 'reg_alpha': 18.62452898049466, 'reg_lambda': 46.38140894797107, 'gamma': 0.13318906952932075}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:21:44,265] Trial 81 finished with value: 0.10363954683022172 and parameters: {'max_depth': 2, 'learning_rate': 0.003604327422474928, 'subsample': 0.9715326193958463, 'colsample_bytree': 0.0979822262103289, 'colsample_bynode': 0.358090903348411, 'colsample_bylevel': 0.6165501305530479, 'min_child_weight': 10, 'reg_alpha': 25.493721533881057, 'reg_lambda': 47.642401573785975, 'gamma': 0.14713659251718697}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:21:52,366] Trial 82 finished with value: 0.09893486970932423 and parameters: {'max_depth': 2, 'learning_rate': 0.002387816390446488, 'subsample': 0.8861966269990519, 'colsample_bytree': 0.16889684206913574, 'colsample_bynode': 0.2395243765614082, 'colsample_bylevel': 0.5548140942207155, 'min_child_weight': 9, 'reg_alpha': 18.793027787527038, 'reg_lambda': 28.281922594778944, 'gamma': 0.5756640441700343}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:22:00,630] Trial 83 finished with value: 0.09868086973446706 and parameters: {'max_depth': 2, 'learning_rate': 0.002823720022405751, 'subsample': 0.9305168344369951, 'colsample_bytree': 0.14876247441706666, 'colsample_bynode': 0.2994660896442811, 'colsample_bylevel': 0.6714802864800448, 'min_child_weight': 9, 'reg_alpha': 14.490034007269996, 'reg_lambda': 23.055624368140386, 'gamma': 0.2035781258508158}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:22:09,080] Trial 84 finished with value: 0.10395490373114978 and parameters: {'max_depth': 2, 'learning_rate': 0.0017749265405093007, 'subsample': 0.9663758223905214, 'colsample_bytree': 0.11677465707420026, 'colsample_bynode': 0.5075182267955451, 'colsample_bylevel': 0.6195456085477608, 'min_child_weight': 10, 'reg_alpha': 21.332914550742778, 'reg_lambda': 45.00263034216592, 'gamma': 0.8702462278533458}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:22:17,232] Trial 85 finished with value: 0.09675822929693527 and parameters: {'max_depth': 2, 'learning_rate': 0.0016959679216371217, 'subsample': 0.8259081456739337, 'colsample_bytree': 0.07898719454622032, 'colsample_bynode': 0.5744442699062688, 'colsample_bylevel': 0.6299598713238932, 'min_child_weight': 10, 'reg_alpha': 20.511962449014476, 'reg_lambda': 44.777667003771406, 'gamma': 0.8448481479870972}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:22:26,012] Trial 86 finished with value: 0.09240839701513734 and parameters: {'max_depth': 2, 'learning_rate': 0.0014660577423466123, 'subsample': 0.9600229374192342, 'colsample_bytree': 0.19298888979183015, 'colsample_bynode': 0.5058703724181965, 'colsample_bylevel': 0.5791621247179637, 'min_child_weight': 10, 'reg_alpha': 37.22939676633472, 'reg_lambda': 51.83074468169722, 'gamma': 1.1501442392880827}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:22:35,011] Trial 87 finished with value: 0.10353401234766565 and parameters: {'max_depth': 2, 'learning_rate': 0.002323438953884282, 'subsample': 0.7559028241439989, 'colsample_bytree': 0.10758593582168718, 'colsample_bynode': 0.5610677890005508, 'colsample_bylevel': 0.5233759302388333, 'min_child_weight': 9, 'reg_alpha': 8.952002471205459, 'reg_lambda': 33.51881849170654, 'gamma': 0.9390844021972796}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:22:43,787] Trial 88 finished with value: 0.09322494236323864 and parameters: {'max_depth': 2, 'learning_rate': 0.0012218580375711035, 'subsample': 0.8749280124166737, 'colsample_bytree': 0.2671093268773127, 'colsample_bynode': 0.1718648560846815, 'colsample_bylevel': 0.7119558614321079, 'min_child_weight': 9, 'reg_alpha': 11.749265476595328, 'reg_lambda': 45.20925725700296, 'gamma': 1.5003397765896658}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:22:53,872] Trial 89 finished with value: 0.09974685422883614 and parameters: {'max_depth': 3, 'learning_rate': 0.0033931174834912828, 'subsample': 0.9370441375472854, 'colsample_bytree': 0.13721909124905735, 'colsample_bynode': 0.4752226017916492, 'colsample_bylevel': 0.5936391523588519, 'min_child_weight': 10, 'reg_alpha': 17.14673737990432, 'reg_lambda': 39.004911257575415, 'gamma': 0.6742036853495936}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:23:02,465] Trial 90 finished with value: 0.09950992074163781 and parameters: {'max_depth': 2, 'learning_rate': 0.004683432431180548, 'subsample': 0.9190905367399177, 'colsample_bytree': 0.07693858449596383, 'colsample_bynode': 0.4409440155902475, 'colsample_bylevel': 0.5453745932403812, 'min_child_weight': 10, 'reg_alpha': 21.131563713878165, 'reg_lambda': 35.23586354057447, 'gamma': 1.245546711895847}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:23:10,891] Trial 91 finished with value: 0.09346109333671576 and parameters: {'max_depth': 2, 'learning_rate': 0.002112446017241902, 'subsample': 0.9778705886283268, 'colsample_bytree': 0.17836623129795934, 'colsample_bynode': 0.5163003304728079, 'colsample_bylevel': 0.6661922324206262, 'min_child_weight': 10, 'reg_alpha': 15.244201462894846, 'reg_lambda': 24.482367895253315, 'gamma': 0.468697404128192}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:23:19,310] Trial 92 finished with value: 0.09539974690684087 and parameters: {'max_depth': 2, 'learning_rate': 0.001741545527817282, 'subsample': 0.9998970387440477, 'colsample_bytree': 0.12333352597020324, 'colsample_bynode': 0.2666064589382285, 'colsample_bylevel': 0.6024408002331822, 'min_child_weight': 10, 'reg_alpha': 27.692303571288953, 'reg_lambda': 29.699090430382533, 'gamma': 0.3936648546300412}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:23:27,433] Trial 93 finished with value: 0.09817130625571735 and parameters: {'max_depth': 2, 'learning_rate': 0.0024833343436354133, 'subsample': 0.9691492529547704, 'colsample_bytree': 0.0969389952786984, 'colsample_bynode': 0.3124254221901051, 'colsample_bylevel': 0.6170186323518914, 'min_child_weight': 10, 'reg_alpha': 24.713774609934333, 'reg_lambda': 17.366209278524344, 'gamma': 0.8484885712360759}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:23:35,421] Trial 94 finished with value: 0.09355368452715823 and parameters: {'max_depth': 2, 'learning_rate': 0.0030832313417769597, 'subsample': 0.9997081156431805, 'colsample_bytree': 0.21145158398524955, 'colsample_bynode': 0.4059504331249303, 'colsample_bylevel': 0.6425039748635283, 'min_child_weight': 9, 'reg_alpha': 23.582791823798413, 'reg_lambda': 20.504693388482075, 'gamma': 0.6005724634034503}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:23:45,627] Trial 95 finished with value: 0.09218459581268522 and parameters: {'max_depth': 3, 'learning_rate': 0.002162291283946645, 'subsample': 0.9567766476093356, 'colsample_bytree': 0.1491725235788483, 'colsample_bynode': 0.5309017449010335, 'colsample_bylevel': 0.6843972151361415, 'min_child_weight': 9, 'reg_alpha': 7.788010793196842, 'reg_lambda': 16.332195152049415, 'gamma': 0.15198778756551073}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:23:53,455] Trial 96 finished with value: 0.09640058035445175 and parameters: {'max_depth': 2, 'learning_rate': 0.003747166852208316, 'subsample': 0.901948300691893, 'colsample_bytree': 0.23049130262874903, 'colsample_bynode': 0.6139554251875876, 'colsample_bylevel': 0.5554220797038104, 'min_child_weight': 10, 'reg_alpha': 11.515385669411106, 'reg_lambda': 39.25334766610437, 'gamma': 0.3516193859316449}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:24:03,418] Trial 97 finished with value: 0.09192767529089672 and parameters: {'max_depth': 3, 'learning_rate': 0.09790090938753815, 'subsample': 0.9225977834082277, 'colsample_bytree': 0.07697693895851344, 'colsample_bynode': 0.3727540952603149, 'colsample_bylevel': 0.7822683822905018, 'min_child_weight': 10, 'reg_alpha': 30.743942715258925, 'reg_lambda': 33.11186759266348, 'gamma': 1.3974202887631113}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:24:11,945] Trial 98 finished with value: 0.10048339913218071 and parameters: {'max_depth': 2, 'learning_rate': 0.0027411967939536333, 'subsample': 0.8357115963142384, 'colsample_bytree': 0.11833480297623114, 'colsample_bynode': 0.43039818130423335, 'colsample_bylevel': 0.49618105776230903, 'min_child_weight': 9, 'reg_alpha': 18.105148275075347, 'reg_lambda': 27.64690104228143, 'gamma': 1.0421607006470772}. Best is trial 52 with value: 0.10627525889669527.\n",
      "[I 2025-07-21 00:24:21,491] Trial 99 finished with value: 0.10411498710879086 and parameters: {'max_depth': 3, 'learning_rate': 0.0015423501399542034, 'subsample': 0.9774328879703247, 'colsample_bytree': 0.06747740601553878, 'colsample_bynode': 0.5005395063629353, 'colsample_bylevel': 0.5936297766900572, 'min_child_weight': 10, 'reg_alpha': 13.480729897468473, 'reg_lambda': 21.61823324886441, 'gamma': 0.05248202345479025}. Best is trial 52 with value: 0.10627525889669527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 2, 'learning_rate': 0.01451225130909297, 'subsample': 0.09674855104145334, 'colsample_bytree': 0.23515054488702938, 'colsample_bynode': 0.5286603055784903, 'colsample_bylevel': 0.2484567071851006, 'min_child_weight': 6, 'reg_alpha': 6.18648185411528, 'reg_lambda': 25.16367998274342, 'gamma': 1.244054097289789}\n",
      "Best Pearson score: 0.10627525889669527\n"
     ]
    }
   ],
   "source": [
    "best_xgboost_params_common_truncated_with_less_interaction = optimize_xgboost(\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_less_interaction_study\",\n",
    "    f\"xgboost_{feature_version}_{default_cv}_{default_random_state}_{default_n_trees}_common_truncated_30_with_less_interaction_study\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3435a2b5",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aadc463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6] [8, 9, 10, 11]\n",
      "[4, 5, 6, 7] [9, 10, 11, 12]\n",
      "[5, 6, 7, 8] [10, 11, 12, 1]\n",
      "[6, 7, 8, 9] [11, 12, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "default_num_layers = 2\n",
    "# Create the CV data, seems to be better with only anonymized features\n",
    "best_features = list(set(best_features + best_interaction_features + best_exp_interaction_features))\n",
    "# best_features = [col for col in train_df.columns if \"X\" in col]\n",
    "# train_added_df = pd.concat([train_df, popular_features_train], axis=1)\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features)\n",
    "\n",
    "# Convert to float32\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "\n",
    "# Convert to MLX\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa80645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-21 00:24:22,196] A new study created in RDB with name: mlp_mlx_2_4_101_2_common_truncated_30_with_less_interaction_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conduct hyperparam opt for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:11<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1501132216619004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:11<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17192123030987272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:11<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12701435074325976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:11<00:00,  2.65it/s]\n",
      "[I 2025-07-21 00:25:08,638] Trial 0 finished with value: 0.13810377070763585 and parameters: {'log2_hidden_layer_0': 5, 'log2_hidden_layer_1': 4, 'lr': 0.00011401144576866207, 'batch_size': 360, 'num_epochs': 30}. Best is trial 0 with value: 0.13810377070763585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10336628011551047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:42<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16389386167873152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:41<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03575507666870065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:41<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07749337775665478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:41<00:00,  4.15s/it]\n",
      "[I 2025-07-21 00:28:01,253] Trial 1 finished with value: 0.08001636719567402 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 2, 'lr': 0.0016110048377545381, 'batch_size': 30, 'num_epochs': 10}. Best is trial 0 with value: 0.13810377070763585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04292315267860913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17383765046239394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1707602401078787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1636112003324053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.17s/it]\n",
      "[I 2025-07-21 00:28:48,223] Trial 2 finished with value: 0.15261048614510675 and parameters: {'log2_hidden_layer_0': 7, 'log2_hidden_layer_1': 6, 'lr': 0.0006397284445480228, 'batch_size': 60, 'num_epochs': 5}. Best is trial 2 with value: 0.15261048614510675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10223285367774901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20176711109092638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.225894772630723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21337275258552496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.17s/it]\n",
      "[I 2025-07-21 00:30:17,433] Trial 3 finished with value: 0.18564918484156767 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00021311118699643669, 'batch_size': 30, 'num_epochs': 5}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10156210305909631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01936140706568699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0052623543034898855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.027209001018436305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.07s/it]\n",
      "[I 2025-07-21 00:31:01,930] Trial 4 finished with value: 0.008329308661091932 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 4, 'lr': 0.007916409621612937, 'batch_size': 120, 'num_epochs': 10}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04642718290060693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20198359738965968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12182962250704786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19803634349873178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.06s/it]\n",
      "[I 2025-07-21 00:31:24,347] Trial 5 finished with value: 0.15353543484017487 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.0011461640896689763, 'batch_size': 120, 'num_epochs': 5}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09229217596526017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19739218858473706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.193456265403016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20240215368089987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.36it/s]\n",
      "[I 2025-07-21 00:31:39,743] Trial 6 finished with value: 0.17681042964513227 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.0016384475510214463, 'batch_size': 180, 'num_epochs': 5}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11399111091187625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1531673606770308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14663626255255377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1913860249444523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.19s/it]\n",
      "[I 2025-07-21 00:33:10,452] Trial 7 finished with value: 0.1501637278996822 and parameters: {'log2_hidden_layer_0': 7, 'log2_hidden_layer_1': 3, 'lr': 0.00019707122917752242, 'batch_size': 60, 'num_epochs': 10}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10946526342469189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [02:05<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028300684210084852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [02:04<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019297313574349652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [02:04<00:00,  4.15s/it]\n",
      "[I 2025-07-21 00:39:29,697] Trial 8 finished with value: -1.0 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 2, 'lr': 0.002661907418163619, 'batch_size': 30, 'num_epochs': 30}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04029818 -0.04029818 -0.04029818 ... -0.04029818 -0.04029818\n",
      " -0.04029818]\n",
      "Error: zero variance prediction\n",
      "-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:25<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10095300362804367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:26<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04308554426333634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:26<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1359938438262015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:26<00:00,  1.07s/it]\n",
      "[I 2025-07-21 00:41:16,306] Trial 9 finished with value: 0.08393320729920585 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.0012478457141046418, 'batch_size': 120, 'num_epochs': 25}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05570043747924185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16997522879319626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1864106414667644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1726554794447713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  5.45it/s]\n",
      "[I 2025-07-21 00:41:31,667] Trial 10 finished with value: 0.15041982412970661 and parameters: {'log2_hidden_layer_0': 5, 'log2_hidden_layer_1': 5, 'lr': 0.0002681804978075502, 'batch_size': 720, 'num_epochs': 20}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07263794681409452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21114445158137107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2164401088961326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2089311017995378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.48it/s]\n",
      "[I 2025-07-21 00:41:46,754] Trial 11 finished with value: 0.18080870097434262 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.0004347857252584504, 'batch_size': 180, 'num_epochs': 5}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08671914162032897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19872387735299676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21022580846757444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2142990870038362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.41it/s]\n",
      "[I 2025-07-21 00:42:30,958] Trial 12 finished with value: 0.18291323285721983 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 2, 'lr': 0.00044023800046285927, 'batch_size': 180, 'num_epochs': 15}. Best is trial 3 with value: 0.18564918484156767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10840415860447192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21192739496940735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22613988556760736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21590570501752637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]\n",
      "[I 2025-07-21 00:43:15,013] Trial 13 finished with value: 0.19205248407352155 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00010928160421260172, 'batch_size': 180, 'num_epochs': 15}. Best is trial 13 with value: 0.19205248407352155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1142369507395451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:01<00:00,  4.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1647490408739504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:01<00:00,  4.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18359769210587712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:02<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1881454569867255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:01<00:00,  4.13s/it]\n",
      "[I 2025-07-21 00:47:28,140] Trial 14 finished with value: 0.15764345614460704 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 3, 'lr': 0.0001090908453924738, 'batch_size': 30, 'num_epochs': 15}. Best is trial 13 with value: 0.19205248407352155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09408163461187513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2096220030163963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22172003992752826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21883795398613404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.59it/s]\n",
      "[I 2025-07-21 00:47:51,234] Trial 15 finished with value: 0.19181311477243082 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00021981488703442031, 'batch_size': 360, 'num_epochs': 15}. Best is trial 13 with value: 0.19205248407352155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11707246215966474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19462873143171483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15484232799900052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050879607608620925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.56it/s]\n",
      "[I 2025-07-21 00:48:14,629] Trial 16 finished with value: 0.12443729620425514 and parameters: {'log2_hidden_layer_0': 6, 'log2_hidden_layer_1': 5, 'lr': 0.00010606867679560662, 'batch_size': 360, 'num_epochs': 15}. Best is trial 13 with value: 0.19205248407352155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09739851777768435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20547038276590432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21811000187569407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21772581671650318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.61it/s]\n",
      "[I 2025-07-21 00:48:37,463] Trial 17 finished with value: 0.1891290681972863 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.0002965470544301975, 'batch_size': 360, 'num_epochs': 15}. Best is trial 13 with value: 0.19205248407352155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11521007143104368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21703019334193496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21327909000007908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21874631783249748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.20it/s]\n",
      "[I 2025-07-21 00:48:49,018] Trial 18 finished with value: 0.18668180219603098 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 3, 'lr': 0.00015673676649365358, 'batch_size': 720, 'num_epochs': 15}. Best is trial 13 with value: 0.19205248407352155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09767160760961249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:09<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21151358406574153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:09<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20380547422006043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:09<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15271491779837043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:09<00:00,  2.72it/s]\n",
      "[I 2025-07-21 00:49:26,024] Trial 19 finished with value: 0.17087984741091342 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.0005845714841209971, 'batch_size': 360, 'num_epochs': 25}. Best is trial 13 with value: 0.19205248407352155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11548541355948126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06287931498482151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:14<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06912008775781896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:14<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14826018905076976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:14<00:00,  1.42it/s]\n",
      "[I 2025-07-21 00:50:24,590] Trial 20 finished with value: 0.08612257165685562 and parameters: {'log2_hidden_layer_0': 5, 'log2_hidden_layer_1': 4, 'lr': 0.003513224304252159, 'batch_size': 180, 'num_epochs': 20}. Best is trial 13 with value: 0.19205248407352155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06423069483401227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2048883581888696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2170208165174936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2174168551108658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.74it/s]\n",
      "[I 2025-07-21 00:50:47,439] Trial 21 finished with value: 0.1885523116224617 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.0003026544341472495, 'batch_size': 360, 'num_epochs': 15}. Best is trial 13 with value: 0.19205248407352155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11488321667261768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21382826427549126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22488635131858833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21612618152868748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.62it/s]\n",
      "[I 2025-07-21 00:51:10,626] Trial 22 finished with value: 0.19284054154047722 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00016471803829948533, 'batch_size': 360, 'num_epochs': 15}. Best is trial 22 with value: 0.19284054154047722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11652136903914176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2151425536086956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21055782472755166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2173083446727845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.62it/s]\n",
      "[I 2025-07-21 00:51:33,737] Trial 23 finished with value: 0.18710436983894496 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 3, 'lr': 0.00015653418260896617, 'batch_size': 360, 'num_epochs': 15}. Best is trial 22 with value: 0.19284054154047722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10540875634674801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1482567587526227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2183904497916312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20291819277491988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.70it/s]\n",
      "[I 2025-07-21 00:51:56,475] Trial 24 finished with value: 0.16099483988285548 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.00015497511128315672, 'batch_size': 360, 'num_epochs': 15}. Best is trial 22 with value: 0.19284054154047722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07441395821224814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1669384194460847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21527695034071295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20171142937041003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.35it/s]\n",
      "[I 2025-07-21 00:52:42,364] Trial 25 finished with value: 0.16716907233961206 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.0004140690742544343, 'batch_size': 180, 'num_epochs': 15}. Best is trial 22 with value: 0.19284054154047722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08474949020124058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21121730680159753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22328229436113864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21868940056421893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.72it/s]\n",
      "[I 2025-07-21 00:53:05,189] Trial 26 finished with value: 0.19260855826148518 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00019742216241904186, 'batch_size': 360, 'num_epochs': 15}. Best is trial 22 with value: 0.19284054154047722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11724523131898569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2172446138951188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21379826766906454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.219245531430113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.23it/s]\n",
      "[I 2025-07-21 00:53:16,802] Trial 27 finished with value: 0.18685196094096704 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 3, 'lr': 0.0001522898842079234, 'batch_size': 720, 'num_epochs': 15}. Best is trial 22 with value: 0.19284054154047722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09711943076957184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:52<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14120827310686648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:52<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016766619623517606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:52<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1300463640402408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:51<00:00,  2.07s/it]\n",
      "[I 2025-07-21 00:56:49,248] Trial 28 finished with value: 0.08759888549547928 and parameters: {'log2_hidden_layer_0': 6, 'log2_hidden_layer_1': 4, 'lr': 0.0007525818189930498, 'batch_size': 60, 'num_epochs': 25}. Best is trial 22 with value: 0.19284054154047722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06237428521129221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:11<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.138021499184304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:11<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21598715926975362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:11<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2026548085300641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:11<00:00,  2.63it/s]\n",
      "[I 2025-07-21 00:57:34,287] Trial 29 finished with value: 0.15960159786615324 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.00010776040577998024, 'batch_size': 360, 'num_epochs': 30}. Best is trial 22 with value: 0.19284054154047722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08174292448049131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:14<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10894571797553737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:14<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13041749972987451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09381169668808163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:14<00:00,  1.38it/s]\n",
      "[I 2025-07-21 00:58:33,410] Trial 30 finished with value: 0.09996943034429832 and parameters: {'log2_hidden_layer_0': 5, 'log2_hidden_layer_1': 4, 'lr': 0.0003113041731218876, 'batch_size': 180, 'num_epochs': 20}. Best is trial 22 with value: 0.19284054154047722.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06670280698369978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2127440820978147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22441513930059237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21853261544995023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.65it/s]\n",
      "[I 2025-07-21 00:58:55,992] Trial 31 finished with value: 0.19312917795521595 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00017885107573809827, 'batch_size': 360, 'num_epochs': 15}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11682487497250649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2131158818815415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22535311785471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21360484368526989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.70it/s]\n",
      "[I 2025-07-21 00:59:18,515] Trial 32 finished with value: 0.1910895067569925 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00013700574611025062, 'batch_size': 360, 'num_epochs': 15}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11228418360644853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20953609379082747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22171997597113935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2187973905188814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.72it/s]\n",
      "[I 2025-07-21 00:59:40,986] Trial 33 finished with value: 0.19183109635224777 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00022115681572143557, 'batch_size': 360, 'num_epochs': 15}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11727092512814283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:10<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17095514094746517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:10<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19867937103667302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:11<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15271308428217006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:10<00:00,  2.74it/s]\n",
      "[I 2025-07-21 01:00:25,541] Trial 34 finished with value: 0.1558029369148003 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.00019371247214143908, 'batch_size': 360, 'num_epochs': 30}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1008641513928929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2121233843895161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22219560022771376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20815603713858824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.66it/s]\n",
      "[I 2025-07-21 01:00:40,886] Trial 35 finished with value: 0.18344793717633365 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00010094091602007184, 'batch_size': 360, 'num_epochs': 10}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09131672694951651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:31<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19744092707283958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:31<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2072154258448125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:30<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1810451644468543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:31<00:00,  2.07s/it]\n",
      "[I 2025-07-21 01:02:47,943] Trial 36 finished with value: 0.1715113069359234 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 3, 'lr': 0.0003639752735974338, 'batch_size': 60, 'num_epochs': 15}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10034371037918725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20952570094868705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22524214578232046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21933482377239708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.03s/it]\n",
      "[I 2025-07-21 01:03:51,624] Trial 37 finished with value: 0.19305147434200473 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00013364243252460766, 'batch_size': 120, 'num_epochs': 15}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11810322686461423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19968971562384358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15157790249714728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22252180187299392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.04s/it]\n",
      "[I 2025-07-21 01:04:34,680] Trial 38 finished with value: 0.16947307961200542 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 3, 'lr': 0.0006754712480845203, 'batch_size': 120, 'num_epochs': 10}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10410289845403689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1960239721433779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.213043660508935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21362593522141926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.03s/it]\n",
      "[I 2025-07-21 01:05:38,239] Trial 39 finished with value: 0.17737808634546073 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.000245037367790058, 'batch_size': 120, 'num_epochs': 15}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08681877750811075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16093989014678386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21160868064596589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19942070400190812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.02it/s]\n",
      "[I 2025-07-21 01:06:00,169] Trial 40 finished with value: 0.16115966286842476 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.00018251247408038025, 'batch_size': 120, 'num_epochs': 5}. Best is trial 31 with value: 0.19312917795521595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07266937667904111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20975634077106955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2254792681211684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21937407033887144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.03s/it]\n",
      "[I 2025-07-21 01:07:03,642] Trial 41 finished with value: 0.19320416749297908 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00013219863321082263, 'batch_size': 120, 'num_epochs': 15}. Best is trial 41 with value: 0.19320416749297908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11820699074080704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2096514666327062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22545458434796353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21939247798247702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.03s/it]\n",
      "[I 2025-07-21 01:08:07,096] Trial 42 finished with value: 0.19315643026399104 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.0001325847776595635, 'batch_size': 120, 'num_epochs': 15}. Best is trial 41 with value: 0.19320416749297908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11812719209281747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20922644623820935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2248550160747273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:16<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22053900513310556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.02s/it]\n",
      "[I 2025-07-21 01:09:11,399] Trial 43 finished with value: 0.19320217322038505 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00013700187632781458, 'batch_size': 120, 'num_epochs': 15}. Best is trial 41 with value: 0.19320416749297908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11818822543549803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.011781735641598423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.010778046626639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.06s/it]\n",
      "[I 2025-07-21 01:09:59,897] Trial 44 finished with value: -1.0 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 3, 'lr': 0.009351153593207233, 'batch_size': 120, 'num_epochs': 15}. Best is trial 41 with value: 0.19320416749297908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00463975 0.00463975 0.00463975 ... 0.00463975 0.00463975 0.00463975]\n",
      "Error: zero variance prediction\n",
      "-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17150703655733981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16635960646102718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15108593976795118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]\n",
      "[I 2025-07-21 01:12:06,847] Trial 45 finished with value: 0.14851992038121783 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.00012613664343354375, 'batch_size': 120, 'num_epochs': 30}. Best is trial 41 with value: 0.19320416749297908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10512709873855323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:26<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20253712736714843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:25<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21836781859235052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:26<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21153736980638904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:26<00:00,  1.05s/it]\n",
      "[I 2025-07-21 01:13:53,055] Trial 46 finished with value: 0.18619778965965889 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.00013221293322876514, 'batch_size': 120, 'num_epochs': 25}. Best is trial 41 with value: 0.19320416749297908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11234884287274753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:20<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04614023551591416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06929275282666408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04014825129269808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:21<00:00,  1.06s/it]\n",
      "[I 2025-07-21 01:15:18,845] Trial 47 finished with value: 0.06322932576971804 and parameters: {'log2_hidden_layer_0': 4, 'log2_hidden_layer_1': 3, 'lr': 0.0021451682422613397, 'batch_size': 120, 'num_epochs': 20}. Best is trial 41 with value: 0.19320416749297908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09733606344359584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15452458155235907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21217308001310778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2045212464433256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:15<00:00,  1.04s/it]\n",
      "[I 2025-07-21 01:16:23,264] Trial 48 finished with value: 0.16464567369211813 and parameters: {'log2_hidden_layer_0': 2, 'log2_hidden_layer_1': 2, 'lr': 0.00012995585449133596, 'batch_size': 120, 'num_epochs': 15}. Best is trial 41 with value: 0.19320416749297908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08736378675968018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015935068224507385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03866993942041929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07371580035978112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.04s/it]\n",
      "[I 2025-07-21 01:16:45,479] Trial 49 finished with value: 0.03145860107633636 and parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.005139415694716412, 'batch_size': 120, 'num_epochs': 5}. Best is trial 41 with value: 0.19320416749297908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0024864036993623804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1889641819247381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "[W 2025-07-21 01:17:27,919] Trial 50 failed with parameters: {'log2_hidden_layer_0': 3, 'log2_hidden_layer_1': 3, 'lr': 0.0004998130091385064, 'batch_size': 30, 'num_epochs': 10} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/justpqa/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/5b/jn4p_4vx7j9gx2jdrmbjlxnr0000gn/T/ipykernel_1140/171025352.py\", line 19, in objective_mlp_mlx\n",
      "    return train_eval_cv_mlx(num_features, hidden_layers_size, dropout, lr, default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)\n",
      "  File \"/var/folders/5b/jn4p_4vx7j9gx2jdrmbjlxnr0000gn/T/ipykernel_1140/2220228450.py\", line 21, in train_eval_cv_mlx\n",
      "    train_mlp_mlx(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs)\n",
      "  File \"/var/folders/5b/jn4p_4vx7j9gx2jdrmbjlxnr0000gn/T/ipykernel_1140/3257613915.py\", line 10, in train_mlp_mlx\n",
      "    mx.eval(model.parameters(), optimizer.state)\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-21 01:17:27,923] Trial 50 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moptimize_mlp_mlx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlp_mlx_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfeature_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdefault_cv\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdefault_random_state\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdefault_num_layers\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_common_truncated_30_with_less_interaction_study\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlp_mlx_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfeature_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdefault_cv\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdefault_random_state\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdefault_num_layers\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_common_truncated_30_with_less_interaction_study\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m, in \u001b[0;36moptimize_mlp_mlx\u001b[0;34m(study_name, storage_name, objective_function, n_trials, n_jobs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConduct hyperparam opt for MLP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      4\u001b[0m     study_name \u001b[38;5;241m=\u001b[39m study_name,\n\u001b[1;32m      5\u001b[0m     direction \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Pearson score:\u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_value)\n",
      "File \u001b[0;32m~/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/drw-crypto-market-prediction/venv/lib/python3.9/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[26], line 19\u001b[0m, in \u001b[0;36mobjective_mlp_mlx\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     16\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m)])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Conduct training based on those parameters\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_eval_cv_mlx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_layers_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 21\u001b[0m, in \u001b[0;36mtrain_eval_cv_mlx\u001b[0;34m(num_features, hidden_layers_size, dropout, lr, cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optimmx\u001b[38;5;241m.\u001b[39mAdam(learning_rate \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtrain_mlp_mlx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_and_grad_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[1;32m     24\u001b[0m pearson \u001b[38;5;241m=\u001b[39m eval_mlp_mlx(model, X_test, Y_test, batch_size)\n",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m, in \u001b[0;36mtrain_mlp_mlx\u001b[0;34m(model, loss_and_grad_fn, optimizer, X_train, Y_train, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mupdate(model, grads)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Force a graph evaluation\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize_mlp_mlx(\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_30_with_less_interaction_study\",\n",
    "    f\"mlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{default_num_layers}_common_truncated_30_with_less_interaction_study\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6402c",
   "metadata": {},
   "source": [
    "#### Twelth Trial: AE-MLP but MLP step is concat of good features + AE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3694815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for batch iteration\n",
    "def batch_iterate_with_concat(batch_size, X, Y, X_good, shuffle = True):\n",
    "    for i in range(0, Y.size, batch_size):\n",
    "        X_curr = X[i: min(i + batch_size, Y.size), :]\n",
    "        Y_curr = Y[i: min(i + batch_size, Y.size)]\n",
    "        X_good_curr = X_good[i: min(i + batch_size, Y.size), :]\n",
    "        if shuffle:\n",
    "            inx_lst = mx.random.permutation(batch_size)\n",
    "            X_curr = X_curr[inx_lst, :]\n",
    "            Y_curr = Y_curr[inx_lst]\n",
    "            X_good_curr = X_good_curr[inx_lst, :]\n",
    "        yield X_curr, Y_curr, X_good_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate function for train & eval step\n",
    "def train_aemlp_mlx_with_concat(ae_model, ae_loss_and_grad_fn, ae_optimizer, ae_num_epochs,\n",
    "                                mlp_model, mlp_loss_and_grad_fn, mlp_optimizer, mlp_num_epochs,\n",
    "                                X_train, Y_train, X_train_good, batch_size):\n",
    "    # Train ae first\n",
    "    ae_model.train()\n",
    "    for _ in tqdm(range(ae_num_epochs)):\n",
    "        for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "            # get gradients for ae, output is the inputs itself\n",
    "            _, ae_grads = ae_loss_and_grad_fn(ae_model, inputs, inputs)\n",
    "\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            ae_optimizer.update(ae_model, ae_grads)\n",
    "\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(ae_model.parameters(), ae_optimizer.state)\n",
    "\n",
    "    # Train mlp later\n",
    "    mlp_model.train()\n",
    "    for _ in tqdm(range(mlp_num_epochs)):\n",
    "        for (inputs, targets, inputs_good) in batch_iterate_with_concat(batch_size, X_train, Y_train, X_train_good):\n",
    "            # get the latent representation for X_train\n",
    "            latent_inputs = ae_model.get_latent(inputs)\n",
    "            used_inputs = mx.concatenate([inputs_good, latent_inputs], axis=1)\n",
    "            # get gradients for mlp\n",
    "            _, mlp_grads = mlp_loss_and_grad_fn(mlp_model, used_inputs, targets)\n",
    "\n",
    "            # Update the optimizer state and model parameters in a single call\n",
    "            mlp_optimizer.update(mlp_model, mlp_grads)\n",
    "\n",
    "            # Force a graph evaluation\n",
    "            mx.eval(mlp_model.parameters(), mlp_optimizer.state)\n",
    "\n",
    "    # # Train ae and mlp together\n",
    "    # ae_model.train()\n",
    "    # mlp_model.train()\n",
    "    # for _ in tqdm(range(ae_num_epochs)):\n",
    "    #     for (inputs, targets) in batch_iterate(batch_size, X_train, Y_train):\n",
    "    #         # get gradients for ae, output is the inputs itself\n",
    "    #         _, ae_grads = ae_loss_and_grad_fn(ae_model, inputs, inputs)\n",
    "\n",
    "    #         # Update the optimizer state and model parameters in a single call\n",
    "    #         ae_optimizer.update(ae_model, ae_grads)\n",
    "\n",
    "    #         # Force a graph evaluation\n",
    "    #         mx.eval(ae_model.parameters(), ae_optimizer.state)\n",
    "\n",
    "    #         # get gradients for mlp\n",
    "    #         latent_inputs = ae_model.get_latent(inputs)\n",
    "    #         used_inputs = mx.concatenate([inputs, latent_inputs], axis=1)\n",
    "    #         _, mlp_grads = mlp_loss_and_grad_fn(mlp_model, used_inputs, targets)\n",
    "\n",
    "    #         # Update the optimizer state and model parameters in a single call\n",
    "    #         mlp_optimizer.update(mlp_model, mlp_grads)\n",
    "\n",
    "    #         # Force a graph evaluation\n",
    "    #         mx.eval(mlp_model.parameters(), mlp_optimizer.state)\n",
    "\n",
    "def eval_aemlp_mlx_with_concat(ae_model, mlp_model, X_test, Y_test, X_test_good, batch_size):\n",
    "    outputs_all = np.zeros(0)\n",
    "    targets_all = np.zeros(0)\n",
    "    ae_model.eval()\n",
    "    mlp_model.eval()\n",
    "    for (inputs, targets, inputs_good) in batch_iterate_with_concat(batch_size, X_test, Y_test, X_test_good, shuffle=False):\n",
    "        latent_inputs = ae_model.get_latent(inputs)\n",
    "        used_inputs = mx.concatenate([inputs_good, latent_inputs], axis=1)\n",
    "        outputs = mlp_model(used_inputs).reshape(-1)\n",
    "        # convert back to numpy\n",
    "        outputs, targets = np.array(outputs), np.array(targets)\n",
    "        # Load to overall Y_test, Y_pred to calculate pearson score later\n",
    "        outputs_all = np.concatenate([outputs_all, outputs])\n",
    "        targets_all = np.concatenate([targets_all, targets])\n",
    "    return pearson_score(targets_all, outputs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f133767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_cv_mlx_aemlp_with_concat(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout, ae_lr, ae_num_epochs,\n",
    "                                        mlp_hidden_layers_size, mlp_dropout, mlp_lr, mlp_num_epochs,\n",
    "                                        cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, \n",
    "                                        X_train_good_arr, X_test_good_arr, batch_size):\n",
    "    cv_pearson = 0\n",
    "    for _, (X_train, X_test, Y_train, Y_test, X_train_good, X_test_good) in enumerate(zip(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, X_train_good_arr, X_test_good_arr)):\n",
    "        # initialize the model\n",
    "        mx.random.seed(default_random_state)\n",
    "        ae_model = AEMLX(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout)\n",
    "\n",
    "        mx.random.seed(default_random_state)\n",
    "        mlp_model = MLPMLX(ae_latent_size + X_train_good.shape[1], mlp_hidden_layers_size, mlp_dropout)\n",
    "\n",
    "        # Initialize the loss function (both use same loss function)\n",
    "        def loss_fn(model, X, Y):\n",
    "            Y_pred = model(X).reshape(-1)\n",
    "            Y = Y.reshape(-1)\n",
    "            return mx.mean(nnmx.losses.mse_loss(Y_pred, Y))\n",
    "        ae_loss_and_grad_fn = nnmx.value_and_grad(ae_model, loss_fn)\n",
    "        mlp_loss_and_grad_fn = nnmx.value_and_grad(mlp_model, loss_fn)\n",
    "\n",
    "        # Reinitialize the optimizer\n",
    "        ae_optimizer = optimmx.Adam(learning_rate = ae_lr)\n",
    "        mlp_optimizer = optimmx.Adam(learning_rate = mlp_lr)\n",
    "\n",
    "        # Train the model\n",
    "        train_aemlp_mlx_with_concat(ae_model, ae_loss_and_grad_fn, ae_optimizer, ae_num_epochs,\n",
    "                                    mlp_model, mlp_loss_and_grad_fn, mlp_optimizer, mlp_num_epochs,\n",
    "                                    X_train, Y_train, X_train_good, batch_size)\n",
    "\n",
    "        # Test the model\n",
    "        pearson = eval_aemlp_mlx_with_concat(ae_model, mlp_model, X_test, Y_test, X_test_good, batch_size)\n",
    "        print(pearson)\n",
    "        if pearson == -1:\n",
    "            return pearson\n",
    "        cv_pearson += pearson\n",
    "    return cv_pearson / cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_aemlp_mlx_with_concat(trial):\n",
    "    # First initialize the parameters\n",
    "    num_features = len(best_features)\n",
    "\n",
    "    # initialize ae layers\n",
    "    ae_num_layers = ae_default_num_layers\n",
    "    ae_log_2_hidden_layers_size = []\n",
    "    for i in range(ae_num_layers):\n",
    "        if len(ae_log_2_hidden_layers_size) == 0:\n",
    "            ae_log_2_hidden_layers_size.append(trial.suggest_int(f\"ae_log2_hidden_layer_{i}\", 3, int(math.ceil(math.log2(num_features)))))\n",
    "        else:\n",
    "            ae_log_2_hidden_layers_size.append(trial.suggest_int(f\"ae_log2_hidden_layer_{i}\", 3, ae_log_2_hidden_layers_size[-1]))\n",
    "    ae_hidden_layers_size = [2**i for i in ae_log_2_hidden_layers_size]\n",
    "    ae_latent_size = 2**trial.suggest_int(\"ae_log2_latent_size\", 3, ae_log_2_hidden_layers_size[-1])\n",
    "    ae_dropout = trial.suggest_categorical(\"ae_dropout\", [0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "    ae_lr = trial.suggest_float(\"ae_lr\", 0.0001, 0.01, log=True)\n",
    "    ae_num_epochs = trial.suggest_categorical(\"num_epochs\", [10, 20, 30, 40, 50])\n",
    "\n",
    "    # initialize mlp layers\n",
    "    mlp_num_layers = mlp_default_num_layers\n",
    "    mlp_log_2_hidden_layers_size = []\n",
    "    for i in range(mlp_num_layers):\n",
    "        if len(mlp_log_2_hidden_layers_size) == 0:\n",
    "            mlp_log_2_hidden_layers_size.append(trial.suggest_int(f\"mlp_log2_hidden_layer_{i}\", 2, int(math.ceil(math.log2(ae_latent_size + num_features)))))\n",
    "        else:\n",
    "            mlp_log_2_hidden_layers_size.append(trial.suggest_int(f\"mlp_log2_hidden_layer_{i}\", 2, mlp_log_2_hidden_layers_size[-1]))\n",
    "    mlp_hidden_layers_size = [2**i for i in mlp_log_2_hidden_layers_size]\n",
    "    mlp_dropout = trial.suggest_categorical(\"mlp_dropout\", [0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "    mlp_lr = trial.suggest_float(\"mlp_lr\", 0.0001, 0.01, log=True)\n",
    "    # mlp_num_epochs = trial.suggest_categorical(\"mlp_num_epochs\", [10, 20, 30, 40, 50])\n",
    "    mlp_num_epochs = ae_num_epochs\n",
    "\n",
    "    # batch size\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [30, 60, 120, 180, 360, 720, 1440])\n",
    "    \n",
    "    # Conduct training based on those parameters\n",
    "    cv_pearson = train_eval_cv_mlx_aemlp_with_concat(num_features, ae_hidden_layers_size, ae_latent_size, ae_dropout, ae_lr, ae_num_epochs,\n",
    "                                                     mlp_hidden_layers_size, mlp_dropout, mlp_lr, mlp_num_epochs,\n",
    "                                                     default_cv, X_train_arr, X_test_arr, Y_train_arr, Y_test_arr,\n",
    "                                                     X_train_good_arr, X_test_good_arr, batch_size)\n",
    "    \n",
    "    return cv_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6860752",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = [col for col in train_df.columns if \"X\" in col and \"interaction\" not in col]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv(train_df, best_features)\n",
    "for i in range(default_cv):\n",
    "    X_train_arr[i] = float64_to_float32(X_train_arr[i])\n",
    "    X_test_arr[i] = float64_to_float32(X_test_arr[i])\n",
    "    Y_train_arr[i] = float64_to_float32(Y_train_arr[i])\n",
    "    Y_test_arr[i] = float64_to_float32(Y_test_arr[i])\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = normal_cv_to_mlx_cv(X_train_arr, X_test_arr, Y_train_arr, Y_test_arr)\n",
    "best_features_good = ['X757', 'X758', 'X759', 'X508', 'X614', 'X752', 'X331', 'X445', 'X465', 'X385', \n",
    "                      'X466', 'X95', 'X23', 'X219', 'X31', 'X373', 'X379', 'X284', 'X750', 'X652', \n",
    "                      'X279', 'X89', 'X169', 'X753', 'X226', 'X28', 'X444', 'X272', 'X271', 'X218']\n",
    "X_train_good_arr, X_test_good_arr, _, _ = create_cv(train_df, best_features_good)\n",
    "for i in range(default_cv):\n",
    "    X_train_good_arr[i] = float64_to_float32(X_train_good_arr[i])\n",
    "    X_test_good_arr[i] = float64_to_float32(X_test_good_arr[i])\n",
    "X_train_good_arr, X_test_good_arr, _, _ = normal_cv_to_mlx_cv(X_train_good_arr, X_test_good_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_default_num_layers = 2\n",
    "mlp_default_num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_aemlp_mlx(\n",
    "    f\"aemlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{ae_default_num_layers}_{mlp_default_num_layers}_with_good_concat_study\",\n",
    "    f\"aemlp_mlx_{feature_version}_{default_cv}_{default_random_state}_{ae_default_num_layers}_{mlp_default_num_layers}_with_good_concat_study\",\n",
    "    objective_function = objective_aemlp_mlx_with_concat\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
